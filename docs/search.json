[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science per psicologi",
    "section": "",
    "text": "Questo è il sito web per “Data Science per psicologi”. Viene qui presentato il materiale delle lezioni dell’insegnamento di Psicometria B000286 (A.A. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze. Lo scopo di questo insegnamento è quello di fornire agli studenti un’introduzione all’analisi dei dati psicologici. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data Science applicata alla psicologia, ovvero, un insieme di conoscenze/competenze che si pongono all’intersezione tra psicologia, statistica e informatica."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Data Science per psicologi",
    "section": "License",
    "text": "License\nThis book was created by Corrado Caudek and is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Prefazione",
    "section": "",
    "text": "Questo libro ti insegnerà i principi base della Data Science, con esempi pratici.\nSembra sensato spendere due parole su una domanda che è importante per gli studenti: perché dobbiamo perdere tanto tempo a studiare l’analisi dei dati psicologici quando in realtà quello che ci interessa è tutt’altro? Questa è una bella domanda. C’è una ragione molto semplice che dovrebbe farci capire perché la Data Science sia così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della Data Science in psicologia: perché la Data Science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici.\nSono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data Science? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data Science. Le tematiche della Data Science non possono essere ignorate né dai ricercatori in psicologia né da coloro che svolgono la professione di psicologo al di fuori dell’Università. Infatti, anche i professionisti al di fuori dall’università non possono fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po’ di Data Science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo.\nLe considerazioni precedenti cercano di chiarire il seguente punto: la Data Science non è qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data Science in tantissimi ambiti della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di Data Science è un tassello imprescindibile del bagaglio professionale dello psicologo. In questo insegnamento verrano trattati i temi base della Data Science e verrà adottato un punto di vista bayesiano, che corrisponde all’approccio più recente e sempre più diffuso in psicologia."
  },
  {
    "objectID": "preface.html#come-studiare",
    "href": "preface.html#come-studiare",
    "title": "Prefazione",
    "section": "Come studiare",
    "text": "Come studiare\nIl giusto metodo di studio per prepararsi all’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. Incoraggio gli studenti a farmi domande per chiarire ciò che non è stato capito appieno. Incoraggio gli studenti a utilizzare i forum attivi su Moodle e, soprattutto, a svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di comprendere se le competenze sviluppate fino a quel punto sono sufficienti rispetto alle richieste dell’esame.\nLa prima fase dello studio, che è sicuramente individuale, è quella in cui lo studente deve acquisire le conoscenze teoriche relative ai problemi che saranno presentati all’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta lo studente ad acquisire la capacità di applicare le conoscenze: è necessario capire come usare un software (\\(\\textsf{R}\\)) per applicare i concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono però separate: il saper fare molto spesso aiuta a capire meglio."
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "Parte 2: Il calcolo delle probabilità",
    "section": "",
    "text": "Nel capitolo ?sec-intro-prob-1 verrà presentata la legge dei grandi numeri, il concetto di variabile casuale e la funzione di massa di probabilità."
  },
  {
    "objectID": "020_expval_var.html",
    "href": "020_expval_var.html",
    "title": "1  Valore atteso e varianza",
    "section": "",
    "text": "Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità."
  },
  {
    "objectID": "020_expval_var.html#valore-atteso",
    "href": "020_expval_var.html#valore-atteso",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.1 Valore atteso",
    "text": "1.1 Valore atteso\nQuando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo “valore tipico”. La nozione di “valore tipico”, tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi:\n\nla media (somma dei valori divisa per il numero dei valori),\nla mediana (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente),\nla moda (il valore che ricorre più spesso).\n\nPer esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) è \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana è \\(3\\) e la moda è \\(1\\). Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per “valore tipico” quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione. \n\nDefinizione 1.1 Sia \\(Y\\) è una variabile casuale discreta che assume i valori \\(y_1, \\dots, y_n\\) con distribuzione \\(P(Y = y_i) = p(y_i)\\). Per definizione il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), è\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^n y_i \\cdot p(y_i).\n\\tag{1.1}\\]\n\nA parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.\n\nEsercizio 1.1 \nSi calcoli il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0).\n\n\nSoluzione. Abbiamo\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5.\n\\]\n\n\nEsercizio 1.2 \nSi calcoli il valore atteso della variabile casuale \\(Y\\) corrispondente ai punti ottenuti dal lancio di un dado equilibrato.\n\n\nSoluzione. Il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{6} y_i \\cdot P(y_i) = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + \\dots + 6 \\cdot \\frac{1}{6} = \\frac{21}{6} = 3.5.\n\\]\n\n\n1.1.1 Interpretazione\nChe interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di previsione (e lo stesso simbolo) tanto per la probabilità che per la speranza matematica. Si può pertanto dire che, dal punto di vista bayesiano, la speranza matematica è l’estensione naturale della nozione di probabilità soggettiva.\n\n1.1.2 Proprietà del valore atteso\nLa proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{1.2}\\]\nL’Equazione 1.2 sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma è anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{1.3}\\]\nL’Equazione 1.3 ci dice che possiamo estrarre una costante dall’operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che\n\\[\n\\mathbb{E}(X Y) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{1.4}\\]\n\nEsercizio 1.3 \nSi considerino le seguenti variabili casuali: \\(Y\\), ovvero il numero che si ottiene dal lancio di un dado equilibrato, e \\(Y\\), il numero di teste prodotto dal lancio di una moneta equilibrata. Si trovi il valore atteso di \\(X+Y\\).\n\n\nSoluzione. Per risolvere il problema iniziamo a costruire lo spazio campionario dell’esperimento casuale consistente nel lancio di un dado e di una moneta.\n\n\n\n\n\n\n\n\n\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) è dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nLo stesso risultato si ottiene nel modo seguente:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsercizio 1.4 \nSi considerino le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali \\(X\\) e \\(Y\\).\n\n\nSoluzione. La distribuzione di probabilità congiunta \\(P(X, Y)\\) è fornita nella tabella seguente.\n\n\n\\(x \\textbackslash y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(XY) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare la proprietà del ?thm-prodindrv. Infatti, il valore atteso di \\(X\\) è\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerciò\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n1.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa:\n\\[\n\\mathbb{E}(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname {d}\\!y.\n\\tag{1.5}\\]\nAnche in questo caso il valore atteso è una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) è ponderato per il corrispondente valore della densità \\(p(y)\\). Possiamo leggere l’integrale pensando che \\(y\\) rappresenti l’ampiezza delle barre infinitamente strette di un istogramma, con la densità \\(p(y)\\) che corrisponde all’altezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma.\nUn’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda della \\(Y\\) individua il valore \\(y\\) più plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densità \\(p(y)\\):\n\\[\n\\mbox{Mo}(Y) = \\mbox{argmax}_y p(y).\n\\tag{1.6}\\]"
  },
  {
    "objectID": "020_expval_var.html#varianza",
    "href": "020_expval_var.html#varianza",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.2 Varianza",
    "text": "1.2 Varianza\nLa seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la varianza.\n\nDefinizione 1.2 Se \\(Y\\) è una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), è\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big].\n\\tag{1.7}\\]\n\nA parole: la varianza è la deviazione media quadratica della variabile dalla sua media.1 Se denotiamo \\(\\mathbb{E}(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\).\n\nEsercizio 1.5 \nPosta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\n\n\nSoluzione. La variabile casuale \\(S\\) ha la seguente distribuzione di probabilità:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(S- \\mathbb{E}(S)\\right)^2 \\cdot P(S) \\notag\\\\\n&= (2 - 7)^2 \\cdot 0.0278 + (3-7)^2 \\cdot 0.0556 + \\dots + (12 - 7)^2 \\cdot 0.0278 \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\n1.2.1 Formula alternativa per la varianza\nC’è un modo più semplice per calcolare la varianza:\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big] &= \\mathbb{E}\\big(Y^2 - 2Y\\mathbb{E}(Y) + \\mathbb{E}(Y)^2\\big)\\notag\\\\\n&= \\mathbb{E}(Y^2) - 2\\mathbb{E}(Y)\\mathbb{E}(Y) + \\mathbb{E}(Y)^2,\n\\end{align}\n\\]\ndato che \\(\\mathbb{E}(Y)\\) è una costante. Pertanto\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2.\n\\tag{1.8}\\]\nA parole: la varianza è la media dei quadrati meno il quadrato della media.\n\nEsercizio 1.6 \nConsideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\n\n\nSoluzione. Il valore atteso di \\(Y\\) è\n\\[\n\\mathbb{E}(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) è\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\n1.2.2 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\), la varianza diventa:\n\\[\n\\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\mathbb{E}(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y.\n\\tag{1.9}\\]\nCome nel caso discreto, la varianza di una v.c. continua \\(Y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(Y\\) dalla loro media."
  },
  {
    "objectID": "020_expval_var.html#deviazione-standard",
    "href": "020_expval_var.html#deviazione-standard",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.3 Deviazione standard",
    "text": "1.3 Deviazione standard\nQuando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell’unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente è denotato dalla lettera greca \\(\\sigma\\).\n\nDefinizione 1.3 Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:\n\\[\n\\sigma_Y = \\sqrt{\\mathbb{V}(Y)}.\n\\tag{1.10}\\]\n\nInterpretiamo la deviazione standard di una variabile casuale come nella statistica descrittiva: misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media.\n\nEsercizio 1.7 \nPer i dadi equilibrati dell’Esercizio 1.5, la deviazione standard della variabile casuale \\(S\\) è uguale a \\(\\sqrt{5.833} = 2.415\\)."
  },
  {
    "objectID": "020_expval_var.html#standardizzazione",
    "href": "020_expval_var.html#standardizzazione",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.4 Standardizzazione",
    "text": "1.4 Standardizzazione\n\nDefinizione 1.4 Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l’espressione\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}.\n\\tag{1.11}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\)."
  },
  {
    "objectID": "020_expval_var.html#momenti-di-variabili-casuali",
    "href": "020_expval_var.html#momenti-di-variabili-casuali",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.5 Momenti di variabili casuali",
    "text": "1.5 Momenti di variabili casuali\n\nSi chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densità \\(p(x)\\), la quantità\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{1.12}\\]\nSe \\(X\\) è una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i).\n\\tag{1.13}\\]\n\nI momenti sono importanti parametri indicatori di certe proprietà di \\(X\\). I più noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x − \\mathbb{E}(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza."
  },
  {
    "objectID": "020_expval_var.html#covarianza",
    "href": "020_expval_var.html#covarianza",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.6 Covarianza",
    "text": "1.6 Covarianza\nLa covarianza quantifica la tendenza delle variabili aleatorie \\(X\\) e \\(Y\\) a “variare assieme”. Per esempio, l’altezza e il peso delle giraffe producono una covarianza positiva perché all’aumentare di una di queste due quantità tende ad aumentare anche l’altra. La covarianza misura la forza e la direzione del legame lineare tra due variabili aleatorie \\(X\\) ed \\(Y\\). Si utilizza la notazione \\(\\mbox{Cov}(X,Y)=\\sigma_{xy}\\).\n\nDefinizione 1.5 Date due variabili aleatorie \\(X\\), \\(Y\\), chiamiamo covarianza tra \\(X\\) ed \\(Y\\) il numero\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}\\Bigl(\\bigl(X - \\mathbb{E}(X)\\bigr) \\bigl(Y - \\mathbb{E}(Y)\\bigr)\\Bigr),\n\\tag{1.14}\\]\ndove \\(\\mathbb{E}(X)\\) e \\(\\mathbb{E}(Y)\\) sono i valori attesi di \\(X\\) ed \\(Y\\).\n\nIn maniera esplicita,\n\\[\n\\mbox{Cov}(X,Y) = \\sum_{(x,y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y).\n\\tag{1.15}\\]\nLa definizione è analoga, algebricamente, a quella di varianza e risulta infatti\n\\[\n\\mathbb{V}(x) = \\mbox{Cov}(X, X)\n\\]\ne\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X).\n\\tag{1.16}\\]\n\nDimostrazione. L’Equazione 1.16 si ricava nel modo seguente:\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}\\Bigl(\\bigl(X-\\mathbb{E}(X)\\bigr) \\bigl(Y-\\mathbb{E}(Y)\\bigr)\\Bigr)\\notag\\\\\n          %&= \\mathbb{E}(XY) - \\mathbb{E}(Y)X -\\mathbb{E}(X)Y + \\mathbb{E}(X)\\mathbb{E}(Y) )\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X) - \\mathbb{E}(X)\\mathbb{E}(Y) + \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X)\\notag.\n\\end{align}\n\\]\n\n\nEsercizio 1.8 \nConsideriamo le variabili casuali definite nell’Esercizio 2.4. Si calcoli la covarianza di \\(X\\) e \\(Y\\).\n\n\nSoluzione. Abbiamo che \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). Ne segue che la covarianza di \\(X\\) e \\(Y\\) è:\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\sum_{(x,y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y)notag\\\\\n&= (0-1.5)(0-0.5)\\cdot \\frac{1}{8} + (0-1.5)(1-0.5) \\cdot 0 \\\\\n   &\\qquad + (1-1.5)(0-0.5)\\cdot \\frac{2}{8} + (1-1.5)(1-0.5) \\cdot \\frac{1}{8} \\notag\\\\\n    &\\qquad+ (2-1.5)(0-0.5) \\cdot \\frac{1}{8} + (2-1.5)(1-0.5) \\cdot \\frac{2}{8} \\\\\n   &\\qquad+ (3-1.5)(0-0.5) \\cdot 0 +  (3-1.5)(1-0.5)\\cdot\\frac{1}{8} \\notag\\\\\n   &= \\frac{1}{4}. \\notag\n\\end{align}\n\\]\nLo stesso risultato può essere trovato nel modo seguente. Iniziamo a calcolare il valore atteso del prodotto \\(XY\\):\n\\[\n\\mathbb{E}(XY) = 0 \\cdot\\frac{4}{8} + 1 \\cdot\\frac{1}{8} + 2 \\cdot\\frac{2}{8} + 3 \\cdot\\frac{1}{8} = 1.0.\n\\]\nDunque, la covarianza tra \\(X\\) e \\(Y\\) diventa\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n&= 1 -  1.5\\cdot 0.5 \\notag\\\\\n&= 0.25.\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "020_expval_var.html#correlazione",
    "href": "020_expval_var.html#correlazione",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.7 Correlazione",
    "text": "1.7 Correlazione\nLa covarianza dipende dall’unità di misura delle due variabili e quindi non consente di stabilire l’intensità della relazione. Una misura standardizzata della relazione che intercorre fra due variabili è invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie.\n\nIl coefficiente di correlazione tra \\(X\\) ed \\(Y\\) è il numero definito da\n\\[\n\\rho(X,Y) =\\frac{\\mbox{Cov}(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}}.\n\\tag{1.17}\\]\n\nSi può anche scrivere \\(\\rho_{X,Y}\\) al posto di \\(\\rho(X,Y)\\).\nIl coefficiente di correlazione \\(\\rho_{xy}\\) è un numero puro, cioè non dipende dall’unità di misura delle variabili, e assume valori compresi tra -1 e +1."
  },
  {
    "objectID": "020_expval_var.html#proprietà",
    "href": "020_expval_var.html#proprietà",
    "title": "1  Valore atteso e varianza",
    "section": "\n1.8 Proprietà",
    "text": "1.8 Proprietà\n\nLa covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) è nulla: \\(\\mbox{Cov}(c,X) = 0;\\)\nla covarianza è simmetrica: \\(\\mbox{Cov}(X,Y) = \\mbox{Cov}(Y,X);\\)\nvale \\(-1 \\leq \\rho(X,Y) \\leq 1;\\)\nla correlazione non dipende dall’unità di misura: \\(\\rho(aX, bY) = \\rho(X,Y), \\qquad \\forall a, b > 0;\\)\nse \\(Y = a + bX\\) è una funzione lineare di \\(X\\) con costanti \\(a\\) e \\(b\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\);\nla covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, è uguale al prodotto delle costanti per la covarianza tra \\(X\\) e \\(Y\\): \\(\\mbox{Cov}(aX,bY) = ab \\;\\mbox{Cov}(X,Y), \\qquad \\forall a,b \\in\\);\nvale \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2 \\cdot \\mbox{Cov}(X,Y)\\);\nvale \\(\\mbox{Cov}(X + Y, Z) = \\mbox{Cov}(X,Z) + \\mbox{Cov}(Y,Z);\\)\nper una sequenza di variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}\\left( \\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i,j: i<j}cov(X_i, X_j);\\)\nvale \\(\\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_jY_j\\right) = \\sum_{i=1}^n \\sum_{j=1}^m a_j b_j\\mbox{Cov}(X_j, Y_j);\\)\nse \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(\\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_jX_j\\right) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i).\\)\n\n\n1.8.1 Incorrelazione\n\nDefinizione 1.6 Si dice che \\(X\\) ed \\(Y\\) sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla,\n\\[\n\\sigma_{XY} = \\mathbb{E} \\big[(X - \\mu_X) (y-\\mu_u) \\big] = 0,\n\\tag{1.18}\\]\nche si può anche scrivere come\n\\[\n\\rho_{XY} = 0, \\quad \\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\]\n\nSi introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se \\(\\mbox{Cov}(X, Y) = 0\\), non è detto che \\(X\\) ed \\(Y\\) siano indipendenti.\n\nEsercizio 1.9 Siano \\(X\\) e \\(Y\\) due variabili aleatorie discrete avente una distribuzione di massa di probabilità congiunta pari a\n\\[\nf_{XY}(x,y) = \\frac{1}{4} \\quad (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}\n\\]\ne zero altrimenti. Le due variabili aleatorie \\(X\\) e \\(Y\\) sono mutuamente indipendenti?\n\n\nSoluzione. La distribuzione marginale della \\(X\\) è\n\\[\n\\begin{cases}\nX = 0, \\quad  P_X = 1/4, \\\\\nX = 1, \\quad P_X = 2/4, \\\\\nX = 2, \\quad P_X = 1/4.\n\\end{cases}\n\\]\n\\[\n\\mathbb{E}(X) = 0 \\frac{1}{4} + 1 \\frac{2}{4} + 2 \\frac{1}{4} = 1.\n\\]\n\\[\n\\mathbb{E}(X^2) = 0^2 \\frac{1}{4} + 1^2 \\frac{2}{4} + 2^2 \\frac{1}{4} = \\frac{3}{2}.\n\\]\n\\[\n\\mathbb{V}(X) = \\frac{3}{2} - 1^2 = \\frac{1}{2}.\n\\]\nLa distribuzione marginale della \\(Y\\) è\n\\[\n\\begin{cases}\nY = -1, \\quad  P_Y = 1/4, \\\\\nY = 0, \\quad P_Y = 2/4, \\\\\nY = 1, \\quad P_Y = 1/4.\n\\end{cases}\n\\]\n\\[\n\\mathbb{E}(Y) = 0 \\frac{2}{4} + 1 \\frac{1}{4} + (-1) \\frac{1}{4} = 0.\n\\]\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\frac{2}{4} + 1^2 \\frac{1}{4} + (-1)^2 \\frac{1}{4} = \\frac{1}{2}.\n\\]\n\\[\n\\mathbb{V}(X) = \\frac{1}{2} - 0^2 = \\frac{1}{2}.\n\\]\nCalcoliamo ora la covarianza tra \\(X\\) e \\(Y\\):\n\\[\n\\mathbb{E}(XY) = \\sum_x\\sum_y xy f_{XY} (x,y) =\n(0\\cdot 0)\\frac{1}{4} +\n(1\\cdot 1)\\frac{1}{4} +\n(1\\cdot -1)\\frac{1}{4} +\n(2\\cdot 0)\\frac{1}{4} = 0.\n\\]\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y) = 0 - 1\\cdot0 = 0.\n\\]\nQuindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non sono indipendenti, in quanto non è vero che\n\\[\nf_{XY} (x,y) = f_X(x) f_Y(y)\n\\]\nper tutti gli \\(x\\) e \\(y\\).\n\nIn conclusione, anche se condizione di indipendenza implica una covarianza nulla, l’esempio precedente mostra come l’inverso non sia necessariamente vero: la covarianza può essere zero anche quando le due variabili aleatorie non sono indipendenti."
  },
  {
    "objectID": "020_expval_var.html#conclusioni",
    "href": "020_expval_var.html#conclusioni",
    "title": "1  Valore atteso e varianza",
    "section": "Conclusioni",
    "text": "Conclusioni\nLa densità di probabilità congiunta bivariata tiene simultaneamente conto del comportamento di due variabili aleatorie \\(X\\) e \\(Y\\) e di come esse si influenzino. Se \\(X\\) e \\(Y\\) sono legate linearmente, allora il coefficiente di correlazione\n\\[\\begin{equation}\n\\rho = \\frac{\\mbox{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\\notag\n\\end{equation}\\]\nfornisce l’indice maggiormente utilizzato per descrivere l’intensità e il segno dell’associazione lineare. Nel caso di un’associazione lineare perfetta, \\(Y = a + bX\\), avremo \\(\\rho = 1\\) con \\(b\\) positivo ed \\(\\rho = -1\\) con \\(b\\) negativo. Se il coefficiente di correlazione è pari a 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinché \\(\\rho = 0\\) è che le due variabili siano tra loro indipendenti."
  }
]