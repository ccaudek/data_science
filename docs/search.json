[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science per psicologi",
    "section": "",
    "text": "üá∫üá¶"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Data Science per psicologi",
    "section": "License",
    "text": "License\nThis book was created by Corrado Caudek and is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Prefazione",
    "section": "",
    "text": "Questo libro ti insegner√† i principi base della Data Science, con esempi pratici.\nSembra sensato spendere due parole su una domanda che √® importante per gli studenti: perch√© dobbiamo perdere tanto tempo a studiare l‚Äôanalisi dei dati psicologici quando in realt√† quello che ci interessa √® tutt‚Äôaltro? Questa √® una bella domanda. C‚Äô√® una ragione molto semplice che dovrebbe farci capire perch√© la Data Science sia cos√¨ importante per la psicologia. Infatti, a ben pensarci, la psicologia √® una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed √® proprio la variabilit√† inter- e intra-individuale ci√≤ che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia √® molto diversa dall‚Äôingegneria, per esempio. Le propriet√† di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica √® poco importante: le propriet√† dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non pu√≤ dirsi degli individui: ogni individuo √® unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l‚Äôoggetto di studio proprio della psicologia: √® dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa √® la ragione per cui abbiamo tanto bisogno della Data Science in psicologia: perch√© la Data Science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici.\nSono sicuro che, leggendo queste righe, a molti studenti sar√† venuta in mente la seguente domanda: perch√© non chiediamo a qualche esperto di fare il ‚Äúlavoro sporco‚Äù (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ci√≤ che ci interessa, ovvero dei problemi psicologici slegati dai dettagli ‚Äútecnici‚Äù della Data Science? La risposta a questa domanda √® che non √® possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data Science. Le tematiche della Data Science non possono essere ignorate n√© dai ricercatori in psicologia n√© da coloro che svolgono la professione di psicologo al di fuori dell‚ÄôUniversit√†. Infatti, anche i professionisti al di fuori dall‚Äôuniversit√† non possono fare a meno di leggere la letteratura psicologica pi√π recente: il continuo aggiornamento delle conoscenze √® infatti richiesto dalla deontologia della professione. Ma per potere fare questo √® necessario conoscere un bel po‚Äô di Data Science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ci√≤ sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo.\nLe considerazioni precedenti cercano di chiarire il seguente punto: la Data Science non √® qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data Science in tantissimi ambiti della loro attivit√† professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. √à dunque chiaro che possedere delle solide basi di Data Science √® un tassello imprescindibile del bagaglio professionale dello psicologo. In questo insegnamento verrano trattati i temi base della Data Science e verr√† adottato un punto di vista bayesiano, che corrisponde all‚Äôapproccio pi√π recente e sempre pi√π diffuso in psicologia."
  },
  {
    "objectID": "preface.html#come-studiare",
    "href": "preface.html#come-studiare",
    "title": "Prefazione",
    "section": "Come studiare",
    "text": "Come studiare\nIl giusto metodo di studio per prepararsi all‚Äôesame di Psicometria √® quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. Incoraggio gli studenti a farmi domande per chiarire ci√≤ che non √® stato capito appieno. Incoraggio gli studenti a utilizzare i forum attivi su Moodle e, soprattutto, a svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano il livello di difficolt√† richiesto per superare l‚Äôesame e consentono allo studente di comprendere se le competenze sviluppate fino a quel punto sono sufficienti rispetto alle richieste dell‚Äôesame.\nLa prima fase dello studio, che √® sicuramente individuale, √® quella in cui lo studente deve acquisire le conoscenze teoriche relative ai problemi che saranno presentati all‚Äôesame. La seconda fase di studio, che pu√≤ essere facilitata da scambi con altri e da incontri di gruppo, porta lo studente ad acquisire la capacit√† di applicare le conoscenze: √® necessario capire come usare un software (\\(\\textsf{R}\\)) per applicare i concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono per√≤ separate: il saper fare molto spesso aiuta a capire meglio."
  },
  {
    "objectID": "basics.html",
    "href": "basics.html",
    "title": "Parte 1: Nozioni di base",
    "section": "",
    "text": "In questa prima parte affronteremo i temi della misurazione e delll‚Äôanalisi descrittiva dei dati. Nel capitolo Capitolo¬†1 verranno presentati i concetti chiave della Data Science. Nel capitolo Capitolo¬†2 sar√† affrontato il tema della misurazione. Nel capitolo Capitolo¬†3 verranno introdotti i concetti che vengono utilizzati per descrivere le distribuzioni dei dati. Verranno poi introdotti gli indici di tendenza centrale e di dispersione nel capitolo Capitolo¬†4. Infine, nel capitolo Capitolo¬†5 verr√† affrontato il problema di descrivere le relazioni tra variabili.\nPrima di affrontare tali temi sar√† necessario introdurre il linguaggio di programmazione statistica R (un‚Äôintroduzione a R √® fornita in Appendice)."
  },
  {
    "objectID": "001_key_notions.html",
    "href": "001_key_notions.html",
    "title": "1¬† Concetti chiave",
    "section": "",
    "text": "La data science si pone all‚Äôintersezione tra statistica e informatica. La statistica √® un insieme di metodi utilizzati per estrarre informazioni dai dati; l‚Äôinformatica implementa tali procedure in un software. In questo Capitolo vengono introdotti i concetti fondamentali."
  },
  {
    "objectID": "001_key_notions.html#popolazioni-e-campioni",
    "href": "001_key_notions.html#popolazioni-e-campioni",
    "title": "1¬† Concetti chiave",
    "section": "1.1 Popolazioni e campioni",
    "text": "1.1 Popolazioni e campioni\nPopolazione. L‚Äôanalisi dei dati inizia con l‚Äôindividuazione delle unit√† portatrici di informazioni circa il fenomeno di interesse. Si dice popolazione (o universo) l‚Äôinsieme \\(\\Omega\\) delle entit√† capaci di fornire informazioni sul fenomeno oggetto dell‚Äôindagine statistica. Possiamo scrivere \\(\\Omega = \\{\\omega_i\\}_{i=1, \\dots, n}= \\{\\omega_1, \\omega_2, \\dots, \\omega_n\\}\\), oppure \\(\\Omega = \\{\\omega_1, \\omega_2, \\dots \\}\\) nel caso di popolazioni finite o infinite, rispettivamente. Gli elementi \\(\\omega_i\\) dell‚Äôinsieme \\(\\Omega\\) sono detti unit√† statistiche.\nL‚Äôobiettivo principale della ricerca psicologica √® conoscere gli esiti psicologici e i loro fattori trainanti nella popolazione. Questo √® l‚Äôobiettivo delle sperimentazioni psicologiche e della maggior parte degli studi osservazionali in psicologia. √à quindi necessario essere molto chiari sulla popolazione a cui si applicano i risultati della ricerca. La popolazione pu√≤ essere ben definita, ad esempio, tutte le persone che si trovavano nella citt√† di Hiroshima al momento del bombardamento atomico e sono sopravvissute per un anno, o pu√≤ essere ipotetica, ad esempio, tutte le persone depresse che hanno subito o saranno sottoposte ad un intervento psicologico. Il ricercatore deve sempre essere in grado di determinare se un soggetto appartiene o meno alla popolazione oggetto di interesse.\nUna sotto-popolazione √® una popolazione che soddisfa propriet√† ben definite. Ad esempio, potremmo essere interessati alla sotto-popolazione di uomini di et√† inferiore ai 20 anni o alla sotto-popolazione di pazienti depressi sottoposti ad uno specifico intervento psicologico. Molte domande scientifiche riguardano le differenze tra sotto-popolazioni; ad esempio, il confronto tra un gruppo sottoposto a psicoterapia e un gruppo di controllo per determinare se il trattamento √® stato efficace.\nCampione. Un sottoinsieme della popolazione, ovvero un insieme di elementi \\(\\omega_i\\), viene chiamato campione. Ciascuna unit√† statistica \\(\\omega_i\\) (abbreviata con u.s.) √® portatrice dell‚Äôinformazione che verr√† rilevata mediante un‚Äôoperazione di misurazione.\nUn campione √® dunque un sottoinsieme della popolazione utilizzato per conoscere tale popolazione. A differenza di una sotto-popolazione definita in base a chiari criteri, un campione viene generalmente selezionato tramite un procedura casuale. Il campionamento casuale consente allo scienziato di trarre conclusioni sulla popolazione e, soprattutto, di quantificare l‚Äôincertezza sui risultati. I campioni di un sondaggio sono esempi di campioni casuali, ma molti studi osservazionali non sono campionati casualmente. Possono essere campioni di convenienza, come coorti di studenti in un unico istituto, che consistono di tutti gli studenti sottoposti ad un certo intervento psicologico in quell‚Äôistituto. Indipendentemente da come vengono ottenuti i campioni, il loro uso al fine di conoscere una popolazione target significa che i problemi di rappresentativit√† sono inevitabili e devono essere affrontati."
  },
  {
    "objectID": "001_key_notions.html#variabili-e-costanti",
    "href": "001_key_notions.html#variabili-e-costanti",
    "title": "1¬† Concetti chiave",
    "section": "1.2 Variabili e costanti",
    "text": "1.2 Variabili e costanti\nUna variabile √® qualsiasi propriet√† o descrittore che pu√≤ assumere pi√π valori (numerici o categoriali). Una variabile pu√≤ essere pensata come la domanda di cui il valore dell‚Äôu.s. √® la risposta. Ad esempio, ‚ÄúQual √® l‚Äôet√† di questo partecipante?‚Äù ‚Äú19 anni‚Äù. Qui, ‚Äúet√†‚Äù √® la variabile e ‚Äú38‚Äù √® il suo valore.\nLa probabilit√† che la variabile \\(X\\) assuma valore \\(x\\) si scrive \\(P(X = x)\\). Questo √® spesso abbreviato in \\(P(x)\\). Possiamo anche esaminare la probabilit√† di pi√π valori contemporaneamente; per esempio, la probabilit√† che \\(X = x\\) e \\(Y = y\\) √® scritta \\(P(X = x, Y = y)\\) o \\(P(x, y)\\). Si noti che \\(P(X = 19)\\) √® interpretato come la probabilit√† che un individuo selezionato casualmente dalla popolazione abbia 19 anni. Il termine ‚Äúvariabile‚Äù si contrappone al termine ‚Äúcostante‚Äù che descrive una propriet√† invariante di tutte le unit√† statistiche.\nSi dice modalit√† ciascuna delle varianti con cui una variabile statistica pu√≤ presentarsi. Definiamo insieme delle modalit√† di una variabile statistica l‚Äôinsieme \\(M\\) di tutte le possibili espressioni con cui la variabile pu√≤ manifestarsi. Le modalit√† osservate e facenti parte del campione si chiamano dati.\n\nSupponiamo che il fenomeno studiato sia l‚Äôintelligenza. In uno studio, la popolazione potrebbe corrispondere all‚Äôinsieme di tutti gli italiani adulti. La variabile considerata potrebbe essere il punteggio del test standardizzato WAIS-IV. Le modalit√† di tale variabile potrebbero essere 112, 92, 121, ‚Ä¶ Tale variabile √® di tipo quantitativo discreto.\n\n\nSupponiamo che il fenomeno studiato sia il compito Stroop. La popolazione potrebbe corrispondere all‚Äôinsieme dei bambini dai 6 agli 8 anni. La variabile considerata potrebbe essere il reciproco dei tempi di reazione in secondi. Le modalit√† di tale variabile potrebbero essere 1.93, 2.35, 1.32, 1.49, 1.62, 2.93, ‚Ä¶ La variabile √® di tipo quantitativo continuo.\n\n\nSupponiamo che il fenomeno studiato sia il disturbo di personalit√†. La popolazione potrebbe corrispondere all‚Äôinsieme dei detenuti nelle carceri italiane. La variabile considerata potrebbe essere l‚Äôassessment del disturbo di personalit√† tramite interviste cliniche strutturate. Le modalit√† di tale variabile potrebbero essere i Cluster A, Cluster B, Cluster C descritti dal DSM-V. Tale variabile √® di tipo qualitativo.\n\n\n1.2.1 Variabili casuali\nIl termine variabile usato nella statistica √® equivalente al termine variabile casuale usato nella teoria delle probabilit√†. Lo studio dei risultati degli interventi psicologici √® lo studio delle variabili casuali che misurano questi risultati. Una variabile casuale cattura una caratteristica specifica degli individui nella popolazione e i suoi valori variano tipicamente tra gli individui. Ogni variabile casuale pu√≤ assumere in teoria una gamma di valori sebbene, in pratica, osserviamo un valore specifico per ogni individuo. Useremo lettere maiuscole come \\(X\\) e \\(Y\\) per fare riferiremo alle variabili casuali considerate in termini generali; useremo lettere minuscole come \\(x\\) e \\(y\\) quando faremo riferimento ai valori assunti da una variabile casuale in una specifica circostanza.\n\n\n1.2.2 Variabili indipendenti e variabili dipendenti\nUn primo compito fondamentale in qualsiasi analisi dei dati √® l‚Äôidentificazione delle variabili dipendenti (\\(Y\\)) e delle variabili indipendenti (\\(X\\)). Le variabili dipendenti sono anche chiamate variabili di esito o di risposta e le variabili indipendenti sono anche chiamate predittori o covariate. Ad esempio, nell‚Äôanalisi di regressione, che esamineremo in seguito, la domanda centrale √® quella di capire come \\(Y\\) cambia al variare di \\(X\\). Pi√π precisamente, la domanda che viene posta √®: se il valore della variabile indipendente \\(X\\) cambia, qual √® la conseguenza per la variabile dipendente \\(Y\\)? In parole povere, le variabili indipendenti e dipendenti sono analoghe a ‚Äúcause‚Äù ed ‚Äúeffetti‚Äù, laddove le virgolette usate qui sottolineano che questa √® solo un‚Äôanalogia e che la determinazione delle cause pu√≤ avvenire soltanto mediante l‚Äôutilizzo di un appropriato disegno sperimentale e di un‚Äôadeguata analisi statistica.\nSe una variabile √® una variabile indipendente o dipendente dipende dalla domanda di ricerca. A volte pu√≤ essere difficile distinguere le variabili dipendenti dalle variabili indipendenti, in particolare quando siamo specificamente interessati ai rapporti di causa/effetto. Ad esempio, supponiamo di indagare l‚Äôassociazione tra esercizio fisico e insonnia. Vi sono evidenze che l‚Äôesercizio fisico (fatto al momento giusto della giornata) pu√≤ ridurre l‚Äôinsonnia. Ma l‚Äôinsonnia pu√≤ anche ridurre la capacit√† di una persona di fare esercizio fisico. Non √® dunque facile capire quale sia la causa e quale sia l‚Äôeffetto, ovvero quale sia la variabile dipendente e quale la variabile indipendente. La possibilit√† di identificare il ruolo delle variabili (dipendente/indipendente) dipende dalla nostra comprensione del fenomeno in esame.\n\nUno psicologo convoca 120 studenti universitari per un test di memoria. Prima di iniziare l‚Äôesperimento, a met√† dei soggetti viene detto che si tratta di un compito particolarmente difficile; agli altri soggetti non viene data alcuna indicazione. Lo psicologo misura il punteggio nella prova di memoria di ciascun soggetto.\nIn questo esperimento, la variabile indipendente √® l‚Äôinformazione sulla difficolt√† della prova. La variabile indipendente viene manipolata dallo sperimentatore assegnando i soggetti (di solito in maniera causale) o alla condizione (modalit√†) ‚Äúinformazione assegnata‚Äù o ‚Äúinformazione non data‚Äù. La variabile dipendente √® ci√≤ che viene misurato nell‚Äôesperimento, ovvero il punteggio nella prova di memoria di ciascun soggetto.\n\n\n\n1.2.3 La matrice dei dati\nLe realizzazioni delle variabili esaminate in una rilevazione statistica vengono organizzate in una matrice dei dati. Le colonne della matrice dei dati contengono gli insiemi dei dati individuali di ciascuna variabile statistica considerata. Ogni riga della matrice contiene tutte le informazioni relative alla stessa unit√† statistica. Una generica matrice dei dati ha l‚Äôaspetto seguente:\n\\[\nD_{m,n} =\n\\begin{pmatrix}\n  \\omega_1 & a_{1}   & b_{1}   & \\cdots & x_{1} & y_{1}\\\\\n  \\omega_2 & a_{2}   & b_{2}   & \\cdots & x_{2} & y_{2}\\\\\n  \\vdots   & \\vdots  & \\vdots  & \\ddots & \\vdots & \\vdots  \\\\\n\\omega_n  & a_{n}   & b_{n}   & \\cdots & x_{n} & y_{n}\n\\end{pmatrix}\n\\]\ndove, nel caso presente, la prima colonna contiene il nome delle unit√† statistiche, la seconda e la terza colonna si riferiscono a due mutabili statistiche (variabili categoriali; \\(A\\) e \\(B\\)) e ne presentano le modalit√† osservate nel campione mentre le ultime due colonne si riferiscono a due variabili statistiche (\\(X\\) e \\(Y\\)) e ne presentano le modalit√† osservate nel campione. Generalmente, tra le unit√† statistiche \\(\\omega_i\\) non esiste un ordine progressivo; l‚Äôindice attribuito alle unit√† statistiche nella matrice dei dati si riferisce semplicemente alla riga che esse occupano."
  },
  {
    "objectID": "001_key_notions.html#parametri-e-modelli",
    "href": "001_key_notions.html#parametri-e-modelli",
    "title": "1¬† Concetti chiave",
    "section": "1.3 Parametri e modelli",
    "text": "1.3 Parametri e modelli\nOgni variabile casuale ha una distribuzione che descrive la probabilit√† che la variabile assuma qualsiasi valore in un dato intervallo.1 Senza ulteriori specificazioni, una distribuzione pu√≤ fare riferimento a un‚Äôintera famiglia di distribuzioni. I parametri, tipicamente indicati con lettere greche come \\(\\mu\\) e \\(\\alpha\\), ci permettono di specificare di quale membro della famiglia stiamo parlando. Quindi, si pu√≤ parlare di una variabile casuale con una distribuzione Normale, ma se viene specificata la media \\(\\mu\\) = 100 e la varianza \\(\\sigma^2\\) = 15, viene individuata una specifica distribuzione Normale ‚Äì nell‚Äôesempio, la distribuzione del quoziente di intelligenza.\nI metodi statistici parametrici specificano la famiglia delle distribuzioni e quindi utilizzano i dati per individuare, stimando i parametri, una specifica distribuzione all‚Äôinterno della famiglia di distribuzioni ipotizzata. Se \\(f\\) √® la PDF di una variabile casuale \\(Y\\), l‚Äôinteresse pu√≤ concentrarsi sulla sua media e varianza. Nell‚Äôanalisi di regressione, ad esempio, cerchiamo di spiegare come i parametri di \\(f\\) dipendano dalle covariate \\(X\\). Nella regressione lineare classica, assumiamo che \\(Y\\) abbia una distribuzione normale con media \\(\\mu = \\mathbb{E}(Y)\\), e stimiamo come \\(\\mathbb{E}(Y)\\) dipenda da \\(X\\). Poich√© molti esiti psicologici non seguono una distribuzione normale, verranno introdotte distribuzioni pi√π appropriate per questi risultati. I metodi non parametrici, invece, non specificano una famiglia di distribuzioni per \\(f\\). In queste dispense faremo riferimento a metodi non parametrici quando discuteremo della statistica descrittiva.\nIl termine modello √® onnipresente in statistica e nella data science. Il modello statistico include le ipotesi e le specifiche matematiche relative alla distribuzione della variabile casuale di interesse. Il modello dipende dai dati e dalla domanda di ricerca, ma raramente √® unico; nella maggior parte dei casi, esiste pi√π di un modello che potrebbe ragionevolmente usato per affrontare la stessa domanda di ricerca e avendo a disposizione i dati osservati. Nella previsione delle aspettative future dei pazienti depressi che discuteremo in seguito (Zetsche et al., 2019), ad esempio, la specifica del modello include l‚Äôinsieme delle covariate candidate, l‚Äôespressione matematica che collega i predittori con le aspettative future e qualsiasi ipotesi sulla distribuzione della variabile dipendente. La domanda di cosa costituisca un buon modello √® una domanda su cui torneremo ripetutamente in questo insegnamento."
  },
  {
    "objectID": "001_key_notions.html#effetto",
    "href": "001_key_notions.html#effetto",
    "title": "1¬† Concetti chiave",
    "section": "1.4 Effetto",
    "text": "1.4 Effetto\nL‚Äôeffetto √® una qualche misura dei dati. Dipende dal tipo di dati e dal tipo di test statistico che si vuole utilizzare. Ad esempio, se viene lanciata una moneta 100 volte e esce testa 66 volte, l‚Äôeffetto sar√† 66/100. Diventa poi possibile confrontare l‚Äôeffetto ottenuto con l‚Äôeffetto nullo che ci si aspetterebbe da una moneta bilanciata (50/100), o con qualsiasi altro effetto che pu√≤ essere scelto. La dimensione dell‚Äôeffetto si riferisce alla differenza tra l‚Äôeffetto misurato nei dati e l‚Äôeffetto nullo (di solito un valore che ci si aspetta di ottenere in base al caso soltanto)."
  },
  {
    "objectID": "001_key_notions.html#stima-e-inferenza",
    "href": "001_key_notions.html#stima-e-inferenza",
    "title": "1¬† Concetti chiave",
    "section": "1.5 Stima e inferenza",
    "text": "1.5 Stima e inferenza\nLa stima √® il processo mediante il quale il campione viene utilizzato per conoscere le propriet√† di interesse della popolazione. La media campionaria √® una stima naturale della media della popolazione e la mediana campionaria √® una stima naturale della mediana della popolazione. Quando parliamo di stimare una propriet√† della popolazione (a volte indicata come parametro della popolazione) o di stimare la distribuzione di una variabile casuale, stiamo parlando dell‚Äôutilizzo dei dati osservati per conoscere le propriet√† di interesse della popolazione. L‚Äôinferenza statistica √® il processo mediante il quale le stime campionarie vengono utilizzate per rispondere a domande di ricerca e per valutare specifiche ipotesi relative alla popolazione. Discuteremo le procedure bayesiane dell‚Äôinferenza nell‚Äôultima parte di queste dispense."
  },
  {
    "objectID": "001_key_notions.html#metodi-e-procedure-della-psicologia",
    "href": "001_key_notions.html#metodi-e-procedure-della-psicologia",
    "title": "1¬† Concetti chiave",
    "section": "1.6 Metodi e procedure della psicologia",
    "text": "1.6 Metodi e procedure della psicologia\nUn modello psicologico di un qualche aspetto del comportamento umano o della mente ha le seguenti propriet√†:\n\ndescrive le caratteristiche del comportamento in questione,\nformula predizioni sulle caratteristiche future del comportamento,\n√® sostenuto da evidenze empiriche,\ndeve essere falsificabile (ovvero, in linea di principio, deve potere fare delle predizioni su aspetti del fenomeno considerato che non sono ancora noti e che, se venissero indagati, potrebbero portare a rigettare il modello, se si dimostrassero incompatibili con esso).\n\nL‚Äôanalisi dei dati valuta un modello psicologico utilizzando strumenti statistici.\n\n\n\n\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "005_measurement.html",
    "href": "005_measurement.html",
    "title": "2¬† La misurazione in psicologia",
    "section": "",
    "text": "Introduco il problema della misurazione in psicologia parlando dell‚Äôintelligenza. In quanto psicologi, siamo abituati a pensare alla misurazione dell‚Äôintelligenza, ma anche le persone che non sono psicologi sono ben familiari con la misurazione dell‚Äôintelligenza: tra le misurazioni delle caratteristiche psicologiche, infatti, la misurazione dell‚Äôintelligenza √® forse la pi√π conosciuta.\nI test di intelligenza consistono in una serie di problemi di carattere verbale, numerico o simbolico. Come ci si pu√≤ aspettare, alcune persone riescono a risolvere correttamente un numero maggiore di problemi di altre. Possiamo contare il numero di risposte corrette e osservare le differenze individuali nei punteggi calcolati. Scopriamo in questo modo che le differenze individuali nell‚Äôabilit√† di risolvere tali problemi risultano sorprendentemente stabili nell‚Äôet√† adulta. Inoltre, diversi test di intelligenza tendono ad essere correlati positivamente: le persone che risolvono un maggior numero di problemi verbali, in media, tenderanno anche a risolvere correttamente un numero pi√π grande di problemi numerici e simbolici. Esiste quindi una notevole coerenza delle differenze osservate tra le persone, sia nel tempo sia considerando diverse procedure di test e valutazione.\nAvendo stabilito che ci sono differenze individuali tra le persone, √® possibile esaminare le associazioni tra i punteggi dei test di intelligenza e altre variabili. Possiamo indagare se le persone con punteggi pi√π alti nei test di intelligenza, rispetto a persone che ottengono punteggi pi√π bassi, hanno pi√π successo sul lavoro; se guadagnano di pi√π; se votano in modo diverso; o se hanno un‚Äôaspettativa di vita pi√π alta. Possiamo esaminare le differenze nei punteggi dei test di intelligenza in funzione di variabili come il genere, il gruppo etnico-razziale o lo stato socio-economico. Possiamo fare ricerche sull‚Äôassociazione tra i punteggi dei test di intelligenza e l‚Äôefficienza dell‚Äôelaborazione neuronale, i tempi di reazione o la quantit√† di materia grigia all‚Äôinterno della scatola cranica. Tutte queste ricerche sono state condotte e gli psicologi hanno scoperto una vasta gamma di associazioni tra le misure dell‚Äôintelligenza e altre variabili. Alcune di queste associazioni sono grandi e stabili, altre sono piccole e difficili da replicare. In riferimento all‚Äôintelligenza, dunque, gli psicologi hanno condotto un enorme numero di ricerche ponendosi domande diverse. In quali condizioni si verificano determinati effetti? Quali variabili mediano o moderano le relazioni tra i punteggi dei test di intelligenza e altre variabili? Queste relazioni si mantengono stabili in diversi gruppi di persone? Le ricerche sull‚Äôintelligenza umana sono un campo in continuo sviluppo.\nTuttavia, una domanda sorge spontanea: che cosa misurano esattamente i test di intelligenza? Dopo un secolo di ricerche sui punteggi dei test di intelligenza e, in generale, sui test psicologici, non sappiamo ancora rispondere a questa domanda. Questa considerazione relativa ai test di intelligenza ci conduce dunque alle seguenti domande: che cos‚Äô√® esattamente un costrutto psicologico (come l‚Äôintelligenza, ad esempio)? Come pu√≤ essere misurato un costrutto psicologico? Queste sono domande a cui √® difficile rispondere e a cui √® dedicata un‚Äôintera area di ricerca, quella della teoria della misurazione psicologica. Non possiamo qui entrare nel merito delle complessit√† della teoria della misurazione psicologica (questi temi pi√π generali verranno approfonditi nei successivi insegnamenti sulla testistica psicologica). La motivazione delle considerazioni precedenti era solo quella di fare qualche accenno al contesto generale all‚Äôinterno del quale si colloca il tema di cui ci occuperemo qui, ovvero quello delle scale di misura."
  },
  {
    "objectID": "005_measurement.html#le-scale-di-misura",
    "href": "005_measurement.html#le-scale-di-misura",
    "title": "2¬† La misurazione in psicologia",
    "section": "\n2.1 Le scale di misura",
    "text": "2.1 Le scale di misura\nIn generale possiamo dire che la teoria della misurazione si occupa dello studio delle relazioni esistenti tra due domini: il ‚Äúmondo fisico‚Äù e il ‚Äúmondo psicologico‚Äù. Secondo la teoria della misurazione, la misurazione √® un‚Äôattivit√† rappresentativa, cio√® √® un processo di assegnazione di numeri in modo tale da preservare, all‚Äôinterno del dominio numerico, le relazioni qualitative che sono state osservate nel mondo empirico. La teoria della misurazione ha lo scopo di specificare le condizioni necessarie per la costruzione di una rappresentazione adeguata delle relazioni empiriche all‚Äôinterno di un sistema numerico. Da una prospettiva formale, le operazioni descritte dalla teoria della misurazione possono essere concettualizzate in termini di mappatura tra le relazioni esistenti all‚Äôinterno di due insiemi (quello empirico e quello numerico). Il risultato di questa attivit√† √® chiamato ‚Äúscala di misurazione‚Äù.\nUna famosa teoria delle scale di misura √® stata proposta da (Stevens, 1946). Stevens ci fa notare che, in linea di principio, le variabili psicologiche sono in grado di rappresentare (preservare) con diversi gradi di accuratezza le relazioni qualitative che sono state osservate nei fenomeni psicologici. Secondo la teoria di Stevens, possiamo distinguere tra quattro scale di misura: le scale nominali (nominal scales), ordinali (ordinal scales), a intervalli (interval scales), di rapporti (ratio scales). Tali scale di misura consentono operazioni aritmetiche diverse, come indicato nella tabella successiva, in quanto ciasuna di esse √® in grado di ‚Äúcatturare‚Äù soltanto alcune delle propriet√† dei fenomeni psicologici che intende misurare.\n\n\n2.1.1 Scala nominale\nIl livello di misurazione pi√π semplice √® quello della scala nominale. Questa scala di misurazione corrisponde ad una tassonomia. I simoboli o numeri che costituiscono questa scala non sono altro che i nomi delle categorie che utilizziamo per classificare i fenomeni psicologici. In base alle misure fornite da una scala nominale, l‚Äôunica cosa che siamo in grado di dire a proposito di una caratteristica psicologica √® se essa √® uguale o no ad un‚Äôaltra caratteristica psicologica.\nLa scala nominale raggruppa dunque i dati in categorie qualitative mutuamente esclusive (cio√® nessun dato si pu√≤ collocare in pi√π di una categoria). Esiste la sola relazione di equivalenza tra le misure delle u.s., cio√® nella scala nominale gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti: \\(x_i = x_j\\) oppure \\(x_i \\neq x_j\\).\nL‚Äôunica operazione algebrica che possiamo compiere sulle modalit√† della scala nominale √® quella di contare le u.s. che appartengono ad ogni modalit√† e contare il numero delle modalit√† (classi di equivalenza). Dunque la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.\nA partire da una scala nominale √® possibile costruire altre scale nominali che sono equivalenti alla prima trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle modalit√†, ma lasciando per√≤ inalterata la suddivisione u.s. nelle medesime classi di equivalenza. Questo significa che prendendo una variabile misurata su scala nominale e cambiando i nomi delle sue categorie otteniamo una nuova variabile esattamente corrispondente alla prima.\n\n2.1.2 Scala ordinale\nLa scala ordinale conserva la propriet√† della scala nominale di classificare ciascuna u.s. all‚Äôinterno di una e una sola categoria, ma alla relazione di equivalenza tra elementi di una stessa classe aggiunge la relazione di ordinamento tra le classi di equivalenza. Essendo basata su una relazione d‚Äôordine, una scala ordinale descrive soltanto l‚Äôordine di rango tra le modalit√†, ma non ci d√† alcuna informazione su quanto una modalit√† sia pi√π grande di un‚Äôaltra. Non ci dice, per esempio, se la distanza tra le modalit√† \\(a\\) e \\(b\\) sia uguale, maggiore o minore della distanza tra le modalit√† \\(b\\) e \\(c\\).\n\nEsempio 2.1 \nUn esempio classico di scala ordinale √® quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed √® scalfito da quello di livello superiore.\n\n\n2.1.3 Scala ad intervalli\nLa scala ad intervalli include le propriet√† di quella nominale e di quella ordinale, e in pi√π consente di misurare le distanze tra le coppie di u.s. nei termini di un intervallo costante, chiamato unit√† di misura, a cui viene attribuito il valore ‚Äú1‚Äù. La posizione dell‚Äôorigine della scala, cio√® il punto zero, √® scelta arbitrariamente, nel senso che non indica l‚Äôassenza della quantit√† che si sta misurando. Avendo uno zero arbitrario, questa scala di misura consente valori negativi. Lo zero, infatti, non viene attribuito all‚Äôu.s. in cui la propriet√† misurata risulta assente.\nLa scala a intervalli equivalenti ci consente di effettuare operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non era possibile eseguire nel caso di misure a livello di scala ordinale o nominale. Il limite della scala ad intervalli √® quello di non consentire il calcolo del rapporto tra coppie di misure. Possiamo dire, per esempio, che la distanza tra \\(a\\) e \\(b\\) √® la met√† della distanza tra \\(c\\) e \\(d\\). Oppure che la distanza tra \\(a\\) e \\(b\\) √® uguale alla distanza tra \\(c\\) e \\(d\\). Non possiamo dire, per√≤, che \\(a\\) possiede la propriet√† misurata in quantit√† doppia rispetto \\(b\\). Non possiamo cio√® stabilire dei rapporti diretti tra le misure ottenute. Solo per le differenze tra le modalit√† sono dunque permesse tutte le operazioni aritmetiche: le differenze possono essere tra loro sommate, elevate a potenza oppure divise, determinando cos√¨ le quantit√† che stanno alla base della statistica inferenziale.\nNelle scale ad intervalli equivalenti, l‚Äôunit√† di misura √® arbitraria, ovvero pu√≤ essere cambiata attraverso una dilatazione, operazione che consiste nel moltiplicare tutti i valori della scala per una costante positiva. Poich√© l‚Äôaggiunta di una costante non altera le differenze tra i valori della scala, √® anche ammessa la traslazione, operazione che consiste nel sommare una costante a tutti i valori della scala. Essendo la scala invariate rispetto alla traslazione e alla dilatazione, le trasformazioni ammissibili sono le trasformazioni lineari:\n\\[\ny' = a + by, \\quad b > 0.\n\\]\nL‚Äôaspetto che rimane invariante a seguito di una trasformazione lineare √® l‚Äôuguaglianza dei rapporti fra intervalli.\nEsempio di scala ad intervalli √® la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, √® possibile stabilire se due modalit√† sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale √® possibile mettere due modalit√† in una relazione d‚Äôordine: 30\\(^\\circ\\)C \\(>\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, per√≤, √® possibile definire una unit√† di misura per cui √® possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c‚Äô√® una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l‚Äôintensit√† del fenomeno, godono della propriet√† che le differenze tra loro sono direttamente confrontabili e quantificabili.\nIl limite della scala ad intervalli √® quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non √® il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione ‚Äúil doppio di‚Äù che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla propriet√† misurata (cio√® la temperatura). La decisione di che scala usare (Centigrada vs.¬†Fahrenheit) √® arbitraria. Ma questa arbitrariet√† non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realt√† empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit.\nConsideriamo ora l‚Äôaspetto invariante di una trasformazione lineare, ovvero l‚Äôuguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\).\n√à facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall‚Äôunit√† di misura che √® stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]\n\n2.1.4 Scala di rapporti\nNella scala a rapporti equivalenti la posizione dello zero non √® arbitraria, ma corrisponde all‚Äôelemento dotato di intensit√† nulla rispetto alla propriet√† misurata. Una scala a rapporti equivalenti si costruisce associando il numero 0 all‚Äôelemento con intensit√† nulla; viene poi scelta un‚Äôunit√† di misura \\(u\\) e, ad ogni elemento, si assegna un numero \\(a\\) definito come: \\[a = \\frac{d}{u}\\] dove \\(d\\) rappresenta la distanza dall‚Äôorigine. Alle u.s. vengono dunque assegnati dei numeri tali per cui le differenze e i rapporti tra i numeri riflettono le differenze e i rapporti tra le intensit√† della propriet√† misurata.\nOperazioni aritmetiche sono possibili non solo sulle differenze tra i valori della scala (come per la scala a intervalli equivalenti), ma anche sui valori stessi della scala. L‚Äôunica arbitrariet√† riguarda l‚Äôunit√† di misura che si utilizza. L‚Äôunit√† di misura pu√≤ cambiare, ma qualsiasi unit√† di misura si scelga, lo zero deve sempre indicare l‚Äôintensit√† nulla della propriet√† considerata.\nLe trasformazioni ammissibili a questo livello di scala sono dette trasformazioni di similarit√†: \\[y' = by, \\quad b > 0.\\] A questo livello di scala, a seguito delle trasformazioni ammissibili, rimangono invariati anche i rapporti: \\[\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}.\\]"
  },
  {
    "objectID": "005_measurement.html#gerarchia-dei-livelli-di-scala-di-misura",
    "href": "005_measurement.html#gerarchia-dei-livelli-di-scala-di-misura",
    "title": "2¬† La misurazione in psicologia",
    "section": "\n2.2 Gerarchia dei livelli di scala di misura",
    "text": "2.2 Gerarchia dei livelli di scala di misura\nStevens (1946) parla di livelli di scala poich√© i quattro tipi di scala di misura stanno in una precisa gerarchia: la scala nominale rappresenta il livello pi√π basso della misurazione, la scala a rapporti equivalenti √® invece il livello pi√π alto.\n\n\nScale di modalit√†\nOperazioni aritmetiche\n\n\n\nnominali\nenumerare le classi di equivalenza e/o\n\n\n\nle frequenze per ciascuna classe di equivalenza\n\n\nordinali\nenumerare le classi di equivalenza e/o\n\n\n\nle frequenze per ciascuna classe di equivalenza\n\n\nintervallari\ndifferenze (rapporti tra differenze)\n\n\ndi rapporti\nrapporti diretti tra le misure\n\n\n\nPassando da un livello di misurazione ad uno pi√π alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.\n\nPer ci√≤ che riguarda le trasformazioni ammissibili, pi√π il livello di scala √® basso, pi√π le funzioni sono generali (sono minori cio√® i vincoli per passare da una rappresentazione numerica ad un‚Äôaltra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa pi√π restrittiva."
  },
  {
    "objectID": "005_measurement.html#variabili-discrete-o-continue",
    "href": "005_measurement.html#variabili-discrete-o-continue",
    "title": "2¬† La misurazione in psicologia",
    "section": "\n2.3 Variabili discrete o continue",
    "text": "2.3 Variabili discrete o continue\nLe variabili a livello di intervalli e di rapporti possono essere discrete o continue. Le variabili discrete possono assumere alcuni valori ma non altri. Una volta che l‚Äôelenco di valori accettabili √® stato specificato, non ci sono casi che cadono tra questi valori. Le variabili discrete di solito assumono valori interi.\nQuando una variabile pu√≤ assumere qualsiasi valore entro un intervallo specificato, allora si dice che la variabile √® continua. In teoria, ci√≤ significa che frazioni e decimali possono essere utilizzati per raggiungere un livello di precisione qualsiasi. In pratica, a un certo punto dobbiamo arrotondare i numeri, rendendo tecnicamente la variabile discreta. In variabili veramente discrete, tuttavia, non √® possibile aumentare a piacimento il livello di precisione della misurazione.\n\n\nEsempio 2.2 \nIl numero di biciclette possedute da una persona √® una variabile discreta poich√© tale variabile pu√≤ assumere come modalit√† solo i numeri interi non negativi. Frazioni di bicicletta non hanno senso."
  },
  {
    "objectID": "005_measurement.html#alcune-misure-sono-migliori-di-altre",
    "href": "005_measurement.html#alcune-misure-sono-migliori-di-altre",
    "title": "2¬† La misurazione in psicologia",
    "section": "\n2.4 Alcune misure sono migliori di altre",
    "text": "2.4 Alcune misure sono migliori di altre\nIn psicologia, ci√≤ che vogliamo misurare non √® una caratteristica fisica, ma invece √® un concetto teorico inosservabile, ovvero un costrutto. Un costrutto rappresenta il risultato di una fondata riflessione scientifica, non √® per definizione accessibile all‚Äôosservazione diretta, ma viene inferito dall‚Äôosservazione di opportuni indicatori (Sartori, 2005). Ad esempio, supponiamo che un docente voglia valutare quanto bene uno studente comprenda la distinzione tra le quattro diverse scale di misura che sono state descritte sopra. Il docente potrebbe predisporre un test costituito da un insieme di domande e potrebbe contare a quante domande lo studente risponde correttamente. Questo test, per√≤, pu√≤ o pu√≤ non essere una buona misura del costrutto relativo alla conoscenza effettiva delle quattro scale di misura. Per esempio, se il docente scrive le domande del test in modo ambiguo o se usa una linguaggio troppo tecnico che lo studente non conosce, allora i risultati del test potrebbero suggerire che lo studente non conosce la materia in questione anche se in realt√† questo non √® vero. D‚Äôaltra parte, se il docente prepara un test a scelta multipla con risposte errate molto ovvie, allora lo studente pu√≤ ottenere dei buoni risultati al test anche senza essere in grado di comprendere adeguatamente le propriet√† delle quattro scale di misura. In generale non √® possibile misurare un costrutto senza una certa quantit√† di errore. Poniamoci dunque il problema di determinare in che modo una misurazione possa dirsi adeguata.\n\n2.4.1 Tipologie di errori\nL‚Äôerrore √®, per definizione, la differenza tra il valore vero e il valore misurato della grandezza in esame. Gli errori sono classificati come sistematici (o determinati) e casuali (o indeterminati). Gli errori casuali sono fluttuazioni, in eccesso o in difetto rispetto al valore reale, delle singole determinazioni e sono dovuti alle molte variabili incontrollabili che influenzano ogni misura psicologica. Gli errori sistematici, invece, influiscono sulla misurazione sempre nello stesso senso e, solitamente, per una stessa quantit√† (possono essere additivi o proporzionali).\nLe differenze tra le due tipologie di errori, sistematici e casuali, introducono i concetti di accuratezza e di precisione della misura. Una misura viene definita:\n\n\naccurata, quando vi √® un accordo tra la misura effettuata ed il valore reale;\n\nprecisa quando, ripetendo pi√π volte la misura, i risultati ottenuti sono concordanti, cio√® differiscono in maniera irrilevante tra loro.\n\nLa metafora del tiro a bersaglio illustra la relazione tra precisione e accuratezza.\n\n\n\n\nFigura 2.1: Metafora del tiro al bersaglio.\n\n\n\n\nPer tenere sotto controllo l‚Äôincidenza degli errori, sono stati introdotti in psicologia i concetti di attendibilit√† e validit√†.\nUno strumento si dice attendibile quando valuta in modo coerente e stabile la stessa variabile: i risultati ottenuti si mantengono costanti dopo ripetute somministrazione ed in assenza di variazioni psicologiche e fisiche dei soggetti sottoposti al test o cambiamenti dell‚Äôambiente in cui ha luogo la somministrazione.\nL‚Äôattendibilit√† di uno strumento, per√≤, non √® sufficiente: in primo luogo uno strumento di misura deve essere valido, laddove la validit√† rappresenta il grado in cui uno strumento misura effettivamente ci√≤ che dovrebbe misurare. In genere, si fa riferimento ad almeno quattro tipi di validit√†.\n\nLa validit√† di costrutto riguarda il grado in cui un test misura ci√≤ per cui √® stato costruito. Essa si suddivide in: validit√† convergente e validit√† divergente. La validit√† convergente fa riferimento alla concordanza tra uno strumento e un altro che misura lo stesso costrutto. La validit√† divergente, al contrario, valuta il grado di discriminazione tra strumenti che misurano costrutti differenti. Senza validit√† di costrutto le altre forme di validit√† non hanno senso.\nIn base alla validit√† di contenuto, un test fornisce una misura valida di un attributo psicologico se il dominio dell‚Äôattributo √® rappresentato in maniera adeguata dagli item del test. Un requisito di base della validit√† di contenuto √® la rilevanza e la rappresentativit√† del contenuto degli item in riferimento all‚Äôattributo che il test intende misurare.\nLa validit√† di criterio valuta il grado di concordanza tra i risultati dello strumento considerato e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto, o tra i risultati dello strumento considerato e un criterio esterno. Nella validit√† concorrente, costrutto e criterio vengono misurati contestualmente, consentendo un confronto immediato. Nella validit√† predittiva, il costrutto viene misurato prima e il criterio in un momento successivo, consentendo la valutazione della capacit√† dello strumento di predire un evento futuro.\nInfine, la validit√† di facciata fa riferimento al grado in cui il test appare valido ai soggetti a cui esso √® diretto. La validit√† di facciata √® importante in ambiti particolari, quali ad esempio la selezione del personale per una determinata occupazione. In questo caso √® ovviamente importante che chi si sottopone al test ritenga che il test vada a misurare quegli aspetti che sono importanti per le mansioni lavorative che dovranno essere svolte, piuttosto che altre cose. In generale, la validit√† di facciata non √® utile, tranne in casi particolari."
  },
  {
    "objectID": "005_measurement.html#commenti-e-considerazioni-finali",
    "href": "005_measurement.html#commenti-e-considerazioni-finali",
    "title": "2¬† La misurazione in psicologia",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nUna domanda che uno psicologo spesso si pone √®: ‚Äúsulla base delle evidenze osservate, possiamo concludere dicendo che l‚Äôintervento psicologico √® efficace nel trattamento e nella cura del disturbo?‚Äù Le considerazioni svolte in questo capitolo dovrebbero farci capire che, prima di cercare di rispondere a questa domanda con l‚Äôanalisi statistica dei dati, devono essere affrontati i problemi della validit√† e dell‚Äôattendibilit√† delle misure (oltre a stabilire l‚Äôappropriato livello di scala di misura delle osservazioni). L‚Äôattendibilit√† √® un prerequisito della validit√†. Se gli errori di misurazione sono troppo grandi, i dati sono inutili. Inoltre, uno strumento di misurazione pu√≤ essere preciso ma non valido. La validit√† e l‚Äôattendibilit√† delle misurazioni sono dunque entrambe necessarie.\nIn generale, l‚Äôattendibilit√† e la validit√† delle misure devono essere valutate per capire se i dati raccolti da un ricercatore siano adeguati (1) per fornire una risposta alla domanda della ricerca, e (2) per giungere alla conclusione proposta dal ricercatore alla luce dei risultati dell‚Äôanalisi statistica che √® stata eseguita. √à chiaro che le informazioni fornite in questo capitolo si limitano a scalfire la superficie di questi problemi. I concetti qui introdotti, per√≤, devono sempre essere tenuti a mente e costituiscono il fondamento di quanto verr√† esposto nei capitoli successivi.\n\n\n\n\n\n\nStevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677‚Äì680."
  },
  {
    "objectID": "007_freq_distr.html",
    "href": "007_freq_distr.html",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "",
    "text": "Le analisi esplorative dei dati e la statistica descrittiva costituiscono la prima fase dell‚Äôanalisi dei dati psicologici. Consentono di capire come i dati sono distribuiti, ci aiutano ad individuare le osservazioni anomale e gli errori di tabulazione. Consentono di riassumere le distribuzioni dei dati mediante indici sintetici. Consentono di visualizzare e di studiare le relazioni tra le variabili. In questo Capitolo, dopo avere presentato gli obiettivi dell‚Äôanalisi esplorative dei dati, discuteremo il problema della descrizione numerica e della rappresentazione grafica delle distribuzioni di frequenza."
  },
  {
    "objectID": "007_freq_distr.html#chapter-descript",
    "href": "007_freq_distr.html#chapter-descript",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.1 Introduzione all‚Äôesplorazione dei dati",
    "text": "3.1 Introduzione all‚Äôesplorazione dei dati\nLe analisi esplorative dei dati sono indispensabili per condurre in modo corretto una qualsiasi analisi statistica, dal livello base a quello avanzato. Si parla di analisi descrittiva se l‚Äôobiettivo √® quello di descrivere le caratteristiche di un campione. Si parla di analisi esplorativa dei dati (Exploratory Data Analysis o EDA) se l‚Äôobiettivo √® quello di esplorare i dati alla ricerca di nuove informazioni e relazioni tra variabili. Questa distinzione, seppur importante a livello teorico, nella pratica √® pi√π fumosa perch√© spesso entrambe le situazioni si verificano contemporaneamente nella stessa indagine statistica e le metodologie di analisi che si utilizzano sono molto simili.\nN√© il calcolo delle statistiche descrittive n√© l‚Äôanalisi esplorativa dei dati possono essere condotte senza utilizzare un software. Le descrizioni dei concetti di base della EDA saranno dunque fornite di pari passo alla spiegazione di come le quantit√† discusse possono essere calcolate in pratica utilizzando \\(\\mathsf{R}\\)."
  },
  {
    "objectID": "007_freq_distr.html#un-excursus-storico",
    "href": "007_freq_distr.html#un-excursus-storico",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.2 Un excursus storico",
    "text": "3.2 Un excursus storico\nNel 1907 Francis Galton, cugino di Charles Darwin, matematico e statistico autodidatta, geografo, esploratore, teorico della dattiloscopia (ovvero, dell‚Äôuso delle impronte digitali a fini identificativi) e dell‚Äôeugenetica, scrisse una lettera alla rivista scientifica Nature sulla sua visita alla Fat Stock and Poultry Exhibition di Plymouth. L√¨ vide alcuni membri del pubblico partecipare ad un gioco il cui scopo era quello di indovinare il peso della carcassa di un grande bue che era appena stato scuoiato. Galton si procur√≤ i 787 dei biglietti che erano stati compilati dal pubblico e consider√≤ il valore medio di 547 kg come la ‚Äúscelta democratica‚Äù dei partecipanti, in quanto ‚Äúogni altra stima era stata giudicata troppo alta o troppo bassa dalla maggioranza dei votanti‚Äù. Il punto interessante √® che il peso corretto di 543 kg si dimostr√≤ essere molto simile alla ‚Äúscelta democratica‚Äù basata sulle stime dei 787 partecipanti. Galton intitol√≤ la sua lettera a Nature Vox Populi (voce del popolo), ma questo processo decisionale √® ora meglio conosciuto come la ‚Äúsaggezza delle folle‚Äù (wisdom of crowds). Possiamo dire che, nel suo articolo del 1907, Galton effettu√≤ quello che ora chiamiamo un riepilogo dei dati, ovvero calcol√≤ un indice sintetico a partire da un insieme di dati. In questo capitolo esamineremo le tecniche che sono state sviluppate nel secolo successivo per riassumere le grandi masse di dati con cui sempre pi√π spesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare gli indici di posizione e di dispersione, discuteremo le distribuzioni di frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le tecniche di visualizzazione che ci consentono di rappresentare questi sommari dei dati mediante dei grafici. Ma prima di entrare nei dettagli, prendiamoci un momento per capire perch√© abbiamo bisogno della statistica e, per ci√≤ che stiamo discutendo qui, della statistica descrittiva.\nIn generale, che cos‚Äô√® la statistica? Ci sono molte definizioni. Fondamentalmente, la statistica √® un insieme di tecniche che ci consentono di dare un senso al mondo attraverso i dati. Ci√≤ avviene tramite il processo di analisi statistica. L‚Äôanalisi statistica traduce le domande che abbiamo a proposito del mondo in modelli matematici, utilizza i dati per scegliere i modelli matematici che sono apppropriati per descrivere il mondo e, infine, applica tali modelli per trovare una risposta alle domande che ci siamo posti. La statistica consente quindi di collegare le nostre domande a proposito del mondo ai dati, di utilizzare i dati per trovare le risposte alle domande che ci siamo posti e di valutare l‚Äôimpatto delle risposte che abbiamo trovato."
  },
  {
    "objectID": "007_freq_distr.html#riassumere-i-dati",
    "href": "007_freq_distr.html#riassumere-i-dati",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.3 Riassumere i dati",
    "text": "3.3 Riassumere i dati\nIniziamo a porci una domanda. Quando riassumiamo i dati, necessariamente buttiamo via delle informazioni; ma √® una buona idea procedere in questo modo? Non sarebbe meglio conservare le informazioni specifiche di ciascun soggetto che partecipa ad un esperimento psicologico, al di l√† di ci√≤ che viene trasmesso dagli indici riassuntivi della statistica descrittiva? Che dire delle informazioni che descrivono come sono stati raccolti i dati, come l‚Äôora del giorno o l‚Äôumore del partecipante? Tutte queste informazioni vengono perdute quando riassumiamo i dati. La risposta alla domanda che ci siamo posti √® che, in generale, non √® una buona idea conservare tutti i dettagli di ci√≤ che sappiamo. √à molto pi√π utile riassumere le informazioni perch√© la semplificazione risultante consente i processi di generalizzazione.\nIn un contesto letterario, l‚Äôimportanza della generalizzazione √® stata sottolineata da Jorge Luis Borges nel suo racconto ‚ÄúFunes o della memoria‚Äù, che descrive un individuo che perde la capacit√† di dimenticare. Borges si concentra sulla relazione tra generalizzazione e pensiero: ‚ÄúPensare √® dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c‚Äôerano solo dettagli.‚Äù\nCome possiamo ben capire, la vita di Funes non √® facile. Se facciamo riferimento alla psicologia possiamo dire che gli psicologi hanno studiato a lungo l‚Äôutilit√† della generalizzazione per il pensiero. Un esempio √® fornito dal fenomeno della formazione dei concetti e lo psicologo che viene in mente a questo proposito √® sicuramente Eleanor Rosch, la quale ha studiato i principi di base della categorizzazione. I concetti ci forniscono uno strumento potente per organizzare le conoscenze. Noi siamo in grado di riconoscere facilmente i diversi esemplare di un concetto ‚Äì per esempio, ‚Äúgli uccelli‚Äù ‚Äì anche se i singoli esemplari che fanno parte di una categoria sono molto diversi tra loro (l‚Äôaquila, il gabbiano, il pettirosso). L‚Äôuso dei concetti, cio√® la generalizzazione, √® utile perch√© ci consente di fare previsioni sulle propriet√† dei singoli esemplari che appartengono ad una categoria, anche se non abbiamo mai avuto esperienza diretta con essi ‚Äì per esempio, possiamo fare la predizione che tutti gli uccelli possono volare e mangiare vermi, ma non possono guidare un‚Äôautomobile o parlare in inglese. Queste previsioni non sono sempre corrette, ma sono utili.\nLe statistiche descrittive, in un certo senso, ci fornisco l‚Äôanalogo dei ‚Äúprototipi‚Äù che, secondo Eleanor Rosch, stanno alla base del processo psicologico di creazione dei concetti. Un prototipo √® l‚Äôesemplare pi√π rappresentativo di una categoria. In maniera simile, una statistica descrittiva come la media, ad esempio, potrebbe essere intesa come l‚Äôosservazione ‚Äútipica‚Äù.\nLa statistica descrittiva ci fornisce gli strumenti per riassumere i dati che abbiamo a disposizione in una forma visiva o numerica. Le rappresentazioni grafiche pi√π usate della statistica descrittiva sono gli istogrammi, i diagrammi a dispersione o i box-plot, e gli indici sintetici pi√π comuni sono la media, la mediana, la varianza e la deviazione standard."
  },
  {
    "objectID": "007_freq_distr.html#i-dati-grezzi",
    "href": "007_freq_distr.html#i-dati-grezzi",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.4 I dati grezzi",
    "text": "3.4 I dati grezzi\nPer introdurre i principali strumenti della statistica descrittiva considereremo qui i dati raccolti da Zetsche et al. (2019). Questi ricercatori hanno studiato le aspettative negative quale meccanismo chiave nel mantenimento e nella reiterazione della depressione. Nello studio, Zetsche et al. (2019) si sono chiesti se individui depressi maturino delle aspettative accurate sul loro umore futuro, oppure se tali aspettative sono distorte negativamente.1. In uno studio viene esaminato un campione costituito da 30 soggetti con almeno un episodio depressivo maggiore e da 37 controlli sani. Gli autori hanno misurato il livello depressivo con il Beck Depression Inventory (BDI-II). Questi sono i dati che considereremo qui.\n\nQual √® la la gravit√† della depressione riportata dai soggetti nel campione esaminato da Zetsche et al. (2019)?\nPer rispondere a questa domanda, iniziamo a leggere in \\(\\mathsf{R}\\) i dati, assumendo che il file data.mood.csv si trovi nella cartella data contenuta nella working directory.\n\nCodicelibrary(\"rio\")\ndf <- rio::import(\n  here(\"data\", \"data.mood.csv\"),\n  header = TRUE\n)\n\n\nC‚Äô√® un solo valore BDI-II per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del data.frame associate ad ogni soggetto (ciascuna riga corrispondente ad una prova diversa). √à dunque necessario trasformare il data.frame in modo tale da avere un‚Äôunica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto.\n\nCodicebysubj <- df %>%\n  group_by(esm_id) %>%\n  summarise(\n    bdi = mean(bdi)\n  ) %>%\n  na.omit()\n\n\nCi sono dunque 66 soggetti i quali hanno ottenuto i valori sulla scala del BDI-II stampati di seguito. Per semplicit√†, li presentiamo ordinati dal pi√π piccolo al pi√π grande.\n\nCodicesort(bysubj$bdi)\n#>  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1\n#> [26]  2  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30\n#> [51] 30 30 31 31 33 33 34 35 35 35 36 39 41 43 43 44"
  },
  {
    "objectID": "007_freq_distr.html#distribuzioni-di-frequenze",
    "href": "007_freq_distr.html#distribuzioni-di-frequenze",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.5 Distribuzioni di frequenze",
    "text": "3.5 Distribuzioni di frequenze\n√à chiaro che i dati grezzi sono di difficile lettura. Poniamoci dunque il problema di creare una rappresentazione sintetica e comprensibile di questo insieme di valori. Uno dei modi che ci consentono di effettuare una sintesi dei dati √® quello di generare una distribuzione di frequenze.\n\nUna distribuzione di frequenze √® un riepilogo del conteggio della frequenza con cui le modalit√† osservate in un insieme di dati si verificano in un intervallo di valori.\n\nIn altre parole, la distribuzione di frequenze della variabile \\(X\\) corrisponde all‚Äôinsieme delle frequenze assegnate a ciascun possibile valore di \\(X\\).\nPer creare una distribuzione di frequenze possiamo procedere effettuando una partizione delle modalit√† della variabile di interesse in \\(m\\) classi (denotate con \\(\\Delta_i\\)) tra loro disgiunte. In tale partizione, la classe \\(i\\)-esima coincide con un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\) avente \\(a_i\\) e \\(b_i\\) come limite inferiore e superiore associamo l‚Äôampiezza \\(b_i - a_i\\) (non necessariamente uguale per ogni classe) e il valore centrale \\(\\bar{x}_i\\). La scelta delle classi √® arbitraria, ma √® buona norma non definire classi con un numero troppo piccolo (< 5) di osservazioni. Poich√© ogni elemento dell‚Äôinsieme \\(\\{x_i\\}_{i=1}^n\\) appartiene ad una ed una sola classe \\(\\Delta_i\\), possiamo calcolare le quantit√† elencate di seguito.\n\n\nLa frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\n\nPropriet√†: \\(n_1 + n_2 + \\dots + n_m = n\\).\n\n\n\nLa frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe.\n\nPropriet√†: \\(f_1+f_2+\\dots+f_m =1\\).\n\n\nLa frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\)\nLa frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\)\n\n\nSi calcoli la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per i valori del BDI-II del campione clinico di Zetsche et al. (2019).\nPer costruire una distribuzione di frequenza √® innanzitutto necessario scegliere gli intervalli delle classi. Facendo riferimento ai cut-off usati per l‚Äôinterpretazione del BDI-II, definiamo i seguenti intervalli aperti a destra:\n\ndepressione minima: [0, 13.5),\ndepressione lieve: [13.5, 19.5),\ndepressione moderata: [19.5, 28.5),\ndepressione severa: [28.5, 63).\n\nEsaminando i dati, possiamo notare che 36 soggetti cadono nella prima classe, uno nella seconda classe, e cos√¨ via. La distribuzione di frequenza della variabile bdi2 √® riportata nella tabella seguente. Questa distribuzione di frequenza ci aiuta a capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi pi√π estreme. Questo ha senso nel caso presente, in quanto il campione esaminato da Zetsche et al. (2019) includeva due gruppi di soggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi (con valori BDI-II alti).2 In una distribuzione di frequenza tali valori tipici vanno sotto il nome di mode della distribuzione.\n\n\n\nLim. classi\nFr.¬†ass.\nFr.¬†rel.\nFr.¬†ass. cum.\nFr.¬†rel. cum.\n\n\n\n\\([0, 13.5)\\)\n36\n36/66\n36\n36/66\n\n\n\\([13.5, 19.5)\\)\n1\n1/66\n37\n37/66\n\n\n\\([19.5, 28.5)\\)\n12\n12/66\n49\n49/66\n\n\n\\([28.5, 63)\\)\n17\n17/66\n66\n66/66\n\n\n\n\nPoniamoci ora il problema di costruire la tabella precedente utilizzando \\(\\mathsf{R}\\). Usando la funzione cut(), dividiamo il campo di variazione (ovvero, la differenza tra il valore massimo di una distribuzione ed il valore minimo) di una variabile continua x in intervalli e codifica ciascun valore x nei termini dell‚Äôintervallo a cui appartiene. Cos√¨ facendo otteniamo:\n\nCodicebysubj$bdi_level <- cut(\n  bysubj$bdi,\n  breaks = c(0, 13.5, 19.5, 28.5, 63),\n  include.lowest = TRUE,\n  labels = c(\n    \"minimal\", \"mild\", \"moderate\", \"severe\"\n  )\n)\n\nbysubj$bdi_level\n#>  [1] moderate severe   severe   moderate severe   severe   severe   severe  \n#>  [9] moderate severe   moderate mild     severe   minimal  minimal  minimal \n#> [17] severe   moderate minimal  minimal  minimal  minimal  minimal  moderate\n#> [25] minimal  minimal  minimal  minimal  minimal  minimal  minimal  severe  \n#> [33] minimal  minimal  severe   minimal  moderate minimal  minimal  minimal \n#> [41] severe   minimal  minimal  severe   severe   moderate severe   severe  \n#> [49] minimal  moderate minimal  moderate severe   moderate moderate minimal \n#> [57] minimal  minimal  minimal  minimal  minimal  minimal  minimal  minimal \n#> [65] minimal  minimal \n#> Levels: minimal mild moderate severe\n\n\nPossiamo ora usare la funzione table() la quale ritorna un elenco che associa la frequenza assoluta a ciascuna modalit√† della variabile ‚Äì ovvero, ritorna la distribuzione di frequenza assoluta.\n\nCodicetable(bysubj$bdi_level)\n#> \n#>  minimal     mild moderate   severe \n#>       36        1       12       17\n\n\nLa distribuzione di frequenza relativa si ottiene dividendo ciascuna frequenza assoluta per il numero totale di osservazioni:\n\nCodicetable(bysubj$bdi_level) / sum(table(bysubj$bdi_level))\n#> \n#>    minimal       mild   moderate     severe \n#> 0.54545455 0.01515152 0.18181818 0.25757576\n\n\n\n\nLimiti delle classi\nFrequenza assoluta\nFrequenza relativa\n\n\n\n[0, 13.5)\n36\n36/66\n\n\n[13.5, 19.5)\n1\n1/66\n\n\n[19.5, 28.5)\n12\n12/66\n\n\n[28.5, 63]\n17\n17/66\n\n\n\n\nInsiemi di variabili possono anche avere distribuzioni di frequenze, dette distribuzioni congiunte. La distribuzione congiunta di un insieme di variabili \\(V\\) √® l‚Äôinsieme delle frequenze di ogni possibile combinazione di valori delle variabili in \\(V\\). Ad esempio, se \\(V\\) √® un insieme di due variabili, \\(X\\) e \\(Y\\), ciascuna delle quali pu√≤ assumere due valori, 1 e 2, allora una possibile distribuzione congiunta di frequenze relative per \\(V\\) √® \\(f(X = 1, Y = 1) = 0.2\\), \\(f(X = 1, Y = 2) = 0.1\\), \\(f(X = 2, Y = 1) = 0.5\\), \\(f(X = 2, Y = 2) = 0.2\\). Proprio come con le distribuzioni di frequenze relative di una singola variabile, le frequenze relative di una distribuzione congiunta devono sommare a 1."
  },
  {
    "objectID": "007_freq_distr.html#istogramma",
    "href": "007_freq_distr.html#istogramma",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.6 Istogramma",
    "text": "3.6 Istogramma\nI dati che sono stati sintetizzati in una distribuzione di frequenze possono essere rappresentati graficamente in un istogramma. Un istogramma si costruisce riportando sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate i valori della funzione costante a tratti\n\\[\n\\varphi_n(x)= \\frac{f_i}{b_i-a_i}, \\quad x\\in \\Delta_i,\\, i=1, \\dots, m\n\\] che misura la densit√† della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\), ovvero il rapporto fra la frequenza relativa \\(f_i\\) e l‚Äôampiezza (\\(b_i - a_i\\)) della classe. In questo modo il rettangolo dell‚Äôistogramma associato alla classe \\(\\Delta_i\\) avr√† un‚Äôarea proporzionale alla frequenza relativa \\(f_i\\). Si noti che l‚Äôarea totale dell‚Äôistogramma delle frequenze relative √® data della somma delle aree dei singoli rettangoli e quindi vale 1.0.\n\nSi utilizzi \\(\\mathsf{R}\\) per costruire un istogramma per i valori BDI-II riportati da Zetsche et al. (2019).\nCon i quattro intervalli individuati dai cut-off del BDI-II otteniamo la rappresentazione riportata nella figura @ref(fig:hist1zetsche). Per chiarezza, precisiamo che ggplot() utilizza intervalli aperti a destra. Nel caso della prima barra dell‚Äôistogramma, l‚Äôampiezza dell‚Äôintervallo √® pari a 13.5 e l‚Äôarea della barra (ovvero, la frequenza relativa) √® uguale a 36/66. Dunque l‚Äôaltezza della barra √® uguale a \\((36 / 66) / 13.5 = 0.040\\). Lo stesso procedimento si applica per il calcolo dell‚Äôaltezza degli altri rettangoli.\n\nCodicebysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = c(0, 13.5, 19.5, 28.5, 44.1)\n    # il valore BDI-II massimo √® 44\n  ) +\n  scale_x_continuous(\n    breaks = c(0, 13.5, 19.5, 28.5, 44.1)\n  ) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densit√† di frequenza\"\n  )\n\n\n\nIstogramma per i valori BDI-II riportati da Zetsche et al.¬†(2019).\n\n\n\n\nAnche se nel caso presente √® sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un‚Äôampiezza uguale. Questo √® il caso dell‚Äôistogramma della figura @ref(fig:hist2zetsche).\n\nCodicebysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = seq(0, 44.1, length.out = 7)\n  ) +\n  scale_x_continuous(\n    breaks = c(0.00, 7.35, 14.70, 22.05, 29.40, 36.75, 44.10)\n  ) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densit√† di frequanza\"\n  )\n\n\n\nUna rappresentazione pi√π comune per l‚Äôistogramma dei valori BDI-II nella quale gli intervalli delle classi hanno ampiezze uguali."
  },
  {
    "objectID": "007_freq_distr.html#kernel-density-plot",
    "href": "007_freq_distr.html#kernel-density-plot",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.7 Kernel density plot",
    "text": "3.7 Kernel density plot\nIl confronto tra le figure @ref(fig:hist1zetsche) e @ref(fig:hist2zetsche) rende chiaro il limite dell‚Äôistogramma: il profilo dell‚Äôistogramma √® arbitrario, in quanto dipende dal numero e dall‚Äôampiezza delle classi. Questo rende difficile l‚Äôinterpretazione.\nIl problema precedente pu√≤ essere alleviato utilizzando una rappresentazione alternativa della distribuzione di frequenza, ovvero la stima della densit√† della frequenza dei dati (detta anche stima kernel di densit√†). Un modo semplice per pensare a tale rappresentazione, che in inglese va sotto il nome di kernel density plot (cio√® i grafici basati sulla stima kernel di densit√†), √® quello di immaginare un grande campione di dati, in modo che diventi possibile definire un enorme numero di classi di equivalenza di ampiezza molto piccola, le quali non risultino vuote. In tali circostanze, la funzione di densit√† empirica non √® altro che il profilo lisciato dell‚Äôistogramma. La stessa idea si applica anche quando il campione √® piccolo. In tali circostanze, invece di raccogliere le osservazioni in barre come negli istogrammi, lo stimatore di densit√† kernel colloca una piccola ‚Äúgobba‚Äù (bump), determinata da un fattore \\(K\\) (kernel) e da un parametro \\(h\\) di smussamento detto ampiezza di banda (bandwidth), in corrispondenza di ogni osservazione, quindi somma le gobbe risultanti generando una curva smussata.\nL‚Äôinterpretazione che possiamo attribuire al kernel density plot √® simile a quella che viene assegnata agli istogrammi: l‚Äôarea sottesa al kernel density plot in un certo intervallo rappresenta la proporzione di casi della distribuzione che hanno valori compresi in quell‚Äôintervallo.\n\nAll‚Äôistogramma dei valori BDI-II di Zetsche et al. (2019) si sovrapponga un kernel density plot.\n\nCodicebysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = seq(0, 44.1, length.out = 7)\n  ) +\n  geom_density(\n    aes(x = bdi),\n    adjust = 0.5,\n    size = 0.8,\n    #fill = colors[2],\n    alpha = 0.5\n  ) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densit√† di frequenza\"\n  )\n\n\n\nKernel density plot e corrispondente istogramma per i valori BDI-II."
  },
  {
    "objectID": "007_freq_distr.html#forma-di-una-distribuzione",
    "href": "007_freq_distr.html#forma-di-una-distribuzione",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.8 Forma di una distribuzione",
    "text": "3.8 Forma di una distribuzione\nIn generale, la forma di una distribuzione descrive come i dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un‚Äôillustrazione grafica √® fornita nella figura @ref(fig:distrib-shapes). Nel pannello 1 la distribuzione √® unimodale con asimmetria negativa; nel pannello 2 la distribuzione √® unimodale con asimmetria positiva; nel pannello 3 la distribuzione √® simmetrica e unimodale; nel pannello 4 la distribuzione √® bimodale.\n\n\n\n\nFigura 3.1: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale.\n\n\n\n\n\nIl kernel density plot della figura @ref(fig:zetschehist3) indica che la distribuzione dei valori del BDI-II nel campione di Zetsche et al. (2019) √® bimodale. Ci√≤ indica che le osservazioni della distribuzione si addensano in due cluster ben distinti: un gruppo di osservazioni tende ad avere valori BDI-II bassi, mentre l‚Äôaltro gruppo tende ad avere BDI-II alti. Questi due cluster di osservazioni corrispondono al gruppo di controllo e al gruppo clinico nel campione di dati esaminato da Zetsche et al. (2019)."
  },
  {
    "objectID": "007_freq_distr.html#indici-di-posizione",
    "href": "007_freq_distr.html#indici-di-posizione",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "\n3.9 Indici di posizione",
    "text": "3.9 Indici di posizione\n\n3.9.1 Quantili\nLa descrizione della distribuzione dei valori BDI-II di Zetsche et al. (2019) pu√≤ essere facilitata dalla determinazione di alcuni valori caratteristici che sintetizzano le informazioni contenute nella distribuzione di frequenze. Si dicono quantili (o frattili) quei valori caratteristici che hanno le seguenti propriet√†. I quartili sono quei valori che ripartiscono i dati \\(x_i\\) in quattro parti ugualmente numerose (pari ciascuna al 25% del totale). Il primo quartile, \\(q_1\\), lascia alla sua sinistra il 25% del campione pensato come una fila ordinata (a destra quindi il 75%). Il secondo quartile \\(q_2\\) lascia a sinistra il 50% del campione (a destra quindi il 50%). Esso viene anche chiamato mediana. Il terzo quartile lascia a sinistrail 75% del campione (a destra quindi il 25%). Secondo lo stesso criterio, si dicono decili i quantili di ordine \\(p\\) multiplo di 0.10 e percentili i quantili di ordine \\(p\\) multiplo di 0.01.\nCome si calcolano i quantili? Consideriamo la definizione di quantile non interpolato di ordine \\(p\\) \\((0 < p < 1)\\). Si procede innanzitutto ordinando i dati in ordine crescente, \\(\\{x_1, x_2, \\dots, x_n\\}\\). Ci sono poi due possibilit√†. Se il valore \\(np\\) non √® intero, sia \\(k\\) l‚Äôintero tale che \\(k < np < k + 1\\) ‚Äì ovvero, la parte intera di \\(np\\). Allora \\(q_p = x_{k+1}.\\) Se \\(np = k\\) con \\(k\\) intero, allora \\(q_p = \\frac{1}{2}(x_{k} + x_{k+1}).\\) Se vogliamo calcolare il primo quartile \\(q_1\\), ad esempio, utilizziamo \\(p = 0.25\\). Dovendo calcolare gli altri quantili basta sostituire a \\(p\\) il valore appropriato.\nGli indici di posizione, tra le altre cose, hanno un ruolo importante, ovvero vengono utilizzati per creare una rappresentazione grafica di una distribuzione di valori che √® molto popolare e pu√≤ essere usata in alternativa ad un istogramma (in realt√† vedremo poi come possa essere combinata con un istogramma). Tale rappresentazione va sotto il nome di box-plot.\n\nPer fare un esempio, consideriamo i nove soggetti del campione clinico di Zetsche et al. (2019) che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti i valori ordinati del BDI-II (per semplicit√† li chiameremo \\(x\\)) sono i seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43. Per il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantit√† \\(np = 9 \\cdot 0.5 = 4.5\\), non intero. Quindi, \\(q_1 = x_{4 + 1} = 27\\). Per il calcolo del quantile (non interpolato) di ordine \\(p = 2/3\\) dobbiamo considerare la quantit√† \\(np = 9 \\cdot 2/3 = 6\\), intero. Quindi, \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).\n\n\n3.9.2 Diagramma a scatola\nIl diagramma a scatola (o box plot) √® uno strumento grafico utile al fine di ottenere informazioni circa la dispersione e l‚Äôeventuale simmetria o asimmetria di una distribuzione. Per costruire un box-plot si rappresenta sul piano cartesiano un rettangolo (cio√® la ‚Äúscatola‚Äù) di altezza arbitraria la cui base corrisponde alla dist intanza interquartile (IQR = \\(q_{0.75} - q_{0.25}\\)). La linea interna alla scatola rappresenta la mediana \\(q_{0.5}\\). Si tracciano poi ai lati della scatola due segmenti di retta i cui estremi sono detti ‚Äúvalore adiacente‚Äù inferiore e superiore. Il valore adiacente inferiore √® il valore pi√π piccolo tra le osservazioni che risulta maggiore o uguale al primo quartile meno la distanza corrispondente a 1.5 volte la distanza interquartile. Il valore adiacente superiore √® il valore pi√π grande tra le osservazioni che risulta minore o uguale a \\(Q_3+1.5\\) IQR. I valori esterni ai valori adiacenti (chiamati valori anomali) vengono rappresentati individualmente nel box-plot per meglio evidenziarne la presenza e la posizione.\n\n\n\n\nFigura 3.2: Box-plot: \\(M\\) √® la mediana, \\(\\bar{x}\\) √® la media aritmetica e IQR √® la distanza interquartile (\\(Q_3 - Q_1\\)).\n\n\n\n\n\nPer i dati di Zetsche et al. (2019), si utilizzi un box-plot per rappresentare graficamente la distribuzione dei punteggi BDI-II nel gruppo dei pazienti e nel gruppo di controllo.\nNella figura @ref(fig:violin-zetsche) sinistra sono rappresentati i dati grezzi. La linea curva che circonda (simmetricamente) le osservazioni √® l‚Äôistogramma lisciato (kernel density plot) che abbiamo descritto in precedenza. Nella figura @ref(fig:violin-zetsche) destra sono rappresentanti gli stessi dati: il kernel density plot √® lo stesso di prima, ma al suo interno √® stato collocato un box-plot. Entrambe le rappresentazioni suggeriscono che la distribuzione dei dati √® all‚Äôincirca simmetrica nel gruppo clinico. Il gruppo di controllo mostra invece un‚Äôasimmetria positiva.\n\nCodicebysubj <- df %>%\n  group_by(esm_id, group) %>%\n  summarise(\n    bdi = mean(bdi),\n    nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE)\n  ) %>%\n  na.omit() %>%\n  ungroup()\n\nbysubj$group <- forcats::fct_recode(\n  bysubj$group,\n  \"Controlli\\n sani\" = \"ctl\",\n  \"Depressione\\n maggiore\" = \"mdd\"\n)\n\np1 <- bysubj %>%\n  ggplot(aes(x = group, y = bdi)) +\n  geom_violin(trim = FALSE) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", dotsize = 0.7) +\n  labs(\n    x = \"\",\n    y = \"BDI-II\"\n  )\np2 <- bysubj %>%\n  ggplot(aes(x = group, y = bdi)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.05) +\n  labs(\n    x = \"\",\n    y = \"BDI-II\"\n  )\np1 + p2\n\n\n\nDue versioni di un violin plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al.¬†(2019).\n\n\n\n\n\n\n3.9.3 Sina plot\nSi noti che i box plot non sono necessariamente la rappresentazione migliore della distribuzione di una variabile. Infatti, richiedono la comprensione di concetti complessi (quali i quantili e la differenza interquantile) che non sono necessari se vogliamo presentare in maniera grafica la distribuzione della variabile e, in generale, non sono compresi da un pubblico di non specialisti. Inoltre, i box plot nascondono informazioni che di solito sono importanti. √à dunque preferibile presentare direttamente i dati.\nNella figura @ref(fig:sina-zetsche) viene presentato un cosiddetto ‚Äúsina plot‚Äù. In tale rappresentazione grafica vengono mostrate le singole osservazioni divise in classi. Ai punti viene aggiunto un jitter, cos√¨ da evitare sovrapposizioni. L‚Äôampiezza del jitter lungo l‚Äôasse \\(x\\) √® determinata dalla distribuzione della densit√† dei dati all‚Äôinterno di ciascuna classe; quindi il grafico mostra lo stesso contorno di un violin plot, ma trasmette informazioni sia sul numero di punti dati, sia sulla distribuzione della densit√†, sui valori anomali e sulla distribuzione dei dati in un formato molto semplice, comprensibile e sintetico. Per un esempio in una recente pubblicazione, possiamo considerare le figure 3 e 6 di Lazic et al. (2020).\n\nSi generi un sina plot per i dati della figura @ref(fig:violin-zetsche). Si aggiunga alla figura una rappresentazione della mediana.\n\nCodicezetsche_summary <- bysubj %>%\n  group_by(group) %>%\n  summarize(\n    bdi_mean = mean(bdi),\n    bdi_sd = sd(bdi),\n    bdi_median = median(bdi)\n  ) %>%\n  ungroup()\n\nbysubj %>%\n  ggplot(\n    aes(x = group, y = bdi, color = group)\n  ) +\n  ggforce::geom_sina(aes(color = group, size = 1, alpha = .5)) +\n  geom_errorbar(\n    aes(y = bdi_median, ymin = bdi_median, ymax = bdi_median),\n    data = zetsche_summary, width = 0.3, size = 1\n  ) +\n  labs(\n    x = \"\",\n    y = \"BDI-II\",\n    color = \"Gruppo\"\n  ) +\n  theme(legend.position = \"none\") +\n  scale_colour_grey(start = 0.7, end = 0)\n\n\n\nSina plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al.¬†(2019) con l‚Äôindicazione della mediana per ciascun gruppo.\n\n\n\n\n\n\n3.9.4 L‚Äôeccellenza grafica\nNon c‚Äô√® un unico modo ‚Äúcorretto‚Äù per la rappresentazione grafica dei dati. Ciascuno dei grafici che abbiamo discusso in precedenza ha i suoi pregi e i suoi difetti. Un ricercatore che ha molto influenzato il modo in cui viene realizzata la visualizzazione dei dati scientifici √® Edward Tufte, soprannominato dal New York Times il ‚ÄúLeonardo da Vinci dei dati.‚Äù Secondo Tufte, ‚Äúl‚Äôeccellenza nella grafica consiste nel comunicare idee complesse in modo chiaro, preciso ed efficiente‚Äù. Nella visualizzazione delle informazioni, l‚Äô‚Äúeccellenza grafica‚Äù ha l‚Äôobiettivo di comunicare al lettore il maggior numero di idee nella maniera pi√π diretta e semplice possibile. Secondo Tufte (2001), le rappresentazioni grafiche dovrebbero:\n\nmostrare i dati;\nindurre l‚Äôosservatore a riflettere sulla sostanza piuttosto che sulla progettazione grafica, o qualcos‚Äôaltro;\nevitare di distorcere quanto i dati stanno comunicando (‚Äúintegrit√† grafica‚Äù);\npresentare molte informazioni in forma succinta;\nrivelare la coerenza tra le molte dimensioni dei dati;\nincoraggiare l‚Äôosservatore a confrontare differenti sottoinsiemi di dati;\nrivelare i dati a diversi livelli di dettaglio, da una visione ampia alla struttura di base;\nservire ad uno scopo preciso (descrizione, esplorazione, o la risposta a qualche domanda);\nessere fortemente integrate con le descrizioni statistiche e verbali dei dati fornite nel testo.\n\nIn base a questi principi, figura @ref(fig:sina-zetsche) sembra fornire la rappresentazione migliore dei dati di Zetsche et al. (2019). Il seguente link fornisce alcune illustrazioni dei principi elencati sopra."
  },
  {
    "objectID": "007_freq_distr.html#commenti-e-considerazioni-finali",
    "href": "007_freq_distr.html#commenti-e-considerazioni-finali",
    "title": "3¬† Variabili e distribuzioni di frequenza",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nUna distribuzione √® una rappresentazione del modo in cui le diverse modalit√† di una variabile \\(X\\) si distribuiscono nelle unit√† statistiche che compongono il campione o la popolazione oggetto di studio. Il modo pi√π diretto per trasmettere descrivere le propriet√† della distribuzione di una variabile discreta √® quello di fornire una rappresentazione grafica della distribuzione di frequenza. In seguito vedremo la corrispondente rappresentazione che viene usata nel caso delle variabili continue.\n\n\n\n\n\n\nLazic, S. E., Semenova, E., & Williams, D. P. (2020). Determining organ weight toxicity with bayesian causal models: Improving on the analysis of relative organ weights. Scientific Reports, 10(1), 1‚Äì12.\n\n\nTufte, E. R. (2001). The visual display of quantitative information. Graphics press Cheshire, CT.\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "011_loc_scale.html",
    "href": "011_loc_scale.html",
    "title": "4¬† Indici di posizione e di scala",
    "section": "",
    "text": "L‚Äôanalisi grafica, esaminata in precedenza, costituisce la base di partenza di qualsivoglia analisi quantitativa dei dati. Tramite opportune rappresentazioni grafiche possiamo individuare alcune caratteristiche importanti di una distribuzione: per esempio, √® possibile capire se la distribuzione √® simmetrica o asimmetrica; oppure se √® unimodale o multimodale. Successivamente, possiamo calcolare degli indici numerici che descrivono in modo sintetico le caratteristiche di base dei dati esaminati (er un‚Äôintroduzione ‚Äúsoft‚Äù alla nozione di tendenza centrale di una distribuzione statistica, si segua il link)."
  },
  {
    "objectID": "011_loc_scale.html#indici-di-tendenza-centrale",
    "href": "011_loc_scale.html#indici-di-tendenza-centrale",
    "title": "4¬† Indici di posizione e di scala",
    "section": "\n4.1 Indici di tendenza centrale",
    "text": "4.1 Indici di tendenza centrale\nTra le misure di tendenza centrale, ovvero tra gli indici che forniscono un‚Äôidea dei valori attorno ai quali sono prevalentemente concentrati i dati di un campione, quella pi√π comunemente usata √® la media.\n\n4.1.1 Media\nTutti conosciamo la media aritmetica di \\(\\{x_1, x_2, \\dots, x_n\\}\\), ovvero il numero reale \\(\\bar{x}\\) definito da\n\\[\\begin{equation}\n\\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i.\n(\\#eq:mean)\n\\end{equation}\\]\nNella @ref(eq:mean) abbiamo usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione √® molto usata in statistica e viene descritta in Appendice.\nLa media gode della seguente importante propriet√†: la somma degli scarti tra ciascuna modalit√† \\(x_i\\) e la media aritmetica \\(\\bar{x}\\) √® nulla, cio√®\n\\[\\begin{equation}\n\\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\label{eq:diffmeansumzero}\n\\end{equation}\\]\nInfatti,\n\\[\n\\begin{aligned}\n\\sum_{i=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\n\\end{aligned}\n\\]\nCi√≤ ci consente di pensare alla media come al baricentro della distribuzione.\nUn‚Äôaltra propriet√† della media √® la seguente. La somma dei quadrati degli scarti tra ciascuna modalit√† \\(x_i\\) e una costante arbitraria \\(a\\), cio√®\n\\[\\begin{equation}\n\\varphi(a) = \\sum_{i=1}^n (x_i - a)^2,\\notag\n\\end{equation}\\]\n√® minima per \\(a = \\bar{x}\\).\n\nNota. Il concetto statistico di media ha suscitato molte battute. Per esempio, il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare battute simili alle precedenti. In particolare, dobbiamo notare che la media non √® sempre l‚Äôindice che meglio rappresenta la tendenza centrale di una distribuzione. In particolare, ci√≤ non accade quando la distribuzione √® asimmetrica, o in presenza di valori anomali (outlier) ‚Äì si veda il pannello di destra della figura @ref(fig:violin-zetsche). In tali circostanze, la tendenza centrale della distribuzione √® meglio rappresentata dalla mediana o dalla media spuntata.\n\n\nSi calcoli la media dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019).\n\nCodicedf <- rio::import(\n  here(\"data\", \"data.mood.csv\"),\n  header = TRUE\n)\nbysubj <- df %>%\n  group_by(group, esm_id) %>%\n  summarise(\n    bdi = mean(bdi)\n  ) %>%\n  na.omit()\n\n\n\nCodicebysubj %>%\n  group_by(group) %>%\n  summarise(\n    avg_bdi = mean(bdi)\n  )\n#> # A tibble: 2 √ó 2\n#>   group avg_bdi\n#>   <chr>   <dbl>\n#> 1 ctl      1.61\n#> 2 mdd     30.9\n\n\n\n\n4.1.2 Media spuntata\nLa media spuntata \\(\\bar{x}_t\\) (trimmed mean) non √® altro che la media dei dati calcolata considerando solo il 90% (o altra percentuale) dei dati centrali. Per calcolare \\(\\bar{x}_t\\) si ordinando i dati secondo una sequenza crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), per poi eliminare il primo 5% e l‚Äôultimo 5% dei dati della serie cos√¨ ordinata. La media spuntata √® data dalla media aritmetica dei dati rimanenti.\n\nSi calcoli la media spuntata dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019) escludendo il 10% dei valori pi√π estremi in ciascun gruppo.\n\nCodicebysubj %>%\n  group_by(group) %>%\n  summarise(\n    avg_trim_bdi = mean(bdi, trim = 0.1)\n  )\n#> # A tibble: 2 √ó 2\n#>   group avg_trim_bdi\n#>   <chr>        <dbl>\n#> 1 ctl            1  \n#> 2 mdd           30.6\n\n\n\n\n4.1.3 Moda e mediana\nIn precedenza abbiamo gi√† incontrato altri due popolari indici di tendenza centrale: la moda (Mo), ovvero il valore centrale della classe con la frequenza massima (pu√≤ succedere che una distribuzione abbia pi√π mode; in tal caso si dice multimodale e questo operatore perde il suo significato di indice di tendenza centrale) e la mediana \\(\\tilde{x}\\).\n\nSi calcolino i quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019).\n\nCodicebysubj %>%\n  group_by(group) %>%\n  summarise(\n    q25 = quantile(bdi, probs = 0.25),\n    q50 = quantile(bdi, probs = 0.50),\n    q75 = quantile(bdi, probs = 0.75)\n  )\n#> # A tibble: 2 √ó 4\n#>   group   q25   q50   q75\n#>   <chr> <dbl> <dbl> <dbl>\n#> 1 ctl       0     1     2\n#> 2 mdd      26    30    35\n\n\n\n\nNota. Si noti che solitamente i software restituiscono un valore interpolato del \\(p\\)-esimo quantile \\(q_p\\) \\((0 < p < 1)\\), il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sar√† identico a quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato qui. Se, per qualche ragione, vogliamo conoscere l‚Äôalgoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software."
  },
  {
    "objectID": "011_loc_scale.html#indici-di-dispersione",
    "href": "011_loc_scale.html#indici-di-dispersione",
    "title": "4¬† Indici di posizione e di scala",
    "section": "\n4.2 Indici di dispersione",
    "text": "4.2 Indici di dispersione\nLe medie e gli indici di posizione descritti in precedenza forniscono delle sintesi dei dati che mettono in evidenza la tendenza centrale delle osservazioni. Tali indici, tuttavia, non considerano un aspetto importante della distribuzione dei dati, ovvero la variabilit√† dei valori numerici della variabile statistica. √à dunque necessario sintetizzare la distribuzione di una variabile statistica oltre che con le misure di posizione anche tramite l‚Äôutilizzo di indicatori che valutino la dispersione delle unit√† statistice.\n\nNota. Un‚Äôintroduzione ‚Äúsoft‚Äù al tema degli indici di posizione √® fornita nel seguente link.\n\n\n4.2.1 Indici basati sull‚Äôordinamento dei dati\n√à possibile calcolare degli indici di variabilit√† basati sull‚Äôordinamento dei dati. L‚Äôindice pi√π ovvio √® l‚Äôintervallo di variazione, ovvero la distanza tra il valore massimo e il valore minimo di una distribuzione di modalit√†, mentre in precedenza abbiamo gi√† incontrato la differenza interquartile. Questi due indici, per√≤, hanno il limite di essere calcolati sulla base di due soli valori della distribuzione (\\(x_{\\text{max}}\\) e \\(x_{\\text{mini}}\\), oppure \\(x_{0.25}\\) e \\(x_{0.75}\\)). Pertanto non utilizzano tutte le informazioni che sono disponibili. Inoltre, l‚Äôintervallo di variazione ha il limite di essere pesantemente influenzato dalla presenza di valori anomali.\n\n4.2.2 Varianza\nDati i limiti delle statistiche precedenti √® pi√π comune misurare la variabilit√† di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Infatti, la misura di variabilit√† di gran lunga pi√π usata per valutare la variabilit√† di una variabile statistica √® senza dubbio la varianza. La varianza\n\\[\\begin{equation}\ns^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2\n(\\#eq:var-descr)\n\\end{equation}\\]\n√® la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione. La varianza √® una misura di dispersione pi√π complessa di quelle esaminate in precedenza. √à appropriata solo nel caso di distribuzioni simmetriche e, anch‚Äôessa, √® fortemente influenzata dai valori anomali. Inoltre, √® espressa in un‚Äôunit√† di misura che √® il quadrato dell‚Äôunit√† di misura dei dati originari e quindi ad essa non pu√≤ essere assegnata un‚Äôinterpretazione intuitiva.\n\nSi calcoli la varianza dei valori BDI-II per i dati di Zetsche et al. (2019).\nApplicando la formula precedente, per tutto il campione abbiamo\n\nCodicevar(bysubj$bdi)\n#> [1] 239.8732\n\n\n\n\n4.2.3 Precisione\nSi definisce precisione l‚Äôinverso della varianza:\n\\[\\begin{equation}\n\\tau = \\frac{1}{\\sigma^2}.\n(\\#eq:precision)\n\\end{equation}\\]\nAlcuni ritengono che la precisione sia pi√π ‚Äúintuitiva‚Äù della varianza perch√© dice quanto sono concentrati i valori attorno alla media piuttosto che quanto sono dispersi. In altri termini, si potrebbe argomentare che siamo pi√π interessati a quanto sia precisa una misurazione piuttosto che a quanto sia imprecisa. Pi√π sono dispersi i valori attorno alla media (alta varianza), meno sono precisi (poca precisione); minore √® la varianza, maggiore √® la precisione.\nLa precisione √® uno dei due parametri naturali della distribuzione gaussiana. Nei termini della @ref(eq:precision), la distribuzione gaussiana (si veda il Capitolo @ref(distr-rv-cont)) pu√≤ essere espressa nel modo seguente\n\\[\n{\\displaystyle f(y)=\\sqrt{\\frac{\\tau}{2\\pi}} e^{-{\\frac {1}{2}}\\tau\\left({y-\\mu }\\right)^{2}}},\n\\] anzich√© come\n\\[\n{\\displaystyle f(y)={\\frac {1}{\\sigma {\\sqrt {2\\pi }}}}e^{-{\\frac {1}{2}}\\left({\\frac {y-\\mu }{\\sigma }}\\right)^{2}}}.\n\\]\n\n4.2.4 Scarto tipo\nPer le ragioni espresse sopra, la misura pi√π usata della dispersione di una distribuzione di dati √® lo scarto quadratico medio (o scarto tipo, o deviazione standard), ovvero la radice quadrata della varianza1. A differenza della varianza, dunque, lo scarto tipo √® espresso nella stessa unit√† di misura dei dati. Come nel caso della varianza, anche lo scarto tipo \\(s\\) dovrebbe essere usato soltanto quando la media √® adeguata per misurare il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media \\(\\bar{x}\\), anche lo scarto tipo √® fortemente influenzato dai dati anomali (outlier), ovvero dalla presenza di uno o di pochi dati che sono molto pi√π distanti dalla media rispetto agli altri valori della distribuzione. Quando tutte le osservazioni sono uguali, \\(s = 0\\), altrimenti \\(s > 0\\).\nAllo scarto tipo pu√≤ essere assegnata una semplice interpretazione: lo scarto tipo √® simile (ma non identico) allo scarto semplice medio campionario, ovvero alla media aritmetica dei valori assoluti degli scarti dalla media. Lo scarto tipo ci dice, dunque, quanto sono distanti, in media, le singole osservazioni dal centro della distribuzione. Un‚Äôinterpretazione pi√π precisa del significato dello scarto tipo √® fornita nel Paragrafo successivo.\n\nSi calcoli lo scarto tipo per i valori BDI-II di dati di Zetsche et al. (2019).\nApplicando la formula precedente, per tutto il campione abbiamo\n\nCodicesd(bysubj$bdi)\n#> [1] 15.48784\n\n\n\n\n4.2.5 Deviazione mediana assoluta\nUna misura robusta della dispersione statistica di un campione √® la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero:\n\\[\n{\\displaystyle \\operatorname {MAD} =\\operatorname {median} \\left(\\ \\left|X_{i}-\\operatorname {median} (X)\\right|\\ \\right)}\n\\] Nel caso di una distribuzione dei dati unimodale simmetrica di forma campanulare (ovvero, normale) si ha che\n\\[\n{\\displaystyle \\text{deviazione standard} \\approx 1.4826\\ \\operatorname {MAD} .\\,}\n\\] Pertanto, solitamente i software restituiscono il valore MAD moltiplicato per una tale costante.\n\nSi calcoli il valore MAD per i valori BDI-II riportati da Zetsche et al. (2019).\nApplicando la formula precedente, per tutto il campione abbiamo\n\nCodice1.4826 * median(abs(bysubj$bdi - median(bysubj$bdi)))\n#> [1] 8.8956\n\n\nNel caso presente, i dati seguono una distribuzione bimodale, dunque \\(1.4826\\ \\operatorname {MAD}\\) produce un valore piuttosto diverso dalla deviazione standard.\n\n\n4.2.6 Indici di variabilit√† relativi\nA volte pu√≤ essere interessante effettuare un confronto fra due misure di variabilit√† di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unit√† di misura. In questi casi, le misure di variabilit√† precedentemente descritte si rivelano inadeguate in quanto dipendono dall‚Äôunit√† di misura adottata. Diventa dunque necessario ricorrere a particolari numeri adimensionali detti indici relativi di variabilit√†. Il pi√π importante di tali indici √® il coefficiente di variazione, ovvero il numero puro\n\\[\nC_v = \\frac{\\sigma}{\\bar{x}}\n\\] ottenuto dal rapporto tra la deviazione standard e la media dei dati. Un altro indice relativo di variabilit√† √® la differenza interquartile rapportata al primo quartile oppure al terzo quartile oppure alla mediana, cio√®:\n\\[\n\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\n\\]"
  },
  {
    "objectID": "011_loc_scale.html#commenti-e-considerazioni-finali",
    "href": "011_loc_scale.html#commenti-e-considerazioni-finali",
    "title": "4¬† Indici di posizione e di scala",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLe statistiche descrittive ci forniscono degli indici sintetici che riassumono i dati, ovvero le nostre misurazioni dell‚Äôintera popolazione o di un campione estratto da una popolazione. Le statistiche descrittive comprendono gli indici di tendenza centrale e gli indici di dispersione. Gli indici di tendenza centrale includono la media, la mediana e la moda, mentre gli indici di dispersione includono lo scarto tipo, la varianza, la curtosi e l‚Äôasimmetria.\n\n\n\n\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "012_correlation.html",
    "href": "012_correlation.html",
    "title": "5¬† Le relazioni tra variabili",
    "section": "",
    "text": "Nella loro ricerca, Zetsche et al. (2019) hanno misurato il livello di depressione dei soggetti utilizzando due scale psicometriche: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Il BDI-II √® uno strumento self-report che valutare la presenza e l‚Äôintensit√† di sintomi depressivi in pazienti adulti e adolescenti di almeno 13 anni di et√† con diagnosi psichiatrica mentre la CES-D √® una scala self-report progettata per misurare i sintomi depressivi che sono stati vissuti nella settimana precedente nella popolazione generale, specialmente quella degli adolescenti/giovani adulti. Una domanda ovvia che ci pu√≤ venire in mente √®: quanto sono simili le misure ottenute mediante queste due scale?\n√à chiaro che i numeri prodotti dalle scale BDI-II e CES-D non possono essere identici, e questo per due motivi: (1) la presenza degli errori di misurazione e (2) l‚Äôunit√† di misura delle due variabili. L‚Äôerrore di misurazione corrompe sempre, almeno in parte, qualunque operazione di misurazione. E questo √® vero specialmente in psicologia dove l‚Äôattendibilit√† degli strumenti di misurazione √® minore che in altre discipline (quali la fisica, ad esempio). Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere uguali √® che l‚Äôunit√† di misura delle due scale √® arbitraria. Infatti, qual √® l‚Äôunit√† di misura della depressione? Chi pu√≤ dirlo! Ma, al di l√† delle differenze derivanti dall‚Äôerrore di misurazione e dalla differente unit√† di misura, ci aspettiamo che, se le due scale misurano entrambe lo stesso costrutto, allora i valori prodotti dalle due scale dovranno essere tra loro linearmente associati. Per capire cosa si intende con ‚Äúassociazione lineare‚Äù iniziamo a guardare i dati. Per fare questo utilizziamo una rappresentazione grafica che va sotto il nome di diagramma a dispersione."
  },
  {
    "objectID": "012_correlation.html#diagramma-a-dispersione",
    "href": "012_correlation.html#diagramma-a-dispersione",
    "title": "5¬† Le relazioni tra variabili",
    "section": "\n5.1 Diagramma a dispersione",
    "text": "5.1 Diagramma a dispersione\nIl diagramma di dispersione √® la rappresentazione grafica delle coppie di punti individuati da due variabili \\(X\\) e \\(Y\\).\nPer fare un esempio concreto, consideriamo le variabili BDI-II e CES-D di Zetsche et al. (2019). Il diagramma di dispersione per tali variabili si ottiene ponendo, ad esempio, i valori BDI-II sull‚Äôasse delle ascisse e quelli del CES-D sull‚Äôasse delle ordinate. In tale grafico, fornito dalla Figura¬†5.1, cascun punto corrisponde ad un individuo del quale, nel caso presente, conosciamo il livello di depressione misurato dalle due scale psicometriche.\nDalla Figura¬†5.1 possiamo vedere che i dati mostrano una tendenza a disporsi attorno ad una retta ‚Äì nel gergo statistico, questo fatto viene espresso dicendo che i punteggi CES-D tendono ad essere linearmente associati ai punteggi BDI-II. √à ovvio, tuttavia, che tale relazione lineare √® lungi dall‚Äôessere perfetta ‚Äì se fosse perfetta, tutti i punti del diagramma a dispersione si disporrebbero esattamente lungo una retta.\n\nCodicedf <- rio::import(\n  here(\"data\", \"data.mood.csv\"),\n  header = TRUE\n)\nbysubj <- df %>%\n  group_by(esm_id, group) %>%\n  summarise(\n    bdi = mean(bdi),\n    cesd = mean(cesd_sum)\n  ) %>%\n  na.omit() %>%\n  ungroup()\nm_cesd <- bysubj %>%\n  dplyr::pull(cesd) %>%\n  mean()\nm_bdi <- bysubj %>%\n  dplyr::pull(bdi) %>%\n  mean()\nFONT_SIZE <- 9\nbysubj %>%\n  ggplot(\n    aes(x = bdi, y = cesd, color = group)\n  ) +\n  geom_point(size = 3, alpha = .9) +\n  geom_hline(yintercept = m_cesd, linetype = \"dashed\", \n             color = \"gray\") +\n  geom_vline(xintercept = m_bdi, linetype = \"dashed\", \n             color = \"gray\") +\n  geom_text(x = -1, y = 16, label = \"I\", color = \"gray\", \n            size = FONT_SIZE) +\n  geom_text(x = 0, y = 46, label = \"IV\", color = \"gray\", \n            size = FONT_SIZE) +\n  geom_text(x = 18, y = 46, label = \"III\", color = \"gray\", \n            size = FONT_SIZE) +\n  geom_text(x = 18, y = 16, label = \"II\", color = \"gray\", \n            size = FONT_SIZE) +\n  labs(\n    x = \"BDI-II\",\n    y = \"CESD\"\n  ) +\n  theme(legend.position = \"none\") +\n  scale_colour_grey(start = 0.7, end = 0)\n\n\n\nFigura 5.1: Associazione tra le variabili BDI-II e CES-D nello studio di Zetsche et al.¬†(2019). In grigio sono rappresentate le osservazioni del gruppo di controllo; in nero quelle dei pazienti."
  },
  {
    "objectID": "012_correlation.html#covarianza",
    "href": "012_correlation.html#covarianza",
    "title": "5¬† Le relazioni tra variabili",
    "section": "\n5.2 Covarianza",
    "text": "5.2 Covarianza\nIl problema che ci poniamo ora √® quello di trovare un indice numerico che descrive di quanto la nube di punti si discosta da una perfetta relazione lineare tra le due variabili, ovvero che descrive la direzione e la forza della relazione lineare tra le due variabili. Ci sono vari indici statistici che possono essere utilizzati a questo scopo.\nIniziamo a considerare il pi√π importante di tali indici, chiamato covarianza. In realt√† la definizione di questo indice non ci sorprender√† pi√π di tanto in quanto, in una forma solo apparentemente diversa, l‚Äôabbiamo gi√† incontrato in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) √® definita come la media degli scarti quadratici di ciascuna osservazione dalla media:\n\\[\nS_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\]\nInfatti, la varianza viene talvolta descritta come la ‚Äúcovarianza di una variabile con s√© stessa‚Äù.\nAdesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, chiediamoci come due variabili \\(X\\) e \\(Y\\) ‚Äúvariano insieme‚Äù (co-variano). √à facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa:\n\\[\nS_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\]\nL‚Äôequazione precedente ci fornisce dunque la definizione della covarianza.\nPer capire il significato di tale equazione, supponiamo di dividere il grafico della Figura¬†5.1 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario.\nSe prevalgono punti nel I e III quadrante, allora la nuvola di punti avr√† un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avr√† un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l‚Äôassociazione lineare si dice positiva se la covarianza √® positiva, negativa se la covarianza √® negativa.\nIl segno della covarianza ci informa sulla direzione della relazione, ma invece il valore assoluto della covarianza ci dice ben poco. Esso, infatti, dipende dall‚Äôunit√† di misura delle variabili. Nel caso presente questo concetto √® difficile da comprendere, dato che le due variabili in esame non hanno un‚Äôunit√† di misura (ovvero, hanno un‚Äôunit√† di misura arbitraria e priva di significato). Ma quest‚Äôidea diventa chiara se pensiamo alla relazione lineare tra l‚Äôaltezza e il peso delle persone, ad esempio. La covarianza tra queste due quantit√† √® certamente positiva, ma il valore assoluto della covarianza diventa pi√π grande se l‚Äôaltezza viene misurata in millimetri e il peso in grammi, e diventa pi√π piccolo l‚Äôaltezza viene misurata in metri e il peso in chilogrammi. Dunque, il valore della covarianza cambia al mutare dell‚Äôunit√† di misura delle variabili anche se l‚Äôassociazione tra le variabili resta costante."
  },
  {
    "objectID": "012_correlation.html#correlazione",
    "href": "012_correlation.html#correlazione",
    "title": "5¬† Le relazioni tra variabili",
    "section": "\n5.3 Correlazione",
    "text": "5.3 Correlazione\nDato che il valore assoluto della covarianza √® di difficile interpretazione ‚Äì in pratica, non viene mai interpretato ‚Äì √® necessario trasformare la covarianza in modo tale da renderla immune alle trasformazioni dell‚Äôunit√† di misura delle variabili. Questa operazione si dice standardizzazione e corrisponde alla divisione della covarianza per le deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili:\n\\[\nr_{XY} = \\frac{S_{XY}}{s_X s_Y}.\n\\]\nLa quantit√† che si ottiene in questo modo viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l‚Äôuno dall‚Äôaltro, la hanno introdotta).\nIl coefficiente di correlazione ha le seguenti propriet√†:\n\nha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi;\n√® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili;\nassume valori compresi tra -1 e +1.\n\nAd esso possiamo assegnare la seguente interpretazione:\n\n\n\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra);\n\n\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra);\n\n\\(-1 < r_{XY} < +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensit√† diversa;\n\n\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\).\n\n\nPer i dati della Figura¬†5.1, la covarianza √® 207.426. Il segno positivo della covarianza ci dice che tra le due variabili c‚Äô√® un‚Äôassociazione lineare positiva. Per capire qual √® l‚Äôintensit√† della relazione lineare tra le due variabili calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore √® prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva."
  },
  {
    "objectID": "012_correlation.html#correlazione-e-causazione",
    "href": "012_correlation.html#correlazione-e-causazione",
    "title": "5¬† Le relazioni tra variabili",
    "section": "\n5.4 Correlazione e causazione",
    "text": "5.4 Correlazione e causazione\nFacendo riferimento nuovamente alla Figura¬†5.1, possiamo dire che, in molte applicazioni (ma non nel caso presente!) l‚Äôasse \\(x\\) rappresenta una quantit√† nota come variabile indipendente e l‚Äôinteresse si concentra sulla sua influenza sulla variabile dipendente tracciata sull‚Äôasse \\(y\\). Ci√≤ presuppone per√≤ che sia nota la direzione in cui l‚Äôinfluenza causale potrebbe risiedere. √à importante tenere bene a mente che la correlazione √® soltanto un indice descrittivo della relazione lineare tra due variabili e in nessun caso pu√≤ essere usata per inferire alcunch√© sulle relazioni causali che legano le variabili. √à ben nota l‚Äôespressione: ‚Äúcorrelazione non significa causazione‚Äù.\nDi opinione diversa era invece Karl Pearson (1911), il quale ha affermato:\n\nQuanto spesso, quando √® stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‚Äòqual √® la sua causa?‚Äô. Questa √® una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, pu√≤ essere pi√π facile rispondere alla domanda: ‚Äòin che misura altri fenomeni sono associati con esso?‚Äô. Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze.\n\nChe alla seconda domanda posta da Pearson sia facile rispondere √® indubbio. Che la nostra comprensione di un fenomeno possa aumentare sulla base delle informazioni fornite unicamente dalle correlazioni, invece, √® molto dubbio e quasi certamente falso."
  },
  {
    "objectID": "012_correlation.html#usi-della-correlazione",
    "href": "012_correlation.html#usi-della-correlazione",
    "title": "5¬† Le relazioni tra variabili",
    "section": "\n5.5 Usi della correlazione",
    "text": "5.5 Usi della correlazione\nAnche se non pu√≤ essere usata per studiare le relazioni causali, la correlazione viene usata per molti altri scopi tra i quali, per esempio, quello di misurare la validit√† concorrente di un test psiologico. Se un test psicologico misura effettivamente ci√≤ che ci si aspetta che misuri (nel caso dell‚Äôesempio presente, la depressione), allora dovremo aspettarci che fornisca una correlazione alta con risultati di altri test che misurano lo stesso costrutto ‚Äì come nel caso dei dati di (Zetsche et al., 2019). Un‚Äôaltra propriet√† desiderabile di un test psicometrico √® la validit√† divergente: i risultati di test psicometrici che misurano costrutti diversi dovrebbero essere poco associati tra loro. In altre parole, in questo secondo caso dovremmo aspettarci che la correlazione sia bassa."
  },
  {
    "objectID": "012_correlation.html#correlazione-di-spearman",
    "href": "012_correlation.html#correlazione-di-spearman",
    "title": "5¬† Le relazioni tra variabili",
    "section": "\n5.6 Correlazione di Spearman",
    "text": "5.6 Correlazione di Spearman\nUna misura alternativa della relazione lineare tra due variabili √® fornita dal coefficiente di correlazione di Spearman e dipende soltanto dalla relazione d‚Äôordine dei dati, non dagli specifici valori dei dati. Tale misura di associazione √® appropriata quando, del fenomeno in esame, gli psicologi sono stati in grado di misurare soltanto le relazioni d‚Äôordine tra le diverse modalit√† della risposta dei soggetti, non l‚Äôintensit√† della risposta. Le variabili psicologiche che hanno questa propriet√† si dicono ordinali. Nel caso di variabili ordinali, non √® possibile sintetizzare i dati mediante le statistiche descrittive che abbiamo introdotto in questo capitolo, quali ad esempio la media e la varianza, ma √® invece solo possibile riassumere i dati mediante una distribuzione di frequenze per le varie modalit√† della risposta."
  },
  {
    "objectID": "012_correlation.html#correlazione-nulla",
    "href": "012_correlation.html#correlazione-nulla",
    "title": "5¬† Le relazioni tra variabili",
    "section": "\n5.7 Correlazione nulla",
    "text": "5.7 Correlazione nulla\nUn ultimo aspetto da mettere in evidenza a proposito della correlazione riguarda il fatto che la correlazione descrive la direzione e l‚Äôintensit√† della relazione lineare tra due variabili. Relazioni non lineari tra le variabili, anche se sono molto forti, non vengono catturate dalla correlazione. √à importante rendersi conto che una correlazione pari a zero non significa che non c‚Äô√® relazione tra le due variabili, ma solo che tra esse non c‚Äô√® una relazione lineare.\n\nLa Figura¬†5.2 fornisce un esempio di correlazione nulla in presenza di una chiara relazione (non lineare) tra due variabili.\n\n\n\n\nFigura 5.2: Due insiemi di dati (fittizi) per i quali i coefficienti di correlazione di Pearson sono entrambi 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili."
  },
  {
    "objectID": "012_correlation.html#commenti-e-considerazioni-finali",
    "href": "012_correlation.html#commenti-e-considerazioni-finali",
    "title": "5¬† Le relazioni tra variabili",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa prima fase dell‚Äôanalisi dei dati riassume i dati mediante gli strumenti della statistica descrittiva. Le tipiche domande che vengono affrontate in questa fase sono: qual √® la distribuzione delle variabili di interesse? Quali relazioni a coppie si possono osservare nel campione? Ci sono delle osservazioni ‚Äòanomale‚Äô, ovvero estremamente discrepanti rispetto alle altre, sia quando si esaminano le statistiche descrittive univariate (ovvero, quelle che riguardano le caratteristiche di una variabile presa singolarmente), sia quando vengono esaminate le statistiche bivariate (ovvero, le statistiche che descrivono l‚Äôassociazione tra le variabili)? √à importante avere ben chiare le idee su questi punti prima di procedere con qualsiasi procedura statistica di tipo inferenziale. Per rispondere alle domande che abbiamo elencato sopra, ed ad altre simili, √® molto utile procedere con delle rappresentazioni grafiche dei dati. √à chiaro che, quando disponiamo di grandi moli di dati (come √® sempre il caso in psicologia), l‚Äôanalisi descrittiva dei dati deve essere svolta mediante un software statistico.\n\n\n\n\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "Parte 2: Il calcolo delle probabilit√†",
    "section": "",
    "text": "Nel capitolo Capitolo¬†6 verr√† presentata la legge dei grandi numeri, il concetto di variabile casuale e la funzione di massa di probabilit√†."
  },
  {
    "objectID": "015_prob_intro.html",
    "href": "015_prob_intro.html",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "",
    "text": "In questa parte della dispensa verr√† introdotta la teoria delle probabilit√†. Prima di entrare nei dettagli, cerchiamo di capire perch√© la probabilit√† sia cruciale per la ricerca scientifica.\nLa teoria delle probabilit√† √® cruciale per la scienza perch√© la ricerca procede mediante l‚Äôinferenza induttiva. Non siamo mai completamente sicuri della verit√† di una proposizione (ipotesi, teoria): al valore di verit√† di una proposizione possiamo solo assegnare un giudizio probabilistico. L‚Äôapproccio bayesiano √® una scuola di pensiero che usa la probabilit√† per quantificare il grado di fiducia che pu√≤ essere attribuito ad una proposizione. L‚Äôinferenza statistica bayesiana √® un tipo di inferenza induttiva che ha lo scopo di quantificare la fiducia che si ha nell‚Äôipotesi \\(H\\) dopo il verificarsi del dato d‚Äôevidenza \\(E\\). Per quantificare un tale grado di fiducia l‚Äôinferenza statistica bayesiana utilizza la teoria delle probabilit√†. Una comprensione dell‚Äôinferenza statistica bayesiana richiede dunque, preliminarmente, la conoscenze della teoria delle probabilit√†."
  },
  {
    "objectID": "015_prob_intro.html#che-cos√®-la-probabilit√†",
    "href": "015_prob_intro.html#che-cos√®-la-probabilit√†",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "\n6.1 Che cos‚Äô√® la probabilit√†?",
    "text": "6.1 Che cos‚Äô√® la probabilit√†?\nLa definizione della probabilit√† √® un problema estremamente dibattuto ed aperto. Sono state fornite due possibili soluzioni al problema di definire il concetto di probabilit√†.\n\nLa natura della probabilit√† √® ‚Äúontologica‚Äù (ovvero, basata sulla metafisica): la probabilit√† √® una propriet√† della della realtaÃÄ, del mondo, di come sono le cose, indipendentemente dalla nostra esperienza. √à una visione che qualcuno chiama ‚Äúoggettiva‚Äù.\nLa natura della probabilit√† √® ‚Äúepistemica‚Äù (ovvero, basata sulla conoscenza): la probabilit√† si riferisce alla conoscenza che abbiamo del mondo, non al mondo in s√©. Di conseguenza √® detta, in contrapposizione alla precedente definizione, ‚Äúsoggettiva‚Äù.\n\nIn termini epistemici, la probabilit√† fornisce una misura della nostra incertezza sul verificarsi di un fenomeno, alla luce delle informazioni disponibili. Potremmo dire che c‚Äô√® una ‚Äúscala‚Äù naturale che ha per estremi il vero (1: evento certo) da una parte ed il falso (0: evento impossibile) dall‚Äôaltra. La probabilit√† √® la quantificazione di questa scala: descrive lo stato della nostra incertezza rispetto al contenuto di verit√† di una proposizione.\nL‚Äôincertezza nelle nostre previsioni pu√≤ sorgere per due ragioni fondamentalmente diverse. Il primo √® dovuto alla nostra ignoranza delle cause nascoste sottostanti o dei meccanismi che generano i dati. Questa √® appunto un‚Äôincertezza epistemica. Il secondo tipo di incertezza deriva dalla variabilit√† intrinseca dei fenomeni, che non pu√≤ essere ridotta anche se raccogliamo pi√π dati. Questa seconda forma di incertezza √® talvolta chiamata aleatoria. Come esempio concreto, consideriamo il lancio di una moneta equilibrata. Sappiamo con certezza che la probabilit√† di testa √® \\(P = 0.5\\), quindi non c‚Äô√® incertezza epistemica, ma non questo non √® sufficiente per prevedere con certezza il risultato ‚Äì ovvero, l‚Äôincertezza aleatoria persiste anche in assenza di incertezza epistemica.\nNell‚Äôinterpretazione frequentista, la probabilit√† \\(P(E)\\) rappresenta la frequenza relativa a lungo termine di un grande numero di ripetizioni di un esperimento casuale sotto le medesime condizioni. Viene stressata qui l‚Äôidea che ci√≤ di cui parliamo √® qualcosa che emerge nel momento in cui √® possibile ripetere l‚Äôesperimento casuale tante volte sotto le medesime condizioni ‚Äì sono invece esclusi gli eventi unici e irripetibili.\n\n\nL‚Äôinterpretazione bayesiana della probabilit√† fa invece ricorso ad una concezione pi√π ampia, non legata al solo evento in s√© ma che include anche il soggetto assegnante la funzione di probabilit√†. In pratica l‚Äôassegnazione di probabilit√† bayesiana viene effettuata dal decisore, in base alle proprie conoscenze a priori integrate con tutto il generico bagaglio culturale personale. In questo modo, la probabilit√† non sar√† obbligatoriamente la stessa per tutti i soggetti, ma variarier√† a seconda delle informazioni a disposizione, dell‚Äôesperienza personale e soprattutto del punto di vista proprio di ogni decisore ed √® dunque assimilabile al ‚Äúgrado di fiducia‚Äù ‚Äì in inglese degree of belief ‚Äì di un dato soggetto, in un dato istante e con un dato insieme d‚Äôinformazioni, circa l‚Äôaccadere dell‚Äôevento \\(E\\). ‚Äú[N]essuna scienza ci permetter√† di dire: il tale fatto accadr√†, andr√† cos√¨ e cos√¨, perch√© ci√≤ √® conseguenza di tale legge, e tale legge √® una verit√† assoluta, ma tanto meno ci condurr√† a concludere scetticamente: la verit√† assoluta non esiste, e quindi tale fatto pu√≤ accadere e pu√≤ non accadere, pu√≤ andare cos√¨ e pu√≤ andare in tutt‚Äôaltro modo, nulla io ne so. Quel che si potr√† dire √® questo: io prevedo che il tale fatto avverr√†, e avverr√† nel tal modo, perch√© l‚Äôesperienza del passato e l‚Äôelaborazione scientifica cui il pensiero dell‚Äôuomo l‚Äôha sottoposta mi fanno sembrare ragionevole questa previsione‚Äù (Finetti, 1931).\nL‚Äôimpostazione bayesiana, sviluppata da Ramsey e de Finetti, riconduce l‚Äôassegnazione di probabilit√† allo scommettere sul verificarsi di un evento: la probabilit√† di un evento \\(E\\) √® la quota \\(p(E)\\) che un individuo reputa di dover pagare ad un banco per ricevere ‚Äú1‚Äù ovvero ‚Äú0‚Äù verificandosi o non verificandosi \\(E\\).\nSecondo De Finetti, le valutazioni di probabilit√† degli eventi devono rispondere ai principi di equit√† e coerenza. Una scommessa risponde al principio di equit√† se il ruolo di banco e giocatore sono scambiabili in ogni momento del gioco e sempre alle stesse condizioni. Una scommessa risponde al principio di coerenza se non vi sono combinazioni di scommesse che consentano (sia al banco che al giocatore) di realizzare perdite o vincite certe.\nL‚Äôapproccio definettiano dell‚Äôimpostazione della scommessa si basa dunque sulle assunzioni di razionalit√† e coerenza del decisore, al quale √® fatto esplicito divieto di effettuare scommesse a perdita o guadagno certo. Il decisore, proponendo la scommessa, deve essere disposto a scambiare il posto dello scommettitore con quello del banco.\nIl metodo della scommessa, oltre che una definizione, fornisce un mezzo operativo di assegnazione della probabilit√†. Sulla base di questa definizione operativa, che si pu√≤ ritenere ragionevolmente soddisfatta dal comportamento di un qualunque individuo che agisca in modo razionale in condizioni di incertezza, possono essere agevolmente dimostrate tutte le propriet√† classiche della probabilit√†: essa non pu√≤ assumere valori negativi, n√© pu√≤ essere superiore all‚Äôunit√†; se \\(E\\) √® un evento certo, la sua probabilit√† √® 1; se invece \\(E\\) √® un evento impossibile, la sua probabilit√† √® 0.\nI problemi posti dall‚Äôapproccio definettiano riguardano l‚Äôarbitrariet√† dell‚Äôassegnazione soggettivit√† di probabilit√† la quale sembra negare la validit√† dell‚Äôintero costrutto teorico. In risposta a tale critica, i bayesiani sostengono che gli approcci oggettivisti alla probabilit√† nascondono scelte arbitrarie preliminari e sono basate su assunzioni implausibili. √à molto pi√π onesto esplicitare subito tutte le scelte arbitrarie effettuate nel corso dell‚Äôanalisi in modo da controllarne coerenza e razionalit√†."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali-e-probabilit√†-di-un-evento",
    "href": "015_prob_intro.html#variabili-casuali-e-probabilit√†-di-un-evento",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "\n6.2 Variabili casuali e probabilit√† di un evento",
    "text": "6.2 Variabili casuali e probabilit√† di un evento\nEsaminiamo qui di seguito alcuni concetti di base della teoria delle probabilit√†, la quale pu√≤ essere vista come un‚Äôestensione della logica.\n\n6.2.1 Eventi e probabilit√†\nNella teoria delle probabilit√† il risultato ‚Äútesta‚Äù nel lancio di una moneta √® chiamato evento.1 Un evento, denotato da una variabile binaria, corrisponde ad uno stato del mondo che si verifica oppure no. Ad esempio, \\(Y\\) = 1 pu√≤ denotare l‚Äôevento per cui il lancio di una moneta produce il risultato testa. Il funzionale \\(P(Y)\\) denota la probabilit√† con cui si ritiene che l‚Äôevento \\(Y\\) sia vero (o la proporzione di volte che si verifica tale evento osservando a lungo termine delle ripetizioni indipendenti di un esperimento casuale). Ad esempio, per il lancio di una moneta equilibrata, la probabilit√† dell‚Äôevento ‚Äúil risultato del lancio della moneta √® testa‚Äù √® scritta come \\(P(Y = 1) = 0.5.\\)\nSe la moneta √® equilibrata dobbiamo anche avere \\(P(Y = 0) = 0.5\\). I due eventi Y = 1 e \\(Y\\) = 0 sono mutuamente esclusivi nel senso che non possono entrambi verificarsi contemporaneamente: \\(P(Y = 1\\; \\land \\; Y = 0) = 0.\\) Gli eventi \\(Y\\) = 1 e \\(Y\\) = 0 di dicono esaustivi, nel senso che almeno uno di essi deve verificarsi e nessun altro tipo di evento √® possibile. Nella notazione probabilistica, \\(P(Y = 1\\; \\lor \\; Y = 0) = 1.\\) Il connettivo logico ‚Äúo‚Äù (\\(\\lor\\)) specifica eventi disgiunti, ovvero eventi che non possono verificarsi contemporaneamente (eventi incompatibili) e per i quali, perci√≤, la probabilit√† della loro congiunzione √® \\(P(A \\; \\land \\; B) = 0\\). Il connettivo logico ‚Äúe‚Äù (\\(\\land\\)), invece, specifica eventi congiunti, ovvero eventi che possono verificarsi contemporaneamente (eventi compatibili) e per i quali, perci√≤, la probabilit√† della loro congiunzione √® \\(P(A \\; \\land \\; B) > 0\\). La probabilit√† del verificarsi di due eventi congiunti \\(A\\) e \\(B\\) si pu√≤ denotare, in maniera equivalente, con la notazione precedente, oppure con \\(P(A \\cap B)\\), oppure con \\(P(A, B)\\).\nSi richiede che \\(0 \\leq P(A) \\leq 1\\), dove \\(P(A) = 0\\) denota l‚Äôevento impossibile e \\(P(A) = 1\\) denota l‚Äôevento certo. Scriviamo \\(P(\\lnot A)\\) o \\(P(\\bar{A})\\) per denotare la probabilit√† che l‚Äôevento \\(A\\) non avvenga; questa probabilit√† √® definita come \\(P(\\bar{A}) = 1 ‚àí P(A)\\).\n\n6.2.2 Spazio campione e risultati possibili\nAnche se il lancio di una moneta produce sempre uno specifico risultato nel mondo reale, possiamo anche immaginare i possibili risultati alternativi che si sarebbero potuti osservare. Quindi, anche se in uno specifico lancio la moneta d√† testa (\\(Y\\) = 1), possiamo immaginare la possibilit√† che il lancio possa avere prodotto croce (\\(Y\\) = 0). Tale ragionamento controfattuale √® la chiave per comprendere la teoria delle probabilit√† e l‚Äôinferenza statistica.\nI risultati possibili che si possono osservare come conseguenza del lancio di una moneta determinano i valori possibili che la variabile casuale pu√≤ assumere. L‚Äôinsieme \\(\\Omega\\) di tutti i risultati possibili √® chiamato spazio campione (sample space). Lo spazio campione pu√≤ essere concettualizzato come un‚Äôurna contenente una pallina per ogni possibile risultato del lancio della moneta. Su ogni pallina √® scritto il valore della variabile casuale. Uno specifico lancio di una moneta ‚Äì ovvero, l‚Äôosservazione di uno specifico valore di una variabile casuale ‚Äì √® chiamato esperimento casuale.\nIl lancio di un dado ci fornisce l‚Äôesempio di un altro esperimento casuale. Supponiamo di essere interessati all‚Äôevento ‚Äúil lancio del dado produce un numero dispari‚Äù. Un evento seleziona un sottoinsieme dello spazio campione: in questo caso, l‚Äôinsieme dei risultati \\(\\{1, 3, 5\\}\\). Se esce 3, per esempio, diciamo che si √® verificato l‚Äôevento ‚Äúdispari‚Äù (ma l‚Äôevento ‚Äúdispari‚Äù si sarebbe anche verificato anche se fosse uscito 1 o 5)."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali",
    "href": "015_prob_intro.html#variabili-casuali",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "\n6.3 Variabili casuali",
    "text": "6.3 Variabili casuali\nSia \\(Y\\) il risultato del lancio di moneta equilibrata, non di un generico lancio di una moneta, ma un‚Äôistanza specifica del lancio di una specifica moneta in un dato momento. Definita in questo modo, \\(Y\\) √® una variabile casuale, ovvero una variabile i cui valori non possono essere previsti con esattezza. Se la moneta √® equilibrata, c‚Äô√® una probabilit√† del 50% che il lancio della moneta dia come risultato ‚Äútesta‚Äù e una probabilit√† del 50% che dia come risultato ‚Äúcroce‚Äù. Per facilitare la trattazione, le variabili casuali assumono solo valori numerici. Per lo specifico lancio della moneta in questione, diciamo, ad esempio, che la variabile casuale \\(Y\\) assume il valore 1 se esce testa e il valore 0 se esce croce.\nUna variabile casuale pu√≤ essere discreta o continua. Una variabile casuale discreta puoÃÄ assumere un numero finito di valori \\(x_1, \\dots ,x_n\\), in corrispondenza degli eventi \\(E_i, \\dots, E_n\\) che si verificano con le rispettive probabilit√† \\(p_1, \\dots, p_n\\). Un esempio √® il punteggio totale di un test psicometrico costituito da item su scala Likert. Invece un esempio di una variabile casuale continua √® la distanza tra due punti, che pu√≤ assumere infiniti valori all‚Äôinterno di un certo intervallo. L‚Äôinsieme \\(S\\) dei valori che la variabile casuale pu√≤ assumere √® detto spazio dei valori o spazio degli stati.\nLa caratteristica fondamentale di una variabile casuale √® data dall‚Äôinsieme delle probabilit√† dei suoi valori, detta distribuzione di probabilit√†. Nel seguito useremo la notazione \\(P(\\cdot)\\) per fare riferimento alle distribuzioni di probabilit√† delle variabili casuali discrete e \\(p(\\cdot)\\) per fare riferimento alla densit√† di probabilit√† delle variabili casuali continue. In questo contesto, l‚Äôinsieme dei valori che la variabile casuale pu√≤ assumere √® detto supporto della sua distribuzione di probabilit√†. Il supporto di una variabile casuale pu√≤ essere finito (come nel caso di una variabile casuale uniforme di supporto \\([a, b]\\)) o infinito (nel caso di una variabile causale gaussiana il cui supporto coincide con la retta reale)."
  },
  {
    "objectID": "015_prob_intro.html#usare-la-simulazione-per-stimare-le-probabilit√†",
    "href": "015_prob_intro.html#usare-la-simulazione-per-stimare-le-probabilit√†",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "\n6.4 Usare la simulazione per stimare le probabilit√†",
    "text": "6.4 Usare la simulazione per stimare le probabilit√†\n\nIn questa dispensa verr√† adottata l‚Äôinterpretazione bayesiana delle probabilit√†. Tuttavia, le regole di base della teoria delle probabilit√† sono le stesse, indipendentemente dall‚Äôinterpretazione adottata. Pertanto, negli esempi seguenti, possiamo utilizzare la simulazione per stimare le probabilit√† degli eventi in un modo diretto, ovvero mediante la generazione di molteplici osservazioni delle variabili casuali derivate dagli eventi di interesse.\nAd esempio, per simulare in R il lancio di una moneta equilibrata iniziamo con il definire un vettore che contiene i risultati possibili del lancio della moneta (ovvero i valori possibili della variabile casuale \\(Y\\)):\n\nCodicecoin <- c(0, 1)\n\n\nL‚Äôestrazione casuale di uno di questi due possibili valori (ovvero, la simulazione di uno specifico lancio di una moneta) si realizza con la funzione sample():\n\nCodicesample(coin, size = 1)\n#> [1] 0\n\n\nIn maniera equivalente, la stessa operazione si pu√≤ realizzare mediante l‚Äôistruzione\n\nCodicerbinom(1, 1, 0.5)\n#> [1] 1\n\n\nSupponiamo di ripetere questo esperimento casuale 100 volte e di registrare i risultati cos√¨ ottenuti. La stima della probabilit√† dell‚Äôevento \\(P(Y = 1)\\) √® data dalla frequenza relativa del numero di volte in cui abbiamo osservato l‚Äôevento di interesse (\\(Y = 1\\)):\n\nCodiceM <- 100\ny <- rep(NA, M)\nfor (m in 1:M) {\n  y[m] = rbinom(1, 1, 0.5)\n}\nestimate = sum(y) / M\n\ncat(\"estimated P[Y = 1] =\", estimate)\n#> estimated P[Y = 1] = 0.53\n\n\nRipetiamo questa procedura 10 volte.\n\nCodiceflip_coin <- function(M) {\n  y <- rep(NA, M)\n  for (m in 1:M) {\n    y[m] = rbinom(1, 1, 0.5)\n  }\n  estimate <- sum(y) / M\n  cat(\"estimated P[Y = 1] =\", estimate, \"\\n\")\n}\n\n\n\nCodicefor(i in 1:10) {\n  flip_coin(100)\n}\n#> estimated P[Y = 1] = 0.44 \n#> estimated P[Y = 1] = 0.52 \n#> estimated P[Y = 1] = 0.46 \n#> estimated P[Y = 1] = 0.57 \n#> estimated P[Y = 1] = 0.47 \n#> estimated P[Y = 1] = 0.46 \n#> estimated P[Y = 1] = 0.48 \n#> estimated P[Y = 1] = 0.49 \n#> estimated P[Y = 1] = 0.47 \n#> estimated P[Y = 1] = 0.62\n\n\nDato che la moneta √® equilibrata, la stima delle probabilit√† dell‚Äôevento \\(P(Y = 1)\\) √® simile a al valore che ci aspettiamo, ovvero \\(P(Y = 1) = 0.5\\), ma il risultato ottenuto nelle simulazioni non √® esatto. Proviamo ad aumentare il numero di lanci in ciascuna simulazione:\n\nCodicefor(i in 1:10) {\n  flip_coin(1000)\n}\n#> estimated P[Y = 1] = 0.497 \n#> estimated P[Y = 1] = 0.529 \n#> estimated P[Y = 1] = 0.493 \n#> estimated P[Y = 1] = 0.511 \n#> estimated P[Y = 1] = 0.506 \n#> estimated P[Y = 1] = 0.52 \n#> estimated P[Y = 1] = 0.49 \n#> estimated P[Y = 1] = 0.495 \n#> estimated P[Y = 1] = 0.489 \n#> estimated P[Y = 1] = 0.496\n\n\nIn questo secondo caso, gli errori tendono ad essere pi√π piccoli che nel caso precedente. Cosa succede se in ciascuna simulazione esaminiamo i risultati di 10,000 lanci della moneta?\n\nCodicefor(i in 1:10) {\n  flip_coin(1e4)\n}\n#> estimated P[Y = 1] = 0.4885 \n#> estimated P[Y = 1] = 0.4957 \n#> estimated P[Y = 1] = 0.4902 \n#> estimated P[Y = 1] = 0.5032 \n#> estimated P[Y = 1] = 0.5048 \n#> estimated P[Y = 1] = 0.4931 \n#> estimated P[Y = 1] = 0.4965 \n#> estimated P[Y = 1] = 0.499 \n#> estimated P[Y = 1] = 0.4979 \n#> estimated P[Y = 1] = 0.4973\n\n\nOra le stime ottenute sono molto vicine alla vera probabilit√† che vogliamo stimare (cio√® 0.5, perch√© la moneta √® equilibrata).\nI risultati delle simulazioni precedenti pongono dunque il problema di determinare quale sia il numero di lanci di cui abbiamo bisogno per assicurarci che le stime siano accurate (ovvero, vicine al valore corretto della probabilit√†)"
  },
  {
    "objectID": "015_prob_intro.html#la-legge-dei-grandi-numeri",
    "href": "015_prob_intro.html#la-legge-dei-grandi-numeri",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "\n6.5 La legge dei grandi numeri",
    "text": "6.5 La legge dei grandi numeri\nLa visualizzazione mediante grafici contribuisce alla comprensione dei concetti della statistica e della teoria delle probabilit√†. Un modo per descrivere ci√≤ che accade all‚Äôaumentare del numero \\(M\\) di ripetizioni del lancio della moneta consiste nel registrare la stima della probabilit√† dell‚Äôevento \\(P(Y = 1)\\) in funzione del numero di ripetizioni dell‚Äôesperimento casuale per ogni \\(m \\in 1:M\\). Possiamo ottenere un grafico dell‚Äôandamento della stima di \\(P(Y = 1)\\) in funzione di \\(m\\) nel modo seguente:\n\nCodicenrep <- 1e4\nestimate <- rep(NA, nrep)\nflip_coin <- function(m) {\n  y <- rbinom(m, 1, 0.5)\n  phat <- sum(y) / m\n  phat\n}\nfor(i in 1:nrep) {\n  estimate[i] <- flip_coin(i)\n}\nd <- tibble(\n  n = 1:nrep, \n  estimate\n)\nd %>% \n  ggplot(aes(x = n, y = estimate)) +\n  geom_line() +\n  labs(\n    x = \"Numero di lanci della moneta\", \n    y = \"Stima di P(Y = 1)\"\n)\n\n\n\nFigura 6.1: Stima della probabilit√† di successo in funzione del numero dei lanci di una moneta.\n\n\n\n\nLa Figura¬†6.1, quando √® espressa su una scala lineare, non rivela chiaramente l‚Äôandamento della simulazione. Imponiamo dunque una scala logaritmica sull‚Äôasse delle ascisse (\\(x\\)). Su scala logaritmica, i valori tra 1 e 10 vengono tracciati all‚Äôincirca con la stessa ampiezza che si osserva tra i valori 50 e 700, eccetera.\n\nCodiced %>%\n  ggplot(aes(x = n, y = estimate)) +\n  geom_line() +\n  geom_hline(\n    yintercept = 0.5, color = \"gray\", size = 1\n  ) +\n  scale_x_log10(\n    breaks = c(\n      1, 3, 10, 50, 200,\n      700, 2500, 10000\n    )\n  ) +\n  labs(\n    x = \"Numero dei lanci della moneta (scala logaritmica)\",\n    y = \"Stima di P(Y = 1)\"\n  )\n\n\n\nFigura 6.2: Stima della probabilit√† di successo in funzione del numero dei lanci di una moneta.\n\n\n\n\nLa legge dei grandi numeri ci dice che, all‚Äôaumentare del numero di ripetizioni dell‚Äôesperimento casuale, la media dei risultati ottenuti tende al valore atteso, man mano che vengono eseguite pi√π prove. Nella figura Figura¬†6.2 vediamo infatti che, all‚Äôaumentare del numero M di lanci della moneta, la stima di \\(P(Y = 1)\\) converge al valore 0.5."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali-multiple",
    "href": "015_prob_intro.html#variabili-casuali-multiple",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "\n6.6 Variabili casuali multiple",
    "text": "6.6 Variabili casuali multiple\nLe variabili casuali non esistono isolatamente. Abbiamo iniziato con una sola variabile casuale \\(Y\\) che rappresenta il risultato di un singolo, specifico lancio di una moneta equlibrata. Ma supponiamo ora di lanciare la moneta tre volte. I risultati di ciascuno dei tre lanci possono essere rappresentati da una diversa variabile casuale, ad esempio, \\(Y_1 , Y_2 , Y_3\\). Possiamo assumere che ogni lancio sia indipendente, ovvero che non dipenda dal risultato degli altri lanci. Per ciascuna di queste variabili \\(Y_n\\), con \\(n \\in 1:3\\), abbiamo che \\(P(Y_n =1)=0.5\\) e \\(P(Y_n =0)=0.5\\).\n√à possibile combinare pi√π variabili casuali usando le operazioni aritmetiche. Se \\(Y_1 , Y_2, Y_3\\) sono variabili casuali che rappresentano tre lanci di una moneta equilibrata (o un lancio di tre monete equilibrate), possiamo definire la somma di tali variabili casuali come\n\\[\nZ = Y_1 + Y_2 + Y_3.\n\\]\nPossiamo simulare i valori assunti dalla variabile casuale Z simulando i valori di \\(Y_1, Y_2, Y_3\\) per poi sommarli.\n\nCodicey1 <- rbinom(1, 1, 0.5)\ny2 <- rbinom(1, 1, 0.5)\ny3 <- rbinom(1, 1, 0.5)\nc(y1, y2, y3)\n#> [1] 1 0 1\nz <- sum(c(y1, y2, y3))\ncat(\"z =\", z, \"\\n\")\n#> z = 2\n\n\novvero,\n\nCodicey <- rep(NA, 3)\nfor (i in 1:3) {\n  y[i] <- rbinom(1, 1, 0.5)\n}\ny\n#> [1] 0 1 1\nz <- sum(y)\ncat(\"z =\", z, \"\\n\")\n#> z = 2\n\n\noppure, ancora pi√π semplicemente:\n\nCodicey <- rbinom(3, 1, 0.5)\ny\n#> [1] 1 0 1\nz <- sum(y)\ncat(\"z =\", z, \"\\n\")\n#> z = 2\n\n\nPossiamo ripetere questa simulazione \\(M = 1e5\\) volte:\n\nCodiceM <- 1e5\nz <- rep(NA, M)\nfor(i in 1:M) {\n  y <- rbinom(3, 1, 0.5)\n  z[i] <- sum(y)\n}\n\n\ne calcolare una stima della probabilit√† che la variabile casuale \\(Z\\) assuma ciascuno dei possibili valori 0, 1, 2, 3:\n\nCodicetable(z) / M\n#> z\n#>       0       1       2       3 \n#> 0.12585 0.37495 0.37480 0.12440\n\n\nNel caso di 4 monete equilibrate, avremo:\n\nCodiceM <- 1e5\nz <- rep(NA, M)\nfor(i in 1:M) {\n  y <- rbinom(4, 1, 0.5)\n  z[i] <- sum(y)\n}\ntable(z) / M\n#> z\n#>       0       1       2       3       4 \n#> 0.06340 0.24917 0.37360 0.25022 0.06361\n\n\nUna variabile casuale le cui modalit√† possono essere costituite solo da numeri interi √® detta variabile casuale discreta:\n\\[\n\\mathbb{Z} = \\dots, -2, -1, 0, 1, 2, \\dots\n\\]"
  },
  {
    "objectID": "015_prob_intro.html#sec:fun-mass-prob",
    "href": "015_prob_intro.html#sec:fun-mass-prob",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "\n6.7 Funzione di massa di probabilit√†",
    "text": "6.7 Funzione di massa di probabilit√†\n√à conveniente avere una funzione che associa una probabilit√† a ciascun possibile valore di una variabile casuale. In generale, ci√≤ √® possibile se e solo se la variabile casuale √® discreta, cos√¨ com‚Äô√® stata definita nel Paragrafo precedente. Ad esempio, se consideriamo \\(Z = Y_1 + \\dots + Y_4\\) come, ad esempio, il numero di risultati ‚Äútesta‚Äù in 4 lanci della moneta, allora possiamo definire la seguente funzione:\n\\[\n\\begin{array}{rclll}\np_Z(0) & = & 1/16 & & \\mathrm{TTTT}\n\\\\\np_Z(1) & = & 4/16 & & \\mathrm{HTTT, THTT, TTHT, TTTH}\n\\\\\np_Z(2) & = & 6/16 & & \\mathrm{HHTT, HTHT, HTTH, THHT, THTH, TTTH}\n\\\\\np_Z(3) & = & 4/16 & & \\mathrm{HHHT, HHTH, HTHH, THHH}\n\\\\\np_Z(4) & = & 1/16 & & \\mathrm{HHHH}\n\\end{array}\n\\]\nIl lancio di quattro monete pu√≤ produrre 16 risultati possibili. Dato che i lanci sono indipendenti, se le monete sono equilibrate ogni possibile risultato √® ugualmente probabile. Nella tabella in alto, le sequenze dei risultati possibili del lancio delle 4 monete sono riportate nella colonna pi√π a destra. Le probabilit√† si ottengono dividendo il numero di sequenze che producono lo stesso numero di eventi testa per il numero dei risultati possibili.\nLe sequenze come \\(\\mathrm{TTTT}\\), \\(\\mathrm{HTTT}\\), ecc. sono chiamate ‚Äúeventi elementari‚Äù (corrispondono ad un possibile esito dell‚Äôesperimento casuale). L‚Äôevento \\(Z = u\\), con \\(u \\in 0 \\dots, 4\\) √® un ‚Äúevento composto‚Äù, il quale pu√≤ essere costituito da pi√π eventi elementari.\nLa funzione \\(p_Z\\) √® stata costruita per associare a ciascun valore \\(u\\) della variabile casuale \\(Z\\) la probabilit√† dell‚Äôevento \\(Z = u\\). Convenzionalmente, queste probabilit√† sono scritte come\n\\[\nP_Z(z) = P(Z = z).\n\\]\nLa parte a destra dell‚Äôuguale si pu√≤ leggere come: ‚Äúla probabilit√† che la variabile casuale \\(Z\\) assuma il valore \\(z\\)‚Äù. Una funzione definita come sopra √® detta funzione di massa di probabilit√† della variabile casuale \\(Z\\). Ad ogni variabile casuale discreta √® associata un‚Äôunica funzione di massa di probabilit√†.\nUna rappresentazione grafica della stima della funzione di massa di probabilit√† per l‚Äôesperimento casuale del lancio di quattro monete equilibrate √® fornita nella Figura¬†6.3.\n\nCodiceset.seed(1234)\nM <- 1e5\nnflips <- 4\nu <- rbinom(M, nflips, 0.5)\nx <- 0:nflips\ny <- rep(NA, nflips + 1)\nfor (n in 0:nflips) {\n  y[n + 1] <- sum(u == n) / M\n}\nbar_plot <-\n  data.frame(Z = x, count = y) %>%\n  ggplot(aes(x = Z, y = count)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(\n    breaks = 0:4,\n    labels = c(0, 1, 2, 3, 4)\n  ) +\n  labs(\n    y = \"Probabilit√† stimata P(Z = z)\"\n  )\nbar_plot\n\n\n\nFigura 6.3: Grafico di \\(M = 100,000\\) simulazioni della funzione di massa di probabilit√† di una variabile casuale definita come il numero di teste in quattro lanci di una moneta equilibrata.\n\n\n\n\nSe \\(A\\) √® un sottoinsieme della variabile casuale \\(Z\\), allora denotiamo con \\(P_{z}(A)\\) la probabilit√† assegnata ad \\(A\\) dalla distribuzione \\(P_{z}\\). Mediante una distribuzione di probabilit√† \\(P_{z}\\) √® dunque possibile determinare la probabilit√† di ciascun sottoinsieme \\(A \\subset Z\\) come\n\\[\\begin{equation}\nP_{z}(A) = \\sum_{z \\in A} P_{z}(Z = z).\n\\end{equation}\\]\nUna funzione di massa di probabilit√† soddisfa le propriet√†\n\n\n\\(0 \\leq P(X=x) \\leq 1\\),\n\n\\(\\sum_{x \\in X} P(x) = 1\\).\n\n\nNel caso dell‚Äôesempio discusso nel Paragrafo @ref(sec:fun-mass-prob), la probabilit√† che la variabile casuale \\(Z\\) sia un numero dispari √®\n\\[\nP(\\text{Z √® un numero dispari}) = P_{z}(Z = 1) + P_{z}(Z = 3) = \\frac{4}{16} + \\frac{4}{16} = \\frac{1}{2}.\n\\]\n\n\n6.7.1 Funzione di ripartizione\nData una variabile casuale discreta \\(X\\) possiamo calcolare la probabilit√† che \\(X\\) non superi un certo valore \\(x\\), ossia la sua funzione di ripartizione. Poich√® \\(X\\) assume valori discreti possiamo cumulare le probabilit√† mediante una somma:\n\\[\nF(x_k) = P(X \\leq x_k) = \\sum_{x \\leq x_k} P(x).\n\\]"
  },
  {
    "objectID": "015_prob_intro.html#commenti-e-considerazioni-finali",
    "href": "015_prob_intro.html#commenti-e-considerazioni-finali",
    "title": "6¬† La logica dell‚Äôincerto",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo capitolo abbiamo visto come si costruisce lo spazio campione di un esperimento casuale, quali sono le propriet√† di base della probabilit√† e come si assegnano le probabilit√† agli eventi definiti sopra uno spazio campione discreto. Abbiamo anche introdotto le nozioni di variabile casuale, ovvero di una variabile che assume i suoi valori in maniera casuale. Abbiamo descritto il modo di specificare la probabilit√† con cui sono una variabile casuale assume i suoi differenti valori, ovvero la funzione di ripartizione \\(F(X) = P(X < x)\\) e la funzione di massa di probabilit√†.\n\n\n\n\n\n\nFinetti, B. de. (1931). Probabilismo. Logos, 163‚Äì219."
  },
  {
    "objectID": "016_conditional_prob.html",
    "href": "016_conditional_prob.html",
    "title": "7¬† Probabilit√† condizionata",
    "section": "",
    "text": "Il fondamento della statistica bayesiana √® il teorema di Bayes e il teorema di Bayes √® una semplice ridescrizione della probabilit√† condizionata. Esaminiamo dunque la nozione di probabilit√† condizionata."
  },
  {
    "objectID": "016_conditional_prob.html#sec-bayes-cancer",
    "href": "016_conditional_prob.html#sec-bayes-cancer",
    "title": "7¬† Probabilit√† condizionata",
    "section": "\n7.1 Probabilit√† condizionata su altri eventi",
    "text": "7.1 Probabilit√† condizionata su altri eventi\nL‚Äôattribuzione di una probabilit√† ad un evento √® sempre condizionata dalle conoscenze che abbiamo a disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilit√† di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambier√† anche la probabilit√† che attribuiremo all‚Äôevento in questione. Infatti, si pu√≤ pensare che tutte le probabilit√† siano probabilit√† condizionate, anche se l‚Äôevento condizionante non √® sempre esplicitamente menzionato.\nPer introdurre la probabilit√† condizionata, Albert & Hu (2019) utilizzando il famoso paradosso delle tre carte. ‚ÄúCi sono tre carte, delle quali la prima (\\(A\\)) √® rossa su entrambi i lati, la seconda (\\(B\\)) su un lato √® rossa e sull‚Äôaltro √® bianca e la terza (\\(C\\)) √® bianca su entrambi i lati. Ponendo su un tavolo una delle tre carte, scelta a caso, ottengo che il lato visibile √® di colore rosso. Qual √® la probabilit√† che anche il lato non visibile sia di colore rosso? La risposta intuitiva porta solitamente a rispondere che la probabilit√† ricercata sia pari al 50%, in quanto solo due carte (la \\(A\\) e la \\(B\\)) possono mostrare il colore rosso e solo una di queste (la \\(A\\)) pu√≤ mostrare anche sull‚Äôaltro lato il colore rosso; tuttavia si dimostra che la risposta giusta √® 2/3.‚Äù (da Wikipedia)\nAlbert & Hu (2019) propongono di risolvere il problema con una simulazione in \\(\\textsf{R}\\): prima di tutto si sceglie una carta a caso, e poi si sceglie un lato della carta. Ci sono tre carte possibili, che chiamiamo ‚Äúc_rossa‚Äù, ‚Äúc_bianca‚Äù, e ‚Äúc_entrambi‚Äù. Per la carta rossa, ci sono due lati rossi; per la carta bianca ci sono due lati bianchi e la carta ‚Äúentrambi‚Äù ha un lato rosso e un lato bianco.\n\nCodicedf <- tibble(\n  Carta = c(\n    \"c_rossa\", \"c_rossa\", \"c_bianca\", \"c_bianca\", \"c_entrambi\", \n    \"c_entrambi\"\n  ),\n  Lato = c(\n    \"rosso\", \"rosso\", \"bianco\", \"bianco\", \"rosso\", \"bianco\"\n  )\n)\ndf\n#> # A tibble: 6 √ó 2\n#>   Carta      Lato  \n#>   <chr>      <chr> \n#> 1 c_rossa    rosso \n#> 2 c_rossa    rosso \n#> 3 c_bianca   bianco\n#> 4 c_bianca   bianco\n#> 5 c_entrambi rosso \n#> 6 c_entrambi bianco\n\n\nEstraiamo una carta a caso e classifichiamo il risultato ottenuto in base al tipo di carta e lato osservato. Ripetiamo l‚Äôesperimento 1,000 volte:\n\nCodiceset.seed(84735)\ncarte <- sample_n(df, 1e3, replace = TRUE)\ntable(carte$Carta, carte$Lato)\n#>             \n#>              bianco rosso\n#>   c_bianca      353     0\n#>   c_entrambi    143   160\n#>   c_rossa         0   344\n\n\nSe si osserva il colore rosso (seconda colonna nella tabella precedente), questo risultato √® dovuto ad una carta \\(A\\) (‚Äúrossa‚Äù) in 344 casi e ad una carta \\(B\\) (‚Äúentrambi‚Äù) in 160 casi. Quindi, nella simulazione il risultato per cui √® stato osservato un colore rosso (344 + 160) √® associato ad una carta \\(A\\) (‚Äúrossa‚Äù) in circa 2/3 dei casi ‚Äì se il lato visibile √® di colore rosso, allora c‚Äô√® una probabilit√† di 2/3 che anche il lato non visibile sia di colore rosso.\nQuesto esempio dimostra come le nostre intuizioni a proposito della probabilit√† condizionata non sono sempre corrette. Consideriamo un altro problema pi√π articolato.\n\nEsempio 7.1 \nSupponiamo che lo screening per la diagnosi precoce del tumore mammario si avvalga di un test che √® accurato al 90%, nel senso che classifica correttamente il 90% delle donne colpite dal cancro e il 90% delle donne che non hanno il cancro al seno. Supponiamo che l‚Äô1% delle donne sottoposte allo screening abbia effettivamente il cancro al seno (e d‚Äôaltra parte, il 99% non lo ha). Ci chiediamo: (1) qual √® la probabilit√† che una donna scelta a caso ottenga una mammografia positiva, e (2) se la mammografia √® positiva, qual √® la probabilit√† che vi sia effettivamente un tumore al seno?\n\n\nSoluzione. Per risolvere questo problema, supponiamo che il test in questione venga somministrato ad un grande campione di donne, diciamo a 1000 donne. Di queste 1000 donne, 10 (ovvero, l‚Äô1%) hanno il cancro al seno. Per queste 10 donne, il test dar√† un risultato positivo in 9 casi (ovvero, nel 90% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test dar√† un risultato positivo in 99 casi (se la probabilit√† di un vero positivo √® del 90%, la probabilit√† di un falso positivo √® del 10%). Questa situazione √® rappresentata nella figura Figura¬†7.1.\nCombinando i due risultati precedenti, vediamo che il test d√† un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l‚Äôhanno, per un totale di 108 risultati positivi. Dunque, la probabilit√† di ottenere un risultato positivo al test √® \\(\\frac{108}{1000}\\) = 11%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilit√† di essere una donna che ha veramente il cancro al seno, dato un risultato positivo al test (che ha le propriet√† descritte sopra), √® pari a \\(\\frac{9}{108}\\) = 8%.\n\n\n\n\nFigura 7.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne.\n\n\n\n\n\nNell‚Äôesercizio precedente, la probabilit√† dell‚Äôevento ‚Äúottenere un risultato positivo al test‚Äù √® una probabilit√† non condizionata, mentre la probabilit√† dell‚Äôevento ‚Äúavere il cancro al seno, dato che il test ha prodotto un risultato positivo‚Äù √® una probabilit√† condizionata.\nIn termini generali, la probabilit√† condizionata \\(P(A \\mid B)\\) rappresenta la probabilit√† che si verifichi l‚Äôevento \\(A\\) sapendo che si √® verificato l‚Äôevento \\(B\\). Arriviamo dunque alla seguente definizione.\n\nDefinizione 7.1 Dato un qualsiasi evento \\(A\\), si chiama probabilit√† condizionata di \\(A\\) dato \\(B\\) il numero\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) > 0,\n\\tag{7.1}\\]\ndove \\(P(A\\cap B)\\) √® la probabilit√† congiunta dei due eventi, ovvero la probabilit√† che si verifichino entrambi.\n\nConcludiamo con un problema molto semplice per consolidare la nostra comprensione del concetto di probabilit√† condizionata.\n\nEsempio 7.2 \nDa un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta una in modo casuale. Qual √® la probabilit√† che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual √® la probabilit√† che il valore numerico della carta sia 7, 8 o 9?\n\n\nSoluzione. Ci sono 13 carte di cuori, dunque la risposta alla prima domanda √® 1/4. Questa √® una probabilit√† non condizionata, dunque il suo calcolo non presenta alcuna difficolt√†. La seconda probabilit√† cercata √® una probabilit√† condizionata. Anche in questo secondo caso dobbiamo solo contare, ma, in questo caso, considerando solo un sottoinsieme di carte, ovvero le 13 carte di cuori. In questo modo √® facile arrivare al risultato cercato, ovvero 3/13. Applicando la formula Equazione¬†7.1, con \\(A\\) = 7, 8, o 9 e \\(B\\) = cuori, arriviamo allo stesso risulato:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{3/52}{13/52} = \\frac{3}{13}.\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#la-regola-moltiplicativa",
    "href": "016_conditional_prob.html#la-regola-moltiplicativa",
    "title": "7¬† Probabilit√† condizionata",
    "section": "\n7.2 La regola moltiplicativa",
    "text": "7.2 La regola moltiplicativa\nDalla definizione di probabilit√† condizionata (Equazione¬†7.1) √® possibile esprimere la probabilit√† congiunta tramite le condizionate. La regola moltiplicativa (o legge delle probabilit√† composte, o regola della catena) afferma che la probabilit√† che si verifichino due eventi \\(A\\) e \\(B\\) √® pari alla probabilit√† di uno dei due eventi moltiplicato con la probabilit√† dell‚Äôaltro evento condizionato al verificarsi del primo:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{7.2}\\]\nLa Equazione¬†7.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right)\n\\tag{7.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = {}& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot \\\\\n& P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 7.3 Da un‚Äôurna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell‚Äôurna. Indichiamo con \\(B_i\\) l‚Äôevento: ‚Äúesce una pallina bianca alla \\(i\\)-esima estrazione‚Äù e con \\(N_i\\) l‚Äôestrazione di una pallina nera. L‚Äôevento: ‚Äúescono due palline bianche nelle prime due estrazioni‚Äù √® rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l‚ÄôEquazione¬†7.2, la sua probabilit√† vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perch√© nella prima estrazione \\(\\Omega\\) √® costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilit√† condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perch√© nella seconda estrazione, se √® verificato l‚Äôevento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l‚Äôesperimento consiste nell‚Äôestrazione successiva di 3 palline, la probabilit√† che queste siano tutte bianche, per la Equazione¬†7.3, vale\n\\[\nP(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2),\n\\]\ndove la probabilit√† \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che si sia verificato l‚Äôevento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio campionario per questa probabilit√† condizionata √® costituito da 4 palline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e quindi:\n\\[\nP (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8}  = \\frac{1}{6}.\n\\]\nLa probabilit√† dell‚Äôestrazione di tre palline nere √® invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#lindipendendenza-stocastica",
    "href": "016_conditional_prob.html#lindipendendenza-stocastica",
    "title": "7¬† Probabilit√† condizionata",
    "section": "\n7.3 L‚Äôindipendendenza stocastica",
    "text": "7.3 L‚Äôindipendendenza stocastica\nUn concetto molto importante per le applicazioni statistiche della probabilit√† √® quello dell‚Äôindipendenza stocastica. L‚ÄôEquazione¬†7.1 consente di esprimere il concetto di indipendenza di un evento da un altro in forma intuitiva: se \\(A\\) e \\(B\\) sono eventi indipendenti, allora il verificarsi di \\(A\\) non influisce sulla probabilit√† del verificarsi di \\(B\\), ovvero non la condiziona, e il verificarsi di \\(B\\) non influisce sulla probabilit√† del verificarsi di \\(A\\). Infatti, per l‚ÄôEquazione¬†7.1, si ha che, se \\(A\\) e \\(B\\) sono due eventi indipendenti, risulta:\n\\[\nP(A \\mid B) = \\frac{P(A)P(B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A)P(B)}{P(A)} = P(B).\n\\]\nPossiamo dunque dire che due eventi \\(A\\) e \\(B\\) sono indipendenti se\n\\[\n\\begin{split}\nP(A \\mid B) &= P(A), \\\\\nP(B \\mid A) &= P(B).\n\\end{split}\n\\]\n\nEsempio 7.4 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = {esce un 1 o un 2 nel primo lancio} e \\(B\\) = {il punteggio totale √® 8}. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nRappresentiamo qui sotto lo spazio campione dell‚Äôesperimento casuale.\n\n\n\n\nRappresentazione dello spazio campionario dei risultati dell‚Äôesperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l‚Äôevento \\(B\\): ‚Äòil punteggio totale √® 8‚Äô.\n\n\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti. Infatti, le loro probabilit√† valgono \\(P(A) = 12/36\\) e \\(P(B) = 5/36\\) e la probabilit√† della loro intersezione √®\n\\[\nP(A \\cap B) = 1/36 = 3/108 \\neq P(A)P(B) = 5/108.\n\\]\n\n\nNota. Il concetto di indipendenza √® del tutto differente da quello di incompatibilit√†. Si noti infatti che due eventi A e B incompatibili (per i quali si ha \\(A \\cap B = \\emptyset\\)) sono statisticamente dipendenti, poich√© il verificarsi dell‚Äôuno esclude il verificarsi dell‚Äôaltro: \\(P(A \\cap B)=0 \\neq P(A)P(B)\\)."
  },
  {
    "objectID": "016_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "href": "016_conditional_prob.html#il-teorema-della-probabilit√†-totale",
    "title": "7¬† Probabilit√† condizionata",
    "section": "\n7.4 Il teorema della probabilit√† totale",
    "text": "7.4 Il teorema della probabilit√† totale\nDato un insieme finito \\(A_i\\) di eventi, nel calcolo della probabilit√† dell‚Äôunione di tutti gli eventi, se gli eventi considerati non sono a due a due incompatibili, si deve tenere conto delle loro intersezioni. In particolare, la probabilit√† dell‚Äôunione di due eventi \\(A\\) e \\(B\\) √® pari alla somma delle singole probabilit√† \\(P(A)\\) e \\(P(B)\\) diminuita della probabilit√† della loro intersezione:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\tag{7.4}\\]\nNel caso di tre eventi, si ha\n\\[\n\\begin{split}\nP(A \\cup B \\cup C) &= P(A)+P(B)+P(C)-P(A\\cap B)-P(A\\cap C) - \\\\\n& \\qquad P(B\\cap C) + P(A\\cap B\\cap C).\n\\end{split}\n\\]\nLa formula per il caso di \\(n\\) eventi si ricava per induzione.\nPer il caso di due soli eventi, se \\(A\\) e \\(B\\) sono indipendenti, l‚ÄôEquazione¬†7.4 si modifica nella relazione seguente:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A)P(B).\n\\]\nNel caso di due eventi \\(A\\) e \\(B\\) incompatibili, se cio√® \\(P(A \\cap B) = \\varnothing\\), si ha che\n\\[\nA\\cap B=\\varnothing \\Rightarrow P(A\\cup B)=P(A)+P(B).\n\\]\nSi pu√≤ dimostrare per induzione che ci√≤ vale anche per un insieme finito di eventi \\(A_{n}\\) a due a due incompatibili, ovvero che:\n\\[\nA_i\\cap A_j=\\varnothing, i\\neq j \\Rightarrow P\\left(\\bigcup_{i=1}^n A_i\\right)=\\sum_{i=1}^nP(A_i).\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#il-teorema-della-probabilit√†-assoluta",
    "href": "016_conditional_prob.html#il-teorema-della-probabilit√†-assoluta",
    "title": "7¬† Probabilit√† condizionata",
    "section": "\n7.5 Il teorema della probabilit√† assoluta",
    "text": "7.5 Il teorema della probabilit√† assoluta\nIl teorema della probabilit√† assoluta consente di calcolare la probabilit√† di un evento \\(E\\) di cui sono note le probabilit√† condizionate rispetto ad altri eventi \\((H_i)_{i\\geq 1}\\), a condizione che essi costituiscano una partizione dell‚Äôevento certo \\(\\Omega\\), ovvero\n\n\n\\(\\bigcup_{i=1}^\\infty H_i = \\Omega\\);\n\n\\(H_j \\cap H_j = \\emptyset, i\\neq j\\);\n\n\\(P(H_i) > 0, i = 1, \\dots, \\infty\\).\n\nNel caso di una partizione dello spazio campione in \\(n\\) sottoinsiemi abbiamo\n\\[\nP(E) = \\sum_{i=1}^n P(H_i\\cap E) = \\sum_{i=1}^n P(E \\mid H_i) P(H_i).\n\\]\nConsideriamo, ad esempio, una partizione dell‚Äôevento certo in tre sottoinsiemi.\n\n\n\n\nPartizione dell‚Äôevento certo \\(\\Omega\\) in tre sottoinsiemi sui quali viene definito l‚Äôevento \\(E\\).\n\n\n\n\nIn tali circostanze si ha che\n\\[\nP(E) = P(E \\cap H_1) + P(E \\cap H_2) + P(E \\cap H_3),\n\\tag{7.5}\\]\novvero\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2) + P(E \\mid H_3) P(H_3).\n\\tag{7.6}\\]\nIn base al teorema della probabilit√† assoluta, dunque, se l‚Äôevento \\(E\\) √® costituito da tutti gli eventi elementari in \\(E \\cap H_1\\), \\(E \\cap H_2\\) e \\(E \\cap H_3\\), allora la sua probabilit√† √® data dalla somma delle probabilit√† condizionate \\(P(E \\mid H_i)\\), ciascuna delle quali pesata per la probabilit√† dell‚Äôevento condizionante \\(H_i\\).\n\nEsempio 7.5 Si considerino tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un‚Äôurna anch‚Äôessa scelta a caso. Qual √® la probabilit√† che la pallina estratta sia di colore rosso?\n\n\nSoluzione. Sia \\(R\\) l‚Äôevento ‚Äúla pallina estratta √® rossa‚Äù e sia \\(U_i\\) l‚Äôevento che corrisponde alla scelta dell‚Äô\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilit√† assoluta, la probabilit√† di estrarre una pallina rossa √® dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#indipendenza-condizionale",
    "href": "016_conditional_prob.html#indipendenza-condizionale",
    "title": "7¬† Probabilit√† condizionata",
    "section": "\n7.6 Indipendenza condizionale",
    "text": "7.6 Indipendenza condizionale\nAggiungo qui delle considerazioni sul concetto di indipendenza condizionale a cui si far√† riferimento nell‚Äôultima parte della dispensa. L‚Äôindipendenza condizionale descrive situazioni in cui un‚Äôosservazione √® irrilevante o ridondante quando si valuta la certezza di un‚Äôipotesi. L‚Äôindipendenza condizionale √® solitamente formulata nei termini della probabilit√† condizionata, come un caso speciale in cui la probabilit√† dell‚Äôipotesi data un‚Äôosservazione non informativa √® uguale alla probabilit√† senza tale osservazione non informativa.\nSe \\(A\\) √® l‚Äôipotesi e \\(B\\) e \\(C\\) sono osservazioni, l‚Äôindipendenza condizionale pu√≤ essere espressa come l‚Äôuguaglianza:\n\\[\nP(A \\mid B,C)=P(A \\mid C).\n\\]\nDato che \\(P(A \\mid B,C)\\) √® uguale a \\(P(A \\mid C)\\), questa uguaglianza corrisponde all‚Äôaffermazione che \\(B\\) non fornisce alcun contributo alla certezza di \\(A\\). In questo caso si dice che \\(A\\) e \\(B\\) condizionalmente indipendenti dato \\(C\\), scritto simbolicamente come: \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\).\nIn maniera equivalente, l‚Äôindipendenza condizionale \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\) si verifica se:\n\\[\nP(A, B \\mid C) = P(A \\mid C) P(B \\mid C).\n\\]\nUn esempio √® il seguente (da Wikipedia). Siano due eventi le probabilit√† che le persone \\(A\\) e \\(B\\) tornino a casa in tempo per la cena, e il terzo evento √® il fatto che una tempesta di neve ha colpito la citt√†. Mentre sia \\(A\\) che \\(B\\) hanno una probabilit√† pi√π piccola di tornare a casa in tempo per la cena di quando non c‚Äô√® la neve, tali probabilit√† sono indipendenti l‚Äôuna dall‚Äôaltra. Cio√®, sapere che \\(A\\) √® in ritardo non ci dice nulla sul fatto che \\(B\\) sia in ritardo o meno ‚Äì \\(A\\) e \\(B\\) potrebbero vivere in quartieri diversi, percorrere distanze diverse e utilizzare mezzi di trasporto diversi. Tuttavia, se sapessimo che \\(A\\) e \\(B\\) vivono nello stesso quartiere, usano lo stesso mezzo di trasporto e lavorano nello stesso luogo, allora i due eventi non sarebbero condizionatamente indipendenti."
  },
  {
    "objectID": "016_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "016_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "7¬† Probabilit√† condizionata",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa probabilit√† condizionata √® importante perch√© ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle domande pi√π importanti delle analisi statistiche √® infatti quella che si chiede se due variabili siano associate tra loro oppure no. In questo Capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione). In seguito vedremo come sia possibile fare inferenza sull‚Äôassociazione tra variabili.\n\n\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and bayesian modeling. Chapman; Hall/CRC."
  },
  {
    "objectID": "017_bayes_theorem.html",
    "href": "017_bayes_theorem.html",
    "title": "8¬† L‚Äôinterpretazione soggettivista della probabilit√†",
    "section": "",
    "text": "Il teorema di Bayes assume un ruolo fondamentale nell‚Äôinterpretazione soggettivista della probabilit√† perch√® descrive l‚Äôaggiornamento della credenza che si aveva nel verificarsi dell‚Äôipotesi \\(H\\) (quantificata con la probabilit√† assegnata all‚Äôipotesi) in conseguenza del verificarsi dell‚Äôevidenza \\(E\\)."
  },
  {
    "objectID": "017_bayes_theorem.html#il-teorema-di-bayes",
    "href": "017_bayes_theorem.html#il-teorema-di-bayes",
    "title": "8¬† L‚Äôinterpretazione soggettivista della probabilit√†",
    "section": "\n8.1 Il teorema di Bayes",
    "text": "8.1 Il teorema di Bayes\n\nTeorema 8.1 Sia \\((H_i)_{i\\geq 1}\\) una partizione dell‚Äôevento certo \\(\\Omega\\) e sia \\(E \\subseteq \\Omega\\) un evento tale che \\(P(E) > 0\\), allora, per \\(i = 1, \\dots, \\infty\\):\n\\[\n{\\mbox{P}}(H_i \\mid E) = \\frac{{\\mbox{P}}(E \\mid H_i){\\mbox{P}}(H_i)}{\\sum_{j=1}^{\\infty}{\\mbox{P}}(H_j)P(E \\mid H_j)}.\n\\tag{8.1}\\]\n\nL‚ÄôEquazione¬†8.1 contiene tre concetti fondamentali. I primi due distinguono il grado di fiducia precedente al verificarsi dell‚Äôevidenza \\(E\\) da quello successivo al verificarsi dell‚Äôevidenza \\(E\\). Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega,\\) si definisce\n\n\nprobabilit√† a priori, \\(P(H)\\), la probabilit√† attribuita al verificarsi dell‚Äôipotesi \\(H\\) prima di sapere che si √® verificato l‚Äôevento \\(E\\);\n\nprobabilit√† a posteriori, \\(P(H \\mid E)\\), la probabilit√† assegnata ad \\(H\\) una volta che sia noto \\(E\\), ovvero l‚Äôaggiornamento della probabilit√† a priori alla luce della nuova evidenza \\(E\\).\n\nIl terzo concetto definisce la probabilit√† che ha l‚Äôevento \\(E\\) di verificarsi quando √® vera l‚Äôipotesi \\(H\\), ovvero la probabilit√† dell‚Äôevidenza in base all‚Äôipotesi. Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega\\) si definisce\n\n\nverosimiglianza di \\(H\\) dato \\(E\\), \\(P(E \\mid H)\\), la probabilit√† condizionata che si verifichi \\(E\\), se √® vera \\(H\\).\n\nSi noti che, per il calcolo della quantit√† a denominatore della Equazione¬†8.1, si ricorre al teorema della probabilit√† assoluta.\n\nEsercizio 8.1 \nConsiderando una partizione dell‚Äôevento certo \\(\\Omega\\) in due soli eventi che chiamiamo ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo conosciute le probabilit√† a priori \\(P(H_1)\\) e \\(P(H_2)\\). Consideriamo un terzo evento \\(E \\subseteq \\Omega\\) con probabilit√† non nulla di cui si conosce la verosimiglianza, ovvero si conoscono le probabilit√† condizionate \\({\\mbox{P}}(E \\mid H_1)\\) e \\(P(E \\mid H_2)\\). Supponendo che si sia verificato l‚Äôevento \\(E\\), vogliamo conoscere le probabilit√† a posteriori delle ipotesi, ovvero \\(P(H_1 \\mid E)\\) e \\(P(H_2 \\mid E)\\).\n\n\n\n\n\nFigura 8.1: Partizione dell‚Äôevento certo in due eventi chiamati ‚Äòipotesi‚Äô. L‚Äôevidenza \\(E\\) √® un sottoinsieme dello spazio campione.\n\n\n\n\n\nSoluzione. Per trovare le probabilit√† cercate scriviamo:\n\\[\n\\begin{split}\nP(H_1 \\mid E) &= \\frac{P(E \\cap H_1)}{P(E)}\\notag\\\\\n              &= \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n\\end{split}\n\\]\nSapendo che \\(E = (E \\cap H_1) \\cup (E \\cap H_2)\\) e che \\(H_1\\) e \\(H_2\\) sono eventi disgiunti, ovvero \\(H_1 \\cap H_2 = \\emptyset\\), ne segue che possiamo calcolare \\({\\mbox{P}}(E)\\) utilizzando il teorema della probabilit√† assoluta:\n\\[\n\\begin{split}\nP(E) &= P(E \\cap H_1) + P(E \\cap H_2)\\notag\\\\\n     &= P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n\\end{split}\n\\]\nSostituendo tale risultato nella formula precedente otteniamo:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n\\tag{8.2}\\]\nUn lettore attento si sar√† reso conto che, in precedenza, abbiamo gi√† applicato il teorema di Bayes quando abbiamo risolto l‚ÄôEsempio¬†7.1. In quel caso, le due ipotesi erano ‚Äúmalattia presente‚Äù, che possiamo denotare con \\(M\\), e ‚Äúmalattia assente‚Äù, \\(M^\\complement\\). L‚Äôevidenza \\(E\\) era costituita dal risultato positivo al test, ovvero \\(+\\). Con questa notazione l‚ÄôEquazione¬†8.2 diventa:\n\\[\nP(M \\mid +) = \\frac{P(+ \\mid M) P(M)}{P(+ \\mid M) P(M) + P(+ \\mid M^\\complement) P(M^\\complement)}\n\\]\nInserendo i dati nella formula, otteniamo\n\\[\n\\begin{align}\nP(M \\mid +) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "017_bayes_theorem.html#commenti-e-considerazioni-finali",
    "href": "017_bayes_theorem.html#commenti-e-considerazioni-finali",
    "title": "8¬† L‚Äôinterpretazione soggettivista della probabilit√†",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIl teorema di Bayes rende esplicito il motivo per cui la probabilit√† non possa essere pensata come uno stato oggettivo, quanto piuttosto come un‚Äôinferenza soggettiva e condizionata. Il denominatore del membro di destra della Equazione¬†8.1 eÃÄ un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantit√†: \\({\\mbox{P}}(H_i\\)) e \\({\\mbox{P}}(E \\mid H_i)\\). La probabilit√† \\({\\mbox{P}}(H_i\\)) eÃÄ la probabilit√† probabilit√† a priori (prior) dell‚Äôipotesi \\(H_i\\) e rappresenta l‚Äôinformazione che l‚Äôagente bayesiano possiede a proposito dell‚Äôipotesi \\(H_i\\). Diremo che \\({\\mbox{P}}(H_i)\\) codifica il grado di fiducia che l‚Äôagente ripone in \\(H_i\\) precedentemente al verificarsi dell‚Äôevidenza \\(E\\). Nell‚Äôinterpretazione bayesiana, \\({\\mbox{P}}(H_i)\\) rappresenta un giudizio personale dell‚Äôagente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. La probabilit√† condizionata \\({\\mbox{P}}(E \\mid H_i)\\) rappresenta invece la verosimiglianza di \\(H_i\\) dato \\(E\\) e descrive la plausibilit√† che si verifichi l‚Äôevento \\(E\\) se √® vera l‚Äôipotesi \\(H_i\\). Il teorema di Bayes descrive la regola che l‚Äôagente deve seguire per aggiornare il suo grado di fiducia nell‚Äôipotesi \\(H_i\\) alla luce del verificarsi dell‚Äôevento \\(E\\). La \\({\\mbox{P}}(H_i \\mid E)\\) √® chiamata probabilit√† a posteriori dato che rappresenta la nuova probabilit√† che l‚Äôagente assegna all‚Äôipotesi \\(H_i\\) affinch√© rimanga consistente con le nuove informazioni fornitegli da \\(E\\).\nLa probabilit√† a posteriori dipende sia dall‚Äôevidenza \\(E\\), sia dalla conoscenza a priori dell‚Äôagente \\({\\mbox{P}}(H_i)\\). √à dunque chiaro come non abbia senso parlare di una probabilit√† oggettiva: per il teorema di Bayes la probabilit√† √® definita condizionatamente alla probabilit√† a priori, la quale a sua volta, per definizione, √® un‚Äôassegnazione soggettiva. Ne segue pertanto che ogni probabilit√† deve essere considerata come una rappresentazione del grado di fiducia soggettiva dell‚Äôagente. Dato che ogni assegnazione probabilistica rappresenta uno stato di conoscenza e che ciascun particolare stato di conoscenza √® arbitrario, un accordo tra agenti diversi non √® richiesto.\nCi√≤ nonostante, la teoria delle probabilit√† ci fornisce uno strumento che, alla luce di nuove evidenze, consente di aggiornare in un modo razionale il grado di fiducia che attribuiamo ad un‚Äôipotesi, via via che nuove evidenze vengono raccolte, in modo tale da formulare un‚Äôipotesi a posteriori la quale non √® mai definitiva, ma pu√≤ sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama aggiornamento bayesiano. Vedremo nel Capitolo @sec-intro-bayes-inference come estendere l‚ÄôEquazione¬†8.1 al caso continuo."
  },
  {
    "objectID": "018_joint_prob.html",
    "href": "018_joint_prob.html",
    "title": "9¬† Probabilit√† congiunta",
    "section": "",
    "text": "La probabilit√† congiunta √® la probabilit√† che due o pi√π eventi si verifichino contemporaneamente. In questo Capitolo verr√† esaminato il caso discreto."
  },
  {
    "objectID": "018_joint_prob.html#sec-fun-join-prob",
    "href": "018_joint_prob.html#sec-fun-join-prob",
    "title": "9¬† Probabilit√† congiunta",
    "section": "\n9.1 Funzione di probabilit√† congiunta",
    "text": "9.1 Funzione di probabilit√† congiunta\nDopo aver trattato della distribuzione di probabilit√† di una variabile casuale, la quale associa ad ogni evento elementare dello spazio campione uno ed un solo numero reale, √® naturale estendere questo concetto al caso di due o pi√π variabili casuali. Iniziamo a descrivere il caso discreto con un esempio. Consideriamo l‚Äôesperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campione √®\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}.\n\\]\nDato che i tre lanci sono tra loro indipendenti, non c‚Äô√® ragione di aspettarsi che uno degli otto risultati possibili dell‚Äôesperimento sia pi√π probabile degli altri, dunque possiamo associare a ciascuno degli otto eventi elementari dello spazio campione la stessa probabilit√†, ovvero 1/8.\nDefiniamo sullo spazio campione \\(\\Omega\\) le seguenti variabili casuali:\n\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) = ‚Äúnumero di realizzazioni con il risultato testa nei tre lanci‚Äù,\n\n\\(Y \\in \\{0, 1\\}\\) = ‚Äúnumero di realizzazioni con il risultato testa nel primo lancio‚Äù.\n\nIndicando con T = ‚Äòtesta‚Äô e C = ‚Äòcroce‚Äô, si ottiene la situazione riportata nella Tabella¬†9.1.\n\n\nTabella 9.1: Spazio campione dell‚Äôesperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \\(X\\) = ‚Äònumero di realizzazioni con il risultato testa nei tre lanci‚Äô e \\(Y\\) = ‚Äònumero di realizzazioni con il risultato testa nel primo lancio‚Äô.\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\n\nCi poniamo il problema di associare un valore di probabilit√† ad ogni coppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si realizza in corrispondenza di un solo evento elementare, ovvero CCC; avr√† dunque una probabilit√† pari a\n\\[\nP(X=0, Y=0) = P(CCC) = 1/8.\n\\]\nNel caso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC. La probabilit√† dell‚Äôevento composto \\(P(X=1, Y=0)\\) √® dunque uguale alla somma delle probabilit√† dei due eventi elementari che lo costituiscono, cio√©\n\\[\nP(X=1, Y=0) = P(\\mbox{CCT}) + P(\\mbox{CTC}) = 1/8 + 1/8 = 1/4.\n\\]\nDi seguito sono riportati i calcoli per tutte le possibili coppie \\(X, Y\\):\n\\[\n\\begin{align}\nP(X = 0, Y = 0) &= P(\\omega_8 = CCC) = 1/8; \\notag\\\\\nP(X = 1, Y = 0) &= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\\nP(X = 1, Y = 1) &= P(\\omega_7 = TCC) = 1/8; \\notag\\\\\nP(X = 2, Y = 0) &= P(\\omega_4 = CTT) = 1/8; \\notag\\\\\nP(X = 2, Y = 1) &= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\\nP(X = 3, Y = 1) &= P(\\omega_1 = TTT) = 1/8; \\notag\n\\end{align}\n\\]\nLe probabilit√† cos√¨ trovate sono riportate nella Tabella¬†9.2 che descrive la distribuzione di probabilit√† congiunta delle variabili casuali \\(X\\) (‚Äúnumero di realizzazioni con il risultato testa nei tre lanci‚Äù) e \\(Y\\) (‚Äúnumero di realizzazioni con il risultato testa nel primo lancio‚Äù) per l‚Äôesperimento casuale che consiste nel lancio di tre monete equilibrate.\n\n\nTabella 9.2: Distribuzione di probabilit√† congiunta per i risultati dell‚Äôesperimento consistente nel lancio di tre monete equilibrate.\n\n\\(x \\textbackslash y\\)\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n2/8\n\n\n3\n0\n1/8\n\n\n\n\nIn generale, possiamo dire che, dato uno spazio campione discreto \\(\\Omega\\), √® possibile associare ad ogni evento elementare \\(\\omega_i\\) dello spazio campione una coppia di numeri reali \\((x, y)\\), essendo \\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente definizione.\n\nDefinizione 9.1 Siano \\(X\\) e \\(Y\\) due variabili casuali. La funzione che associa ad ogni coppia \\((x, y)\\) un valore di probabilit√† prende il nome di funzione di probabilit√† congiunta:\n\\[\nP(x, y) = P(X = x, Y = y).\n\\]\n\nIl termine ‚Äúcongiunta‚Äù deriva dal fatto che questa probabilit√† √® legata al verificarsi di una coppia di valori, il primo associato alla variabile casuale \\(X\\) ed il secondo alla variabile casuale \\(Y\\). Nel caso di due sole variabili casuali si parla di distribuzione bivariata, mentre nel caso di pi√π variabili casuali si parla di distribuzione multivariata.\n\n9.1.1 Propriet√†\nUna distribuzione di massa di probabilit√† congiunta bivariata deve soddisfare due propriet√†:\n\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\);\nla probabilit√† totale deve essere uguale a 1: \\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1.\\)\n\n\n9.1.2 Eventi\nSi noti che dalla probabilit√† congiunta possiamo calcolare la probabilit√† di qualsiasi evento definito in base alle variabili aleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto, consideriamo nuovamente l‚Äôesperimento casuale discusso in precedenza.\n\nEsercizio 9.1 \nPer la distribuzione di massa di probabilit√† congiunta riportata nella tabella Tabella¬†9.2 si trovi la probabilit√† dell‚Äôevento \\(X+Y \\leq 1\\).\n\n\nSoluzione. Per trovare la probabilit√† richiesta dobbiamo sommare le probabilit√† associate a tutte le coppie \\((x,y)\\) che soddisfano la condizione \\(X+Y \\leq 1\\), ovvero\n\\[\nP_{XY}(X+Y \\leq 1) = P_{XY}(0, 0)+ P_{XY}(0, 1) + P_{XY}(1, 0) = 3/8.\n\\]\n\n\n9.1.3 Funzioni di probabilit√† marginali\nLa distribuzione marginale di un sottoinsieme di variabili casuali √® la distribuzione di probabilit√† delle variabili contenute nel sottoinsieme. Come spiegato da Wikipedia: > il termine variabile marginale √® usato per riferirsi a quelle variabili nel sottoinsieme delle variabili che vengono trattenute ovvero utilizzate. Questo termine, marginale, √® attribuito ai valori ottenuti ad esempio sommando in una tabella di valori lungo le righe oppure lungo le colonne, trascrivendo il risultato appunto a margine rispettivamente della riga o colonna sommata. La distribuzione delle variabili marginali (la distribuzione marginale) √® ottenuta mediante marginalizzazione sopra le variabili da ‚Äúscartare‚Äù, e le variabili scartate sono dette fuori marginalizzate.\nNel caso di due variabili casuali discrete \\(X\\) e \\(Y\\) di cui conosciamo la distribuzione congiunta, la distribuzione marginale di \\(X\\), \\(P(X=x)\\), √® dunque\n\\[\nP(X = x) = \\sum_y P(X, Y = y) = \\sum_y P(X \\mid Y = y) P(Y = y),\n\\]\ndove \\(P(X = x,Y = y)\\) √® la distribuzione congiunta di \\(X, Y\\), mentre \\(P(X = x \\mid Y = y)\\) √® la distribuzione condizionata di \\(X\\) dato \\(Y\\).\nLe probabilit√† bivariate marginali e congiunte di variabili casuali discrete sono spesso rappresentate mediante tabelle di contingenza. Si noti che \\(P(X = x)\\) e \\(P(Y = y)\\) sono normalizzate:\n\\[\n\\sum_x P(X=x) = 1.0, \\quad \\sum_y P(Y=y) = 1.0.\n\\]\nNel caso continuo si sostituisce l‚Äôintegrazione alla somma ‚Äì si veda la Sezione¬†9.1.4.\n\nEsercizio 9.2 \nPer l‚Äôesperimento casuale descritto nella Sezione¬†9.1, si calcolino le probabilit√† marginali di \\(X\\) e \\(Y\\).\n\n\nSoluzione. Come indicato nella Tabella¬†9.3, \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\) e \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(i,\\) \\(P_Y (Y = i) = \\sum_x p_{xy}(x, y = i)\\).\n\n\nTabella 9.3: Distribuzione di probabilit√† congiunta \\(P(X,Y)\\) per i risultati dell‚Äôesperimento consistente nel lancio di tre monete equilibrate e probabilit√† marginali \\(P(X)\\) e \\(P(Y)\\).\n\n\\(x \\textbackslash y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n9.1.4 Marginalizzazione di variabili casuali continue\nNella trattazione della statistca bayesiana useremo spesso il concetto di ‚Äúmarginalizzazione‚Äù e vedremo equazioni come la seguente:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) = \\int_{\\theta} p(y \\mid \\theta) p(\\theta),\n\\tag{9.1}\\]\nladdove \\(y\\) e \\(\\theta\\) sono due variabili casuali continue ‚Äì nello specifico, con \\(y\\) denoteremo i dati e con \\(\\theta\\) i parametri di un modello statistico. Alla luce di quanto detto sopra, √® possibiile pensare al caso continuo indicato nella Equazione¬†9.1 come all‚Äôestensione dell‚Äôesempio discusso in questo capitolo ad un numero infinito di valori delle due variabili continue (qui \\(y\\) e \\(\\theta\\))."
  },
  {
    "objectID": "018_joint_prob.html#valore-atteso-di-una-funzione-di-una-variabile-casuale",
    "href": "018_joint_prob.html#valore-atteso-di-una-funzione-di-una-variabile-casuale",
    "title": "9¬† Probabilit√† congiunta",
    "section": "\n9.2 Valore atteso di una funzione di una variabile casuale",
    "text": "9.2 Valore atteso di una funzione di una variabile casuale\nA volte ci viene data una variabile casuale $ X$e dobbiamo lavorare con una funzione di \\(X\\). Se \\(X\\) √® una variabile casuale e \\(h(X)\\) √® una funzione di \\(X\\), allora anche \\(h(X)\\) √® una variabile casuale. Se si vuole calcolare il valore atteso di \\(h(X)\\), lo si pu√≤ fare usando la funzione di massa di probabilit√† o la funzione di densit√† di probabilit√† di \\(X\\); non √® necessario conoscere la funzione di massa di probabilit√† (o la funzione di densit√† di probabilit√†) di \\(h(X)\\).\n\nEsercizio 9.3 \nSia \\(X\\) una variabile casuale discreta. Si trovi \\(\\mathbb{E}(aX + b)\\).\n\n\nSoluzione. \\(\\mathbb{E}(aX + b) = a\\mathbb{E}(X) + b = a \\sum_{x \\in \\Omega} xP(x) + b.\\) Si noti che la soluzione ha richiesto l‚Äôuso \\(P(x)\\), e non di \\(P(aX + b)\\).\n\n\nNota. Il risultato precedente √® valido per variabili casuali continua dove la somma viene sostituita da un integrale."
  },
  {
    "objectID": "018_joint_prob.html#valore-atteso-di-una-funzione-di-molteplici-variabili-casuali",
    "href": "018_joint_prob.html#valore-atteso-di-una-funzione-di-molteplici-variabili-casuali",
    "title": "9¬† Probabilit√† congiunta",
    "section": "\n9.3 Valore atteso di una funzione di molteplici variabili casuali",
    "text": "9.3 Valore atteso di una funzione di molteplici variabili casuali\nA volte ci vengono fornite due variabili casuali \\(X\\) e \\(Y\\) e dobbiamo lavorare con una funzione di \\(X\\) e \\(Y\\). Se \\(X\\) e \\(Y\\) sono variabili casuali e \\(h(X, Y)\\) √® una funzione di \\(X\\) e \\(Y\\), allora anche \\(h( X, Y)\\) √® una variabile casuale. Se si desidera calcolare la media di \\(h(X, Y)\\), lo si pu√≤ fare utilizzando la funzione di massa di probabilit√† congiunta (o la funzione di densit√† di probabilit√† congiunta di \\(X\\) e \\(Y\\)); non √® necessario conoscere la funzione di massa di probabilit√† congiunta (o la funzione di massa congiunta funzione di densit√† di probabilit√†) di \\(h(X, Y)\\).\n\nEsercizio 9.4 ¬†\nSiano \\(X\\) e \\(Y\\) due variabili casuali discrete con distribuzione di massa di probabilit√† congiunta\n\\[\nP_{XY} (1,1) = 1/3; \\quad P_{XY}  (1,2) = 1/8; \\quad P_{XY} (2,1) = 1/2; \\quad P_{XY} (2,2) = 1/24.\n\\]\nSi trovi il valore atteso di \\(g(X, Y) = XY\\).\n\n\nSoluzione. \\[\n\\begin{align}\n\\mathbb{E}g(X, Y) &= \\mathbb{E}(XY) \\notag\\\\\n&= \\sum_{x=1}^2 \\sum_{y=1}^2 x y P_{XY}(x, y) \\notag\\\\\n&= 1 \\cdot 1 \\cdot \\frac{1}{3} +  \n   1 \\cdot 2 \\cdot \\frac{1}{8} +\n   2 \\cdot 1 \\cdot \\frac{1}{2} +\n   2 \\cdot 2 \\cdot \\frac{1}{24}\\notag\\\\\n&= \\frac{7}{4}.\\notag\n\\end{align}\n\\]\n\n\nEsercizio 9.5 \nSia \\(X_1, X_2, \\dots, X_n\\) una sequenza di variabili casuali i.i.d., ciascuna con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Si trovi il valore atteso di \\(X = X_1 + X_2 + \\dots + X_n\\).\n\n\nSoluzione. \\(\\mathbb{E}(X) = \\mathbb{E}(X_1) + \\mathbb{E}(X_2) + \\dots + \\mathbb{E}(X_n) = \\sum_{i=1}^n \\mathbb{E}(X_i) = n \\mu.\\)\n\n\nEsercizio 9.6 \nSia \\(X_1, X_2, \\dots, X_n\\) una sequenza di variabili casuali i.i.d., ciascuna con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Si definisca una nuova variabile casuale\n\\[\n\\bar{X} = \\frac{X_1 + X_2 + \\dots + X_n}{n}\n\\]\ndetta media campionaria. Si trovi il valore atteso di \\(\\bar{X}\\).\n\n\nSoluzione. \\(\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) = \\mu.\\)"
  },
  {
    "objectID": "018_joint_prob.html#distribuzioni-condizionali",
    "href": "018_joint_prob.html#distribuzioni-condizionali",
    "title": "9¬† Probabilit√† congiunta",
    "section": "\n9.4 Distribuzioni condizionali",
    "text": "9.4 Distribuzioni condizionali\nSe \\(X\\) e \\(Y\\) sono variabili casuali distribuite congiuntamente, conoscere il valore di \\(X\\) pu√≤ modificare le probabilit√† relative alla variabile casuale \\(Y\\). Per calcolare questa nuova probabilit√†, √® necessaria l‚Äôidea di una distribuzione condizionale.\n\nDefinizione 9.2 Siano \\(X\\) e \\(Y\\) variabili casuali discrete distribuite congiuntamente. Definiamo la funzione di massa di probabilit√† condizionata di \\(X\\) dato che \\(Y = y\\) nei termini seguenti:\n\\[\nP_{X \\mid Y} (x \\mid y) = P(X = x \\mid Y = y) = \\frac{P_{XY} (x, y)}{P_Y(y)}\n\\]\n\n\nEsercizio 9.7 \nSupponiamo che \\(X\\) e \\(Y\\) siano variabili casuali discrete con valori 1, 2, 3, 4 e che per \\(x,y = 1, 2, 3, 4\\) la funzione di massa di probabilit√† congiunta sia data da\n\\[\n\\begin{equation}\n  P_{XY}(x,y) =\n    \\begin{cases}\n      \\frac{1}{16} & \\text{se $x = y$}\\\\\n      \\frac{2}{16} & \\text{se $x < y$}\\\\\n      0 & \\text{se $x > y$}\n    \\end{cases}       \n\\end{equation}\n\\]\nSi trovi la funzione di probabilit√† condizionata di \\(Y\\) dato che \\(X = 3\\).\n\n\nSoluzione. La distribuzione congiunta di massa di probabilit√† √® la seguente:\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n\\(P_X(x)\\)\n\n\n\n1\n1/16\n2/16\n2/16\n2/16\n7/16\n\n\n2\n0\n1/16\n2/16\n2/16\n5/16\n\n\n3\n0\n0\n1/16\n2/16\n3/16\n\n\n4\n0\n0\n0\n1/16\n1/16\n\n\n\\(P_Y(y)\\)\n1/16\n3/16\n5/16\n7/16\n1.0\n\n\n\nDunque otteniamo\n\\[\nP_{Y\\mid X}(1 \\mid 3) =  \\frac{P_{XY}(3,1)}{P_X(3)} = 0\n\\]\n\\[\nP_{Y\\mid X}(2 \\mid 3) =  \\frac{P_{XY}(3,2)}{P_X(3)} = 0\n\\]\n\\[\nP_{Y\\mid X}(3 \\mid 3) =  \\frac{P_{XY}(3,3)}{P_X(3)} = \\frac{(1/16)}{(3/16)} = \\frac{1}{3}\n\\]\n\\[\nP_{Y\\mid X}(4 \\mid 3) =  \\frac{P_{XY}(3,4)}{P_X(3)} = \\frac{(2/16)}{(3/16)} = \\frac{2}{3}\n\\]"
  },
  {
    "objectID": "018_joint_prob.html#valore-atteso-condizionato",
    "href": "018_joint_prob.html#valore-atteso-condizionato",
    "title": "9¬† Probabilit√† congiunta",
    "section": "\n9.5 Valore atteso condizionato",
    "text": "9.5 Valore atteso condizionato\nUn valore atteso condizionato √® un valore atteso, o media, calcolato utilizzando una funzione di massa di probabilit√† condizionale (o una funzione di densit√† di probabilit√† condizionale).\n\nDefinizione 9.3 Siano \\(X\\) e \\(Y\\) variabili casuali discrete congiunte. Definiamo il valore atteso condizionato di \\(X\\) dato che \\(Y = y\\) come\n\\[\n\\begin{align}\n\\mathbb{E} (X \\mid Y = y) &= \\sum_x x P(X = x \\mid Y = y)\\notag\\\\\n&= \\sum_x x P_{X \\mid Y}(x \\mid y) \\notag\n\\end{align}\n\\]\n\n\nEsercizio 9.8 \nSi trovi il valore atteso condizionato dell‚ÄôEsercizio¬†9.7 dato che \\(X = 3\\).\n\n\nSoluzione. Abbiamo che\n\\[\n\\begin{align}\n\\mathbb{E} (X \\mid Y = 3) &= \\sum_x x P(X = x \\mid Y = 3)\\notag\\\\\n&= \\frac{1 \\cdot P_{XY}(3,1)}{P_X(3)} + \\frac{2 \\cdot P_{XY}(3,2)}{P_X(3)} +\n\\frac{3 \\cdot P_{XY}(3,3)}{P_X(3)} + \\frac{4 \\cdot P_{XY}(3,4)}{P_X(3)} \\notag\\\\\n&= 3 \\cdot \\frac{1}{3} + 4 \\cdot \\frac{2}{3} \\notag\\\\\n&= \\frac{11}{3} \\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "018_joint_prob.html#indipendenza",
    "href": "018_joint_prob.html#indipendenza",
    "title": "9¬† Probabilit√† congiunta",
    "section": "\n9.6 Indipendenza",
    "text": "9.6 Indipendenza\nLa nozione di indipendenza per le variabili casuali √® molto simile alla nozione di indipendenza per gli eventi. Due variabili casuali sono indipendenti se la conoscenza relativa a una di esse non influisce sulle probabilit√† dell‚Äôaltra. Nel caso di due variabili casuali discrete, presentiamo qui una definizione di indipendenza formulatanei termini della loro distribuzione di massa di probabilit√† congiunta.\n\nDefinizione 9.4 Due variabili casuali \\(X\\) e \\(Y\\) distribuite congiuntamente si dicono indipendenti se e solo se\n\\[\nP_{X, Y}(x, y) = P_X(x) P_Y(y).\n\\]\n\nA parole, se due variabili discrete \\(X\\) e \\(Y\\) non si influenzano, ovvero se sono statisticamente indipendenti, allora la distribuzione di massa di probabilit√† congiunta si ottiene come prodotto delle funzioni di probabilit√† marginali di \\(X\\) e \\(Y\\). Se \\(P_{X, Y}(x, y) \\neq P_X(x) P_Y(y)\\), allora le due variabili si dicono associate.\nVedremo in seguito come una misura del grado di associazione lineare tra due variabili casuali √® fornita dalla covarianza (o dalla correlazione)."
  },
  {
    "objectID": "018_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "018_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "9¬† Probabilit√† congiunta",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn alcuni casi, diverse variabili casuali possono essere associate a ciascuna unit√† statistica della popolazione. Ad esempio, immaginiamo di scegliere uno studente a caso dall‚Äôelenco di tutti gli studenti iscritti a un‚Äôuniversit√† e di misurare l‚Äôaltezza e il peso di quello studente. A ogni individuo nella popolazione degli studenti corrispondono dunque due variabili casuali, altezza e peso. Quando due o pi√π variabili casuali sono associate a ciascun elemento di una popolazione, si dice che le variabili casuali sono distribuite congiuntamente. In questo capitolo abbiamo visto come si possa rappresentare la distribuzione di massa di probabilit√† congiunta di due variabili casuali discrete e come si possano ottenere le distribuzioni marginali delle due variabili. Abbiamo anche esaminato i concetti di distribuzione marginale, distribuzione condizionata e indipendenza."
  },
  {
    "objectID": "019_density_func.html",
    "href": "019_density_func.html",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "",
    "text": "Finora abbiamo considerato solo variabili casuali discrete, cio√® variabili che assumono solo valori interi. Ma cosa succede se vogliamo usare variabili casuali per rappresentare lunghezze, o volumi, o distanze, o una qualsiasi delle altre propriet√† continue nel mondo fisico o psicologico? √à necessario generalizzare l‚Äôapproccio usato finora.\nLe variabili casuali continue assumono valori reali. L‚Äôinsieme dei numeri reali √® non numerabile perch√© √® pi√π grande dell‚Äôinsieme degli interi.1 Le leggi della probabilit√† sono le stesse per le variabili casuali discrete e quelle continue. La nozione di funzione di massa di probabilit√†, invece, deve essere sostituita dal suo equivalente continuo, ovvero dalla funzione di densit√† di probabilit√†. Lo scopo di questo Capitolo √® quello di chiarire il significato di questa nozione, usando un approccio basato sulle simulazioni."
  },
  {
    "objectID": "019_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "019_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "\n10.1 Spinner e variabili casuali continue uniformi",
    "text": "10.1 Spinner e variabili casuali continue uniformi\nConsideriamo il seguente esperimento casuale. Facciamo ruotare ad alta velocitaÃÄ uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma (individuata dall‚Äôangolo acuto con segno tra il suo asse e l‚Äôasse orizzontale del goniometro). Chiamiamo \\(\\Theta\\) la variabile casuale ‚Äúpendenza dello spinner‚Äù ‚Äì Figura¬†10.1. Nella trattazione seguente useremo i gradi e, di conseguenza, \\(\\Theta \\in [0, 360]\\).\n\n\n\n\nFigura 10.1: Uno spinner che riposa a 36 gradi, o il dieci percento del percorso intorno al cerchio. La pendenza dello spinner pu√≤ assumere qualunque valore tra 0 e 360 gradi.\n\n\n\n\nCosa implica per \\(\\Theta\\) dire che lo spinner √® simmetrico? Possiamo dire che, in ciascuna prova, la rotazione dello spinner produce un angolo qualunque da 0 a 360 gradi. In altri termini, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilit√† di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, poich√© 36 gradi √® un decimo del percorso intorno al cerchio, la probabilit√† di ottenere un qualsiasi intervallo di 36 gradi sar√† sempre uguale al 10%. Ovvero \\(\\mbox{P}(0 \\leq \\Theta \\leq 36) \\ = \\ \\frac{1}{10}\\) e \\(\\mbox{P}(200 \\leq \\Theta \\leq 236) \\ = \\ \\frac{1}{10}\\).\n√à importante notare che le probabilit√† precedenti non si riferiscono al fatto che \\(\\Theta\\) assume uno specifico valore, ma piuttosto all‚Äôevento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilit√† che la pendenza \\(\\Theta\\) dello spinner cada in intervallo √® la frazione del cerchio rappresentata dall‚Äôintervallo, cio√®,\n\\[\n\\mbox{P}(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}, \\qquad 0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360.\n\\]\nLa ragione di questo √® che le variabili casuali continue non hanno una massa di probabilit√†. Invece, una massa di probabilit√† viene assegnata alla realizzazione della variabile casuale in un intervallo di valori.\n\n10.1.1 Il paradosso delle variabili casuali continue\nNel nostro esempio, la pendenza dello spinner √® esattamente 36 gradi; ma avrebbe anche potuto essere 36.0376531 gradi, o qualunque altro valore in quell‚Äôintorno. Qual √® la probabilit√† che la pendenza dello spinner sia esattamente 36? Paradossalmente, la risposta √® zero:\n\\[\n\\mbox{P}(\\Theta = 36) = 0.\n\\]\nInfatti, se la probabilit√† di un qualunque valore fosse maggiore di zero, ogni altro possibile valore dovrebbe avere la stessa probabilit√†, dato che abbiamo assunto che tutti i valori \\(\\Theta\\) siano egualmente probabili. Ma se poi andiamo a sommare tutte queste probabilit√† il totale diventer√† maggiore di uno, il che non √® possibile.\nNel caso delle variabili casuali continue dobbiamo dunque rinunciare a qualcosa, e quel qualcosa √® l‚Äôidea che, in una distribuzione continua, ciascun valore puntuale della variabile casuale possa avere una massa di probabilit√† maggiore di zero. Il paradosso sorge perch√© una realizzazione della variabile casuale continua produce sempre un qualche numero, ma ciscuno di tali numeri ha probabilit√† nulla."
  },
  {
    "objectID": "019_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "019_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "\n10.2 La funzione di ripartizione per una variabile casuale continua",
    "text": "10.2 La funzione di ripartizione per una variabile casuale continua\nSupponiamo che \\(\\Theta \\sim \\mathcal{U}(0, 360)\\) sia la pendenza dello spinner. La funzione di ripartizione (ovvero, la distribuzione cumulativa) √® definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = \\mbox{P}(\\Theta \\leq \\theta).\n\\]\nCio√®, √® la probabilit√† che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\). In questo caso, poich√© si presume che lo spinner sia simmetrico, la funzione di distribuzione cumulativa √®\n\\[\nF_{\\Theta}(\\theta) = \\frac{\\theta}{360}.\n\\]\nQuesta √® una funzione lineare di \\(\\theta\\), cio√® \\(\\frac{1}{360} \\cdot \\theta\\), come indicato dal grafico della Figura¬†10.2.\n\n\n\n\nFigura 10.2: Funzione di distribuzione cumulativa per l‚Äôangolo \\(\\theta\\) (in gradi) risultante da una rotazione di uno spinner simmetrico. La linea tratteggiata mostra il valore a 180 gradi, che corrisponde ad una probabilit√† di 0.5, e la linea tratteggiata a 270 gradi, che corrisponde ad una probabilit√† di 0.75.\n\n\n\n\nPossiamo verificare questo risultato mediante simulazione. Per stimare la funzione di ripartizione, simuliamo \\(M\\) valori \\(\\theta^{(m)}\\) e poi li ordiniamo in ordine crescente.\n\nCodiceM <- 1000\ntheta <- runif(M, 0, 360)\ntheta_asc <- sort(theta)\nprob <- (1:M) / M\nunif_cdf_df <- data.frame(\n  theta = theta_asc,\n  prob = prob\n)\nunif_cdf_plot <-\n  unif_cdf_df %>%\n  ggplot(aes(x = theta, y = prob)) +\n  geom_line() +\n  scale_x_continuous(breaks = c(0, 90, 180, 270, 360)) +\n  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1.0)) +\n  xlab(expression(theta)) +\n  ylab(expression(F(Theta)(theta)))\nunif_cdf_plot\n\n\n\nFigura 10.3: Grafico della funzione di ripartizione di una variabile casuale \\(\\Theta\\) che rappresenta il risultato di una rotazione di uno spinner simmetrico. Come previsto, tale funzione √® una semplice funzione lineare perch√© la variabile sottostante \\(\\Theta\\) ha una distribuzione uniforme.\n\n\n\n\nAnche con M = 1000, tale grafico √® praticamente indistinguibile da quello prodotto per via analitica.\nCome nel caso delle variabili casuali discrete, la funzione di ripartizione pu√≤ essere utilizzata per calcolare la probabilit√† che la variabile casuale assuma valori in un certo intervallo. Ad esempio\n\\[\\begin{align}\n\\mbox{P}(180 < \\Theta \\leq 270) &= \\mbox{P}(\\Theta \\leq 270) \\ - \\ \\mbox{P}(\\Theta \\leq 180) \\notag\\\\\n&= F_{\\Theta}(270) - F_{\\Theta}(180)\\notag\\\\\n&= \\frac{3}{4} - \\frac{1}{2} \\notag\\\\\n&= \\frac{1}{4}.\n\\end{align}\\]"
  },
  {
    "objectID": "019_density_func.html#la-distribuzione-uniforme",
    "href": "019_density_func.html#la-distribuzione-uniforme",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "\n10.3 La distribuzione uniforme",
    "text": "10.3 La distribuzione uniforme\nDopo avere visto come generare numeri casuali uniformi da 0 a 360, consideriamo ora una variabile casuale che assume valori nell‚Äôintervallo da 0 a 1. Chiamiamo tale variabile casuale \\(\\Theta\\) e assumiamo che abbia una distribuzione continua uniforme sull‚Äôintervallo [0, 1]:\n\\[\n\\Theta \\sim \\mathcal{U}(0, 1).\n\\]\nPoich√© le probabilit√† assumono valori nell‚Äôintervallo [0, 1], possiamo pensare a \\(\\Theta\\) come ad un valore di probabilit√† preso a caso in ciascuna realizzazione dell‚Äôesperimento casuale.\nLa distribuzione uniforme √® la pi√π semplice delle distribuzioni di densit√† di probabilit√†. Per chiarire le propriet√† di tale distribuzione, iniziamo con una simulazione e generiamo 10,000 valori casuali di \\(\\Theta\\). I primi 10 di tali valori sono stampati qui di seguito:\n\nCodiceset.seed(1234)\nM <- 10000\ntheta <- runif(M)\ntheta[1:10]\n#>  [1] 0.113703411 0.622299405 0.609274733 0.623379442 0.860915384 0.640310605\n#>  [7] 0.009495756 0.232550506 0.666083758 0.514251141\n\n\nCreiamo ora un istogramma che descrive la distribuzione delle 10,000 realizzazioni \\(\\Theta\\) che abbiamo trovato:\n\nCodicedf_prob_unif <- data.frame(theta = theta)\nunif_prob_plot <-\n  ggplot(df_prob_unif, aes(theta)) +\n  geom_histogram(\n    binwidth = 1 / 34, center = 1 / 68, color = \"black\",\n    size = 0.25\n  ) +\n  scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +\n  scale_y_continuous(lim = c(0, 1000), breaks = c(500, 1000)) +\n  xlab(expression(paste(Theta, \" ~ Uniform(0, 1)\")))\nunif_prob_plot\n\n\n\nFigura 10.4: Istogramma di \\(10\\,000\\) realizzazioni \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\).\n\n\n\n\n√à chiaro che, all‚Äôaumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell‚Äôistogramma tender√† a diventare una linea retta. Ci√≤ significa che la funzione di densit√† di una variabile casuale uniforme continua √® una costante. Cio√®, se \\(\\Theta \\sim \\mathcal{U} (a, b)\\), allora \\(p_{\\Theta}(\\theta) = c\\), dove \\(c\\) √® una costante.\n\nCodiceuniform_pdf_df <- data.frame(y = c(0, 1), p_y = c(1, 1))\nuniform_pdf_plot <-\n  ggplot(uniform_pdf_df, aes(x = y, y = p_y)) +\n  geom_line(size = 0.5, color = \"#333333\") +\n  geom_point(size = 1.5, color = \"#333333\") +\n  scale_x_continuous(breaks = c(0, 1), labels = c(\"a\", \"b\")) +\n  scale_y_continuous(\n    lim = c(0, 1), breaks = c(0, 1),\n    labels = c(\"0\", \"c\")\n  ) +\n  xlab(expression(theta)) +\n  ylab(expression(paste(p[Theta], \"(\", theta, \" | a, b)\"))) +\n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = 1, y = 0, xend = 1, yend = 1),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 0),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = -0.25, y = 0, xend = 0, yend = 0)) +\n  geom_segment(aes(x = 1, y = 0, xend = 1.25, yend = 0)) +\n  geom_point(aes(x = 0, y = 0),\n    size = 1.5, shape = 21,\n    fill = \"#ffffe6\"\n  ) +\n  geom_point(aes(x = 1, y = 0),\n    size = 1.5, shape = 21,\n    fill = \"#ffffe6\"\n  )\nuniform_pdf_plot\n\n\n\nFigura 10.5: Distribuzione uniforme\n\n\n\n\nDalla Figura¬†10.5 vediamo che l‚Äôarea sottesa alla funzione di densit√† √® \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densit√† di una variabile casuale uniforme continua non dipende da \\(\\theta\\) ‚Äî √® costante e identica per ogni possibile valore \\(\\theta\\).2 Vedremo nel prossimo Paragrafo che, eseguendo una trasformazione su questa variabile casuale uniforme, possiamo creare altre variabili casuali di interesse.\n\nSi consideri una variabile casuale uniforme \\(X\\) definita sull‚Äôintervallo [0, 100]. Si trovi la probabilit√† \\(P(20 < X < 60)\\).\nPer trovare la soluzione √® sufficiente calcolare l‚Äôarea di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilit√† cercata √® dunque \\(P(20 < X < 60) = 40 \\cdot 0.01 = 0.4\\)."
  },
  {
    "objectID": "019_density_func.html#dagli-istogrammi-alle-densit√†",
    "href": "019_density_func.html#dagli-istogrammi-alle-densit√†",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "\n10.4 Dagli istogrammi alle densit√†",
    "text": "10.4 Dagli istogrammi alle densit√†\nNon esiste l‚Äôequivalente di una funzione di massa di probabilit√† per le variabili casuali continue. Esiste invece una funzione di densit√† di probabilit√† la quale, nei termini di una simulazione, pu√≤ essere concepita nel modo seguente: avendo a disposizione un numero enorme di casi, quando l‚Äôintervallo \\(\\Delta\\) di ciascuna classe \\(\\rightarrow\\) 0, il profilo dell‚Äôistogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) √® detta funzione di densitaÃÄ di probabilitaÃÄ.\nCome si trasformano gli istogrammi all‚Äôaumentare del numero di osservazioni? Per fare un esempio, considereremo una funzione di una variabile casuale uniforme \\([0, 1]\\). Nello specifico, esamineremo la funzione logit:\n\\[\n\\alpha = \\log \\left(\\frac{\\theta}{1-\\theta}\\right)\n\\]\nAlcuni valori \\(\\alpha\\) presi a caso sono i seguenti:\n\nCodiceset.seed(1234)\nM <- 10000\nlogit <- function(x) log(x / (1 - x))\ntheta <- runif(M)\nalpha <- logit(theta)\nfor (m in 1:10)\n  print(alpha[m])\n#> [1] -2.053458\n#> [1] 0.4993195\n#> [1] 0.4442646\n#> [1] 0.5039172\n#> [1] 1.822914\n#> [1] 0.5767125\n#> [1] -4.647369\n#> [1] -1.193965\n#> [1] 0.6905252\n#> [1] 0.05702001\n\n\nNei grafici seguenti, la numerosit√† cresce da \\(10\\) a \\(1\\,000\\,000\\).\n\nCodicedf_log_odds_growth <- data.frame()\nfor (log10M in 1:6) {\n  M <- 10^log10M\n  alpha <- logit(runif(M))\n  df_log_odds_growth <- rbind(\n    df_log_odds_growth,\n    data.frame(\n      alpha = alpha,\n      M = rep(sprintf(\"M = %d\", M), M)\n    )\n  )\n}\nlog_odds_growth_plot <-\n  df_log_odds_growth %>%\n  ggplot(aes(alpha)) +\n  geom_histogram(color = \"black\", bins = 75) +\n  facet_wrap(~M, scales = \"free\") +\n  scale_x_continuous(\n    lim = c(-8.5, 8.5), breaks = c(-5, 0, 5)\n  ) +\n  xlab(expression(paste(Phi, \" = \", logit(Theta)))) +\n  ylab(\"proportion of draws\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.spacing.x = unit(2, \"lines\"),\n    panel.spacing.y = unit(2, \"lines\")\n  )\nlog_odds_growth_plot\n\n\n\nFigura 10.6: Istogramma di \\(M\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta).\\) Il profilo limite dell‚Äôistogramma √® evidenziato nella figura in basso a destra che √® stata costruita usando \\(1\\,000\\,000\\) di osservazioni.\n\n\n\n\nIn un istogramma, l‚Äôarea di ciascuna barra √® proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo. Perch√© tutti gli intervalli hanno la stessa ampiezza, anche l‚Äôaltezza di ciascuna barra sar√† proporzionale alla frequenza relativa delle osservazioni in quel‚Äôintervallo.\nNella simulazione, possiamo pensare all‚Äôarea di ciascuna barra dell‚Äôistogramma come alla stima della probabilit√† che la variabile casuale assuma un valore compreso nell‚Äôintervallo considerato. All‚Äôaumentare del numero \\(M\\) di osservazioni, le probabilit√† stimate si avvicinano sempre di pi√π ai veri valori della probabilit√†. All‚Äôaumentare del numero degli intervalli (quando l‚Äôampiezza \\(\\Delta\\) dell‚Äôintervallo \\(\\rightarrow\\) 0), il profilo dell‚Äôistogramma tende a diventare una curva continua. Tale curva continua √® la funzione di densit√† di probabilit√† della variabile casuale. Per l‚Äôesempio presente, con \\(M =1\\,000\\,000\\), otteniamo il grafico riportato nella figura @ref(fig:hist-dens-example).\n\nCodiceM <- 1e6\nalpha <- logit(runif(M))\ndensity_limit_df <- data.frame(alpha = alpha)\ndensity_limit_plot <-\n  density_limit_df %>%\n  ggplot(aes(alpha)) +\n  geom_histogram(\n    stat = \"density\", n = 75, color = \"black\", size = 0.15\n  ) +\n  stat_function(\n    fun = dlogis,\n    args = list(location = 0, scale = 1),\n    col = \"black\",\n    size = 0.3\n  ) +\n  scale_x_continuous(\n    lim = c(-9, 9),\n    breaks = c(-6, -4, -2, 0, 2, 4, 6)\n  ) +\n  xlab(\n    expression(paste(Phi, \" = \", logit(Theta)))\n  ) +\n  ylab(\"Frequenza relativa\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\ndensity_limit_plot\n\n\n\nFigura 10.7: Istogramma di \\(M = 1\\,000\\,000\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0,1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta)\\). La spezzata nera congiunge i punti centrali superiori delle barre dell‚Äôistogramma. Nel limite, quando il numero di osservazioni e di barre tende all‚Äôinfinito, tale spezzata approssima la funzione di densit√† di probabilit√† della variabile casuale.\n\n\n\n\nNella statistica descrittiva abbiamo gi√† incontrato una rappresentazione che ha lo stesso significato della funzione di densit√†, ovvero il kernel density plot. La stima della densit√† del kernel (KDE), infatti, √® un metodo non parametrico per stimare la funzione di densit√† di probabilit√† di una variabile casuale."
  },
  {
    "objectID": "019_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "href": "019_density_func.html#funzione-di-densit√†-di-probabilit√†",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "\n10.5 Funzione di densit√† di probabilit√†",
    "text": "10.5 Funzione di densit√† di probabilit√†\nPer descrivere le probabilit√† che possono essere associate ad una variabile casuale continua \\(X\\) √® necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due propriet√†:\n\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l‚Äôordinata della funzione di densit√† √® 0 o positiva;\n\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l‚Äôarea sottesa dalla \\(p(x)\\) √® unitaria3;\n\n\\(p(a < x < b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l‚Äôarea sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilit√† che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. √à possibile che \\(p(x) > 1\\), quindi una densit√† di probabilit√† non pu√≤ essere interpretata come una probabilit√†. Piuttosto, la densit√† \\(p(x)\\) pu√≤ essere utilizzata per confrontare la fiducia relativa che pu√≤ essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui √® disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) > p(x_l)\\), allora possiamo concludere che √® pi√π probabile, in termini relativi, osservare realizzazioni \\(X\\) nell‚Äôintorno di \\(x_k\\) piuttosto che nell‚Äôintorno di \\(x_l\\)."
  },
  {
    "objectID": "019_density_func.html#la-funzione-di-ripartizione",
    "href": "019_density_func.html#la-funzione-di-ripartizione",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "\n10.6 La funzione di ripartizione",
    "text": "10.6 La funzione di ripartizione\nLa funzione di ripartizione \\(F(X)\\) √® quella funzione che associa a ogni valore di una variabile casuale \\(X\\) la probabilit√† che la variabile assuma valore minore o uguale a un prefissato valore \\(x_k\\). Come nel caso discreto, anche nel caso continuo la funzione di ripartizione √® sempre non negativa, monotona non decrescente tra \\(0\\) e \\(1\\), tale che:\n\\[\n\\lim_{x \\to -\\infty} F_x(X) = F_X(-\\infty) = 0, \\quad \\lim_{x \\to +\\infty} F_X(X) = F_X(+\\infty) = 1.\n\\]\n\n\n\n\n\nSe \\(X\\) √® una variabile aleatoria continua, la funzione di ripartizione √®:\n\\[\nF(x_k) = P(X \\leq x_k) = \\int_{-\\infty}^{x_k} f(x) \\,\\operatorname {d}\\!x .\n\\]"
  },
  {
    "objectID": "019_density_func.html#media-e-mediana",
    "href": "019_density_func.html#media-e-mediana",
    "title": "10¬† La densit√† di probabilit√†",
    "section": "\n10.7 Media e mediana",
    "text": "10.7 Media e mediana\nConcludiamo questo capitolo con alcune considerazioni relative al contronto tra la media (valore atteso) e la mediana, nel caso di variabili casuali continue.\nPer distribuzioni simmetriche, sappiamo che la media e la mediana sono uguali. Chiediamoci ora cosa succede, nel caso di variabili casuali continue, nel caso di distribuzioni asimmetriche.\nLa mediana indica il punto in cui la ‚Äúmassa totale‚Äù della distribuzione √® suddivisa in due porzioni uguali. Nel caso della densit√† di probabilit√†, ciascuna di queste porzioni rappresenta un‚Äôarea uguale, \\(A_1 = A_2 = 1/2\\) poich√© l‚Äôarea totale sottesa alla funzione di densit√† √® 1 per definizione.\n\n\n\n\nFigura 10.8: Qual √® la differenza tra mediana e media in una funzione di densit√†?\n\n\n\n\nLa Figura¬†10.8 mostra come differiscono i due concetti di mediana (indicata dalla linea verticale) e media (indicata dal ‚Äúpunto di equilibrio‚Äù triangolare). A sinistra, per una densit√† di probabilit√† simmetrica, la media e la mediana coincidono. A destra, una piccola porzione della distribuzione √® stata spostata all‚Äôestremo destro. Questa modifica non ha influito sulla posizione della mediana, poich√© le aree a destra e a sinistra della linea verticale sono ancora uguali. In altri termini, la mediana, \\(x_m\\), divide l‚Äôarea sottesa alla funzione di densit√† in due porzioni uguali:\n\\[\n\\int_{-\\infty}^{x_m} p(x) dx = \\int_{x_m}^{-\\infty} p(x) dx = \\frac{1}{2}.\n\\]\nSegue da tale definizione che la mediana √® il valore \\(x\\) per il quale la distribuzione cumulativa soddisfa\n\\[\nF(x_m) = \\frac{1}{2}.\n\\]\nTuttavia, il fatto che una parte della massa sia stata allontanata verso destra porta a uno spostamento della media della distribuzione, per compensare tale cambiamento. In altre parole, la media contiene pi√π informazioni sulla distribuzione ‚Äúspaziale‚Äù delle osservazioni, rispetto alla mediana. Ci√≤ deriva dal fatto che la media della distribuzione (il valore atteso) √® una ‚Äúsomma‚Äù ‚Äì cio√® √® un integrale ‚Äì di termini cha hanno la forma \\(x p(x) \\Delta x\\). Quindi la posizione lungo l‚Äôasse \\(x\\), ovvero \\(x\\), e non solo la ‚Äúmassa‚Äù, \\(p(x) \\Delta x\\), influenza il contributo che le componenti della distribuzione hanno sulla media."
  },
  {
    "objectID": "020_expval_var.html",
    "href": "020_expval_var.html",
    "title": "11¬† Valore atteso e varianza",
    "section": "",
    "text": "Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densit√† di probabilit√†. Una descrizione pi√π sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cio√® il baricentro della distribuzione di probabilit√†; la variabilit√†, cio√® la dispersione della distribuzione di probabilit√† attorno ad un centro; la forma della distribuzione di probabilit√†, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilit√† e la sua variabilit√†."
  },
  {
    "objectID": "020_expval_var.html#valore-atteso",
    "href": "020_expval_var.html#valore-atteso",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.1 Valore atteso",
    "text": "11.1 Valore atteso\nQuando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual √® il suo ‚Äúvalore tipico‚Äù. La nozione di ‚Äúvalore tipico‚Äù, tuttavia, √® ambigua. Infatti, essa pu√≤ essere definita in almeno tre modi diversi:\n\nla media (somma dei valori divisa per il numero dei valori),\nla mediana (il valore centrale della distribuzione, quando la variabile √® ordinata in senso crescente o decrescente),\nla moda (il valore che ricorre pi√π spesso).\n\nPer esempio, la media di \\(\\{3, 1, 4, 1, 5\\}\\) √® \\(\\frac{3+1+4+1+5}{5} = 2.8\\), la mediana √® \\(3\\) e la moda √® \\(1\\). Tuttavia, la teoria delle probabilit√† si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per ‚Äúvalore tipico‚Äù quando facciamo riferimento alle variabili casuali. Giungiamo cos√¨ alla seguente definizione. \n\nDefinizione 11.1 Sia \\(Y\\) √® una variabile casuale discreta che assume i valori \\(y_1, \\dots, y_n\\) con distribuzione \\(P(Y = y_i) = p(y_i)\\). Per definizione il valore atteso di \\(Y\\), \\(\\mathbb{E}(Y)\\), √®\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^n y_i \\cdot p(y_i).\n\\tag{11.1}\\]\n\nA parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale √® definito come la somma di tutti i valori che la variabile casuale pu√≤ prendere, ciascuno pesato dalla probabilit√† con cui il valore √® preso.\n\nEsercizio 11.1 \nSi calcoli il valore atteso della variabile casuale \\(Y\\) corrispondente al lancio di una moneta equilibrata (testa: Y = 1; croce: Y = 0).\n\n\nSoluzione. Abbiamo\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{2} y_i \\cdot P(y_i) = 0 \\cdot \\frac{1}{5} + 1 \\cdot \\frac{1}{5} = 0.5.\n\\]\n\n\nEsercizio 11.2 \nSi calcoli il valore atteso della variabile casuale \\(Y\\) corrispondente ai punti ottenuti dal lancio di un dado equilibrato.\n\n\nSoluzione. Il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = \\sum_{i=1}^{6} y_i \\cdot P(y_i) = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + \\dots + 6 \\cdot \\frac{1}{6} = \\frac{21}{6} = 3.5.\n\\]\n\n\n11.1.1 Interpretazione\nChe interpretazione pu√≤ essere assegnata alla nozione di valore atteso? Bruno de Finetti adott√≤ lo stesso termine di previsione (e lo stesso simbolo) tanto per la probabilit√† che per la speranza matematica. Si pu√≤ pertanto dire che, dal punto di vista bayesiano, la speranza matematica √® l‚Äôestensione naturale della nozione di probabilit√† soggettiva.\n\n11.1.2 Propriet√† del valore atteso\nLa propriet√† pi√π importante del valore atteso √® la linearit√†: il valore atteso di una somma di variabili casuali √® uguale alla somma dei lori rispettivi valori attesi:\n\\[\n\\mathbb{E}(X + Y) = \\mathbb{E}(X) + \\mathbb{E}(Y).\n\\tag{11.2}\\]\nL‚ÄôEquazione¬†11.2 sembra ragionevole quando \\(X\\) e \\(Y\\) sono indipendenti, ma √® anche vera quando \\(X\\) e \\(Y\\) sono associati. Abbiamo anche che\n\\[\n\\mathbb{E}(cY) = c \\mathbb{E}(Y).\n\\tag{11.3}\\]\nL‚ÄôEquazione¬†11.3 ci dice che possiamo estrarre una costante dall‚Äôoperatore di valore atteso. Tale propriet√† si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \\(X\\) e \\(Y\\) sono indipendenti, abbiamo che\n\\[\n\\mathbb{E}(X Y) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\tag{11.4}\\]\n\nEsercizio 11.3 \nSi considerino le seguenti variabili casuali: \\(Y\\), ovvero il numero che si ottiene dal lancio di un dado equilibrato, e \\(Y\\), il numero di teste prodotto dal lancio di una moneta equilibrata. Si trovi il valore atteso di \\(X+Y\\).\n\n\nSoluzione. Per risolvere il problema iniziamo a costruire lo spazio campionario dell‚Äôesperimento casuale consistente nel lancio di un dado e di una moneta.\n\n\n\n\n\n\n\n\n\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n(0, 1)\n(0, 2)\n(0, 3)\n(0, 4)\n(0, 5)\n(0, 6)\n\n\n1\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(1, 5)\n(1, 6)\n\n\n\novvero\n\n\n\\(x \\textbackslash y\\)\n1\n2\n3\n4\n5\n6\n\n\n\n0\n1\n2\n3\n4\n5\n6\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\nIl risultato del lancio del dado √® indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avr√† la stessa probabilit√† di verificarsi, ovvero \\(P(\\omega) = \\frac{1}{12}\\). Il valore atteso di \\(X+Y\\) √® dunque uguale a:\n\\[\n\\mathbb{E}(X+Y) = 1 \\cdot \\frac{1}{12} + 2 \\cdot \\frac{1}{12} + \\dots + 7 \\cdot \\frac{1}{12} = 4.0.\n\\]\nLo stesso risultato si ottiene nel modo seguente:\n\\[\n\\mathbb{E}(X+Y) = \\mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.\n\\]\n\n\nEsercizio 11.4 \nSi considerino le variabili casuali \\(X\\) e \\(Y\\) definite nel caso del lancio di tre monete equilibrate, dove \\(X\\) conta il numero delle teste nei tre lanci e \\(Y\\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali \\(X\\) e \\(Y\\).\n\n\nSoluzione. La distribuzione di probabilit√† congiunta \\(P(X, Y)\\) √® fornita nella tabella seguente.\n\n\n\\(x \\textbackslash y\\)\n0\n1\n\\(p(Y)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(p(y)\\)\n4/8\n4/8\n1.0\n\n\n\nIl calcolo del valore atteso di \\(XY\\) si riduce a\n\\[\n\\mathbb{E}(XY) = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{2}{8} + 3 \\cdot \\frac{1}{8} = 1.0.\n\\]\nSi noti che le variabili casuali \\(Y\\) e \\(Y\\) non sono indipendenti. Dunque non possiamo usare la propriet√† del ?thm-prodindrv. Infatti, il valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = 1 \\cdot \\frac{3}{8} + 2 \\cdot \\frac{3}{8} + 3 \\cdot \\frac{1}{8} = 1.5\n\\]\ne il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot \\frac{4}{8} + 1 \\cdot \\frac{4}{8} = 0.5.\n\\]\nPerci√≤\n\\[\n1.5 \\cdot 0.5 \\neq 1.0.\n\\]\n\n\n11.1.3 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\) il valore atteso diventa:\n\\[\n\\mathbb{E}(Y) = \\int_{-\\infty}^{+\\infty} y p(y) \\,\\operatorname {d}\\!y.\n\\tag{11.5}\\]\nAnche in questo caso il valore atteso √® una media ponderata della \\(y\\), nella quale ciascun possibile valore \\(y\\) √® ponderato per il corrispondente valore della densit√† \\(p(y)\\). Possiamo leggere l‚Äôintegrale pensando che \\(y\\) rappresenti l‚Äôampiezza delle barre infinitamente strette di un istogramma, con la densit√† \\(p(y)\\) che corrisponde all‚Äôaltezza di tali barre e la notazione \\(\\int_{-\\infty}^{+\\infty}\\) che corrisponde ad una somma.\nUn‚Äôaltra misura di tendenza centrale delle variabili casuali continue √® la moda. La moda della \\(Y\\) individua il valore \\(y\\) pi√π plausibile, ovvero il valore \\(y\\) che massimizza la funzione di densit√† \\(p(y)\\):\n\\[\n\\mbox{Mo}(Y) = \\mbox{argmax}_y p(y).\n\\tag{11.6}\\]"
  },
  {
    "objectID": "020_expval_var.html#varianza",
    "href": "020_expval_var.html#varianza",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.2 Varianza",
    "text": "11.2 Varianza\nLa seconda pi√π importante propriet√† di una variabile casuale, dopo che conosciamo il suo valore atteso, √® la varianza.\n\nDefinizione 11.2 Se \\(Y\\) √® una variabile casuale discreta con distribuzione \\(p(y)\\), per definizione la varianza di \\(Y\\), \\(\\mathbb{V}(Y)\\), √®\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big].\n\\tag{11.7}\\]\n\nA parole: la varianza √® la deviazione media quadratica della variabile dalla sua media.1 Se denotiamo \\(\\mathbb{E}(Y) = \\mu\\), la varianza \\(\\mathbb{V}(Y)\\) diventa il valore atteso di \\((Y - \\mu)^2\\).\n\nEsercizio 11.5 \nPosta \\(S\\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di \\(S\\).\n\n\nSoluzione. La variabile casuale \\(S\\) ha la seguente distribuzione di probabilit√†:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(s\\)\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\\(P(S = s)\\)\n\\(\\frac{1}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{6}{36}\\)\n\\(\\frac{5}{36}\\)\n\\(\\frac{4}{36}\\)\n\\(\\frac{3}{36}\\)\n\\(\\frac{2}{36}\\)\n\\(\\frac{1}{36}\\)\n\n\nEssendo \\(\\mathbb{E}(S) = 7\\), la varianza diventa\n\\[\n\\begin{align}\n\\mathbb{V}(S) &= \\sum \\left(S- \\mathbb{E}(S)\\right)^2 \\cdot P(S) \\notag\\\\\n&= (2 - 7)^2 \\cdot 0.0278 + (3-7)^2 \\cdot 0.0556 + \\dots + (12 - 7)^2 \\cdot 0.0278 \\notag\\\\\n&= 5.8333.\\notag\n\\end{align}\n\\]\n\n\n11.2.1 Formula alternativa per la varianza\nC‚Äô√® un modo pi√π semplice per calcolare la varianza:\n\\[\n\\begin{align}\n\\mathbb{E}\\Big[\\big(Y - \\mathbb{E}(Y)\\big)^2\\Big] &= \\mathbb{E}\\big(Y^2 - 2Y\\mathbb{E}(Y) + \\mathbb{E}(Y)^2\\big)\\notag\\\\\n&= \\mathbb{E}(Y^2) - 2\\mathbb{E}(Y)\\mathbb{E}(Y) + \\mathbb{E}(Y)^2,\n\\end{align}\n\\]\ndato che \\(\\mathbb{E}(Y)\\) √® una costante. Pertanto\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2.\n\\tag{11.8}\\]\nA parole: la varianza √® la media dei quadrati meno il quadrato della media.\n\nEsercizio 11.6 \nConsideriamo la variabile casuale \\(Y\\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilit√† di testa uguale a 0.8. Si trovi la varianza di \\(Y\\).\n\n\nSoluzione. Il valore atteso di \\(Y\\) √®\n\\[\n\\mathbb{E}(Y) = 0 \\cdot 0.2 + 1 \\cdot 0.8 = 0.8.\n\\]\nUsando la formula tradizionale della varianza otteniamo:\n\\[\n\\mathbb{V}(Y) = (0 - 0.8)^2 \\cdot 0.2 + (1 - 0.8)^2 \\cdot 0.8 = 0.16.\n\\]\nLo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \\(Y^2\\) √®\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.8 = 0.8.\n\\]\ne la varianza diventa\n\\[\n\\mathbb{V}(Y) = \\mathbb{E}(Y^2) - \\big(\\mathbb{E}(Y) \\big)^2 = 0.8 - 0.8^2 = 0.16.\n\\]\n\n\n11.2.2 Variabili casuali continue\nNel caso di una variabile casuale continua \\(Y\\), la varianza diventa:\n\\[\n\\mathbb{V}(Y) = \\int_{-\\infty}^{+\\infty} \\large[y - \\mathbb{E}(Y)\\large]^2 p(y) \\,\\operatorname {d}\\!y.\n\\tag{11.9}\\]\nCome nel caso discreto, la varianza di una v.c. continua \\(Y\\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \\(Y\\) dalla loro media."
  },
  {
    "objectID": "020_expval_var.html#deviazione-standard",
    "href": "020_expval_var.html#deviazione-standard",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.3 Deviazione standard",
    "text": "11.3 Deviazione standard\nQuando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell‚Äôunit√† di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato deviazione standard e solitamente √® denotato dalla lettera greca \\(\\sigma\\).\n\nDefinizione 11.3 Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:\n\\[\n\\sigma_Y = \\sqrt{\\mathbb{V}(Y)}.\n\\tag{11.10}\\]\n\nInterpretiamo la deviazione standard di una variabile casuale come nella statistica descrittiva: misura approssimativamente la distanza tipica o prevista dei possibili valori \\(y\\) dalla loro media.\n\nEsercizio 11.7 \nPer i dadi equilibrati dell‚ÄôEsercizio¬†11.5, la deviazione standard della variabile casuale \\(S\\) √® uguale a \\(\\sqrt{5.833} = 2.415\\)."
  },
  {
    "objectID": "020_expval_var.html#standardizzazione",
    "href": "020_expval_var.html#standardizzazione",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.4 Standardizzazione",
    "text": "11.4 Standardizzazione\n\nDefinizione 11.4 Data una variabile casuale \\(Y\\), si dice variabile standardizzata di \\(Y\\) l‚Äôespressione\n\\[\nZ = \\frac{Y - \\mathbb{E}(Y)}{\\sigma_Y}.\n\\tag{11.11}\\]\n\nSolitamente, una variabile standardizzata viene denotata con la lettera \\(Z\\)."
  },
  {
    "objectID": "020_expval_var.html#momenti-di-variabili-casuali",
    "href": "020_expval_var.html#momenti-di-variabili-casuali",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.5 Momenti di variabili casuali",
    "text": "11.5 Momenti di variabili casuali\n\nSi chiama momento di ordine \\(q\\) di una v.c. \\(X\\), dotata di densit√† \\(p(x)\\), la quantit√†\n\\[\n\\mathbb{E}(X^q) = \\int_{-\\infty}^{+\\infty} x^q p(x) \\; dx.\n\\tag{11.12}\\]\nSe \\(X\\) √® una v.c. discreta, i suoi momenti valgono:\n\\[\n\\mathbb{E}(X^q) = \\sum_i x_i^q P(x_i).\n\\tag{11.13}\\]\n\nI momenti sono importanti parametri indicatori di certe propriet√† di \\(X\\). I pi√π noti sono senza dubbio quelli per \\(q = 1\\) e \\(q = 2\\). Il momento del primo ordine corrisponde al valore atteso di \\(X\\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \\(X\\), operando una traslazione \\(x_0 = x ‚àí \\mathbb{E}(X)\\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza."
  },
  {
    "objectID": "020_expval_var.html#covarianza",
    "href": "020_expval_var.html#covarianza",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.6 Covarianza",
    "text": "11.6 Covarianza\nLa covarianza quantifica la tendenza delle variabili aleatorie \\(X\\) e \\(Y\\) a ‚Äúvariare assieme‚Äù. Per esempio, l‚Äôaltezza e il peso delle giraffe producono una covarianza positiva perch√© all‚Äôaumentare di una di queste due quantit√† tende ad aumentare anche l‚Äôaltra. La covarianza misura la forza e la direzione del legame lineare tra due variabili aleatorie \\(X\\) ed \\(Y\\). Si utilizza la notazione \\(\\mbox{Cov}(X,Y)=\\sigma_{xy}\\).\n\nDefinizione 11.5 Date due variabili aleatorie \\(X\\), \\(Y\\), chiamiamo covarianza tra \\(X\\) ed \\(Y\\) il numero\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}\\Bigl(\\bigl(X - \\mathbb{E}(X)\\bigr) \\bigl(Y - \\mathbb{E}(Y)\\bigr)\\Bigr),\n\\tag{11.14}\\]\ndove \\(\\mathbb{E}(X)\\) e \\(\\mathbb{E}(Y)\\) sono i valori attesi di \\(X\\) ed \\(Y\\).\n\nIn maniera esplicita,\n\\[\n\\mbox{Cov}(X,Y) = \\sum_{(x,y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y).\n\\tag{11.15}\\]\nLa definizione √® analoga, algebricamente, a quella di varianza e risulta infatti\n\\[\n\\mathbb{V}(x) = \\mbox{Cov}(X, X)\n\\]\ne\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X).\n\\tag{11.16}\\]\n\nDimostrazione. L‚ÄôEquazione¬†11.16 si ricava nel modo seguente:\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}\\Bigl(\\bigl(X-\\mathbb{E}(X)\\bigr) \\bigl(Y-\\mathbb{E}(Y)\\bigr)\\Bigr)\\notag\\\\\n          %&= \\mathbb{E}(XY) - \\mathbb{E}(Y)X -\\mathbb{E}(X)Y + \\mathbb{E}(X)\\mathbb{E}(Y) )\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X) - \\mathbb{E}(X)\\mathbb{E}(Y) + \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n          &= \\mathbb{E}(XY) - \\mathbb{E}(Y)\\mathbb{E}(X)\\notag.\n\\end{align}\n\\]\n\n\nEsercizio 11.8 \nConsideriamo le variabili casuali definite nell‚ÄôEsercizio 2.4. Si calcoli la covarianza di \\(X\\) e \\(Y\\).\n\n\nSoluzione. Abbiamo che \\(\\mu_X = 1.5\\) e \\(\\mu_Y = 0.5\\). Ne segue che la covarianza di \\(X\\) e \\(Y\\) √®:\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\sum_{(x,y) \\in \\Omega} (x - \\mu_X) (y - \\mu_Y) f(x, y)\\notag\\\\\n&= (0-1.5)(0-0.5)\\cdot \\frac{1}{8} + (0-1.5)(1-0.5) \\cdot 0 \\\\\n   &\\qquad + (1-1.5)(0-0.5)\\cdot \\frac{2}{8} + (1-1.5)(1-0.5) \\cdot \\frac{1}{8} \\notag\\\\\n    &\\qquad+ (2-1.5)(0-0.5) \\cdot \\frac{1}{8} + (2-1.5)(1-0.5) \\cdot \\frac{2}{8} \\\\\n   &\\qquad+ (3-1.5)(0-0.5) \\cdot 0 +  (3-1.5)(1-0.5)\\cdot\\frac{1}{8} \\notag\\\\\n   &= \\frac{1}{4}. \\notag\n\\end{align}\n\\]\nLo stesso risultato pu√≤ essere trovato nel modo seguente. Iniziamo a calcolare il valore atteso del prodotto \\(XY\\):\n\\[\n\\mathbb{E}(XY) = 0 \\cdot\\frac{4}{8} + 1 \\cdot\\frac{1}{8} + 2 \\cdot\\frac{2}{8} + 3 \\cdot\\frac{1}{8} = 1.0.\n\\]\nDunque, la covarianza tra \\(X\\) e \\(Y\\) diventa\n\\[\n\\begin{align}\n\\mbox{Cov}(X,Y) &= \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y)\\notag\\\\\n&= 1 -  1.5\\cdot 0.5 \\notag\\\\\n&= 0.25.\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "020_expval_var.html#correlazione",
    "href": "020_expval_var.html#correlazione",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.7 Correlazione",
    "text": "11.7 Correlazione\nLa covarianza dipende dall‚Äôunit√† di misura delle due variabili e quindi non consente di stabilire l‚Äôintensit√† della relazione. Una misura standardizzata della relazione che intercorre fra due variabili √® invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie.\n\nIl coefficiente di correlazione tra \\(X\\) ed \\(Y\\) √® il numero definito da\n\\[\n\\rho(X,Y) =\\frac{\\mbox{Cov}(X,Y)}{\\sqrt{\\mathbb{V}(X)\\mathbb{V}(Y)}}.\n\\tag{11.17}\\]\n\nSi pu√≤ anche scrivere \\(\\rho_{X,Y}\\) al posto di \\(\\rho(X,Y)\\).\nIl coefficiente di correlazione \\(\\rho_{xy}\\) √® un numero puro, cio√® non dipende dall‚Äôunit√† di misura delle variabili, e assume valori compresi tra -1 e +1."
  },
  {
    "objectID": "020_expval_var.html#propriet√†",
    "href": "020_expval_var.html#propriet√†",
    "title": "11¬† Valore atteso e varianza",
    "section": "\n11.8 Propriet√†",
    "text": "11.8 Propriet√†\n\nLa covarianza tra una variabile aleatoria \\(X\\) e una costante \\(c\\) √® nulla: \\(\\mbox{Cov}(c,X) = 0;\\)\nla covarianza √® simmetrica: \\(\\mbox{Cov}(X,Y) = \\mbox{Cov}(Y,X);\\)\nvale \\(-1 \\leq \\rho(X,Y) \\leq 1;\\)\nla correlazione non dipende dall‚Äôunit√† di misura: \\(\\rho(aX, bY) = \\rho(X,Y), \\qquad \\forall a, b > 0;\\)\nse \\(Y = a + bX\\) √® una funzione lineare di \\(X\\) con costanti \\(a\\) e \\(b\\), allora \\(\\rho(X,Y) = \\pm 1\\), a seconda del segno di \\(b\\);\nla covarianza tra \\(X\\) e \\(Y\\), ciascuna moltiplicata per una costante, √® uguale al prodotto delle costanti per la covarianza tra \\(X\\) e \\(Y\\): \\(\\mbox{Cov}(aX,bY) = ab \\;\\mbox{Cov}(X,Y), \\qquad \\forall a,b \\in\\);\nvale \\(\\mathbb{V}(X \\pm Y) = \\mathbb{V}(X) + \\mathbb{V}(Y) \\pm 2 \\cdot \\mbox{Cov}(X,Y)\\);\nvale \\(\\mbox{Cov}(X + Y, Z) = \\mbox{Cov}(X,Z) + \\mbox{Cov}(Y,Z);\\)\nper una sequenza di variabili aleatorie \\(X_1, \\dots, X_n\\), si ha \\(\\mathbb{V}\\left( \\sum_{i=1}^n X_i\\right) = \\sum_{i=1}^n \\mathbb{V}(X_i) + 2\\sum_{i,j: i<j}cov(X_i, X_j);\\)\nvale \\(\\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^m b_jY_j\\right) = \\sum_{i=1}^n \\sum_{j=1}^m a_j b_j\\mbox{Cov}(X_j, Y_j);\\)\nse \\(X_1, X_2, \\dots, X_n\\) sono indipendenti, allora \\(\\mbox{Cov}\\left(\\sum_{i=1}^n a_i X_i, \\sum_{j=1}^n b_jX_j\\right) = \\sum_{i=1}^n a_i b_i \\mathbb{V}(X_i).\\)\n\n\n11.8.1 Incorrelazione\n\nDefinizione 11.6 Si dice che \\(X\\) ed \\(Y\\) sono incorrelate, o linermente indipendenti, se la loro covarianza √® nulla,\n\\[\n\\sigma_{XY} = \\mathbb{E} \\big[(X - \\mu_X) (y-\\mu_u) \\big] = 0,\n\\tag{11.18}\\]\nche si pu√≤ anche scrivere come\n\\[\n\\rho_{XY} = 0, \\quad \\mathbb{E}(XY) = \\mathbb{E}(X) \\mathbb{E}(Y).\n\\]\n\nSi introduce cos√¨ un secondo tipo di indipendenza, pi√π debole, dopo quello di indipendenza stocastica. Viceversa, per√≤, se \\(\\mbox{Cov}(X, Y) = 0\\), non √® detto che \\(X\\) ed \\(Y\\) siano indipendenti.\n\nEsercizio 11.9 Siano \\(X\\) e \\(Y\\) due variabili aleatorie discrete avente una distribuzione di massa di probabilit√† congiunta pari a\n\\[\nf_{XY}(x,y) = \\frac{1}{4} \\quad (x,y) \\in \\{(0,0), (1,1), (1, -1), (2,0) \\}\n\\]\ne zero altrimenti. Le due variabili aleatorie \\(X\\) e \\(Y\\) sono mutuamente indipendenti?\n\n\nSoluzione. La distribuzione marginale della \\(X\\) √®\n\\[\n\\begin{cases}\nX = 0, \\quad  P_X = 1/4, \\\\\nX = 1, \\quad P_X = 2/4, \\\\\nX = 2, \\quad P_X = 1/4.\n\\end{cases}\n\\]\n\\[\n\\mathbb{E}(X) = 0 \\frac{1}{4} + 1 \\frac{2}{4} + 2 \\frac{1}{4} = 1.\n\\]\n\\[\n\\mathbb{E}(X^2) = 0^2 \\frac{1}{4} + 1^2 \\frac{2}{4} + 2^2 \\frac{1}{4} = \\frac{3}{2}.\n\\]\n\\[\n\\mathbb{V}(X) = \\frac{3}{2} - 1^2 = \\frac{1}{2}.\n\\]\nLa distribuzione marginale della \\(Y\\) √®\n\\[\n\\begin{cases}\nY = -1, \\quad  P_Y = 1/4, \\\\\nY = 0, \\quad P_Y = 2/4, \\\\\nY = 1, \\quad P_Y = 1/4.\n\\end{cases}\n\\]\n\\[\n\\mathbb{E}(Y) = 0 \\frac{2}{4} + 1 \\frac{1}{4} + (-1) \\frac{1}{4} = 0.\n\\]\n\\[\n\\mathbb{E}(Y^2) = 0^2 \\frac{2}{4} + 1^2 \\frac{1}{4} + (-1)^2 \\frac{1}{4} = \\frac{1}{2}.\n\\]\n\\[\n\\mathbb{V}(X) = \\frac{1}{2} - 0^2 = \\frac{1}{2}.\n\\]\nCalcoliamo ora la covarianza tra \\(X\\) e \\(Y\\):\n\\[\n\\mathbb{E}(XY) = \\sum_x\\sum_y xy f_{XY} (x,y) =\n(0\\cdot 0)\\frac{1}{4} +\n(1\\cdot 1)\\frac{1}{4} +\n(1\\cdot -1)\\frac{1}{4} +\n(2\\cdot 0)\\frac{1}{4} = 0.\n\\]\n\\[\n\\mbox{Cov}(X,Y) = \\mathbb{E}(XY) - \\mathbb{E}(X)\\mathbb{E}(Y) = 0 - 1\\cdot0 = 0.\n\\]\nQuindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non sono indipendenti, in quanto non √® vero che\n\\[\nf_{XY} (x,y) = f_X(x) f_Y(y)\n\\]\nper tutti gli \\(x\\) e \\(y\\).\n\nIn conclusione, anche se condizione di indipendenza implica una covarianza nulla, l‚Äôesempio precedente mostra come l‚Äôinverso non sia necessariamente vero: la covarianza pu√≤ essere zero anche quando le due variabili aleatorie non sono indipendenti."
  },
  {
    "objectID": "020_expval_var.html#conclusioni",
    "href": "020_expval_var.html#conclusioni",
    "title": "11¬† Valore atteso e varianza",
    "section": "Conclusioni",
    "text": "Conclusioni\nLa densit√† di probabilit√† congiunta bivariata tiene simultaneamente conto del comportamento di due variabili aleatorie \\(X\\) e \\(Y\\) e di come esse si influenzino. Se \\(X\\) e \\(Y\\) sono legate linearmente, allora il coefficiente di correlazione\n\\[\\begin{equation}\n\\rho = \\frac{\\mbox{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\\notag\n\\end{equation}\\]\nfornisce l‚Äôindice maggiormente utilizzato per descrivere l‚Äôintensit√† e il segno dell‚Äôassociazione lineare. Nel caso di un‚Äôassociazione lineare perfetta, \\(Y = a + bX\\), avremo \\(\\rho = 1\\) con \\(b\\) positivo ed \\(\\rho = -1\\) con \\(b\\) negativo. Se il coefficiente di correlazione √® pari a 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinch√© \\(\\rho = 0\\) √® che le due variabili siano tra loro indipendenti."
  },
  {
    "objectID": "distr.html",
    "href": "distr.html",
    "title": "Parte 3: Distribuzioni di v.c. discrete e continue",
    "section": "",
    "text": "In questa parte della dispensa verranno presentate le pi√π importanti distribuzioni di massa di probabilit√† e di densit√† di probabilit√†."
  },
  {
    "objectID": "022_discr_rv_distr.html",
    "href": "022_discr_rv_distr.html",
    "title": "12¬† Distribuzioni di v.c. discrete",
    "section": "",
    "text": "In questo Capitolo verranno esaminate le principali distribuzioni di probabilit√† delle variabili casuali discrete. Un esperimento casuale che pu√≤ dare luogo a solo due possibili esiti (successo, insuccesso) √® modellabile con una variabile casuale di Bernoulli. Una sequenza di prove di Bernoulli costituisce un processo Bernoulliano. Il numero di successi dopo \\(n\\) prove di Bernoulli corrisponde ad una variabile casuale che segue la legge binomiale. La distribuzione binomiale risulta da un insieme di prove di Bernoulli solo se il numero totale \\(n\\) √® fisso per disegno. Se il numero di prove √® esso stesso una variabile casuale, allora il numero di successi nella corrispondente sequenza di prove bernoulliane segue al distribuzione di Poisson. Concluderemo con la distribuzione discreta uniforme."
  },
  {
    "objectID": "022_discr_rv_distr.html#una-prova-bernoulliana",
    "href": "022_discr_rv_distr.html#una-prova-bernoulliana",
    "title": "12¬† Distribuzioni di v.c. discrete",
    "section": "\n12.1 Una prova Bernoulliana",
    "text": "12.1 Una prova Bernoulliana\nSe un esperimento casuale ha solo due esiti possibili, allora le repliche indipendenti di questo esperimento sono chiamate ‚Äúprove Bernoulliane‚Äù (il lancio di una moneta √® il tipico esempio).\n\nDefinizione 12.1 Viene detta variabile di Bernoulli una variabile casuale discreta \\(Y = \\{0, 1\\}\\) con la seguente distribuzione di probabilit√†:\n\\[\nP(Y \\mid \\theta) =\n  \\begin{cases}\n    \\theta     & \\text{se $Y = 1$}, \\\\\n    1 - \\theta & \\text{se $Y = 0$},\n  \\end{cases}\n\\]\ncon \\(0 \\leq \\theta \\leq 1\\). Convenzionalmente l‚Äôevento \\(\\{Y = 1\\}\\) con probabilit√† \\(\\theta\\) viene chiamato ‚Äúsuccesso‚Äù mentre l‚Äôevento \\(\\{Y = 0\\}\\) con probabilit√† \\(1-\\theta\\) viene chiamato ‚Äúinsuccesso‚Äù.\n\nApplicando l‚Äôoperatore di valore atteso e di varianza, otteniamo\n\\[\n\\begin{align}\n\\mathbb{E}(Y) &= 0 \\cdot P(Y=0) + 1 \\cdot P(Y=1) = \\theta, \\\\\n\\mathbb{V}(Y) &= (0 - \\theta)^2 \\cdot P(Y=0) + (1 - \\theta)^2 \\cdot P(Y=1) = \\theta(1-\\theta).\n\\end{align}\n\\tag{12.1}\\]\nScriviamo \\(Y \\sim \\mbox{Bernoulli}(\\theta)\\) per indicare che la variabile casuale \\(Y\\) ha una distribuzione Bernoulliana di parametro \\(\\theta\\).\n\nEsercizio 12.1 \nNel caso del lancio di una moneta equilibrata la variabile casuale di Bernoulli assume i valori \\(0\\) e \\(1\\). La distribuzione di massa di probabilit√† √® pari a \\(\\frac{1}{2}\\) in corrispondenza di entrambi i valori. La funzione di distribuzione vale \\(\\frac{1}{2}\\) per \\(Y = 0\\) e \\(1\\) per \\(Y = 1\\)."
  },
  {
    "objectID": "022_discr_rv_distr.html#una-sequenza-di-prove-bernoulliane",
    "href": "022_discr_rv_distr.html#una-sequenza-di-prove-bernoulliane",
    "title": "12¬† Distribuzioni di v.c. discrete",
    "section": "\n12.2 Una sequenza di prove Bernoulliane",
    "text": "12.2 Una sequenza di prove Bernoulliane\nLa distribuzione binomiale √® rappresentata dall‚Äôelenco di tutti i possibili numeri di successi \\(Y = \\{0, 1, 2, \\dots n\\}\\) che possono essere osservati in \\(n\\) prove Bernoulliane indipendenti di probabilit√† \\(\\theta\\), a ciascuno dei quali √® associata la relativa probabilit√†. Esempi di una distribuzione binomiale sono i risultati di una serie di lanci di una stessa moneta o di una serie di estrazioni da un‚Äôurna (con reintroduzione). La distribuzione binomiale di parametri \\(n\\) e \\(\\theta\\) √® in realt√† una famiglia di distribuzioni: al variare dei parametri \\(\\theta\\) e \\(n\\) variano le probabilit√†.\n\nDefinizione 12.2 La probabilit√† di ottenere \\(y\\) successi e \\(n-y\\) insuccessi in \\(n\\) prove Bernoulliane √® data dalla distribuzione binomiale:\n\\[\n\\begin{align}\nP(Y=y) &= \\binom{n}{y} \\theta^{y} (1-\\theta)^{n-y} \\notag \\\\\n&= \\frac{n!}{y!(n-y)!} \\theta^{y} (1-\\theta)^{n-y},\n\\end{align}\n\\tag{12.2}\\]\ndove \\(n\\) = numero di prove Bernoulliane, \\(\\theta\\) = probabilit√† di successo in ciascuna prova e \\(y\\) = numero di successi.\n\n\nDimostrazione. L‚ÄôEquazione¬†12.2 pu√≤ essere derivata nel modo seguente. Indichiamo con \\(S\\) il successo e con \\(I\\) l‚Äôinsuccesso di ciascuna prova. Una sequenza di \\(n\\) prove Bernoulliane dar√† come esito una sequenza di \\(n\\) elementi \\(S\\) e \\(I\\). Ad esempio, una sequenza che contiene \\(y\\) successi √® la seguente:\n\\[\n\\overbrace{SS\\dots S}^\\text{$y$ volte} \\overbrace{II\\dots I}^\\text{$n-y$ volte}\n\\]\nEssendo \\(\\theta\\) la probabilit√† di \\(S\\) e \\(1-\\theta\\) la probabilit√† di \\(I\\), la probabilit√† di ottenere la specifica sequenza riportata sopra √®\n\\[\n\\begin{equation}\n\\overbrace{\\theta \\theta\\dots \\theta}^\\text{$y$ volte} \\overbrace{(1-\\theta)(1-\\theta)\\dots (1-\\theta)}^\\text{$n-y$ volte} = \\theta^y \\cdot (1-\\theta)^{n-y}.\n\\end{equation}\n\\tag{12.3}\\]\nNon siamo per√≤ interessati alla probabilit√† di una specifica sequenza di \\(S\\) e \\(I\\) ma, bens√¨, alla probabilit√† di osservare una qualsiasi sequenza di \\(y\\) successi in \\(n\\) prove. In altre parole, vogliamo la probabilit√† dell‚Äôunione di tutti gli eventi corrispondenti a \\(y\\) successi in \\(n\\) prove.\n√à immediato notare che una qualsiasi altra sequenza contenente esattamente \\(y\\) successi avr√† sempre come probabilit√† \\(\\theta^y \\cdot (1-\\theta)^{n-y}\\): il prodotto infatti resta costante anche se cambia l‚Äôordine dei fattori.1 Per trovare il risultato cercato dobbiamo moltiplicare l‚ÄôEquazione¬†12.3 per il numero di sequenze possibili di \\(y\\) successi in \\(n\\) prove.\nIl numero di sequenze che contengono esattamente \\(y\\) successi in \\(n\\) prove. La risposta √® fornita dal coefficiente binomiale:\n\\[\n\\begin{equation}\n\\binom{n}{y} = \\frac{n!}{y!(n-y)!},\n\\end{equation}\n\\tag{12.4}\\]\ndove il simbolo \\(n!\\) si legge \\(n\\) fattoriale ed √® uguale al prodotto di \\(n\\) numeri interi decrescenti a partire da \\(n\\). Per definizione \\(0! = 1\\).\nEssendo la probabilit√† dell‚Äôunione di \\(K\\) elementi incompatibili uguale alla somma delle loro rispettive probabilit√†, e dato che le sequenze di \\(y\\) successi in \\(n\\) prove hanno tutte la stessa probabilit√†, per trovare la formula della distributione binomiale Equazione¬†12.2 √® sufficiente moltiplicare l‚ÄôEquazione¬†12.3 per l‚ÄôEquazione¬†12.4.\n\nLa distribuzione di probabilit√† di alcune distribuzioni binomiali, per due valori di \\(n\\) e \\(\\theta\\), √® fornita nella Figura¬†12.1.\n\n\n\n\nFigura 12.1: Alcune distribuzioni binomiali. Nella figura, il parametro \\(\\theta\\) √® indicato con \\(p\\).\n\n\n\n\n\nEsercizio 12.2 \nUsando l‚ÄôEquazione¬†12.2, si trovi la probabilit√† di \\(y = 2\\) successi in \\(n = 4\\) prove Bernoulliane indipendenti con \\(\\theta = 0.2\\)\n\n\nSoluzione. Abbiamo\n\\[\n\\begin{aligned}\nP(Y=2) &= \\frac{4!}{2!(4-2)!} 0.2^{2} (1-0.2)^{4-2} \\notag  \\\\\n&= \\frac{4 \\cdot 3 \\cdot 2 \\cdot 1}{(2 \\cdot 1)(2 \\cdot 1)}\n0.2^{2} 0.8^{2} = 0.1536. \\notag\n\\end{aligned}\n\\]\nRipetendo i calcoli per i valori \\(y = 0, \\dots, 4\\) troviamo la distribuzione binomiale di parametri \\(n = 4\\) e \\(\\theta = 0.2\\):\n\n\ny\nP(Y = y)\n\n\n\n0\n0.4096\n\n\n1\n0.4096\n\n\n2\n0.1536\n\n\n3\n0.0256\n\n\n4\n0.0016\n\n\nsum\n1.0\n\n\n\nLo stesso risultato si ottiene usando la sequente istruzione R:\n\nCodicedbinom(0:4, 4, 0.2)\n#> [1] 0.4096 0.4096 0.1536 0.0256 0.0016\n\n\n\n\nEsercizio 12.3 \nLanciando \\(5\\) volte una moneta onesta, qual √® la probabilit√† che esca testa almeno tre volte?\n\n\nSoluzione. In R, la soluzione si trova con\n\nCodicedbinom(3, 5, 0.5) + dbinom(4, 5, 0.5) + dbinom(5, 5, 0.5)\n#> [1] 0.5\n\n\nAlternativamente, possiamo trovare la probabilit√† dell‚Äôevento complementare a quello definito dalla funzione di ripartizione calcolata mediante pbinom(), ovvero\n\nCodice1 - pbinom(2, 5, 0.5)\n#> [1] 0.5\n\n\n\n\n12.2.1 Valore atteso e deviazione standard\nLa media (numero atteso di successi in \\(n\\) prove) e la deviazione standard di una distribuzione binomiale si trovano nel modo seguente:\n\\[\n\\begin{align}\n\\mu    &= n\\theta,  \\notag \\\\\n\\sigma &= \\sqrt{n\\theta(1-\\theta)}.\n\\end{align}\n\\tag{12.5}\\]\n\nDimostrazione. Essendo \\(Y\\) la somma di \\(n\\) prove Bernoulliane indipendenti \\(Y_i\\), √® facile vedere che\n\\[\\begin{align}\n\\mathbb{E}(Y) &= \\mathbb{E}\\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{E}(Y_i) = n\\theta, \\\\\n\\mathbb{V}(Y) &= \\mathbb{V} \\left( \\sum_{i=1}^n Y_i \\right) = \\sum_{i=1}^n \\mathbb{V}(Y_i) = n \\theta (1-\\theta).\n\\end{align}\\]\n\n\nEsercizio 12.4 \nSi trovino il valore atteso e la varianza del lancio di quattro monete con probabilit√† di successo pari a \\(\\theta = 0.2\\).\n\n\nSoluzione. Il valore atteso √® \\(\\mu = n \\theta = 4 \\cdot 0.2 = 0.8.\\) Ci√≤ significa che, se l‚Äôesperimento casuale venisse ripetuto infinite volte, l‚Äôesito testa verrebbe osservato un numero medio di volte pari a 0.8. La varianza √® \\(n \\theta (1-\\theta) = 4 \\cdot 0.2 \\cdot (1 - 0.2) = 0.64\\)."
  },
  {
    "objectID": "022_discr_rv_distr.html#distribuzione-di-poisson",
    "href": "022_discr_rv_distr.html#distribuzione-di-poisson",
    "title": "12¬† Distribuzioni di v.c. discrete",
    "section": "\n12.3 Distribuzione di Poisson",
    "text": "12.3 Distribuzione di Poisson\nLa distribuzione di Poisson √® una distribuzione di probabilit√† discreta che esprime le probabilit√† per il numero di eventi che si verificano successivamente ed indipendentemente in un dato intervallo di tempo, sapendo che mediamente se ne verifica un numero \\(\\lambda\\). La distribuzione di Poisson serve dunque per contare il numero di volte in cui un evento ha luogo in un determinato intervallo di tempo. La stessa distribuzione pu√≤ essere estesa anche per contare gli eventi che hanno luogo in una determinata porzione di spazio.\n\nLa distribuzione di Poisson pu√≤ essere intesa come limite della distribuzione binomiale, dove la probabilit√† di successo \\(\\theta\\) √® pari a \\(\\frac{\\lambda}{n}\\) con \\(n\\) che tende a \\(\\infty\\):\n\\[\\begin{equation}\n\\lim_{y \\rightarrow \\infty} \\binom{n}{y} \\theta^y (1-\\theta)^{n-y} = \\frac{\\lambda^y}{y!}e^{-\\lambda}.\n\\end{equation}\\]\n\nAlcune distribuzioni di Poisson sono riportate nella figura Figura¬†12.2.\n\n\n\n\nFigura 12.2: Alcune distribuzioni di Poisson.\n\n\n\n\n\nEsercizio 12.5 \nSupponiamo che un evento accada 300 volte all‚Äôora. Si vuole determinare la probabilit√† che in un minuto accadano esattamente 3 eventi.\n\n\nSoluzione. Il numero medio di eventi in un minuto √® pari a\n\nCodicelambda <- 300 / 60\nlambda\n#> [1] 5\n\n\nQuindi la probabilit√† che in un minuto si abbiano 3 eventi √® pari a\n\nCodicey <- 3\n(lambda^y / factorial(y)) * exp(-lambda)\n#> [1] 0.1403739\n\n\n\n\nEsercizio 12.6 \nPer i dati dell‚ÄôEsercizio¬†12.5, si trovi la probabilit√† che un evento accada almeno 8 volte in un minuto.\n\n\nSoluzione. La probabilit√† cercata √®\n\\[\np(y \\geq 8) = 1 - p (y \\leq 7) = 1- \\sum_{i = 0}^7 \\frac{\\lambda^7}{7!}e^{-\\lambda},\n\\]\ncon \\(\\lambda = 5\\).\nSvolgendo i calcoli in R otteniamo:\n\nCodice1 - ppois(q = 7, lambda = 5)\n#> [1] 0.1333717\nppois(q = 7, lambda = 5, lower.tail = FALSE)\n#> [1] 0.1333717\n\n\n\n\nEsercizio 12.7 \nSapendo che un evento avviene in media 6 volte al minuto, si calcoli (a) la probabilit√† di osservare un numero di eventi uguale o inferiore a 3 in un minuto, e (b) la probabilit√† di osservare esattamente 2 eventi in 30 secondi.\n\n\nSoluzione. Per la domanda (a), \\(\\lambda = 6\\) e la probabilit√† richiesta √®\n\nCodiceppois(q = 3, lambda = 6, lower.tail = TRUE)\n#> [1] 0.1512039\n\n\nNel caso di (b), \\(\\lambda = 6 / 2\\) e la probabilit√† richiesta √®\n\nCodicedpois(x = 2, lambda = 3)\n#> [1] 0.2240418\n\n\n\n\n12.3.1 Alcune propriet√† della variabile di Poisson\n\nIl valore atteso, la moda e la varianza della variabile di Poisson sono uguali a \\(\\lambda\\).\nLa somma \\(Y_1 + \\dots + Y_n\\) di \\(n\\) variabili casuali indipendenti con distribuzioni di Poisson di parametri \\(\\lambda_{1},\\dots,\\lambda_{n}\\) segue una distribuzione di Poisson di parametro \\(\\lambda = \\lambda_{1}+\\dots+\\lambda_{n}\\).\nLa differenze di due variabili di Poisson non √® una variabile di Poisson. Basti infatti pensare che pu√≤ assumere valori negativi."
  },
  {
    "objectID": "022_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "href": "022_discr_rv_distr.html#distribuzione-discreta-uniforme",
    "title": "12¬† Distribuzioni di v.c. discrete",
    "section": "\n12.4 Distribuzione discreta uniforme",
    "text": "12.4 Distribuzione discreta uniforme\nUna distribuzione discreta uniforme √® una distribuzione di probabilit√† discreta che √® uniforme su un insieme, ovvero che attribuisce ad ogni elemento dell‚Äôinsieme discreto e finito \\(S\\) su cui √® definita la stessa probabilit√† \\(p\\) di verificarsi.\nSi consideri una variabile casuale \\(X\\) con supporto \\(1, 2, \\dots, m\\). Un esperimento casuale in cui si verifica questa distribuzione √® la scelta casuale di un intero compreso tra 1 e \\(m\\) inclusi. Sia \\(X\\) il numero scelto. Allora\n\\[\nP(X = x) = \\frac{1}{m}, \\quad x = 1, \\dots, m.\n\\]\nIl valore atteso di \\(X\\) √®\n\\[\n\\mathbb{E}(X) = \\sum_{x=1}^m x f_X(x) = \\sum_{x=1}^m x \\frac{1}{m} = \\frac{1}{m} (1 + 2 + \\dots + m) = \\frac{m+1}{2},\n\\]\ndove abbiamo utilizzato l‚Äôidentit√† \\(1+2+¬∑¬∑¬∑+m = m(m+1)/2\\).\nPer trovare la varianza, prima calcoliamo\n\\[\n\\mathbb{E}(X^2) = \\frac{1}{m} \\sum_{x=1}^m x^2,\n\\] e poi troviamo\n\\[\n\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left[\\mathbb{E}(X)\\right]^2.\n\\]\n\n12.4.1 Distribuzione discreta uniforme con \\(\\textsf{R}\\)\n\nLa sintassi per simulare una variabile casuale uniforme discreta √® sample(x, size, replace = TRUE). L‚Äôargomento x identifica i numeri da cui campionare casualmente. Se x √® un numero, il campionamento viene eseguito da 1 a x. L‚Äôargomento size indica quanto dovrebbe essere grande la dimensione del campione e replace indica se i numeri devono essere reintrodotti o meno nell‚Äôurna dopo essere stati estratti. L‚Äôopzione di default √® replace = FALSE ma per le uniformi discrete i valori estratti devono essere sostituiti. Seguono alcuni esempi.\n\nPer lanciare un dado equilibrato 3000 volte: sample(6, size = 3000, replace = TRUE);\nper scegliere 27 numeri casuali da 30 a 70: sample(30:70, size = 27, replace = TRUE);\nper lanciare una moneta equa 1000 volte: sample(c(\"H\",\"T\"), size = 1000, replace = TRUE)."
  },
  {
    "objectID": "022_discr_rv_distr.html#distribuzione-beta-binomiale",
    "href": "022_discr_rv_distr.html#distribuzione-beta-binomiale",
    "title": "12¬† Distribuzioni di v.c. discrete",
    "section": "\n12.5 Distribuzione beta-binomiale",
    "text": "12.5 Distribuzione beta-binomiale\nLa distribuzione beta-binomiale di parametri \\(N\\), \\(\\alpha\\) e \\(\\beta\\) √® una distribuzione discreta con una funzione di massa di probabilit√† uguale a\n\\[\n\\mbox{BetaBinomial}(y \\mid N, \\alpha, \\beta) = \\binom{N}{y} \\frac{B(y + \\alpha, N-y+\\beta)}{B(\\alpha, \\beta)},\n\\tag{12.6}\\]\ndove la funzione beta √® \\(B(u, v) = \\frac{\\Gamma(u)\\Gamma(v)}{\\Gamma(u+v)}\\).\nSenza entrare nei dettagli, ci accontentiamo di sapere che tale distribuzione √® implementata nella funzione dbbinom() del pacchetto extraDistr."
  },
  {
    "objectID": "022_discr_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "022_discr_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "12¬† Distribuzioni di v.c. discrete",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa distribuzione binomiale √® una distribuzione di probabilit√† discreta che descrive il numero di successi in un processo di Bernoulli, ovvero la variabile aleatoria \\(Y = Y_1 + \\dots + Y_n\\) che somma \\(n\\) variabili casuali indipendenti di uguale distribuzione di Bernoulli \\(\\mathcal{B}(\\theta)\\), ognuna delle quali pu√≤ fornire due soli risultati: il successo con probabilit√† \\(\\theta\\) e l‚Äôinsuccesso con probabilit√† \\(1 - \\theta\\).\nLa distribuzione binomiale √® molto importante per le sue molte applicazioni. Nelle presenti dispense dedicate all‚Äôanalisi bayesiana, √® importante perch√© costituisce il fondamento del caso pi√π semplice dell‚Äôaggiornamento bayesiano, ovvero il caso Beta-Binomiale. Il modello Beta-Binomiale fornisce un esempio paradigmatico dell‚Äôapproccio bayesiano all‚Äôinferenza e sar√† trattato in maniera analitica nei capitoli successivi. √à dunque importante che le propriet√† della distribuzione binomiale risultino ben chiare."
  },
  {
    "objectID": "023_cont_rv_distr.html",
    "href": "023_cont_rv_distr.html",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "",
    "text": "Dopo avere introdotto con una simulazione il concetto di funzione di densit√† nel Capitolo Capitolo¬†10, prendiamo ora in esame alcune delle densit√† di probabilit√† pi√π note. La pi√π importante di esse √® sicuramente la distribuzione Normale."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-gaussiana",
    "href": "023_cont_rv_distr.html#distribuzione-gaussiana",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.1 Distribuzione Gaussiana",
    "text": "13.1 Distribuzione Gaussiana\nNon c‚Äô√® un‚Äôunica distribuzione gaussiana (o normale): la distribuzione gaussiana √® una famiglia di distribuzioni. Tali distribuzioni sono dette ‚Äúgaussiane‚Äù in onore di Carl Friedrich Gauss (uno dei pi√π grandi matematici della storia il quale, tra le altre cose, scopr√¨ l‚Äôutilit√† di tale funzione di densit√† per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale funzione di densit√† alle misurazioni dell‚Äôuomo. Karl Pearson us√≤ per primo il termine ‚Äúdistribuzione normale‚Äù anche se ammise che questa espressione ‚Äúha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell‚Äôaltro, non siano normali.‚Äù\n\n13.1.1 Limite delle distribuzioni binomiali\nIniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre not√≤ che, aumentando il numero di prove di una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Con 10 prove e una probabilit√† di successo di 0.9 in ciascuna prova, la distribuzione √® chiaramente asimmetrica.\n\nCodiceN <- 10\nx <- 0:10\ny <- dbinom(x, N, 0.9)\nbinomial_limit_plot <-\n  tibble(x = x, y = y) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_bar(\n    stat = \"identity\", color = \"black\", size = 0.2\n  ) +\n  xlab(\"y\") +\n  scale_x_continuous(breaks = c(0, 2, 4, 6, 8, 10)) +\n  ylab(\"Binomial(y | 10, 0.9)\")\nbinomial_limit_plot\n\n\n\nFigura 13.1: Probabilit√† del numero di successi in \\(N = 10\\) prove bernoulliane indipendenti, ciascuna con una probabilit√† di successo di 0.90. Il risultato √® una distribuzione \\(\\mbox{Bin}(y \\mid 10, 0.9)\\). Con solo dieci prove, la distribuzione √® fortemente asimmetrica negativa.\n\n\n\n\nMa se aumentiamo il numero di prove di un fattore di 100 a N = 1000, senza modificare la probabilit√† di successo di 0.9, la distribuzione assume una forma campanulare quasi simmetrica. Dunque, de Moivre scopr√¨ che, quando N √® grande, la funzione gaussiana (che introdurremo qui sotto), nonostante sia la densit√† di v.a. continue, fornisce una buona approssimazione alla funzione di massa di probabilit√† binomiale.\n\nCodiceN <- 1000\nx <- 0:1000\ny <- dbinom(x, N, 0.9)\nbinomial_limit_plot <-\n  tibble(x = x, y = y) %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_bar(stat = \"identity\", color = \"black\", size = 0.2) +\n  xlab(\"y\") +\n  ylab(\"Binomial(y | 1000, 0.9)\") +\n  xlim(850, 950)\nbinomial_limit_plot\n\n\n\nFigura 13.2: Probabilit√† del numero di successi in \\(N = 1000\\) prove bernoulliane indipendenti, ciascuna con una probabilit√† di successo di 0.90. Il risultato √® una distribuzione \\(\\mbox{Bin}(y \\mid 1000, 0.9)\\). Con mille prove, la distribuzione √® quasi simmetrica a forma campanulare.\n\n\n\n\nLa distribuzione Normale fu scoperta da Gauss nel 1809. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione."
  },
  {
    "objectID": "023_cont_rv_distr.html#normal-random-walk",
    "href": "023_cont_rv_distr.html#normal-random-walk",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.2 La Normale prodotta con una simulazione",
    "text": "13.2 La Normale prodotta con una simulazione\nMcElreath (2020) illustra come sia possibile giungere alla distribuzione Normale mediante una simulazione. Supponiamo che vi siano mille persone tutte allineate su una linea di partenza. Quando viene dato un segnale, ciascuna persona lancia una moneta e fa un passo in avanti oppure all‚Äôindietro a seconda che sia uscita testa o croce. Supponiamo che la lunghezza di ciascun passo vari da 0 a 1 metro. Ciascuna persona lancia una moneta 16 volte e dunque compie 16 passi.\nAlla conclusione di queste passeggiate casuali (random walk) non possiamo sapere con esattezza dove si trover√† ciascuna persona, ma possiamo conoscere con certezza le caratteristiche della distribuzione delle mille distanze dall‚Äôorigine. Per esempio, possiamo predire in maniera accurata la proporzione di persone che si sono spostate in avanti oppure all‚Äôindietro. Oppure, possiamo predire accuratamente la proporzione di persone che si troveranno ad una certa distanza dalla linea di partenza (es., a 1.5 m dall‚Äôorigine).\nQueste predizioni sono possibili perch√© tali distanze si distribuiscono secondo la legge Normale. √à facile simulare questo processo usando . I risultati della simulazione sono riportati nella Figura¬†13.3.\n\nCodicepos <-\n  replicate(100, runif(16, -1, 1)) %>%\n  as_tibble() %>%\n  rbind(0, .) %>%\n  mutate(step = 0:16) %>%\n  gather(key, value, -step) %>%\n  mutate(person = rep(1:100, each = 17)) %>%\n  group_by(person) %>%\n  mutate(position = cumsum(value)) %>%\n  ungroup()\n\nggplot(\n  data = pos,\n  aes(x = step, y = position, group = person)\n) +\n  geom_vline(xintercept = c(4, 8, 16), linetype = 2) +\n  geom_line(aes(color = person < 2, alpha = person < 2)) +\n  scale_color_manual(values = c(\"gray\", \"black\")) +\n  scale_alpha_manual(values = c(1 / 5, 1)) +\n  scale_x_continuous(\n    \"Numero di passi\",\n    breaks = c(0, 4, 8, 12, 16)\n  ) +\n  labs(y = \"Posizione\") +\n  theme(legend.position = \"none\")\n\n\n\nFigura 13.3: Passeggiata casuale di 4, 8 e 16 passi. La spezzata nera indica la media delle distanze dall‚Äôorigine come funzione del numero di passi.\n\n\n\n\nUn kernel density plot delle distanze ottenute dopo 4, 8 e 16 passi √® riportato nella Figura¬†13.4. Nel pannello di destra, al kernel density plot √® stata sovrapposta una densit√† Normale di opportuni parametri (linea tratteggiata).\n\nCodicep1 <-\n  pos %>%\n  filter(step == 4) %>%\n  ggplot(aes(x = position)) +\n  geom_line(stat = \"density\", color = \"black\") +\n  labs(title = \"4 passi\")\n\np2 <-\n  pos %>%\n  filter(step == 8) %>%\n  ggplot(aes(x = position)) +\n  geom_density(color = \"black\", outline.type = \"full\") +\n  labs(title = \"8 passi\")\n\nsd <-\n  pos %>%\n  filter(step == 16) %>%\n  summarise(sd = sd(position)) %>%\n  pull(sd)\n\np3 <-\n  pos %>%\n  filter(step == 16) %>%\n  ggplot(aes(x = position)) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = 0, sd = sd),\n    linetype = 2\n  ) +\n  geom_density(color = \"black\", alpha = 1 / 2) +\n  labs(\n    title = \"16 passi\",\n    y = \"Densit√†\"\n  )\n\n(p1 | p2 | p3) & coord_cartesian(xlim = c(-6, 6))\n\n\n\nFigura 13.4: Kernel density plot dei risultati della passeggiata casuale riportata nella figura precente, dopo 4, 8 e 16 passi. Nel pannello di destra, una densit√† Normale di opportuni parametri √® sovrapposta all‚Äôistogramma lisciato.\n\n\n\n\nQuesta simulazione mostra che qualunque processo nel quale viene sommato un certo numero di valori casuali, tutti provenienti dalla medesima distribuzione, converge ad una distribuzione Normale. Non importa quale sia la forma della distribuzione di partenza: essa pu√≤ essere uniforme, come nell‚Äôesempio presente, o di qualunque altro tipo. La forma della distribuzione da cui viene realizzato il campionamento determina la velocit√† della convergenza alla Normale. In alcuni casi la convergenza √® lenta; in altri casi la convergenza √® molto rapida (come nell‚Äôesempio presente).\nDa un punto di vista formale, diciamo che una variabile casuale continua \\(Y\\) ha una distribuzione Normale se la sua densit√† √®\n\\[\nf(y; \\mu, \\sigma) = {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y -  \\mu)^2}{2 \\sigma^2} \\right\\},\n\\tag{13.1}\\]\ndove \\(\\mu \\in \\mathbb{R}\\) e \\(\\sigma > 0\\) sono i parametri della distribuzione.\nLa densit√† normale √® unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densit√† in corrispondenza di \\(\\mu\\).\nIl significato dei parametri \\(\\mu\\) e \\(\\sigma\\) che appaiono nell‚ÄôEquazione¬†13.1 viene chiarito dalla dimostrazione che\n\\[\n\\mathbb{E}(Y) = \\mu, \\qquad \\mathbb{V}(Y) = \\sigma^2.\n\\]\nLa rappresentazione grafica di quattro densit√† Normali tutte con media 0 e con deviazioni standard 0.25, 0.5, 1 e 2 √® fornita nella Figura¬†13.5.\n\n\n\n\nFigura 13.5: Alcune distribuzioni Normali.\n\n\n\n\n\n13.2.1 Concentrazione\n√à istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:\n\\[\n\\begin{align}\nP(\\mu - \\sigma < Y < \\mu + \\sigma) &= P (-1 < Z < 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma < Y < \\mu + 2\\sigma) &= P (-2 < Z < 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma < Y < \\mu + 3\\sigma) &= P (-3 < Z < 3) \\simeq 0.997. \\notag\n\\end{align}\n\\]\nSi noti come un dato la cui distanza dalla media √® superiore a 3 volte la deviazione standard presenti un carattere di eccezionalit√† perch√© meno del 0.3% dei dati della distribuzione Normale presentano questa caratteristica.\nPer indicare la distribuzione Normale si usa la notazione \\(\\mathcal{N}(\\mu, \\sigma)\\).\n\n13.2.2 Funzione di ripartizione\nIl valore della funzione di ripartizione di \\(Y\\) nel punto \\(y\\) √® l‚Äôarea sottesa alla curva di densit√† \\(f(y)\\) nella semiretta \\((-\\infty, y]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\n\\[\nF(y) = \\int_{-\\infty}^y {1 \\over {\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(y - \\mu)^2}{2\\sigma^2} \\right\\} dy,\n\\tag{13.2}\\]\npertanto le probabilit√† \\(P(Y < y)\\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.\n\nEsercizio 13.1 Usiamo \\(\\mathsf{R}\\) per calcolare la funzione di ripartizione della Normale. La funzione pnorm(q, mean, sd) restituisce la funzione di ripartizione della Normale con media mean e deviazione standard sd, ovvero l‚Äôarea sottesa alla funzione di densit√† di una Normale con media mean e deviazione standard sd nell‚Äôintervallo \\([-\\infty, q]\\).\nPer esempio, in precedenza abbiamo detto che il 68% circa dell‚Äôarea sottesa ad una Normale √® compresa nell‚Äôintervallo \\(\\mu \\pm \\sigma\\). Verifichiamo per la distribuzione del QI \\(\\sim \\mathcal{N}(\\mu = 100, \\sigma = 15)\\):\n\nCodicepnorm(100+15, 100, 15) - pnorm(100-15, 100, 15)\n#> [1] 0.6826895\n\n\nIl 95% dell‚Äôarea √® compresa nell‚Äôintervallo \\(\\mu \\pm 1.96 \\cdot\\sigma\\):\n\nCodicepnorm(100 + 1.96 * 15, 100, 15) - pnorm(100 - 1.96 * 15, 100, 15)\n#> [1] 0.9500042\n\n\nQuasi tutta la distribuzione √® compresa nell‚Äôintervallo \\(\\mu \\pm 3 \\cdot\\sigma\\):\n\nCodicepnorm(100 + 3 * 15, 100, 15) - pnorm(100 - 3 * 15, 100, 15)\n#> [1] 0.9973002\n\n\n\n\n13.2.3 Distribuzione Normale standard\nLa distribuzione Normale di parametri \\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard. La famiglia Normale √® l‚Äôinsieme avente come elementi tutte le distribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \\(Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y)\\) allora\n\\[\nX = a + b Y \\sim \\mathcal{N}(\\mu_X = a+b \\mu_Y, \\sigma_X = \\left|b\\right|\\sigma_Y).\n\\]\nL‚Äôarea sottesa alla curva di densit√† di \\(\\mathcal{N}(\\mu, \\sigma)\\) nella semiretta \\((-\\infty, y]\\) √® uguale all‚Äôarea sottesa alla densit√† Normale standard nella semiretta \\((-\\infty, z]\\), in cui \\(z = (y -\\mu_Y )/\\sigma_Y\\) √® il punteggio standard di \\(Y\\). Per la simmetria della distribuzione, l‚Äôarea sottesa nella semiretta \\([1, \\infty)\\) √® uguale all‚Äôarea sottesa nella semiretta \\((-\\infty, 1]\\) e quest‚Äôultima coincide con \\(F(-1)\\). Analogamente, l‚Äôarea sottesa nell‚Äôintervallo \\([y_a, y_b]\\), con \\(y_a < y_b\\), √® pari a \\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono i punteggi standard di \\(y_a\\) e \\(y_b\\).\nSi ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \\(0 \\leq p \\leq 1\\), il problema √® quello di determinare un numero \\(z \\in \\mathbb{R}\\) tale che \\(P(Z < z) = p\\). Il valore \\(z\\) cercato √® detto quantile di ordine \\(p\\) della Normale standard e pu√≤ essere trovato mediante un software.\n\nEsercizio 13.2 \nSupponiamo che l‚Äôaltezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un‚Äôaltezza compresa tra \\(1.7\\) e \\(1.8\\) m.\n\n\nSoluzione. Il problema ci chiede di trovare l‚Äôarea sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell‚Äôintervallo \\([1.7, 1.8]\\):\n\nCodicedf <- tibble(x = seq(1.4, 2.0, length.out = 100)) %>%\n  mutate(y = dnorm(x, mean = 1.7, sd = 0.1))\n\nggplot(df, aes(x, y)) +\n  geom_area(fill = \"sky blue\") +\n  gghighlight(x < 1.8 & x > 1.7) +\n  labs(\n    x = \"Altezza\",\n    y = \"Densit√†\"\n  )\n\n\n\n\n\n\n\nLa risposta si trova utilizzando la funzione di ripartizione \\(F(X)\\) della legge \\(\\mathcal{N}(1.7, 0.1)\\) in corrispondenza dei due valori forniti dal problema: \\(F(X = 1.8) - F(X = 1.7)\\). Utilizzando la seguente istruzione\n\nCodicepnorm(1.8, 1.7, 0.1) - pnorm(1.7, 1.7, 0.1)\n#> [1] 0.3413447\n\n\notteniamo il \\(31.43\\%\\).\nIn maniera equivalente, possiamo standardizzare i valori che delimitano l‚Äôintervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell‚Äôintervallo sono\n\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamo\n\nCodicepnorm(1.0, 0, 1) - pnorm(0, 0, 1)\n#> [1] 0.3413447\n\n\nIl modo pi√π semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilit√† richiesta non √® altro che la met√† dell‚Äôarea sottesa dalle distribuzioni Normali nell‚Äôintervallo \\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).\n\n\n13.2.3.1 Funzione di ripartizione della normale standard e funzione logistica\nSi noti che la funzione logistica (in blu), pur essendo del tutto diversa dalla Normale dal punto di vista formale, assomiglia molto alla Normale standard quando le due cdf hanno la stessa varianza.\n\nCodicetibble(x = c(-3, 3)) %>%\n  ggplot(aes(x = x)) +\n  stat_function(fun = pnorm) +\n  stat_function(\n    fun = plogis,\n    args = list(scale = 0.56)\n  )"
  },
  {
    "objectID": "023_cont_rv_distr.html#teorema-del-limite-centrale",
    "href": "023_cont_rv_distr.html#teorema-del-limite-centrale",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.3 Teorema del limite centrale",
    "text": "13.3 Teorema del limite centrale\nLaplace dimostr√≤ il teorema del limite centrale (TLC) nel 1812. Il TLC ci dice che se prendiamo una sequenza di variabili casuali indipendenti e le sommiamo, tale somma tende a distribuirsi come una Normale. Il TLC specifica inoltre, sulla base dei valori attesi e delle varianze delle v.c. che vengono sommate, quali sono i parametri della distribuzione Normale cos√¨ ottenuta.\n\nTeorema 13.1 Si supponga che \\(Y = Y_1, \\dots, Y_i, \\ldots, Y_n\\) sia una sequenza di v.a. i.i.d. con \\(\\mathbb{E}(Y_i) = \\mu\\) e \\(\\mbox{SD}(Y_i) = \\sigma\\). Si definisca una nuova v.c. come:\n\\[\nZ = \\frac{1}{n} \\sum_{i=1}^n Y_i.\n\\]\nCon \\(n \\rightarrow \\infty\\), \\(Z\\) tender√† ad una Normale con lo stesso valore atteso di \\(Y_i\\) e una deviazione standard che sar√† pi√π piccola della deviazione standard originaria di un fattore pari a \\(\\frac{1}{\\sqrt{n}}\\):\n\\[\np_Z(z) \\rightarrow \\mathcal{N}\\left(z \\ \\Bigg| \\ \\mu, \\, \\frac{1}{\\sqrt{n}} \\cdot \\sigma \\right).\n\\]\n\nIl TLC pu√≤ essere generalizzato a variabili che non hanno la stessa distribuzione purch√© siano indipendenti e abbiano aspettative e varianze finite. Molti fenomeni naturali, come l‚Äôaltezza dell‚Äôuomo adulto di entrambi i generi, sono il risultato di una serie di effetti additivi relativamente piccoli, la cui combinazione porta alla normalit√†, indipendentemente da come gli effetti additivi sono distribuiti. Questo √® il motivo per cui la distribuzione normale forniscre una buona rappresentazione della distribuzione di molti fenomeni naturali."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-chi-quadrato",
    "href": "023_cont_rv_distr.html#distribuzione-chi-quadrato",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.4 Distribuzione Chi-quadrato",
    "text": "13.4 Distribuzione Chi-quadrato\nDalla Normale deriva la distribuzione \\(\\chi^2\\). La distribuzione \\(\\chi^2_{~k}\\) con \\(k\\) gradi di libert√† descrive la variabile casuale\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono variabili casuali i.i.d. che seguono la distribuzione Normale standard \\(\\mathcal{N}(0, 1)\\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi di libert√†. La densit√† di probabilit√† di \\(\\chi^2_{~\\nu}\\) √®\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x > 0,\n\\]\ndove \\(C_{\\nu}\\) √® una costante positiva.\nLa Figura¬†13.6 mostra alcune distribuzioni Chi-quadrato variando il parametro \\(\\nu\\).\n\n\n\n\nFigura 13.6: Alcune distribuzioni Chi-quadrato.\n\n\n\n\n\n13.4.1 Propriet√†\n\nLa distribuzione di densit√† \\(\\chi^2_{~\\nu}\\) √® asimmetrica.\nIl valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(\\nu\\).\nLa varianza di una variabile \\(\\chi^2_{~\\nu}\\) √® uguale a \\(2\\nu\\).\nPer \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).\nSe \\(X\\) e \\(Y\\) sono due variabili casuali chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libert√†, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti.\n\n\nEsercizio 13.3 Usiamo \\(\\mathsf{R}\\) per disegnare la densit√† chi-quadrato con 3 gradi di libert√† dividendo l‚Äôarea sottesa alla curva di densit√† in due parti uguali.\n\nCodicedf <- tibble(x = seq(0, 15.0, length.out = 100)) %>%\n  mutate(y = dchisq(x, 3))\n\nggplot(df, aes(x, y)) +\n  geom_area(fill = \"sky blue\") +\n  gghighlight(x < 3) +\n  labs(\n    x = \"V.a. chi-quadrato con 3 gradi di libert√†\",\n    y = \"Densit√†\"\n  )"
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-t-di-student",
    "href": "023_cont_rv_distr.html#distribuzione-t-di-student",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.5 Distribuzione \\(t\\) di Student",
    "text": "13.5 Distribuzione \\(t\\) di Student\nDalle distribuzioni Normale e Chi-quadrato deriva un‚Äôaltra distribuzione molto nota, la \\(t\\) di Student. Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili casuali indipendenti, allora il rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\tag{13.3}\\]\ndefinisce la distribuzione \\(t\\) di Student con \\(\\nu\\) gradi di libert√†. Si usa scrivere \\(T \\sim t_{\\nu}\\). L‚Äôandamento della distribuzione \\(t\\) di Student √® simile a quello della distribuzione Normale, ma ha una maggiore dispersione (ha le code pi√π pesanti di una Normale, ovvero ha una varianza maggiore di 1).\nLa Figura¬†13.7 mostra alcune distribuzioni \\(t\\) di Student variando il parametro \\(\\nu\\).\n\n\n\n\nFigura 13.7: Alcune distribuzioni \\(t\\) di Student.\n\n\n\n\n\n13.5.1 Propriet√†\nLa variabile casuale \\(t\\) di Student soddisfa le seguenti propriet√†:\n\nPer \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard \\(\\mathcal{N}(0, 1)\\).\nLa densit√† della \\(t_{\\nu}\\) √® una funzione simmetrica con valore atteso nullo.\nPer \\(\\nu > 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\); pertanto √® sempre maggiore di 1 e tende a 1 per \\(\\nu \\rightarrow \\infty\\)."
  },
  {
    "objectID": "023_cont_rv_distr.html#funzione-beta",
    "href": "023_cont_rv_distr.html#funzione-beta",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.6 Funzione beta",
    "text": "13.6 Funzione beta\nLa funzione beta di Eulero √® una funzione matematica, non una densit√† di probabilit√†. La menzioniamo qui perch√© viene utilizzata nella distribuzione Beta. La funzione beta si pu√≤ scrivere in molti modi diversi; per i nostri scopi la scriveremo cos√¨:\n\\[\nB(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\,,\n\\tag{13.4}\\]\ndove \\(\\Gamma(x)\\) √® la funzione Gamma, ovvero il fattoriale discendente, cio√®\n\\[\n(x-1)(x-2)\\ldots (x-n+1)\\notag\\,.\n\\]\n\nEsercizio 13.4 \nPer esempio, posti \\(\\alpha = 3\\) e \\(\\beta = 9\\), la funzione beta assume il valore\n\nCodicealpha <- 3\nbeta <- 9\nbeta(alpha, beta)\n#> [1] 0.002020202\n\n\nPer chiarire, lo stesso risultato si ottiene con\n\nCodice((2) * (8 * 7 * 6 * 5 * 4 * 3 * 2)) / \n  (11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2)\n#> [1] 0.002020202\n\n\novvero\n\nCodicegamma(alpha) * gamma(beta) / gamma(alpha + beta)\n#> [1] 0.002020202"
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-beta",
    "href": "023_cont_rv_distr.html#distribuzione-beta",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.7 Distribuzione Beta",
    "text": "13.7 Distribuzione Beta\nLa distribuzione Beta √® una distribuzione usata per modellare percentuali e proporzioni in quanto √® definita sull‚Äôintervallo \\((0; 1)\\) ‚Äì ma non include i valori 0 o 1.\n\nDefinizione 13.1 Sia \\(\\pi\\) una variabile casuale che pu√≤ assumere qualsiasi valore compreso tra 0 e 1, cio√® \\(\\pi \\in [0, 1]\\). Diremo che \\(\\pi\\) segue la distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\), \\(\\pi \\sim \\text{Beta}(\\alpha, \\beta)\\), se la sua densit√† √®\n\\[\n\\begin{align}\n\\text{Beta}(\\pi \\mid \\alpha, \\beta) &= \\frac{1}{B(\\alpha, \\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1}\\notag\\\\\n&=  \\frac{\\Gamma(\\alpha+ \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} \\quad \\text{per } \\pi \\in [0, 1]\\,,\n\\end{align}\n\\tag{13.5}\\]\nladdove \\(B(\\alpha, \\beta)\\) √® la funzione beta.\n\nI termini \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione Beta e devono essere entrambi positivi. Tali parametri possono essere interpretati come l‚Äôespressione delle nostre credenze a priori relative ad una sequenza di prove Bernoulliane. Il parametro \\(\\alpha\\) rappresenta il numero di ‚Äúsuccessi‚Äù e il parametro \\(\\beta\\) il numero di ‚Äúinsuccessi‚Äù:\n\\[\n\\frac{\\text{Numero di successi}}{\\text{Numero di successi} + \\text{Numero di insuccessi}} = \\frac{\\alpha}{\\alpha + \\beta}\\notag\\,.\n\\]\nIl rapporto \\(\\frac{1}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\) √® una costante di normalizzazione:\n\\[\n\\int_0^1 \\pi^{\\alpha-1} (1-\\pi)^{\\beta-1} = \\frac{\\Gamma(\\alpha+b)}{\\Gamma(\\alpha)\\Gamma(\\beta)}\\,.\n\\]\nAd esempio, con \\(\\alpha = 3\\) e \\(\\beta = 9\\) abbiamo\n\nCodicea <- 3\nb <- 9\nintegrand <- function(p) {p^{a - 1}*(1 - p)^{b - 1}}\nintegrate(integrand, lower = 0, upper = 1)\n#> 0.002020202 with absolute error < 2.2e-17\n\n\novvero\n\nCodice1 / (gamma(a + b) / (gamma(a) * gamma(b)))\n#> [1] 0.002020202\n\n\novvero\n\nCodicebeta(alpha, beta)\n#> [1] 0.002020202\n\n\nIl valore atteso, la moda e la varianza di una distribuzione Beta sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(\\pi) = \\frac{\\alpha}{\\alpha+\\beta}\\,,\n\\tag{13.6}\\]\n\\[\n\\mbox{Mo}(\\pi) = \\frac{\\alpha-1}{\\alpha+\\beta-2}\\,,\n\\tag{13.7}\\]\n\\[\n\\mathbb{V}(\\pi) = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2 (\\alpha+\\beta+1)}\\,.\n\\tag{13.8}\\]\nAl variare di \\(\\alpha\\) e \\(\\beta\\) si ottengono molte distribuzioni di forma diversa; un‚Äôillustrazione √® fornita dalla seguente GIF animata.\nSi pu√≤ ottenere una rappresentazione grafica della distribuzione \\(\\mbox{Beta}(\\pi \\mid \\alpha, \\beta)\\) con la funzione plot_beta() del pacchetto bayesrules. Per esempio:\n\nCodicebayesrules::plot_beta(alpha = 3, beta = 9)\n\n\n\n\n\n\n\nLa funzione bayesrules::summarize_beta() ci restituisce la media, moda e varianza della distribuzione Beta. Per esempio:\n\nCodicebayesrules::summarize_beta(alpha = 3, beta = 9)\n#>   mean mode        var        sd\n#> 1 0.25  0.2 0.01442308 0.1200961\n\n\n\nNota. Attenzione alle parole: in questo contesto, il termine ‚Äúbeta‚Äù viene utilizzato con tre significati diversi:\n\nla distribuzione di densit√† Beta,\nla funzione matematica beta,\nil parametro \\(\\beta\\).\n\n\n\nEsercizio 13.5 \nNel disturbo depressivo la recidiva √® definita come la comparsa di un nuovo episodio depressivo che si manifesta dopo un prolungato periodo di recupero (6-12 mesi) con stato di eutimia (umore relativamente normale). Supponiamo che una serie di studi mostri una comparsa di recidiva in una proporzione che va dal 20% al 60% dei casi, con una media del 40% (per una recente discussione, si veda Nuggerud-Galeas et al., 2020). Sulla base di queste informazioni, si usi la distribuzione Beta per rappresentare le credenze a priori relativamente alla probabilit√† di recidiva.\n\n\nSoluzione. Il problema richiede di trovare i parametri della distribuzione Beta tali per cui la massa della densit√† sia compresa tra 0.2 e 0.6, con la media in corrispondenza di 0.4. Procedendo per tentativi ed errori, ed usando la funzione bayesrules::plot_beta(), un risultato possibile √® \\(\\mbox{Beta}(16, 24)\\).\nLa funzione find_pars() prende in input la media e \\(\\alpha + \\beta\\), ritorna i valori dei parametri:\n\nCodicefind_pars <- function(ev, n) {\n  a <- ev * n\n  b <- n - a\n  return(c(round(a), round(b)))\n}\n\npars <- find_pars(.4, 40)\npars\n#> [1] 16 24\nbayesrules::plot_beta(pars[1], pars[2])\n\n\n\n\n\n\n\nVerifichiamo il valore della media della distribuzione:\n\nCodice16 / (16 + 24)\n#> [1] 0.4\n\n\nLa moda √®\n\nCodice(16 - 1) / (16 + 24 - 2)\n#> [1] 0.3947368\n\n\nLa deviazione standard della distribuzione √® uguale a circa 8 punti percentuali:\n\nCodicesqrt((16 * 24) / ((16 + 24)^2 * (16 + 24 + 1)))\n#> [1] 0.07650921\n\n\nGli stessi risultati si ottengono usando la funzione bayesrules::summarize_beta():\n\nCodicebayesrules::summarize_beta(alpha = 16, beta = 24)\n#>   mean      mode         var         sd\n#> 1  0.4 0.3947368 0.005853659 0.07650921\n\n\nPossiamo concludere dicendo che, se utilizziamo la distribuzione \\(\\mbox{Beta}(16, 24)\\) per rappresentare le nostre credenze (a priori) rispetto la possibilit√† di recidiva, ci√≤ significa che pensiamo che la nostra incertezza sia quantificabile nei termini di una deviazione standard di circa 8 punti percentuali rispetto a tutti i valori possibili di recidiva, per i quali il valore pi√π verosimile (ovvero, la media della distribuzione) √® 0.40.\n\n\nEsercizio 13.6 \nPoniamoci ora il problema di verificare la nostra comprensione delle funzioni \\(\\mathsf{R}\\) che possono essere usate per la funzione Beta. Si risolva l‚ÄôEsercizio¬†17.1 usando \\(\\mathsf{R}\\).\n\n\nSoluzione. Utilizziamo i seguenti parametri per la distribuzione Beta:\n\nCodicealpha <- 16\nbeta <- 24\n\n\nLa media di una \\(\\mbox{Beta}(16, 24)\\) √®\n\nCodicealpha / (alpha + beta)\n#> [1] 0.4\n\n\nIn corrispondenza della media la densit√† della funzione √®\n\nCodicedbeta(pi, alpha, beta)\n#> [1] 0\n\n\novvero\n\nCodicegamma(alpha + beta) / (gamma(alpha) * gamma(beta)) * \n  pi^(alpha - 1) * (1 - pi)^(beta - 1)\n#> [1] -6.99499e+26\n\n\nUsando la funzione dbeta() possiamo costruire un grafico della funzione \\(\\mbox{Beta}(16, 24)\\) nel modo seguente:\n\nCodicex <- seq(0, 1, length.out = 1e4)\ntibble(x) %>% \n  ggplot(aes(x, dbeta(x, alpha, beta))) +\n  geom_line() +\n  labs(\n    x = \"Probabilit√† di recidiva\",\n    y = \"Densit√† Beta(16, 24)\"\n  )"
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-di-cauchy",
    "href": "023_cont_rv_distr.html#distribuzione-di-cauchy",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.8 Distribuzione di Cauchy",
    "text": "13.8 Distribuzione di Cauchy\nLa distribuzione di Cauchy √® un caso speciale della distribuzione di \\(t\\) di Student con 1 grado di libert√†. √à definita da una densit√† di probabilit√† che corrisponde alla seguente funzione, dipendente da due parametri \\(\\theta\\) e \\(d\\) (con la condizione \\(d > 0\\)),\n\\[\nf(x; \\theta, d) = \\frac{1}{\\pi d} \\frac{1}{1 + \\left(\\frac{x - \\theta}{d} \\right)^2},\n\\tag{13.9}\\]\ndove \\(\\theta\\) √® la mediana della distribuzione e \\(d\\) ne misura la larghezza a met√† altezza."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-log-normale",
    "href": "023_cont_rv_distr.html#distribuzione-log-normale",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.9 Distribuzione log-normale",
    "text": "13.9 Distribuzione log-normale\nSia \\(y\\) una variabile casuale avente distribuzione normale con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Definiamo poi una nuova variabile casuale \\(x\\) attraverso la relazione\n\\[\nx = e^y \\quad \\Longleftrightarrow \\quad y = \\log x.\n\\] Il dominio di definizione della \\(x\\) √® il semiasse \\(x > 0\\) e la densit√† di probabilit√† \\(f(x)\\) √® data da\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\frac{1}{x} \\exp \\left\\{-\\frac{(\\log x -  \\mu)^2}{2 \\sigma^2} \\right\\}.\n\\tag{13.10}\\]\nQuesta funzione di densit√† √® chiamata log-normale.\nIl valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni:\n\\[\n\\mathbb{E}(x) = \\exp \\left\\{\\mu + \\frac{\\sigma^2}{2} \\right\\}.\n\\]\n\\[\n\\mathbb{V}(x) = \\exp \\left\\{2 \\mu + \\sigma^2 \\right\\} \\left(\\exp \\left\\{\\sigma^2 \\right\\}  -1\\right).\n\\]\nSi puoÃÄ dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale."
  },
  {
    "objectID": "023_cont_rv_distr.html#distribuzione-di-pareto",
    "href": "023_cont_rv_distr.html#distribuzione-di-pareto",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "\n13.10 Distribuzione di Pareto",
    "text": "13.10 Distribuzione di Pareto\nLa distribuzione paretiana (o distribuzione di Pareto) √® una distribuzione di probabilit√† continua e cos√¨ chiamata in onore di Vilfredo Pareto. La distribuzione di Pareto √® una distribuzione di probabilit√† con legge di potenza utilizzata nella descrizione di fenomeni sociali e molti altri tipi di fenomeni osservabili. Originariamente applicata per descrivere la distribuzione del reddito in una societ√†, adattandosi alla tendenza che una grande porzione di ricchezza √® detenuta da una piccola frazione della popolazione, la distribuzione di Pareto √® diventata colloquialmente nota e indicata come il principio di Pareto, o ‚Äúregola 80-20‚Äù. Questa regola afferma che, ad esempio, l‚Äô80% della ricchezza di una societ√† √® detenuto dal 20% della sua popolazione. Viene spesso applicata nello studio della distribuzione del reddito, della dimensione dell‚Äôimpresa, della dimensione di una popolazione e nelle fluttuazioni del prezzo delle azioni.\nLa densit√† di una distribuzione di Pareto √®\n\\[\nf(x)=(x_m/x)^\\alpha,\n\\tag{13.11}\\]\ndove \\(x_m\\) (parametro di scala) √® il minimo (necessariamente positivo) valore possibile di \\(X\\) e \\(\\alpha\\) √® un parametro di forma.\n\n\n\n\n\n\n\n\nLa distribuzione di Pareto ha una asimmetria positiva. Il supporto della distribuzione di Pareto √® la retta reale positiva. Tutti i valori devono essere maggiori del parametro di scala \\(x_m\\), che √® in realt√† un parametro di soglia."
  },
  {
    "objectID": "023_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "href": "023_cont_rv_distr.html#commenti-e-considerazioni-finali",
    "title": "13¬† Distribuzioni di v.c. continue",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questa dispensa le densit√† continue che useremo pi√π spesso sono la distribuzione gaussiana e la distribuzione Beta. Faremo un uso limitato della distribuzione \\(t\\) di Student e della distribuzione di Cauchy. Le altre distribuzioni qui descritte sono stato presentate per completezza.\n\n\n\n\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNuggerud-Galeas, S., S√°ez-Benito Suescun, L., Berenguer Torrijo, N., S√°ez-Benito Suescun, A., Aguilar-Latorre, A., Magall√≥n Botaya, R., & Oliv√°n Bl√°zquez, B. (2020). Analysis of depressive episodes, their recurrence and pharmacologic treatment in primary care patients: A retrospective descriptive study. Plos One, 15(5), e0233454."
  },
  {
    "objectID": "024_likelihood.html",
    "href": "024_likelihood.html",
    "title": "14¬† La funzione di verosimiglianza",
    "section": "",
    "text": "La verosimiglianza viene utilizzata sia nell‚Äôinferenza bayesiana che in quella frequentista. In entrambi i paradigmi di inferenza, il suo ruolo √® quantificare la forza con la quale i dati osservati supportano i possibili valori dei parametri sconosciuti di un modello statistico.\nDetto in altre parole, la funzione di verosimiglianza e la funzione di (massa o densit√† di) probabilit√† sono formalmente identiche, ma √® completamente diversa la loro interpretazione:\nLa funzione di verosimiglianza descrive in termini relativi il sostegno empirico che \\(\\theta \\in \\Theta\\) riceve da \\(y\\). Infatti, la funzione di verosimiglianza assume forme diverse al variare di \\(y\\). Possiamo dunque pensare alla funzione di verosimiglianza come alla risposta alla seguente domanda: avendo osservato i dati \\(y\\), quanto risultano (relativamente) credibili i diversi valori del parametro \\(\\theta\\)? In termini pi√π formali possiamo dire: sulla base dei dati, \\(\\theta_1 \\in \\Theta\\) risulta pi√π credibile di \\(\\theta_2 \\in \\Theta\\) quale indice del modello probabilistico generatore dei dati se \\(\\mathcal{L}(\\theta_1) > \\mathcal{L}(\\theta_1)\\).\nSi noti un punto importante: la funzione \\(\\mathcal{L}(\\theta \\mid y)\\) non √® una funzione di densit√†. Infatti, essa non racchiude un‚Äôarea unitaria."
  },
  {
    "objectID": "024_likelihood.html#modello-binomiale",
    "href": "024_likelihood.html#modello-binomiale",
    "title": "14¬† La funzione di verosimiglianza",
    "section": "\n14.1 Modello binomiale",
    "text": "14.1 Modello binomiale\nIniziamo a discutere la funzione di verosimiglianza considerando il caso pi√π semplice, ovvero quello Binomiale.\nPer \\(n\\) prove Bernoulliane indipendenti, le quali producono \\(y\\) successi e (\\(n-y\\)) insuccessi, la funzione nucleo di verosimiglianza (ovvero, la funzione di verosimiglianza da cui sono state escluse tutte le costanti moltiplicative che non hanno alcun effetto su \\(\\hat{\\theta}\\)) √®\n\\[\n\\mathcal{L}(p \\mid y) = \\theta^y (1-\\theta)^{n - y}.\\notag\n\\tag{14.1}\\]\nPer fare un esempio pratico, consideriamo la ricerca di Zetsche et al. (2019). Questi ricercatori hanno trovato che, su 30 pazienti clinicamente depressi, 23 manifestavano delle aspettative relative al loro umore futuro distorsione negativamente. Se i dati di Zetsche et al. (2019) vengono riassunti da una proporzione (ovvero, 23/30), allora √® sensato adottare un modello probabilistico binomiale quale meccanismo generatore dei dati:\n\\[\ny  \\sim \\mbox{Bin}(n, \\theta),\n\\tag{14.2}\\]\nladdove \\(\\theta\\) √® la probabilt√† che una prova Bernoulliana assuma il valore 1 e \\(n\\) corrisponde al numero di prove Bernoulliane. Questo modello assume che le prove Bernoulliane \\(y_i\\) che costituiscono il campione \\(y\\) siano tra loro indipendenti e che ciascuna abbia la stessa probabilit√† \\(\\theta \\in [0, 1]\\) di essere un ‚Äúsuccesso‚Äù (valore 1). In altre parole, il modello generatore dei dati avr√† una funzione di massa di probabilit√†\n\\[\np(y \\mid \\theta)\n\\ = \\\n\\mbox{Bin}(y \\mid n, \\theta).\n\\]\nNei capitoli precedenti √® stato mostrato come, sulla base del modello binomiale, sia possibile assegnare una probabilit√† a ciascun possibile valore \\(y \\in \\{0, 1, \\dots, n\\}\\) assumendo noto il valore del parametro \\(\\theta\\). Ma ora abbiamo il problema inverso, ovvero quello di fare inferenza su \\(\\theta\\) alla luce dei dati campionari \\(y\\). In altre parole, riteniamo di conoscere il modello probabilistico che ha generato i dati, ma di tale modello non conosciamo i parametri: vogliamo dunque ottenere informazioni su \\(\\theta\\) avendo osservato i dati \\(y\\). Per fare questo, in un ottica bayesiana, √® innanzitutto necessario definire la funzione di verosimiglianza.\nPer i dati di Zetsche et al. (2019) la funzione di verosimiglianza corrisponde alla funzione binomiale di parametro \\(\\theta \\in [0, 1]\\) sconosciuto. Abbiamo osservato 23 successi, \\(y = 23\\), in 30 prove, \\(n = 30\\).\n\nCodicen <- 30\ny <- 23\n\n\nLa funzione di verosimiglianza dunque diventa\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} \\theta^{23} + (1-\\theta)^7.\n\\tag{14.3}\\]\nPer costruire la funzione di verosimiglianza dobbiamo applicare l‚ÄôEquazione¬†14.3 tante volte, cambiando ogni volta il valore \\(\\theta\\), ma tenendo sempre costante il valore dei dati. Nella simulazione considereremo 100 possibili valori \\(\\theta \\in [0, 1]\\).\n\nCodicetheta <- seq(0, 1, length.out = 100)\ntheta\n#>   [1] 0.00000000 0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n#>   [7] 0.06060606 0.07070707 0.08080808 0.09090909 0.10101010 0.11111111\n#>  [13] 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n#>  [19] 0.18181818 0.19191919 0.20202020 0.21212121 0.22222222 0.23232323\n#>  [25] 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n#>  [31] 0.30303030 0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n#>  [37] 0.36363636 0.37373737 0.38383838 0.39393939 0.40404040 0.41414141\n#>  [43] 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n#>  [49] 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n#>  [55] 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.59595960\n#>  [61] 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n#>  [67] 0.66666667 0.67676768 0.68686869 0.69696970 0.70707071 0.71717172\n#>  [73] 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n#>  [79] 0.78787879 0.79797980 0.80808081 0.81818182 0.82828283 0.83838384\n#>  [85] 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.89898990\n#>  [91] 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n#>  [97] 0.96969697 0.97979798 0.98989899 1.00000000\n\n\nPer esempio, ponendo \\(\\theta = 0.1\\) otteniamo un valore dell‚Äôordinata della funzione di verosimiglianza\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7.\n\\]\n\nCodicedbinom(23, 30, 0.1)\n#> [1] 9.737168e-18\n\n\nPonendo \\(\\theta = 0.2\\) otteniamo un altro valore dell‚Äôordinata della funzione di verosimiglianza\n\\[\n\\mathcal{L}(\\theta \\mid y) = \\frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7.\n\\]\n\nCodicedbinom(23, 30, 0.2)\n#> [1] 3.581417e-11\n\n\nSe ripetiamo questo processo 100 volte, una volta per ciascuno dei valori \\(\\theta\\) considerati, otteniamo 100 coppie di punti \\(\\theta\\) e \\(f(\\theta)\\).\n\nCodicelike <- choose(n, y) * theta^y * (1 - theta)^(n - y)\n\n\nLa curva che interpola tali punti √® la funzione di verosimiglianza. La Figura¬†14.1 fornisce una rappresentazione grafica di tale funzione.\n\nCodicetibble(theta, like) %>%\n  ggplot(aes(x = theta, y = like)) +\n  geom_line() +\n  vline_at(0.7676768, color = \"lightgray\", linetype=\"dashed\") +\n  labs(\n    y = expression(L(theta)),\n    x = expression(\"Valori possibili di\" ~ theta)\n  )\n\n\n\nFigura 14.1: Funzione di verosimiglianza nel caso di 23 successi in 30 prove.\n\n\n\n\n\n14.1.1 Interpretazione\nCome possiamo interpretare la curva che abbiamo ottenuto? Per alcuni valori \\(\\theta\\) la funzione di verosimiglianza assume valori piccoli; per altri valori \\(\\theta\\) la funzione di verosimiglianza assume valori pi√π grandi. Questi ultimi sono i valori di \\(\\theta\\) pi√π credibili e il valore 23/30 = 0.767 (la moda della funzione di verosimiglianza) √® il valore pi√π credibile di tutti.\n\nCodiced <- tibble(theta, like)\nd[which.max(like), ]$theta\n#> [1] 0.7676768\n\n\n\n14.1.2 La log-verosimiglianza\nDal punto di vista pratico risulta piuÃÄ conveniente utilizzare, al posto della funzione di verosimiglianza, il suo logaritmo naturale, ovvero la funzione di log-verosimiglianza:\n\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta).\n\\tag{14.4}\\]\nPoich√© il logaritmo √® una funzione strettamente crescente (usualmente si considera il logaritmo naturale), allora \\(\\mathcal{L}(\\theta)\\) e \\(\\ell(\\theta)\\) assumono il massimo (o i punti di massimo) in corrispondenza degli stessi valori di \\(\\theta\\):\n\\[\n\\hat{\\theta} = \\mbox{argmax}_{\\theta \\in \\Theta} \\ell(\\theta) = \\mbox{argmax}_{\\theta \\in \\Theta} \\mathcal{L}(\\theta).\n\\]\nPer le propriet√† del logaritmo, la funzione nucleo di log-verosimiglianza √®\n\\[\n\\begin{aligned}\n\\ell(\\theta \\mid y) &= \\log \\mathcal{L}(\\theta \\mid y) \\notag\\\\\n          &= \\log \\left(\\theta^y (1-\\theta)^{n - y} \\right) \\notag\\\\\n          &= \\log \\theta^y + \\log \\left( (1-\\theta)^{n - y} \\right) \\notag\\\\\n          &= y \\log \\theta + (n - y) \\log (1-\\theta).\\notag\n\\end{aligned}\n\\]\nSi noti che non √® necessario lavorare con i logaritmi, ma √® fortemente consigliato. Il motivo √® che i valori della verosimiglianza, in cui si moltiplicano valori di probabilit√† molto piccoli, possono diventare estremamente piccoli ‚Äì qualcosa come \\(10^{-34}\\). In tali circostanze, non √® sorprendente che i programmi dei computer mostrino problemi di arrotondamento numerico. Le trasformazioni logaritmiche risolvono questo problema.\nSvolgiamo nuovamente il problema precedente usando la log-verosimiglianza per trovare il massimo della funzione di log-verosimiglianza. Nella funzione dbinom() ora utilizziamo l‚Äôargomento log = TRUE.\n\nCodicell <- dbinom(y, n, theta, log = TRUE) \n\n\nLa funzione di log-verosimiglianza √® rappresentata nella Figura¬†14.2.\n\nCodicetibble(theta, ll) %>%\n  ggplot(aes(x = theta, y = ll)) +\n  geom_line() +\n  vline_at(0.7676768, color = \"lightgray\", linetype=\"dashed\") +\n  labs(\n    y = expression(\"log-likelihood\" ~ (theta)),\n    x = expression(\"Valori possibili di\" ~ theta)\n  )\n\n\n\nFigura 14.2: Funzione di log-verosimiglianza nel caso di 23 successi in 30 prove.\n\n\n\n\nIl risultato replica quello trovato in precedenza con la funzione di verosimiglianza.\n\nCodiced <- tibble(theta, ll)\nd[which.max(ll), ]$theta\n#> [1] 0.7676768"
  },
  {
    "objectID": "024_likelihood.html#modello-gaussiano",
    "href": "024_likelihood.html#modello-gaussiano",
    "title": "14¬† La funzione di verosimiglianza",
    "section": "\n14.2 Modello gaussiano",
    "text": "14.2 Modello gaussiano\nOra che abbiamo capito come costruire la funzione verosimiglianza di una binomiale √® relativamente semplice fare un passo ulteriore e considerare la verosimiglianza del caso di una funzione di densit√†, ovvero nel caso di una variabile casuale continua. Consideriamo qui il caso della Normale. La densit√† di una distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\) √®\n\\[\nf(y \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left\\{-\\frac{1}{2\\sigma^2}(y-\\mu)^2\\right\\}.\n\\tag{14.5}\\]\nCi poniamo ora il problema di costruire la funzione di verosimiglianza per la densit√† dell‚ÄôEquazione¬†14.5.\n\n14.2.1 Una singola osservazione\nEsaminiamo prima il caso in cui i dati corrispondono ad una singola osservazione \\(y\\).\n\nCodicey <- 114\n\n\nL‚ÄôEquazione¬†14.5 dipende dai parametri \\(\\mu\\) e \\(\\sigma\\) e dai dati \\(y\\). Per semplicit√†, ipotizzeremo \\(\\sigma\\) noto e uguale a 15. Nella simulazione considereremo 1000 valori \\(\\mu\\) compresi tra 70 e 160.\n\nCodicemu <- seq(70, 160, length.out = 1e3)\n\n\nDato che consideriamo 1000 possibili valori \\(\\mu\\), per costruire la funzione di verosimiglianza applicheremo l‚ÄôEquazione¬†14.5 1000 volte. In ciascun passo della simulazione inseriremo nell‚ÄôEquazione¬†14.5\n\nil singolo valore \\(y\\) considerato,\nil valore \\(\\sigma\\) assunto noto,\nciascuno dei valori \\(\\mu\\) che abbiamo considerato.\n\nLa distribuzione Gaussiana √® implementata in \\(\\mathsf{R}\\) nella funzione dnorm(). La funzione dnorm() ha tre argomenti: il valore \\(y\\) (o il vettore \\(y\\)), la media, ovvero il parametro \\(\\mu\\) e la deviazione standard, ovvero il parametro \\(\\sigma\\).\nUsando la funzione dnorm() 1000 volte, una volta per ciascuno dei valori \\(\\mu\\) che abbiamo considerato (e tenendo fissi \\(y = 114\\) e \\(\\sigma = 15\\)) otteniamo 1000 valori \\(f(\\mu)\\).\n\nCodicef_mu <- dnorm(y, mean = mu, sd = 15)\n\n\nLa funzione di verosimiglianza √® la curva che interpola i punti \\(\\big(\\mu, f(\\mu)\\big)\\).\n\nCodicetibble(mu, f_mu) %>% \n  ggplot(\n    aes(x = mu, y = f_mu)\n  ) +\n    geom_line() +\n    vline_at(114, color = \"lightgray\", linetype=\"dashed\") +\n      labs(\n      y = \"Verosimiglianza\",\n      x = c(\"Parametro \\u03BC\")\n    ) \n\n\n\n\n\n\n\nSi noti che la funzione di verosimiglianza cos√¨ trovata ha la forma della distribuzione Gaussiana. Nel caso di una singola osservazione (ma solo in questo caso) ha un‚Äôarea unitaria.\n\nCodiceintegrand <- function(mu) {\n  y = 114\n  sigma = 15\n  dnorm(y, mu, sigma)\n}\nintegrate(integrand, lower = -10000, upper = 10000)\n#> 1 with absolute error < 1.6e-06\n\n\nLa moda della funzione di verosimiglianza √® 114.\n\n14.2.2 Un campione di osservazioni\nConsideriamo ora il caso pi√π generale, ovvero quello di un campione di \\(n\\) osservazioni. Possiamo immaginare un campione casuale \\(y_1, y_2, \\dots, y_n\\) estratto da una popolazione \\(\\mathcal{N}(\\mu, \\sigma)\\) come una sequenza di realizzazioni indipendenti ed identicamente distribuite (di seguito, i.i.d.) della medesima variabile casuale \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\). I parametri sconosciuti sono \\(\\theta = \\{\\mu, \\sigma\\}\\).\nSe le variabili casuali \\(y_1, y_2, \\dots, y_n\\) sono i.i.d., la loro densit√† congiunta √® data da: \\[\\begin{align}\nf(y \\mid \\theta) &= f(y_1 \\mid \\theta) \\cdot f(y_2 \\mid \\theta) \\cdot \\; \\dots \\; \\cdot f(y_n \\mid \\theta)\\notag\\\\\n                 &= \\prod_{i=1}^n f(y_i \\mid \\theta),\n\\end{align}\\]\nladdove \\(f(\\cdot)\\) √® la densit√† Gaussiana di parametri \\(\\mu, \\sigma\\). Tenendo costanti i dati \\(y\\), la funzione di verosimiglianza diventa:\n\\[\\begin{equation}\n\\mathcal{L}(\\theta \\mid y) = \\prod_{i=1}^n f(y_i \\mid \\theta).\n\\end{equation}\\]\nPer chiarire la formula precedente, consideriamo un esempio che utilizza come dati i valori BDI-II dei trenta soggetti del campione clinico di Zetsche et al.¬†(2020).\n\nCodiced <- tibble(\n  y = c(\n    26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, \n    31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22\n    )\n)\n\n\nCi poniamo l‚Äôobiettivo di creare la funzione di verosimiglianza per questi dati, supponendo di sapere (in base ai risultati di ricerche precedenti) che i punteggi BDI-II si distribuiscono secondo la legge Normale e supponendo \\(\\sigma\\) noto e uguale alla deviazione standard del campione.\n\nCodicetrue_sigma <- sd(d$y)\ntrue_sigma \n#> [1] 6.606858\n\n\nAbbiamo visto in precedenza che, per una singola osservazione, la funzione di verosimiglianza √® la densit√† Gaussiana espressa in funzione dei parametri (in questo caso, solo \\(\\mu\\)). Per un campione di osservazioni i.i.d., ovvero \\(y = (y_1, y_2, \\dots, y_n)\\), la verosimiglianza √® la funzione di densit√† congiunta \\(f(y \\mid \\mu, \\sigma)\\) espressa in funzione dei parametri. Dato che le osservazioni sono i.i.d., la densit√† congiunta √® data dal prodotto delle densit√† delle singole osservazioni.\nPer l‚Äôosservazione \\(y_i\\) abbiamo\n\\[\nf(y_i \\mid \\mu, \\sigma) = \\frac{1}{{6.61 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_i - \\mu)^2}{2\\cdot 6.61^2}}\\right\\}.\n\\]\nLa densit√† congiunta √® dunque\n\\[\nf(y \\mid \\mu, \\sigma) = \\, \\prod_{i=1}^n f(y_i \\mid \\mu, \\sigma)\n\\]\nAlla luce dei dati osservati (e assumendo \\(\\sigma = 6.61\\)), la verosimiglianza diventa\n\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu, \\sigma \\mid y) =& \\, \\prod_{i=1}^n f(y_i \\mid \\mu, \\sigma) = \\notag\\\\\n& \\frac{1}{{6.61 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(26 - \\mu)^2}{2\\cdot 6.61^2}}\\right\\} \\times \\notag\\\\\n& \\frac{1}{{6.61 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(35 - \\mu)^2}{2\\cdot 6.61^2}}\\right\\} \\times  \\notag\\\\\n& \\vdots \\notag\\\\\n& \\frac{1}{{6.61 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(22 - \\mu)^2}{2\\cdot 6.61^2}}\\right\\}.\n\\end{aligned}\n\\]\n√à pi√π conveniente svolgere l‚Äôesercizio usando il logaritmo della verosimiglianza. In \\(\\textsf{R}\\), definiamo la funzione di log-verosimiglianza, log_likelihood(), che prende come argomenti y, mu e sigma = 6.61.\n\nCodicelog_likelihood <- function(y, mu, sigma = true_sigma) {\n  sum(dnorm(y, mu, sigma, log = TRUE))\n}\n\n\nL‚Äôargomento y √® un vettore di 30 elementi; gli argomenti mu e sigma sono scalari.\nPer ciascuno valore y, la funzione dnorm() trova la densit√† Normale utilizzando il valore mu in input e sigma = 6.61. L‚Äôargomento log = TRUE specifica che deve essere preso il logaritmo. I 30 valori cos√¨ ottenuti vengono poi sommati dalla funzione sum().\nUtilizzando un singolo valore \\(\\mu\\) otteniamo l‚Äôordinata della funzione di log-verosimiglianza in corrispondenza del valore \\(\\mu\\) utilizzato. Vogliamo per√≤ trovare l‚Äôordinata della log-verosimiglianza per tutti i possibili valori che \\(\\mu\\) pu√≤ assumere. Nella simulazione, usiamo 100,000 valori possibili del parametro \\(\\mu \\in [\\bar{y} - \\mbox{SD}, \\bar{y} + \\mbox{SD}]\\). Mediante un ciclo for(), ripetiamo dunque i calcoli descritti sopra 100,000 volte, una volta per ciascuno dei valori \\(\\mu\\) considerati. I 100,000 risultati vengono salvati nel vettore ll.\n\nCodicenrep <- 1e5\nmu <- seq(\n  mean(d$y) - sd(d$y), \n  mean(d$y) + sd(d$y), \n  length.out = nrep\n)\n\nll <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  ll[i] <- log_likelihood(d$y, mu[i], true_sigma)\n}\n\n\nNel caso di un solo parametro sconosciuto (nel caso presente, \\(\\mu\\)) √® possibile rappresentare la log-verosimiglianza con una curva che interpola i punti (mu, ll).\n\nCodicetibble(mu, ll) %>% \nggplot(aes(x = mu, y = ll)) +\n  geom_line() +\n  vline_at(mean(d$y), color = \"gray\", linetype = \"dashed\") +\n  labs(\n    y = \"Log-verosimiglianza\",\n    x = expression(\"Parametro\"~mu)\n  ) \n\n\n\nFigura 14.3: Log-verosimiglianza del parametro \\(\\mu\\) per i dati di Zetsche et al. (2019).\n\n\n\n\nTale funzione descrive la credibilit√† relativa che pu√≤ essere attribuita ai valori del parametro \\(\\mu\\) alla luce dei dati osservati.\n\n14.2.3 Massima verosimiglianza\nIl valore \\(\\mu\\) pi√π credibile corrisponde al massimo della funzione di log-verosimiglinza e viene detto stima di massima verosimiglianza.\nIl massimo della funzione di log-verosimiglianza, ovvero 30.93 nel caso dell‚Äôesempio presente, √® identico alla media dei dati campionari. Tale risultato, ottenuto per via numerica, pu√≤ essere dimostrato formalmente nel modo seguente.\nUsando la notazione matematica possiamo dire che cerchiamo l‚Äôargmax dell‚Äôequazione precedente rispetto a \\(\\theta\\), ovvero\n\\[\n\\hat{\\theta} = \\text{argmax}_{\\theta} \\prod_{i=1}^n f(y_i \\mid \\theta).\n\\]\nQuesto problema si risolve calcolando le derivate della funzione rispetto a \\(\\theta\\), ponendo le derivate uguali a zero e risolvendo. Saltando tutti i passaggi algebrici di questo procedimento, per \\(\\mu\\) troviamo\n\\[\\begin{equation}\n\\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^n y_i\n\\end{equation}\\]\ne per \\(\\sigma\\) abbiamo\n\\[\\begin{equation}\n\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^n\\frac{1}{n}(y_i- \\mu)^2}.\n\\end{equation}\\]\nIn altri termini, la s.m.v. del parametro \\(\\mu\\) √® la media del campione e la s.m.v. del parametro \\(\\sigma\\) √® la deviazione standard del campione.\n\nEsercizio 14.1 \nDalla Figura¬†14.3 notiamo che il massimo della funzione di log-verosimiglianza calcolata per via numerica, ovvero 30.93, √® identico alla media dei dati campionari e corrisponde al risultato teorico atteso."
  },
  {
    "objectID": "024_likelihood.html#commenti-e-considerazioni-finali",
    "href": "024_likelihood.html#commenti-e-considerazioni-finali",
    "title": "14¬† La funzione di verosimiglianza",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nNella funzione di verosimiglianza i dati (osservati) vengono trattati come fissi, mentre i valori del parametro (o dei parametri) \\(\\theta\\) vengono variati: la verosimiglianza √® una funzione di \\(\\theta\\) per il dato fisso \\(y\\). Pertanto, la funzione di verosimiglianza riassume i seguenti elementi: un modello statistico che genera stocasticamente i dati (in questo capitolo abbiamo esaminato due modelli statistici: quello binomiale e quello Normale), un intervallo di valori possibili per \\(\\theta\\) e i dati osservati \\(y\\).\nNella statistica frequentista l‚Äôinferenza si basa solo sui dati a disposizione e qualunque informazione fornita dalle conoscenze precedenti non viene presa in considerazione. Nello specifico, nella statistica frequentista l‚Äôinferenza viene condotta massimizzando la funzione di (log) verosimiglianza, condizionatamente ai valori assunti dalle variabili casuali campionarie. Le basi dell‚Äôinferenza frequentista, dunque, sono state riassunte in questo Capitolo. Nella statistica bayesiana, invece, l‚Äôinferenza statistica viene condotta combinando la funzione di verosimiglianza con le distribuzioni a priori dei parametri incogniti \\(\\theta\\). Ci√≤ verr√† discusso nei Capitoli successivi.\nLa differenza fondamentale tra inferenza bayesiana e frequentista √® dunque che i frequentisti non ritengono utile descrivere i parametri in termini probabilistici: i parametri dei modelli statistici vengono concepiti come fissi ma sconosciuti. Nell‚Äôinferenza bayesiana, invece, i parametri sconosciuti sono intesi come delle variabili casuali e ci√≤ consente di quantificare in termini probabilistici il nostro grado di intertezza relativamente al loro valore.\n\n\n\n\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "bayes_inference.html",
    "href": "bayes_inference.html",
    "title": "Parte 4: Inferenza bayesiana",
    "section": "",
    "text": "Nel Capitolo¬†15 verr√† introdotto il flusso di lavoro bayesiano.\nIl Capitolo¬†16 spiega cosa significa, in termini bayesiani, fare un‚Äôinferenza. Sar√† considerato qui il caso pi√π semplice, ovvero quello di una proporzione.\nIl Capitolo¬†17 mostra come la distribuzione a posteriori possa essere derivata per via analitica nel caso delle famiglie coniugate di distribuzioni. Verr√† qui esaminato lo schema beta-binomiale.\nIl Capitolo¬†18 discute l‚Äôinfluenza della distribuzione a priori sulla distribuzione a posteriori.\nIl Capitolo¬†19 mostra come la distribuzione a posteriori possa essere approssimata per via numerica, quando una derivazione formale non √® possibile. Verranno descritto il metodo basato su griglia e l‚Äôalgoritmo di Metropolis.\nIl Capitolo¬†20 fornisce un‚Äôintroduzione al linguaggio di programmazione probabilistico Stan. L‚Äôalgoritmo di Metropolis fornisce sempre una buona approssimazione alla distribuzione a posteriori. Ma ha lo svantaggio di essere poco efficiente ‚Äì ovvero di richiedere un numero molto grande di iterazioni per produrre un‚Äôapprossimazione accettabile. Nel caso di modelli statistici complessi, le simulazioni MCMC richiedono un tempo molto lungo (si parla di ore, giorni, settimane‚Ä¶). In tali circostanze √® ovvio che l‚Äôefficienza del campionamento diventa importante. L‚Äôalgoritmo di Metropolis √® molto semplice ma √® poco efficiente. Recentemente sono stati sviluppati algoritmi molto pi√π efficienti. Il linguaggio probabilistico Stan implementa il campionamento hamiltoniano che, correntemente, √® il campionamento MCMC pi√π efficiente. Tale metodo di campionamento √® anche implementato in software che sono pi√π semplici da usare di Stan (si veda, ad esempio, la funzione brm() del pacchetto \\(\\mathsf{R}\\) brms). Tuttavia, per scopi didattici, nel testo presente useremo Stan."
  },
  {
    "objectID": "025_intro_bayes.html",
    "href": "025_intro_bayes.html",
    "title": "15¬† Credibilit√†, modelli e parametri",
    "section": "",
    "text": "L‚Äôobiettivo di questo Capitolo √® di introdurre il quadro concettuale dell‚Äôanalisi dei dati bayesiana."
  },
  {
    "objectID": "025_intro_bayes.html#fondamenti-dellanalisi-dei-dati-bayesiana",
    "href": "025_intro_bayes.html#fondamenti-dellanalisi-dei-dati-bayesiana",
    "title": "15¬† Credibilit√†, modelli e parametri",
    "section": "\n15.1 Fondamenti dell‚Äôanalisi dei dati bayesiana",
    "text": "15.1 Fondamenti dell‚Äôanalisi dei dati bayesiana\nL‚Äôanalisi dei dati bayesiana si basa su due idee fondamentali.\n\nLa prima idea √® la riallocazione della credibilit√† tra le possibilit√†.\n\nLa seconda idea √® che le possibili ipotesi, a cui attribuiamo diversi gradi di credibilit√†, corrispondono ai valori dei parametri di un modello statistico.\n\n\n15.1.1 Prima idea: riallocazione della credibilit√†\nConsideriamo la prima idea. Kruschke (2014) la descrive mediante un riferimento letterario. Il detective immaginario Sherlock Holmes spesso diceva al suo compagno, il dottor Watson: ‚ÄúQuante volte ti ho detto che quando hai eliminato l‚Äôimpossibile, tutto ci√≤ che rimane, per quanto improbabile, deve essere la verit√†?‚Äù (Doyle, 1890, cap. 6). Anche se il ragionamento di Holmes o Watson o Doyle non √® mai stato descritto come un‚Äôinferenza bayesiana, in realt√† lo √®. Nei romanzi di Doyle, Sherlock Holmes ragiona nel modo seguente. Holmes inizia a elencare i vari sospetti di un crimine. A priori, attribuisce un certo grado di credibilit√† alla possibilit√† che il colpevole sia uno dei sospetti considerati. In seguito, Holmes raccoglie sistematicamente le prove che escludono alcuni possibili sospetti. Se √® possibile escludere tutti i possibili sospetti tranne uno, allora Sherlock Holmes conclude attribuendo una piena credibilit√† all‚Äôidea che il colpevole sia il sospetto rimanente, anche se all‚Äôinizio questa idea poteva sembrare poco credibile.\nKruschke (2014) esprime il ragionamento ‚Äúbayesiano‚Äù di Sherlock Holmes mediante la seguente figura. Supponiamo che vi siano quattro possibili ipotesi rispetto ad un fenomeno (nella figura ‚ÄúPossibilities‚Äù): A, B, C, D. Queste ipotesi possono corrispondere, ad esempio, ai quattro sospettati.\n\n\n\n\n\n\n\n\nLa riga superiore riporta la credibilit√† a priori che viene assegnata all‚Äôipotesi che ciascun sospettato sia il colpevole. Nella prima colonna, la credibilit√† a priori si distribuisce equamente tra i quattro sospettati. Si noti che all‚Äôintera credibilit√† a priori assegniamo il valore 1; se ci sono quattro sospettati, e non abbiamo modo di distinguere tra essi, allora la credibilit√† dell‚Äôipotesi che uno di essi sia il colpevole vale 0.25. Se i dati a disposizione consentono di escludere il sospettato A allora, a posteriori, la credibilit√† si ridistribuisce tra i tre rimanenti sospettati come indicato nella figura (ovvero, la credibilit√† dell‚Äôipotesi che uno di essi sia il colpevle varr√† 1/3).\nIl passaggio dalla distribuzione a priori a quella a posteriori si dice aggiornamento bayesiano. Per il caso rappresentato nella prima colonna, l‚Äôaggiornamento bayesiano (ovvero, la riallocazione della credibilit√† alla luce dei dati a disposizione) ha consentito di escludere un sospettato. Nella seconda colonna, a priori si considera impossibile il sospettato A, per cui la credibilit√† di distribuisce equamente tra i rimanenti tre sospettati. Supponendo che i dati consentano di escludere la possibilit√† B, l‚Äôaggiornamento bayesiano ci porta alla distribuzione a posteriori della credibilit√† che si distribuisce equamente tra C e D. In questo caso, sono stati esclusi due sospettati, ma non √® possibile decidere tra C e D. Infine, il caso pi√π fortunato √® descritto nell‚Äôultima colonna; in questo caso, a priori, possiamo escludere A e B. I dati ci consentono di escludere C. Dunque, a posteriori, siamo sicuri (la credibilit√† √® 1) che D sia il colpevole.\nL‚Äôanalisi bayesiana procede allo stesso modo: distribuisce la credibilit√† a priori tra una serie di possibilit√†. Vengono poi acquisite le informazioni fornite dai dati. Sulla base di tali informazioni si ottiene un nuova distribuzione della credibilit√† tra le possibilit√†. Tale aggiornamento delle credenze conduce alla distribuzione a posteriori, la quale descrive il modo in cui abbiamo modificato le nostre credenze a priori alla luce delle informazioni fornite dai dati.\n\n15.1.1.1 I dati sono rumorosi e le inferenze sono probabilistiche\nI casi della figura precedente presupponevano che i dati avessero relazioni deterministiche con le possibili cause. Ad esempio, Sherlock Holmes potrebbe aver trovato un‚Äôimpronta sulla scena del crimine e identificato la taglia e il tipo di scarpa con assoluta certezza, escludendo cos√¨ completamente o implicando un particolare sospettato.\nNella ricerca scientifica la situazione √® pi√π complessa in quanto le relazioni tra i dati e le cause soggiacenti sono solo probabilistiche (non deterministiche). Un vero investigatore potrebbe misurare l‚Äôimpronta di una scarpa e i dettagli del suo battistrada, ma queste misurazioni restringerebbero solo probabilisticamente la gamma delle scarpe possibili che potrebbero aver prodotto l‚Äôimpronta. Al di fuori dei romanzi di Arthur Conan Doyle, le misure non sono mai perfette e l‚Äôimpronta √® solo una rappresentazione imperfetta della scarpa che l‚Äôha prodotta. La relazione tra la causa (cio√® la scarpa) e l‚Äôeffetto misurato (cio√® l‚Äôimpronta) viene complicata dalla presenza del ‚Äúrumore della misurazione‚Äù.\nNella ricerca scientifica, le misurazioni sono fortemente contaminate da molteplici influenze estranee, nonostante gli enormi sforzi dei ricercatori per limitare la loro influenza. Per esempio, in uno studio sull‚Äôapprendimento della statistica da parte degli studenti di psicologia, un ricercatore potrebbe dividere gli studenti in due gruppi: un gruppo sperimentale (che affianca lo studio del materiale dell‚Äôesame con una serie di esercitazioni nelle quali viene utilizzato un software per l‚Äôanalisi dei dati) e un gruppo di controllo (che studia il materiale dell‚Äôesame su un testo e si limita a svolgere degli esercizi scolastici carta-e-penna). Supponiamo che il ricercatore misuri la prestazione all‚Äôesame dei due gruppi. √à chiaro che la prestazione all‚Äôesame per ogni singolo studente, al di l√† dell‚Äôeffetto della manipolazione sperimentale, pu√≤ variare notevolmente a seconda di molte altre influenze, come la motivazione, l‚Äôansia, la possibilit√† di usare un computer, le conoscenze informatiche, la preparazione pregressa nelle materie quantitative, la quantit√† e qualit√† dello studio, ecc. I dati risultanti, quindi, saranno estremamente rumorosi, con un‚Äôenorme variabilit√† all‚Äôinterno di ciascun gruppo e un‚Äôenorme sovrapposizione tra i gruppi. Pertanto, ci saranno molti studenti del gruppo sperimentale che faranno meglio all‚Äôesame della media gruppo di controllo e viceversa. Da queste due distribuzioni di voti all‚Äôesame, molto disperse e sovrapposte, vogliamo inferire qual √® la differenza media tra i due gruppi e quanto possiamo essere certi che vi sia una differenza. Tutte le misurazioni scientifiche (i dati) includono un certo grado di ‚Äúrumore‚Äù. Le tecniche di analisi dei dati sono progettate per inferire le tendenze sottostanti presenti in dati rumorosi. A differenza di Sherlock Holmes, che sulla base di un‚Äôosservazione esclude completamente un sospettato, nella ricerca scientifica vengono raccolti dei dati che modificano solo incrementalmente la credibilit√† che pu√≤ essere attribuita alle possibili tendenze suggerite dai dati. In questo insegnamento vedremo molti esempi realistici di questo processo. Uno dei maggiori vantaggi dell‚Äôanalisi bayesiana √® il fatto che essa consente di utilizzare la teoria delle probabilit√† per riallocare la credibilit√† tra le ipotesi, alla luce delle informazioni fornite dai dati, in un modo non arbitrario e automatico.\n\n15.1.2 Seconda idea: le possibilit√† sono valori di parametri in un modello statistico\nBDI-II prima e dopo un intervento psicologico.\nNel precedente ragionamento ‚Äúbayesiano‚Äù di Sherlock Holmes, le possibilit√† corrispondevano alle quattro modalit√† di una variabile discreta: la variabile era ‚Äúi sospettati del crimine‚Äù e le modalit√† erano A, B, C e D. In statistica, lavorare con variabili discrete √® complicato. √à pi√π semplice svolgere l‚Äôaggiornamento bayesiano mediante gli strumenti della teoria delle probabilit√† se vengono invece utilizzate variabili continue. In tali circostanze, le ‚Äúpossibilit√†‚Äù corrispondono ai valori dei parametri in un modello statistico. Possiamo chiarire questa affermazione nel modo seguente.\nConsideriamo una distribuzione di differenze di punteggi BDI-II misurati prima e dopo un intervento psicologico: se l‚Äôintervento funziona i punteggi BDI-II saranno minori dopo l‚Äôintervento e dunque la differenza prima - dopo sar√† positiva. L‚Äôintervento per√≤ non ha gli stessi effetti sui diversi partecipanti per cui, in uno studio, osserviaamo una distribuzione di punteggi (prima - dopo). Supponiamo che tale distrinuzione di punteggi sia rappresentata dall‚Äôistogramma illustrato nella figura seguente.\n\nCodiceset.seed(2)\nd <- tibble(x = rnorm(2000, mean = 5, sd = 4))\n\n# plot!\nd %>% ggplot(aes(x = x)) +\n  geom_histogram(aes(y = ..density..),\n                 binwidth = 1, fill = \"grey67\", \n                 color = \"grey92\", size = 1/10) +\n  geom_line(data = tibble(x = seq(from = -10, to = 20, by = .01)),\n            aes(x = x, y = dnorm(x, mean = 5, sd = 4)),\n            color = \"grey33\") +\n  labs(subtitle = \"The candidate normal distribution\\nhas a mean of 5 and SD of 4.\",\n       x = \"Data Values\", \n       y = \"Data Probability\") +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\nAll‚Äôistogramma √® sovrapposta una distribuzione Gaussiana di parametri \\(\\mu\\) = 5 e \\(\\sigma\\) = 4. Questa scelta per i valori dei parametri sembra appropriata per descrivere i dati a disposizione. Qui in basso mostriamo gli stessi dati ipotetici con sovrapposta una diversa distribuzione Gaussiana, di parametri \\(\\mu\\) = 3.5 e \\(\\sigma\\) = 5. Anche se questa seconda distribuzione Gaussiana √® plausibile, sicuramente descrive i dati in una maniera peggiore del caso precedente.\n\nCodiceggplot(data = d, aes(x = x)) +\n  geom_histogram(aes(y = ..density..),\n                 binwidth = 1, fill = \"grey67\",\n                 color = \"grey92\", size = 1/8) +\n  stat_function(fun = dnorm, n = 101, args = list(mean = 3.5, sd = 5),\n                color = \"grey33\", linetype = 2) +\n  labs(subtitle = \"The candidate normal distribution\\nhas a mean of 3.5 and SD of 5.\",\n       x = \"Data Values\", \n       y = \"Data Probability\") +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\nIl ruolo dell‚Äôinferenza bayesiana √® quello di calcolare l‚Äôesatta credibilit√† relativa dei valori dei parametri candidati, tenendo anche conto delle loro probabilit√† a priori. In applicazioni realistiche, i valori dei parametri candidati possono formare un continuum infinito. Il parametro di localizzazione della distribuzione normale pu√≤ assumere qualsiasi valore da negativo a positivo infinito. L‚Äôinferenza bayesiana opera senza problemi su continui infiniti.\nCi sono due principali desiderata per una descrizione matematica dei dati. In primo luogo, la descrizione matematica dovrebbe essere comprensibile. Cos√¨ come sarebbe inutile descrivere i dati in una lingua che non conosciamo, sarebbe inutile descrivere i dati con una forma matematica che non comprendiamo, con parametri che non possiamo interpretare. Nel caso di una distribuzione normale, ad esempio, il parametro \\(\\mu\\) medio e il parametro \\(\\sigma\\) sono direttamente interpretabili come indici di posizione e scala della distribuzione. In questo insegnamento useremo descrizioni matematiche dei dati dotate di parametri a cui √® possibile attribuire un‚Äôinterpretazione intuitiva. Pertanto, possiamo dire che l‚Äôanalisi bayesiana rialloca la credibilit√† tra i valori dei parametri all‚Äôinterno di uno spazio di possibilit√† definito dal modello scelto.\nIl secondo desideratum di una modellizzazione matematica √® che dovrebbe essere descrittivamente adeguata, il che significa, all‚Äôincirca, che il modello matematico (in questo caso, la curva Normale) dovrebbe ‚Äúassomigliare‚Äù ai dati. Non dovrebbero esserci discrepanze sistematiche importanti tra le tendenze dei dati e la forma del modello. Decidere se un‚Äôapparente discrepanza sia importante o sistematica non √® un processo definito. Nelle prime fasi della ricerca, potremmo essere soddisfatti di una descrizione approssimativa e ‚Äúabbastanza buona‚Äù dei dati, perch√© cattura tendenze significative che sono interessanti e nuove rispetto alle conoscenze precedenti. Man mano che il campo della ricerca matura, potremmo richiedere descrizioni sempre pi√π accurate dei dati. L‚Äôanalisi bayesiana √® molto utile per valutare la credibilit√† relativa di diverse possibili modellizzazioni matematiche dei dati.\n√à anche importante capire che le descrizioni matematiche dei dati non sono necessariamente spiegazioni causali dei dati. Dire che i dati sono ben descritti da una distribuzione normale con media di 5 e deviazione standard di 4 non spiega quale processo abbia causato i dati aventi quella forma. I parametri hanno un significato solo nel contesto del modello matematico della distribuzione normale; i valori dei parametri non hanno necessariamente un significato se consideriamo le cause dell‚Äôefficacia (o non efficacia) dell‚Äôintervento psicologico nell‚Äôesempio. Meglio sarebbe esprimere le possibili cause dell‚Äôefficiacia dell‚Äôintervento psicologico nei termini di un modello matematico per poi usare i dati, e l‚Äôanalisi bayesiana, per stimare i parametri del modello (ovvero, per attribuire un ‚Äúpeso‚Äù alle possibili cause), ma procedere in questo modo √® possibile solo in pochi casi. Solitamente la psicologia si accontenta di descrivere le differenze medie tra gruppi, senza un‚Äôindagine puntuale delle cause di tali differenze."
  },
  {
    "objectID": "025_intro_bayes.html#modellizzazione-bayesiana",
    "href": "025_intro_bayes.html#modellizzazione-bayesiana",
    "title": "15¬† Credibilit√†, modelli e parametri",
    "section": "\n15.2 Modellizzazione bayesiana",
    "text": "15.2 Modellizzazione bayesiana\nLa moderna statistica bayesiana viene per lo pi√π eseguita utilizzando un linguaggio di programmazione probabilistico implementato su computer. Ci√≤ ha cambiato radicalmente il modo in cui venivano eseguite le statistiche bayesiane anche fin pochi decenni fa. La complessit√† dei modelli che possiamo costruire √® aumentata e la barriera delle competenze matematiche e computazionali che sono richieste √® diminuita. Inoltre, il processo di modellazione iterativa √® diventato, sotto molti aspetti, molto pi√π facile da eseguire. Anche se formulare modelli statistici complessi √® diventato pi√π facile che mai, la statistica √® un campo pieno di sottigliezze che non scompaiono magicamente utilizzando potenti metodi computazionali. Pertanto, avere una buona preparazione sugli aspetti teorici, specialmente quelli rilevanti per la pratica, √® estremamente utile per applicare efficacemente i metodi statistici.\n\nNell‚Äôapproccio bayesiano all‚Äôinferenza statistica si prende in considerazione una variabile casuale \\(Y\\) di cui si conosce la distribuzione a meno di un parametro \\(\\theta\\). Nel caso dell‚Äôesempio precedente, la variabile \\(Y\\) √® la distribuzione delle differenze pre/post dei punteggi BDI-II. Immaginiamo di assumere che \\(Y\\) dia una variabile Gaussiana di cui non conosciamo il parametro \\(\\mu\\) (media) ma di cui conosciamo \\(\\sigma\\).\nSecondo l‚Äôapproccio bayesiano, √® possibile modellare l‚Äôincertezza sul valore del parametro ignoto rappresentandolo con una variabile casuale continua \\(\\Theta\\) avente come supporto l‚Äôinsieme dei valori ammissibili per il parametro cercato. Nel caso dell‚Äôesempio considerato, ci√≤ significa che consideriamo \\(\\mu\\) come una variabile casuale il cui supporto √® \\([-\\infty, \\infty]\\).\nLa funzione di densit√† \\(p(\\theta)\\) prende il nome di distribuzione a priori e rappresenta la sintesi delle opinioni e delle informazioni che si hanno sul parametro prima dell‚Äôosservazione dei dati. Nell‚Äôesempio, anche se \\(\\mu\\) pu√≤ assumere valori nell‚Äôintervallo \\([-\\infty, \\infty]\\), non tutti questi valori sono plausibili. Ad esempio, una differenza di un milione, sulla scala del BDI-II, √® senza senso. A priori, potremmo dunque descrivere la nostra incertezza su \\(\\mu\\) mediante una funzione di densit√† la cui massa √® compresa nell‚Äôintervallo, diciamo, [-20, 20]. In assenza di altre informazioni, questa gamma di valori sembra ragionevole. Inoltre, se non abbiamo motivo di credere che l‚Äôintervento psicologico sar√† sicuramente efficace, la funzione di densit√† che descrive la nostra incertezza su \\(\\mu\\) potrebbe avere media pari a zero. Pertanto, la nostra incertezza iniziale su \\(\\mu\\) potrebbe essere descritta mediante una \\(\\mathcal{N}(0, 7)\\).\nL‚Äôaggiornamento dell‚Äôincertezza su \\(\\theta\\) √® determinata dal verificarsi dell‚Äôevidenza \\(y\\), ovvero dall‚Äôosservazione dei risultati di un esperimento casuale. Nel caso dell‚Äôesempio, potremmo pensare di misurare il BDI-II prima e dopo l‚Äôintervento su 30 pazienti.\nLe informazioni provenienti dal campione osservato \\(y = (y_1, \\dots, y_n)\\) sono contenute nella funzione \\(p(y \\mid \\theta)\\), che, osservata come funzione di \\(\\theta\\) per \\(y\\), prende il nome di funzione di verosimiglianza. In precedenza abbiamo visto come sia possibile costruire la funzione di verosimiglianza Gaussiana nel caso di \\(\\mu\\) incognito e \\(\\sigma\\) noto. Per continuare con l‚Äôesempio in discussione, potremmo pensare di costruire la funzione di verosimiglianza in questo modo. La funzione di verosimiglianza cos√¨ costruita ci direbbe qual √® la verosimiglianza relativa dei valori del parametro \\(\\mu\\) alla luce dei dati osservati (e assumendo \\(\\sigma\\) come noto).\nL‚Äôaggiornamento delle conoscenze a priori incorporate nella distribuzione iniziale \\(p(\\theta)\\) in seguito al verificarsi di \\(Y = y\\) (evidenza empirica) avviene attraverso il teorema di Bayes in cui \\(p(\\theta \\mid y)\\) risulta proporzionale al prodotto della probabilit√† a priori e della verosimiglianza e prende il nome di distribuzione a posteriori:\n\\[\\begin{equation}\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int_{\\Theta}p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta} \\quad \\theta \\in \\Theta.\n(\\#eq:bayes-intro)\n\\end{equation}\\]\nNel caso dell‚Äôesempio in discussione, la distribuzione a posteriori del parametro \\(\\mu\\) fornisce una descrizione della nostra incertezza relativamente all‚Äôefficacia media dell‚Äôintervento psicologico. Se, diciamo, la gran parte della massa della distribuzione a posteriori include valori positivi, ci√≤ ci fornisce evidenza che l‚Äôintervento psicologico sia stato, in media, efficace (cio√®, ha portato ad una riduzione dei valori BDI-II). Se invece la massa della distribuzione a posteriori del parametro \\(\\mu\\) √® ripartita in manera bilanciata tra valori negativi e valori positivi, allora non c‚Äô√® evidenza che l‚Äôintervento psicologico sia stato efficace (per alcuni pazienti ha prodotto un miglioramento, per altri un peggioramento).\nPossiamo dunque dire che, nell‚Äôesempio, la distribuzione a posteriori del parametro \\(\\mu\\) descrive la credibilit√† che possiamo attribuire all‚Äôefficacia dell‚Äôintervento psicologico dopo avere esaminato i dati a disposizione, e includendo le evidenze a priori."
  },
  {
    "objectID": "025_intro_bayes.html#flusso-di-lavoro-bayesiano",
    "href": "025_intro_bayes.html#flusso-di-lavoro-bayesiano",
    "title": "15¬† Credibilit√†, modelli e parametri",
    "section": "\n15.3 Flusso di lavoro bayesiano",
    "text": "15.3 Flusso di lavoro bayesiano\nIn pratica, Martin et al. (2022) descrivono la modellazione bayesiana distinguendo tre passaggi.\n\nDati alcuni dati e alcune ipotesi su come questi dati potrebbero essere stati generati, si progetta un modello statistico combinando e trasformando variabili casuali.\nSi usa il teorema di Bayes per condizionare il modello ai dati. Questo processo viene chiamato ‚Äúinferenza‚Äù e come risultato si ottiene una distribuzione a posteriori.\n\nSi critica il modello utilizzando criteri diversi, inclusi i dati e la nostra conoscenza del dominio, per verificare se abbia senso. Poich√© in generale siamo incerti sul modello, a volte si confrontano modelli diversi.\n\nQuesti tre passaggi vengono eseguiti in modo iterativo e danno luogo a quello che √® chiamato ‚Äúflusso di lavoro bayesiano‚Äù (bayesian workflow).\nEsaminiamo ora pi√π nei dettagli le varie fasi del flusso di lavoro bayesiano.\n\n15.3.1 Notazione\nPer fissare la notazione, nel seguito \\(y\\) rappresenter√† i dati e \\(\\theta\\) rappresenter√† i parametri incogniti di un modello statistico. Sia \\(y\\) che \\(\\theta\\) vengono concepiti come variabili casuali. Con \\(x\\) vengono invece denotate le quantit√† note, come ad esempio i predittori del modello lineare. Per rappresentare in un modo conciso i modelli probabilistici viene usata una notazione particolare. Ad esempio, invece di scrivere \\(p(\\theta) = \\mbox{Beta}(1, 1)\\) scriviamo \\(\\theta \\sim \\mbox{Beta}(1, 1)\\). Il simbolo ‚Äú\\(\\sim\\)‚Äù viene spesso letto ‚Äú√® distribuito come‚Äù. Possiamo anche pensare che significhi che \\(\\theta\\) costituisce un campione casuale estratto dalla distribuzione Beta(1, 1). Allo stesso modo, ad esempio, la verosimiglianza del modello binomiale pu√≤ essere scritta come \\(y \\sim \\text{Bin}(n, \\theta)\\).\n\n15.3.2 Distribuzioni a priori\nQuando adottiamo un approccio bayesiano, i parametri della distribuzione di riferimento non venono considerati come delle costanti incognite ma bens√¨ vengono trattati come variabili casuali; di conseguenza, i parametri assumono una particolare distribuzione che nelle statistica bayesiana viene definita ‚Äúa priori‚Äù. I parametri \\(\\theta\\) possono assumere delle distribuzioni a priori differenti: a seconda delle informazioni disponibili bisogna selezionare una distribuzione di \\(\\theta\\) in modo tale che venga assegnata una probabilit√† maggiore a quei valori del parametro che si ritengono pi√π plausibili. Idealmente, le credenze a priori che portano alla specificazione di una distribuzione a priori dovrebbero essere supportate da una qualche motivazione, come ad esempio i risultati di ricerche precedenti.\n\n\n\n15.3.2.1 Tipologie di distribuzioni a priori\nPossiamo distinguere tra diverse distribuzioni a priori in base a quanto fortemente impegnano il ricercatore a ritenere come credibile un particolare intervallo di valori dei parametri. Un caso estremo √® quello che rivela una totale assenza di conoscenze a priori, il che conduce alle distribuzioni a priori non informative, ovvero quelle che assegnano lo stesso livello di credibilit√† a tutti i valori dei parametri. Le distribuzioni a priori informative, d‚Äôaltra parte, possono essere debolmente informative o fortemente informative, a seconda del modo in cui lo sperimentatore distribuisce la credibilit√† nello spazio del parametro. Un caso estremo di credenza a priori √® quello che assegna tutta la credibilit√† ad un singolo valore del parametro. La figura seguente mostra alcuni esempi di distribuzioni a priori per il modello Binomiale:\n\ndistribuzione non informativa: \\(\\theta_c \\sim \\mbox{Beta}(1,1)\\);\ndistribuzione debolmente informativa: \\(\\theta_c \\sim \\mbox{Beta}(5,2)\\);\ndistribuzione fortemente informativa: \\(\\theta_c \\sim \\mbox{Beta}(50,20)\\);\n\nvalore puntuale: \\(\\theta_c \\sim \\mbox{Beta}(\\alpha, \\beta)\\) con \\(\\alpha, \\beta \\rightarrow \\infty\\) e \\(\\frac{\\alpha}{\\beta} = \\frac{5}{2}\\).\n\n\n\n\n\nEsempi di distribuzioni a priori per il parametro \\(\\theta_c\\) nel Modello Binomiale.\n\n\n\n\n\n15.3.2.2 Selezione della distribuzione a priori\nLa selezione delle distribuzioni a priori √® stata spesso vista come una delle scelte pi√π importanti che un ricercatore fa quando implementa un modello bayesiano in quanto pu√≤ avere un impatto sostanziale sui risultati finali. La soggettivit√† delle distribuzioni a priori √® evidenziata dai critici come un potenziale svantaggio dei metodi bayesiani. A questa critica, Schoot et al. (2021) rispondono dicendo che le distribuzioni a priori svolgono due importanti ruoli statistici: quello della ‚Äúregolarizzazione della stima‚Äù, ovvero, il processo che porta ad indebolire l‚Äôinfluenza indebita di osservazioni estreme, e quello del miglioramento dell‚Äôefficenza della stima, ovvero, la facilitazione dei processi di calcolo numerico di stima della distribuzione a posteriori. L‚Äôeffetto della distribuzione a priori sulla distribuzione a posteriori verr√† discusso in dettaglio nel Capitolo @ref(chapter-balance). Inoltre, Schoot et al. (2021) notano che, a proposito di scelte ‚Äúsoggettive‚Äù, al di l√† della scelta delle distribuzioni a priori, ci sono molti elementi del processo di inferenza statistica che risultano sicuramente ‚Äúsoggettivi‚Äù (cio√®, arbitrari), in particolare la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. Risultano inoltre ‚Äúsoggettivi‚Äù il modo di operazionalizzare la variabile dipendente, il tipo di confronti da esaminare e tante altre dimensioni dell‚Äôinferenza statistica. Per cui, il confronto tra statistica bayesiana e frequentista non pu√≤ essere sicuramente svolto nei termini delle dimensioni oggettivo/soggettivo.\n\n15.3.3 La funzione di verosimiglianza\nLa funzione di verosimiglianza per due casi tipici, quello binomiale e quello Normale, √® stata descritta nel Capitolo @ref(ch:likelihood).\n\nNota. Seguendo una pratica comune, all‚Äôinterno di un framework bayesiano spesso useremo la notazione \\(p(\\cdot)\\) per rappresentare due quantit√† differenti, ovvero la funzione di verosimiglianza e la distribuzione a priori. Questo piccolo abuso di notazione riflette il seguente punto di vista: anche se la verosimiglianza non √® una funzione di densit√† di probabilit√†, noi non vogliamo stressare questo aspetto, ma vogliamo piuttosto pensare alla verosimiglianza e alla distribuzione a priori come a due elementi che sono egualmente necessari per calcolare la distribuzione a posteriori. In altri termini, per cos√¨ dire, questa notazione assegna lo stesso status epistemico alle due diverse quantit√† che si trovano al numeratore della regola di Bayes.\n\n\n15.3.4 La verosimiglianza marginale\nPer il calcolo di \\(p(\\theta \\mid y)\\) √® necessario dividere il prodotto tra la distribuzione a priori e la verosimiglianza per una costante di normalizzazione. Tale costante di normalizzazione, detta verosimiglianza marginale, ha lo scopo di fare in modo che \\(p(\\theta \\mid y)\\) abbia area unitaria.\n\nSi noti che la verosimiglianza marginale (ovvero, l‚Äôintegrale al denominatore della @ref(eq:bayes-intro)) √® spesso di difficile risoluzione analitica per cui l‚Äôinferenza bayesiana solitamente procede attraverso metodi di ricampionamento e metodi iterativi, quali le Catene di Markov Monte Carlo (MCMC).\n\n15.3.5 La distribuzione a posteriori\nLa distribuzione a postreriori si trova applicando il teorema di Bayes:\n\\[\n\\text{probabilit√† a posteriori} = \\frac{\\text{probabilit√† a priori} \\cdot \\text{verosimiglianza}}{\\text{costante di normalizzazione}}\n\\]\nNei Capitoli successivi vedremo come calcolare la distribuzione a posteriori. Ci sono due metodi:\n\nun metodo esatto, che pu√≤ essere usato nel caso delle distribuzioni a priori coniugate;\nun metodo approssimato, che pu√≤ sempre essere usato, ma √® computazionalmente intensivo.\n\n\n15.3.6 Distribuzione predittiva a priori\nLa distribuzione a posteriori √® l‚Äôoggetto centrale nella statistica bayesiana, ma non √® l‚Äôunico. Oltre a fare inferenze sui valori dei parametri, potremmo voler fare inferenze sui dati. Questo pu√≤ essere fatto calcolando la distribuzione predittiva a priori:\n\\[\\begin{equation}\np(y^*) = \\int_\\Theta p(y^* \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\!\\theta .\n(\\#eq:prior-pred-distr)\n\\end{equation}\\]\nLa @ref(eq:prior-pred-distr) descrive la distribuzione prevista dei dati in base al modello (che include la distribuzione a priori e la verosimiglianza), ovvero descrive i dati \\(y^*\\) che ci aspettiamo di osservare, dato il modello, prima di avere osservato i dati del campione.\n√à possibile utilizzare campioni dalla distribuzione predittiva a priori per valutare e calibrare i modelli utilizzando le nostre conoscenze dominio-specifiche. Ad esempio, ci possiamo chiedere: ‚Äú√à sensato che un modello dell‚Äôaltezza umana preveda che un essere umano sia alto -1.5 metri?‚Äù. Gi√† prima di misurare una singola persona, possiamo renderci conto dell‚Äôassurdit√† di questa domanda. Se la distribuzione prevista dei dati consente domande di questo tipo (ovvero, prevede di osservare dati che risultano insensati alla luce delle nostre conoscenze dominio-specifiche), √® chiaro che il modello deve essere riformulato.\n\n\n\n\n15.3.7 Distribuzione predittiva a posteriori\nUn‚Äôaltra quantit√† utile da calcolare √® la distribuzione predittiva a posteriori:\n\\[\\begin{equation}\np(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta .\n(\\#eq:post-pred-distr)\n\\end{equation}\\]\nQuesta √® la distribuzione dei dati attesi futuri \\(\\tilde{y}\\) alla luce della distribuzione a posteriori \\(p(\\theta \\mid y)\\), che a sua volta √® una conseguenza del modello adottato (distribuzione a priori e verosimiglianza) e dei dati osservati. In altre parole, questi sono i dati che il modello si aspetta dopo aver osservato i dati de campione. Dalla @ref(eq:post-pred-distr) possiamo vedere che le previsioni sui dati attesi futuri sono calcolate integrando (o marginalizzando) sulla distribuzione a posteriori dei parametri. Di conseguenza, le previsioni calcolate in questo modo incorporano l‚Äôincertezza relativa alla stima dei parametri del modello."
  },
  {
    "objectID": "025_intro_bayes.html#commenti-e-considerazioni-finali",
    "href": "025_intro_bayes.html#commenti-e-considerazioni-finali",
    "title": "15¬† Credibilit√†, modelli e parametri",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nQuesto Capitolo ha brevemente passato in rassegna i concetti di base dell‚Äôinferenza statistica bayesiana. In base all‚Äôapproccio bayesiano, invece di dire che il parametro di interesse di un modello statistico ha un valore vero ma sconosciuto, diciamo che, prima di eseguire l‚Äôesperimento, √® possibile assegnare una distribuzione di probabilit√†, che chiamano stato di credenza, a quello che √® il vero valore del parametro. Questa distribuzione a priori pu√≤ essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI √® normale con media 100 e deviazione standard 15) o pu√≤ essere del tutto arbitraria. L‚Äôinferenza bayesiana procede poi nel modo seguente: si raccolgono alcuni dati e si calcola la probabilit√† dei possibili valori del parametro alla luce dei dati osservati e delle credenze a priori. Questa nuova distribuzione di probabilit√† √® chiamata ‚Äúdistribuzione a posteriori‚Äù e riassume l‚Äôincertezza dell‚Äôinferenza.\n\n\n\n\n\n\nKruschke, J. (2014). Doing bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian modeling and computation in python. CRC Press.\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., M√§rtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., & Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primer, 1(1), 1‚Äì26."
  },
  {
    "objectID": "026_subj_prop.html",
    "href": "026_subj_prop.html",
    "title": "16¬† Pensare ad una proporzione in termini soggettivi",
    "section": "",
    "text": "Obiettivo di questo Capitolo √® introdurre l‚Äôinferenza bayesiana considerando il modello binomiale. Esamineremo prima il caso di una distribuzione a priori discreta; esamineremo poi il caso di una distribuzione a priori continua. Il materiale qui presentato segue molto da vicino il capitolo 7 del testo di Albert & Hu (2019)."
  },
  {
    "objectID": "026_subj_prop.html#ch-prior-discr-binom",
    "href": "026_subj_prop.html#ch-prior-discr-binom",
    "title": "16¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n16.1 Inferenza bayesiana con una distribuzione a priori discreta",
    "text": "16.1 Inferenza bayesiana con una distribuzione a priori discreta\nNei problemi tradizionali di teoria delle probabilit√† ci sono molti esempi che riguardano l‚Äôestrazione di palline colorate da un‚Äôurna. In questi esempi ci viene fornito il numero di palline di vari colori presenti nell‚Äôurna e ci viene chiesto di calcolare le probabilit√† di vari eventi. Ad esempio, in un‚Äôurna ci sono 40 palline bianche e 20 rosse. Se estrai due palline a caso, qual √® la probabilit√† che entrambe siano bianche?\nL‚Äôapproccio bayesiano considera uno scenario diverso, ovvero quello in cui non conosciamo le proporzioni delle palline colorate presenti nell‚Äôurna. Cio√®, nell‚Äôesempio precedente, sappiamo solo che nell‚Äôurna ci sono due tipi di palline colorate, ma non sappiamo che 40 sono bianche (proporzione di bianco = \\(2/3\\)) e 20 sono rosse (proporzione di rosso = \\(1/3\\)). Ci poniamo la seguente domanda: √® possibile inferire le proporzioni di palline nell‚Äôurna estraendo un campione di palline dall‚Äôurna e osservando i colori delle palline estratte? Espresso in questo modo, questo diventa un problema di inferenza statistica, perch√© stiamo cercando di inferire la proporzione \\(\\theta\\) della popolazione sulla base di un campione casuale. Per continuare con l‚Äôesempio precedente, quello che vogliamo fare √® inferire \\(\\theta\\), ad esempio, la proporzione di palline rosse nell‚Äôurna, alla luce del numero di palline rosse e bianche nel campione.\nLe proporzioni assomigliano alle probabilit√†. Ricordiamo che sono state proposte tre diverse interpretazioni del concetto di probabilit√†.\n\nIl punto di vista classico: √® necessario enumerare tutti gli eventi elementari dello spazio campione nel quale ciascun risultato √® ugualmente probabile.\nIl punto di vista frequentista: √® necessario ripetere l‚Äôesperimento esperimento casuale (cio√® l‚Äôestrazione del campione) molte volte in condizioni identiche.\nLa visione soggettiva: √® necessario esprimere la propria opinione sulla probabilit√† di un evento unico e irripetibile.\n\nLa visione classica non sembra potere funzionare qui, perch√© sappiamo solo che ci sono due tipi di palline colorate e che il numero totale di palline √® 60. Anche se estraiamo un campione di 10 palline, possiamo solo osservare la proporzione di palline rosse nel campione. Non c‚Äô√® modo per potere stabilire che, nello spazio campione, ogni risultato √® ugualmente probabile.\nLa visione frequentista potrebbe funzionare nel caso presente. Possiamo considerare il processo del campionamento (cio√® l‚Äôestrazione di un campione casuale di 10 palline dall‚Äôurna) come un esperimento casuale che produce una proporzione campionaria \\(p\\). Potremmo quindi pensare di ripetere l‚Äôesperimento casuale molte volte nelle stesse condizioni, ottenere una serie di proporzioni campionarie \\(p\\) e infine riassumere in qualche modo questa distribuzione di statistiche campionarie. Ripetendo l‚Äôesperimento casuale tante volte √® possibile ottenere una stima abbastanza accurata della proporzione \\(\\theta\\) di palline rosse nell‚Äôurna. Questo processo √® fattibile, ma per√≤ √® noioso, dispendioso in termini di tempo e soggetto ad errori.\nLa visione soggettivista concepisce invece la probabilit√† sconosciuta \\(\\theta\\) come un‚Äôopinione soggettiva di cui possiamo essere pi√π o meno certi. Questa opinione soggettiva dipende da due tipi di evidenze: le nostre credenze iniziali e le nuove informazioni fornite dai dati che abbiamo osservato. Vedremo in questo capitolo come sia possibile combinare le credenze iniziali rispetto al possibile valore \\(\\theta\\) con le evidenze fornite dai dati per giungere ad una nuova credenza a posteriori su \\(\\theta\\). In particolare, vedremo come si possa pensare in termini soggetti a delle quantit√† sconosciute (in questo caso, \\(\\theta\\)) usando le distribuzioni di probabilit√†.\nEssendo una proporzione, \\(\\theta\\) pu√≤ assumere valori compresi tra 0 e 1. √à possibile pensare che \\(\\theta\\) sia uguale, ad esempio, a 0.5. Ci√≤ significa assegnare all‚Äôevento \\(\\theta = 0.5\\) la probabilit√† 1; in altri termini, significa dire che siamo assolutamente certi che la quantit√† sconosciuta \\(\\theta\\) abbia il valore di 0.5. Questa posizione, per√≤, √® troppo estrema: non possiamo essere assolutamente certi che una quantit√† sconosciuta abbia uno specifico valore; altrimenti non sarebbe una quantit√† sconosciuta. Invece, sembra pi√π sensato pensare che \\(\\theta\\) pu√≤, in linea di principio, assumere diversi valori e attribuire a tali valori livelli diversi di certezza soggettiva.\nConsideriamo, ad esempio, 10 possibili valori \\(\\theta\\).\n\nCodicetheta = seq(0.1, 1, length.out = 10)\ntheta\n#>  [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nSe non abbiamo alcun motivo di pensare diversamente, possiamo assegnare a ciascun valore \\(\\theta\\) la stessa credibilit√†.\n\nCodicep1 <- rep(0.1, 10)\np1\n#>  [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\n\n\nCodicetibble(theta, p1) %>% \n  ggplot(aes(theta, p1)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\n\n\n\nFigura 16.1: Distribuzione a priori per il parametro \\(\\theta\\) (versione 1).\n\n\n\n\nOppure, per qualche ragione, potremmo pensare che i valori centrali della distribuzione di \\(\\theta\\) siamo pi√π credibili dei valori estremi. Tale opinione soggettiva pu√≤ essere descritta dalla seguente distribuzione di massa di probabilit√†.\n\nCodicep2 <- c(\n  0.05, 0.05, 0.05, 0.175, 0.175, 0.175, 0.175, 0.05, 0.05, 0.05\n)\np2\n#>  [1] 0.050 0.050 0.050 0.175 0.175 0.175 0.175 0.050 0.050 0.050\n\n\n\nCodicetibble(theta, p2) %>% \n  ggplot(aes(theta, p2)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\n\n\n\nFigura 16.2: Distribuzione a priori per il parametro \\(\\theta\\) (versione 2).\n\n\n\n\nLa prima distribuzione di probabilit√† √® chiamata distribuzione discreta uniforme perch√© attribuisce la stessa probabilit√† (ovvero, 1/10) ad ogni elemento dell‚Äôinsieme discreto su cui √® definita (ovvero, \\(0.1, 0.2, \\dots, 1.0\\)). Anche la seconda distribuzione √® discreta, ma non √® uniforme: riteniamo pi√π credibile che \\(\\theta\\) assuma un valore nell‚Äôinsieme \\(\\{0.4, 0.5, 0.6, 0.7\\}\\) piuttosto che nell‚Äôinsieme \\(\\{0.1, 0.2, 0.3, 0.8, 0.9, 1.0\\}\\).\nLe credenze relative alla credibilit√† dei possibili valori che \\(\\theta\\) possono assumere forme diverse e corrispondono a quella che viene chiamata la distribuzione a priori, ovvero descrivono le credenze iniziali relative alla quantit√† sconosciuta di interesse.\nLa procedura di inferenza bayesiana ‚Äúaggiorna‚Äù tali credenze a priori utilizzando le informazioni fornite da un campione di dati. Usando il teorema di Bayes, le informazioni fornite dai dati vengono combinate con le nostre credenze precedenti relative alla quantit√† sconosciuta \\(\\theta\\) per giungere ad una credenza detta ‚Äúa posteriori‚Äù.\nSupponendo che i dati corrispondano all‚Äôosservazione di 12 palline rosse in 20 estrazioni con rimessa dall‚Äôurna, usiamo ora la seconda delle distribuzioni a priori descritte sopra per ottenere la distribuzione a posteriori.\nIl teorema di Bayes specifica la distribuzione a posteriori come il prodotto della verosimiglianza e della distribuzione a priori, diviso per una costante di normalizzazione:\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta)p(\\theta)}{p(y)}.\n\\]\nPer trovare la funzione di verosimiglianza, \\(p(y \\mid \\theta)\\), √® necessario pensare a come sono stati ottenuti i dati. I dati corrispondono ai risultati di 20 estrazioni con rimessa da un‚Äôurna. Se l‚Äôestrazione √® casuale con reinserimento, allora i dati (12 successi in 20 prove) possono essere intesi come il risultato di un esperimento casuale binomiale. Usando \\(\\textsf{R}\\), la funzione di verosimiglianza pu√≤ essere generata mediante la funzione dbinom().\n\nCodicelike <- dbinom(12, 20, theta)\nlike\n#>  [1] 5.422595e-08 8.656592e-05 3.859282e-03 3.549744e-02 1.201344e-01\n#>  [6] 1.797058e-01 1.143967e-01 2.216088e-02 3.557765e-04 0.000000e+00\n\n\nPer i 10 valori \\(\\theta\\) considerati, la funzione di verosimiglianza assume la forma indicata dalla Figura¬†16.3 .\n\nCodicetibble(theta, like) %>% \n  ggplot(aes(theta, like)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\n\n\n\nFigura 16.3: Verosimiglianza del modello binomiale nel caso di 12 successi in 20 prove.\n\n\n\n\nPer calcolare la distribuzione a posteriori dobbiamo fare il prodotto (elemento per elemento) del vettore che contiene i valori della distribuzione a priori e del vettore che contiene i valori della funzione di verosimiglianza. Tale prodotto andr√† poi diviso per una costante di normalizzazione, \\(p(y)\\).\nPer la legge della probabilit√† totale, il denominatore corrisponde alla probabilit√† marginale dei dati \\(y\\) ed √® uguale alla somma dei prodotti tra la distribuzione a priori e la funzione di verosimiglianza. Nel caso discreto qui considerato, la probabilit√† marginale dei dati ci calcola come sum(p2 * like).\n\nCodicesum(p2 * like)\n#> [1] 0.08002663\n\n\nLa distribuzione a posteriori di \\(\\theta\\) sar√† dunque uguale a (p2 * like) / sum(p2 * like).\n\nCodicepost <- (p2 * like) / sum(p2 * like)\npost\n#>  [1] 3.387994e-08 5.408570e-05 2.411248e-03 7.762481e-02 2.627064e-01\n#>  [6] 3.929756e-01 2.501596e-01 1.384594e-02 2.222863e-04 0.000000e+00\n\n\nUna rappresentazione grafica della distribuzione a posteriori di \\(\\theta\\) √® fornita dalla Figura¬†16.4.\n\nCodicetibble(theta, post) %>% \n  ggplot(aes(theta, post)) +\n  geom_segment(\n    aes(xend = theta, yend = 0), size = 10, lineend = \"butt\"\n  )\n\n\n\nFigura 16.4: Distribuzione a posteriori per il modello binomiale con 12 successi in 20 prove e la distribuzione a priori indicata in Figura¬†16.2.\n\n\n\n\nConoscendo la distribuzione a posteriori di \\(\\theta\\) diventa possibile calcolare altre quantit√† di interesse. Per esempio, la moda a posteriori di \\(\\theta\\) si ricava direttamente dal grafico precedente, e corrisponde a 0.6. La media a posteriori si trova con la formula del valore atteso delle v.c..\n\nCodicesum(theta * post)\n#> [1] 0.5853112\n\n\nLo stesso si pu√≤ dire della varianza della distribuzione a posteriori.\n\nCodicesum(theta^2 * post) - (sum(theta * post))^2\n#> [1] 0.008817409\n\n\nNel caso di una distribuzione a priori discreta, il calcolo della distribuzione a posteriori √® implementata nella funzione bayesian_crank() del pacchetto ProbBayes. Dato che ProbBayes non √® su CRAN, pu√≤ essere installato nel modo seguente.\n\nCodicelibrary(\"devtools\")\ninstall_github(\"bayesball/ProbBayes\")\n\n\nUna volta installato, il pacchetto pu√≤ essere caricato come facciamo normalmente.\n\nCodicelibrary(\"ProbBayes\")\n\n\nPer usare bayesian_crank() procediamo come indicato di seguito:\n\nCodiced <- tibble(p = theta, Prior = p2)\ny <- 12\nn <- 20\nd$Likelihood <- dbinom(y, prob = d$p, size = n)\ndf <- bayesian_crank(d)\ndf %>% as.data.frame()\n#>      p Prior   Likelihood      Product    Posterior\n#> 1  0.1 0.050 5.422595e-08 2.711298e-09 3.387994e-08\n#> 2  0.2 0.050 8.656592e-05 4.328296e-06 5.408570e-05\n#> 3  0.3 0.050 3.859282e-03 1.929641e-04 2.411248e-03\n#> 4  0.4 0.175 3.549744e-02 6.212052e-03 7.762481e-02\n#> 5  0.5 0.175 1.201344e-01 2.102351e-02 2.627064e-01\n#> 6  0.6 0.175 1.797058e-01 3.144851e-02 3.929756e-01\n#> 7  0.7 0.175 1.143967e-01 2.001943e-02 2.501596e-01\n#> 8  0.8 0.050 2.216088e-02 1.108044e-03 1.384594e-02\n#> 9  0.9 0.050 3.557765e-04 1.778882e-05 2.222863e-04\n#> 10 1.0 0.050 0.000000e+00 0.000000e+00 0.000000e+00\n\n\nVerifichiamo il risultato trovato calcolando, ad esempio, la media a posteriori (come abbiamo fatto sopra):\n\nCodicesum(theta * df$Posterior)\n#> [1] 0.5853112\n\n\nUsando questo metodo possiamo trovare la distribuzione a posteriori di \\(\\theta\\) nel caso di qualunque distribuzione a priori discreta."
  },
  {
    "objectID": "026_subj_prop.html#ch-prior-cont-binom",
    "href": "026_subj_prop.html#ch-prior-cont-binom",
    "title": "16¬† Pensare ad una proporzione in termini soggettivi",
    "section": "\n16.2 Inferenza bayesiana con una distribuzione a priori continua",
    "text": "16.2 Inferenza bayesiana con una distribuzione a priori continua\nIl caso di una distribuzione a priori discreta √® stato discusso solo per scopi didattici. In generale, l‚Äôuso di una distribuzione a priori discreta non √® una buona scelta per rappresentare le nostre credenze a priori sul parametro sconosciuto. Infatti, per definizione, una distribuzione a priori discreta pu√≤ rappresentare solo alcuni dei possibili valori del parametro ‚Äì nel caso discusso sopra, ad esempio, non abbiamo considerato il valore 0.55. Sembra dunque pi√π sensato descrivere le nostre credenze a priori sul parametro utilizzando una distribuzione continua.\nCerchiamo una funzione di densit√† con supporto in \\([0, 1]\\). Il candidato naturale √® fornito dalla funzione Beta (si veda il Capitolo¬†13). Come per le altre funzioni di densit√†, abbiamo a disposizione quattro funzioni \\(\\textsf{R}\\) che ci consentono di manipolare facilmente questa densit√†.\nAd esempio, possiamo valutare la funzione di densit√† \\(\\mbox{Beta}(1, 1)\\) in corrispondenza dei valori \\(p = 0.5\\) e \\(p = 0.8\\), che dovrebbe essere entrambi uguali a 1, e in corrispondenza di \\(p = 1.2\\), che dovrebbe essere ugualea 0 poich√© questo valore √® al di fuori dell‚Äôintervallo \\([ 0, 1]\\).\n\nCodicedbeta(c(0.5, 0.8, 1.2), 1, 1)\n#> [1] 1 1 0\n\n\nOppure possiamo valutare la funzione distribuzione \\(\\mbox{Beta}(1, 1)\\) in corrispondenza dei punti 0.5 e 0.8:\n\nCodicepbeta(c(0.5, 0.8), 1, 1)\n#> [1] 0.5 0.8\n\n\nOppure possiamo calcolare la probabilit√† \\(P(0.5 < p < 0.8)\\)\n\nCodicepbeta(0.8, 1, 1) - pbeta(0.5, 1, 1) \n#> [1] 0.3\n\n\nPossiamo trovare i quantili della distribuzione \\(\\mbox{Beta}(1, 1)\\) di ordine 0.5 e 0.8:\n\nCodiceqbeta(c(0.5, 0.8), 1, 1)\n#> [1] 0.5 0.8\n\n\nInfine, √® possibile simulare dei valori casuali dalla distribuzione \\(\\mbox{Beta}(1, 1)\\). Se vogliamo 5 valori, scriviamo:\n\nCodicerbeta(5, 1, 1)\n#> [1] 0.2523117 0.5492791 0.2174402 0.4063601 0.2128675\n\n\nSe vogliamo 5 valori da una \\(\\mbox{Beta}(2, 10)\\), scriviamo:\n\nCodicerbeta(5, 2, 10)\n#> [1] 0.17364773 0.21332530 0.24430864 0.15817644 0.04897118\n\n\nIl pacchetto ProbBayes offre la funzione beta_area() per visualizzare la probabilit√† di una distribuzione Beta in un certo intrvallo di valori. Per esempio, se vogliamo la probabilit√† dell‚Äôevento per cui la variabile casuale \\(p\\) √® contenuta nell‚Äôintervallo \\([0.1, 0.3]\\) nel caso di una \\(\\mbox{Beta}(2, 10)\\), scriviamo:\n\nCodicebeta_area(0.1, 0.3, c(2, 10))\n\n\n\n\n\n\n\n\n16.2.1 Quali parametri per la distribuzione Beta?\nSe usiamo una distribuzione Beta per rappresentare le nostre credenze a priori sul parametro \\(\\theta\\) (probabilit√† di successo), allora dobbiamo porci il problema di scegliere i parametri che definiscono la distribuzione Beta che meglio rappresenta le nostre opinioni a priori. Il modo pi√π ovvio per ottenere questo risultato √® per prove ed errori. Oppure, possiamo individuare i parametri \\(\\alpha\\) e \\(\\beta\\) della distribuzione interpretando \\(\\alpha\\) come la nostra stima a priori del numero di ‚Äúsuccessi‚Äù, \\(\\beta\\) come a nostra stima a priori del numero di ‚Äúinsuccessi‚Äù e \\(\\alpha + \\beta\\) come il numero di prove del campione. Ad esempio, se pensiamo che, su 30 prove, verranno osservati 10 successi, otteniamo una \\(\\mbox{Beta}(10, 20)\\).\n\nCodicebayesrules::plot_beta(10, 20, mean = TRUE, mode = TRUE)\n\n\n\n\n\n\n\nIn alternativa, potremmo specificare la distribuzione a priori definendo la mediana e un quantile della distribuzione. Per esempio, le nostre opinioni a priori sul parametro potrebbero essere tali per cui pensiamo che la mediana della distribuzione sia 0.25 e il quantile della distribuzione di ordine 0.9 sia 0.5. Usando la Shiny App ProbBayes::ChooseBeta() troviamo i parametri \\(\\alpha = 1.84\\) e \\(\\beta = 4.89\\).\n\nCodicebayesrules::plot_beta(1.84, 4.89, mean = TRUE, mode = TRUE)"
  },
  {
    "objectID": "026_subj_prop.html#commenti-e-considerazioni-finali",
    "href": "026_subj_prop.html#commenti-e-considerazioni-finali",
    "title": "16¬† Pensare ad una proporzione in termini soggettivi",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nAbbiamo qui introdotto la procedura dell‚Äôaggiornamento bayesiano nel caso in cui la distribuzione a priori sia discreta. Abbiamo anche fornito alcune informazioni che sono utili per affrontare il problema nel caso in cui viene utilizzata una distribuzione a priori continua. Se viene utilizzata una distribuzione a priori continua, al denominatore del rapporto di Bayes troviamo un integrale che, in generale, non si pu√≤ risolvere per via analitica. Il caso dell‚Äôinferenza su una proporzione, in cui la distribuzione a priori √® una distribuzione Beta e la verosimiglianza √® binoniale, rappresenta per√≤ un‚Äôeccezione, ovvero consente di derivare le propriet√† della distribuzione a posteriori per via analitica. Il prossimo capitolo ha lo scopo di illustrare questo argomento.\n\n\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and bayesian modeling. Chapman; Hall/CRC."
  },
  {
    "objectID": "029_conjugate_families.html",
    "href": "029_conjugate_families.html",
    "title": "17¬† Distribuzioni coniugate",
    "section": "",
    "text": "Obiettivo di questo Capitolo √® fornire un esempio di derivazione della distribuzione a posteriori scegliendo quale distribuzione a priori una distribuzione coniugata. Esamineremo qui il lo schema beta-binomiale."
  },
  {
    "objectID": "029_conjugate_families.html#lo-schema-beta-binomiale",
    "href": "029_conjugate_families.html#lo-schema-beta-binomiale",
    "title": "17¬† Distribuzioni coniugate",
    "section": "\n17.1 Lo schema beta-binomiale",
    "text": "17.1 Lo schema beta-binomiale\nEsiste una particolare classe di distribuzioni a priori, dette distribuzioni a priori coniugate al modello, che godono di un‚Äôimportante propriet√†: se la distribuzione iniziale appartiene a tale classe, anche la distribuzione finale vi appartiene, cio√© ha la stessa forma funzionale, e l‚Äôaggiornamento della fiducia si riduce alla modifica dei parametri della distribuzione a priori. Ad esempio, se la distribuzione a priori √® una Beta e la verosimiglianza √® binomiale, allora la distribuzione a posteriori sar√† anch‚Äôessa una distribuzione Beta.\nDa un punto di vista matematico, le distribuzioni a priori coniugate sono la scelta pi√π conveniente in quanto consentono di calcolare analiticamente la distribuzione a posteriori con ‚Äúcarta e penna‚Äù, senza la necessit√† di ricorrere a calcoli complessi. Da una prospettiva computazionale moderna, per√≤, le distribuzioni a priori coniugate generalmente non sono migliori delle alternative, dato che i moderni metodi computazionali consentono di eseguire l‚Äôinferenza praticamente con qualsiasi scelta delle distribuzioni a priori, e non solo con le distribuzioni a priori che risultano matematicamente convenienti. Tuttavia, le famiglie coniugate offronto un utile ausilio didattico nello studio dell‚Äôinferenza bayesiana. Questo √® il motivo per cui le esamineremo qui. Nello specifico, esamineremo quello che viene chiamato lo schema beta-binomiale.\nPer fare un esempio concreto, consideriamo nuovamente i dati di Zetsche et al. (2019): nel campione di 30 partecipanti clinici le aspettative future di 23 partecipanti risultano negativamente distorte mentre quelle di 7 partecipanti risultano positivamente distorte. Nel seguito, indicheremo con \\(\\theta\\) la probabilit√† che le aspettative di un paziente clinico siano distorte negativamente. Ci poniamo il problema di ottenere una stima a posteriori di \\(\\theta\\) avendo osservato 23 ‚Äúsuccessi‚Äù in 30 prove. I dati osservati (\\(y = 23\\)) possono essere considerati la manifestazione di una variabile casuale Bernoulliana, dunque la verosimiglianza √® binomiale. In tali circostanze, se viene scelta una distribuzione a priori Beta, allora anche la distribuzione a posteriori sar√† una Beta.\n\n17.1.1 La distribuzione a priori\n√à possibile esprimere diverse credenze iniziali rispetto a \\(\\theta\\) mediante la distribuzione Beta. Ad esempio, la scelta di una \\(\\mbox{Beta}(\\alpha = 4, \\beta = 4)\\) quale distribuzione a priori per il parametro \\(\\theta\\) corrisponde alla credenza a priori che associa all‚Äôevento ‚Äúpresenza di una aspettativa futura distorta negativamente‚Äù una grande incertezza: il valore 0.5 √® il valore di \\(\\theta\\) pi√π plausibile, ma anche gli altri valori del parametro (tranne gli estremi) sono ritenuti piuttosto plausibili. Questa distribuzione a priori esprime la credenza che sia egualmente probabile per un‚Äôaspettativa futura essere distorta negativamente o positivamente.\n\nCodicelibrary(\"bayesrules\")\nplot_beta(alpha = 4, beta = 4, mean = TRUE, mode = TRUE)\n\n\n\n\n\n\n\nPossiamo quantificare la nostra incertezza calcolando, con un grado di fiducia del 95%, la regione nella quale, in base a tale credenza a priori, si trova il valore del parametro. Per ottenere tale intervallo di credibilit√† a priori, usiamo la funzione qbeta() di \\(\\mathsf{R}\\). Nella funzione qbeta() i parametri \\(\\alpha\\) e \\(\\beta\\) sono chiamati shape1 e shape2.\n\nCodiceqbeta(c(0.025, 0.975), shape1 = 4, shape2 = 4)\n#> [1] 0.1840516 0.8159484\n\n\nSe poniamo \\(\\alpha=10\\) e \\(\\beta=10\\), anche questa scelta descrive una credenza a priori per la quale √® egualmente probabile osservare un‚Äôaspettativa futura distorta negativamente o positivamente.\n\nCodiceplot_beta(alpha = 10, beta = 10, mean = TRUE, mode = TRUE)\n\n\n\n\n\n\n\nTuttavia, in questo caso la nostra certezza a priori sul valore del parametro √® maggiore, come indicato dall‚Äôintervallo di ordine 0.95.\n\nCodiceqbeta(c(0.025, 0.975), shape1 = 10, shape2 = 10)\n#> [1] 0.2886432 0.7113568\n\n\nQuale distribuzione a priori dobbiamo scegliere? In un problema concreto di analisi dei dati, la scelta della distribuzione a priori dipende dalle credenze a priori che vogliamo includere nell‚Äôanalisi dei dati. Se non abbiamo alcuna informazione a priori, allora √® possibile usare \\(\\alpha=1\\) e \\(\\beta=1\\), che corrisponde ad una distribuzione a priori uniforme. Ma l‚Äôuso di distribuzioni a priori uniformi √® sconsigliato per vari motivi, inclusa l‚Äôinstabilit√† numerica della stima dei parametri. In tali circostanze sarebbe preferibile usare una distribuzione a priori debolmente informativa, come una \\(\\mbox{Beta}(2, 2)\\).\nNella discussione presente, quale distribuzione a priori useremo una \\(\\mbox{Beta}(2, 10)\\).\n\\[\np(\\theta) = \\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}.\n\\]\n\nCodiceplot_beta(alpha = 2, beta = 10, mean = TRUE, mode = TRUE)\n\n\n\n\n\n\n\nTale distribuzione a priori √® del tutto inappropriata per i dati di Zetsche et al. (2019). La \\(\\mbox{Beta}(2, 10)\\) esprime la credenza che \\(\\theta < 0.5\\), con il valore pi√π plausibile pari a cicrca 0.1. Ma non c‚Äô√® motivo di pensare, a priori, che, per questa popolazione, vi sia una bassa probabilit√† di un‚Äôaspettativa futura distorta negativamente ‚Äì piuttosto √® vero il contrario. La \\(\\mbox{Beta}(2, 10)\\) verr√† usata qui solo per mostrare l‚Äôeffetto che ha una tale scelta sulla distribuzione a posteriori.\n\n17.1.2 La distribuzione a posteriori\nUna volta scelta una distribuzione a priori di tipo Beta, i cui parametri rispecchiano le nostre credenze iniziali su \\(\\theta\\), la distribuzione a posteriori viene specificata dalla formula di Bayes:\n\\[\n\\text{distribuzione a posteriori} = \\frac{\\text{verosimiglianza}\\cdot\\text{distribuzione a priori}}{\\text{verosimiglianza marginale}}.\n\\]\nPer i dati presenti la verosimiglianza √® binomiale per cui abbiamo\n\\[\np(\\theta \\mid n=30, y=23) = \\frac{\\Big[\\binom{30}{23}\\theta^{23}(1-\\theta)^{30-23}\\Big]\\Big[\\frac{\\Gamma(12)}{\\Gamma(2)\\Gamma(10)}\\theta^{2-1} (1-\\theta)^{10-1}\\Big]}{p(y = 23)},\n\\]\nladdove \\(p(y = 23)\\), ovvero la verosimiglianza marginale, √® una costante di normalizzazione.\nRiscriviamo l‚Äôequazione precedente in termini pi√π generali:\n\\[\np(\\theta \\mid n, y) = \\frac{\\Big[\\binom{n}{y}\\theta^{y}(1-\\theta)^{n-y}\\Big]\\Big[\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\\theta^{a-1} (1-\\theta)^{b-1}\\Big]}{p(y)}.\n\\]\nRaccogliendo tutte le costanti otteniamo:\n\\[\np(\\theta \\mid n, y) =\\left[\\frac{\\binom{n}{y}\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}}{p(y)}\\right] \\theta^{y}(1-\\theta)^{n-y}\\theta^{a-1} (1-\\theta)^{b-1}.\n\\]\nSe ignoriamo il termine costante all‚Äôinterno della parentesi quadra il termine di destra dell‚Äôequazione precedente identifica il kernel della distribuzione a posteriori e corrisponde ad una Beta non normalizzata di parametri \\(a + y\\) e \\(b + n - y\\):\n\\[\n\\begin{align}\np(\\theta \\mid n, y) &\\propto \\theta^{y}(1-\\theta)^{n-y}\\theta^{a-1} (1-\\theta)^{b-1},\\notag\\\\\n&\\propto \\theta^{a+y-1}(1-\\theta)^{b+n-y-1}.\n\\end{align}\n\\]\nPer ottenere una distribuzione di densit√†, dobbiamo aggiungere una costante di normalizzazione al kernel della distribuzione a posteriori. In base alla definizione della distribuzione Beta, ed essendo \\(a' = a+y\\) e \\(b' = b+n-y\\), tale costante di normalizzazione √® uguale a\n\\[\n\\frac{\\Gamma(a'+b')}{\\Gamma(a')\\Gamma(b')} = \\frac{\\Gamma(a+b+n)}{\\Gamma(a+y)\\Gamma(b+n-y)}.\n\\]\nPossiamo dunque concludere, nel caso dello schema beta-binomiale, che la distribuzione a posteriori √® una \\(\\mbox{Beta}(a+y, b+n-y)\\):\n\\[\n\\mbox{Beta}(a+y, b+n-y) = \\frac{\\Gamma(a+b+n)}{\\Gamma(a+y)\\Gamma(b+n-y)} \\theta^{a+y-1}(1-\\theta)^{b+n-y-1}.\n\\]\nIn sintesi, per i dati in discussione, moltiplicando verosimiglianza \\(\\mbox{Bin}(n = 30, y = 23 \\mid \\theta)\\) per la la distribuzione a priori \\(\\theta \\sim \\mbox{Beta}(2, 10)\\) e dividendo per la costante di normalizzazione, si ottiene la distribuzione a posteriori \\(p(\\theta \\mid n, y) \\sim \\mbox{Beta}(25, 17)\\).\nQuesto √® un esempio di analisi coniugata. La presente combinazione di verosimiglianza e distribuzione a priori √® chiamata caso coniugato beta-binomiale ed √® descritta dal seguente teorema.\n\nTeorema 17.1 \nSia data la funzione di verosimiglianza \\(\\mbox{Bin}(n, y \\mid \\theta)\\) e sia \\(\\mbox{Beta}(\\alpha, \\beta)\\) una distribuzione a priori. In tali circostanze, la distribuzione a posteriori del parametro \\(\\theta\\) sar√† una distribuzione \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\).\n\n√à facile calcolare il valore atteso a posteriori di \\(\\theta\\). Essendo \\(\\mathbb{E}[\\mbox{Beta}(\\alpha, \\beta)] = \\frac{\\alpha}{\\alpha + \\beta}\\), il risultato cercato diventa\n\\[\n\\mathbb{E}_{\\text{post}} [\\mathrm{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}.\n\\tag{17.1}\\]\n\nEsercizio 17.1 \nSi rappresenti in maniera grafica e si descriva in forma numerica l‚Äôaggiornamento bayesiano beta-binomiale per i dati di Zetsche et al. (2019). Si assuma una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\).\n\n\nSoluzione. Per i dati in questione, l‚Äôaggiornamento bayesiano pu√≤ essere rappresentato in forma grafica usando la funzione plot_beta_binomial() del pacchetto bayesrules:\n\nCodicebayesrules::plot_beta_binomial(\n  alpha = 2, beta = 10, y = 23, n = 30\n  ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUn sommario delle distribuzioni a priori e a posteriori pu√≤ essere ottenuto, ad esempio, usando la funzione summarize_beta_binomial() del pacchetto bayesrules:\n\nCodicebayesrules:::summarize_beta_binomial(\n  alpha = 2, beta = 10, y = 23, n = 30\n)\n#>       model alpha beta      mean mode         var        sd\n#> 1     prior     2   10 0.1666667  0.1 0.010683761 0.1033623\n#> 2 posterior    25   17 0.5952381  0.6 0.005603016 0.0748533\n\n\n\n\nEsercizio 17.2 \nPer i dati di Zetsche et al. (2019), si trovino la media, la moda, la deviazione standard della distribuzione a posteriori di \\(\\theta\\). Si trovi inoltre l‚Äôintervallo di credibilit√† a posteriori del 95% per il parametro \\(\\theta\\).\n\n\nSoluzione. L‚Äôintervallo di credibilit√† a posteriori del 95% per il parametro \\(\\theta\\) si trova usando il Teorema Teorema¬†17.1.\n\nCodiceqbeta(c(0.025, 0.975), shape1 = 25, shape2 = 17)\n#> [1] 0.4450478 0.7368320\n\n\nLa media della distribuzione a posteriori si trova con l‚ÄôEquazione¬†17.1.\n\nCodice25 / (25 + 17)\n#> [1] 0.5952381\n\n\nLa moda della distribuzione a posteriori si trova usando le propriet√† della distribuzione Beta.\n\nCodice(25 - 1) / (25 + 17 - 2)\n#> [1] 0.6\n\n\nLa deviazione standard della distribuzione a posteriori si trova usando le propriet√† della distribuzione Beta.\n\nCodicesqrt((25 * 17) / ((25 + 17)^2 * (25 + 17 + 1)))\n#> [1] 0.0748533\n\n\n\n\nEsercizio 17.3 Si trovino i parametri e le propriet√† della distribuzione a posteriori del parametro \\(\\theta\\) per i dati dell‚Äôesempio relativo alla ricerca di Stanley Milgram discussa da Johnson et al. (2022).\nNel 1963, Stanley Milgram present√≤ una ricerca sulla propensione delle persone a obbedire agli ordini di figure di autorit√†, anche quando tali ordini possono danneggiare altre persone (Milgram, 1963). Nell‚Äôarticolo, Milgram descrive lo studio come\n\nconsist[ing] of ordering a naive subject to administer electric shock to a victim. A simulated shock generator is used, with 30 clearly marked voltage levels that range from IS to 450 volts. The instrument bears verbal designations that range from Slight Shock to Danger: Severe Shock. The responses of the victim, who is a trained confederate of the experimenter, are standardized. The orders to administer shocks are given to the naive subject in the context of a ‚Äúlearning experiment‚Äù ostensibly set up to study the effects of punishment on memory. As the experiment proceeds the naive subject is commanded to administer increasingly more intense shocks to the victim, even to the point of reaching the level marked Danger: Severe Shock.\n\nAll‚Äôinsaputa del partecipante, gli shock elettrici erano falsi e l‚Äôattore stava solo fingendo di provare il dolore dello shock.\n\n\nSoluzione. Johnson et al. (2022) fanno inferenza sui risultati dello studio di Milgram mediante il modello Beta-Binomiale. Il parametro di interesse √® \\(\\theta\\), la probabilt√† che una persona obbedisca all‚Äôautorit√† (in questo caso, somministrando lo shock pi√π severo), anche se ci√≤ significa recare danno ad altri. Johnson et al. (2022) ipotizzano che, prima di raccogliere dati, le credenze di Milgram relative a \\(\\theta\\) possano essere rappresentate mediante una \\(\\mbox{Beta}(1, 10)\\). Sia \\(y = 26\\) il numero di soggetti che, sui 40 partecipanti allo studio, aveva accettato di infliggere lo shock pi√π severo. Assumendo che ogni partecipante si comporti indipendentemente dagli altri, possiamo modellare la dipendenza di \\(y\\) da \\(\\theta\\) usando la distribuzione binomiale. Giungiamo dunque al seguente modello bayesiano Beta-Binomiale:\n\\[\n\\begin{align}\ny \\mid \\theta & \\sim \\mbox{Bin}(n = 40, \\theta) \\notag\\\\\n\\theta & \\sim \\text{Beta}(1, 10) \\; . \\notag\n\\end{align}\n\\]\nUsando le funzioni di bayesrules possiamo facilmente calcolare i parametri e le propriet√† della distribuzione a posteriori.\n\nCodicebayesrules::summarize_beta_binomial(\n  alpha = 1, beta = 10, y = 26, n = 40\n)\n#>       model alpha beta       mean      mode         var         sd\n#> 1     prior     1   10 0.09090909 0.0000000 0.006887052 0.08298827\n#> 2 posterior    27   24 0.52941176 0.5306122 0.004791057 0.06921746\n\n\nIl processo di aggiornamento bayesiano √® descritto dalla figura ottenuta con la funzione bayesrules::plot_beta_binomial().\n\nCodicebayesrules::plot_beta_binomial(\n  alpha = 1, beta = 10, y = 26, n = 40\n  )"
  },
  {
    "objectID": "029_conjugate_families.html#inferenza-bayesiana-con-distribuzioni-a-priori-continue",
    "href": "029_conjugate_families.html#inferenza-bayesiana-con-distribuzioni-a-priori-continue",
    "title": "17¬† Distribuzioni coniugate",
    "section": "\n17.2 Inferenza bayesiana con distribuzioni a priori continue",
    "text": "17.2 Inferenza bayesiana con distribuzioni a priori continue\nL‚Äôinferenza bayesiane sulla proporzione \\(\\theta\\) si basa su vari riepiloghi della distribuzione a posteriori Beta. Il riepilogo che si calcola dalla distribuzione a posteriori dipende dal tipo di inferenza. Consideriamo qui su due tipi di inferenza:\n\nproblemi in cui si √® interessati a valutare la plausibilit√† che il parametro assuma valori contenuti in un dato intervallo di valori,\nstime dell‚Äôintervallo che contiene il parametro ad un dato livello di probabilit√† soggettiva.\n\n\n17.2.1 Verifica di ipotesi bayesiana\nNell‚Äôesempio in discussione sui dati di Zetsche et al. (2019), la nostra credenza a posteriori relativa a \\(\\theta\\) (ovvero, la probabilit√† che l‚Äôaspettativa dell‚Äôumore futuro sia distorta negativamente) √® descritta da una distribuzione Beta(25,17). Una volta definita la distribuzione a posteriori, ci possiamo porre altre domande. Per esempio: qual √® la probabilit√† che \\(\\theta\\) sia maggiore di 0.5?\nUna risposta a questa domanda si pu√≤ trovare usando la funzione pbeta().\n\nCodice1 - pbeta(0.5, 25, 17)\n#> [1] 0.8944882\n\n\nOppure, in maniera equivalente, con la funzione ProbBayes::beta_area().\n\nCodiceProbBayes::beta_area(lo = 0.5, hi = 1.0, shape_par = c(25, 17))\n\n\n\n\n\n\n\nQuesto calcolo pu√≤ anche essere svolto mediante simulazione. Dato che conosciamo la distribuzione target, √® possibile ricavare un campione casuale di osservazioni da una tale distribuzione per poi riassumere il campione in modo tale da trovare \\(\\theta > 0.5\\).\n\nCodicensim <- 1e6\ntheta_samples <- rbeta(nsim, 25, 17)\nsum(theta_samples > 0.5) / nsim\n#> [1] 0.894317\n\n\nIl risultato della simulazione √® molto simile a quello ottenuto in precedenza.\n\n17.2.2 Intervalli di credibilit√†\nUn secondo tipo di inferenza bayesiana √® quella che ci porta a costruire gli intervalli di credibilit√†. Un intervallo di credibilit√† di ordine \\(a \\in [0, 1]\\) √® l‚Äôintervallo di valori che contiene una proporzione della distribuzione a posteriori pari ad \\(a\\).\nLa funzione ProbBayes::beta_interval() consente di calcolare l‚Äôintervallo di credibilit√† che lascia la stessa probabilit√† nelle due code. Per esempio, l‚Äôintervallo di credibilit√† all‚Äô89% per la distribuzione a posteriori dell‚Äôesempio relativo ai dati di Zetsche et al. (2019) √® il seguente.\n\nCodiceProbBayes::beta_interval(0.89, c(25, 17))\n\n\n\n\n\n\n\nPer i dati di Zetsche et al. (2019), l‚Äôintervallo di credibilit√† all‚Äô50% √® il seguente.\n\nCodiceProbBayes::beta_interval(0.5, c(25, 17))"
  },
  {
    "objectID": "029_conjugate_families.html#principali-distribuzioni-coniugate",
    "href": "029_conjugate_families.html#principali-distribuzioni-coniugate",
    "title": "17¬† Distribuzioni coniugate",
    "section": "\n17.3 Principali distribuzioni coniugate",
    "text": "17.3 Principali distribuzioni coniugate\nEsistono altre combinazioni di verosimiglianza e distribuzione a priori le quali producono una distribuzione a posteriori che ha la stessa densit√† della distribuzione a priori. Sono elencate qui sotto le piuÃÄ note coniugazioni tra modelli statistici e distribuzioni a priori.\n\nPer il modello Normale-Normale \\(\\mathcal{N}(\\mu, \\sigma^2_0)\\), la distribizione iniziale √® \\(\\mathcal{N}(\\mu_0, \\tau^2)\\) e la distribuzione finale √® \\(\\mathcal{N}\\left(\\frac{\\mu_0\\sigma^2 + \\bar{y}n\\tau^2}{\\sigma^2 + n\\tau^2}, \\frac{\\sigma^2\\tau^2}{\\sigma^2 + n\\tau^2} \\right)\\).\nPer il modello Poisson-gamma \\(\\text{Po}(\\theta)\\), la distribizione iniziale √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale √® \\(\\Gamma(\\lambda + n \\bar{y}, \\delta +n)\\).\nPer il modello esponenziale \\(\\text{Exp}(\\theta)\\), la distribizione iniziale √® \\(\\Gamma(\\lambda, \\delta)\\) e la distribuzione finale √® \\(\\Gamma(\\lambda + n, \\delta +n\\bar{y})\\).\nPer il modello uniforme-Pareto \\(\\text{U}(0, \\theta)\\), la distribizione iniziale √® \\(\\mbox{Pa}(\\alpha, \\varepsilon)\\) e la distribuzione finale √® \\(\\mbox{Pa}(\\alpha + n, \\max(y_{(n)}, \\varepsilon))\\)."
  },
  {
    "objectID": "029_conjugate_families.html#commenti-e-considerazioni-finali",
    "href": "029_conjugate_families.html#commenti-e-considerazioni-finali",
    "title": "17¬† Distribuzioni coniugate",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLo scopo di questo Capitolo √® stato quello di mostrare come sia possibile integrare le conoscenze a priori (espresse nei termini di una distribuzione a priori) con le evidenze fornite dai dati (espresse nei termini della funzione di verosimiglianza), cos√¨ da determinare, mediante il teorema di Bayes, una distribuzione a posteriori, la quale condensa l‚Äôincertezza che abbiamo sul parametro sconosciuto \\(\\theta\\). Per illustrare tale problema, abbiamo considerato una situazione nella quale \\(\\theta\\) corrisponde alla probabilit√† di successo in una sequenza di prove Bernoulliane. In tali circostanze √® ragionevole esprimere le credenze a priori mediante la densit√† Beta, con opportuni parametri. L‚Äôinferenza rispetto a \\(\\theta\\) pu√≤ essere dunque svolta utilizzando una distribuzione a priori Beta e una verosimiglianza binomiale. In tali circostanze, la distribuzione a posteriori diventa essa stessa una distribuzione Beta. Questo √® il cosiddetto schema beta-binomiale. Dato che utilizza una distribuzione a priori coniugata, lo schema beta-binomiale rende possibile la determinazione analitica dei parametri della distribuzione a posteriori.\n\n\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMilgram, S. (1963). Behavioral study of obedience. The Journal of Abnormal and Social Psychology, 67(4), 371‚Äì378.\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "030_balance_prior_post.html",
    "href": "030_balance_prior_post.html",
    "title": "18¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "",
    "text": "La notazione \\(p(\\theta \\mid y) \\propto p(\\theta) \\ p(y \\mid \\theta)\\) rende particolarmente chiaro che la distribuzione a posteriori √® un ‚Äúmiscuglio‚Äù della distribuzione a priori e della verosimiglianza. Prima di preoccuparci di come calcolare la distribuzione a posteriori in casi diversi dalle famiglie coniugate, cerchiamo di capire meglio cosa significa ‚Äúmescolare‚Äù la distribuzione a priori e la verosimiglianza. Considereremo qui un esempio discusso da Johnson et al. (2022)."
  },
  {
    "objectID": "030_balance_prior_post.html#il-test-di-benchdel",
    "href": "030_balance_prior_post.html#il-test-di-benchdel",
    "title": "18¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n18.1 Il test di Benchdel",
    "text": "18.1 Il test di Benchdel\nNel fumetto di Alison Bechdel The Rule, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole (Bechdel, 1986): almeno due caratteri nel film devono essere donne; queste due donne si parlano; parlano di qualcosa altro oltre a parlare di qualche uomo.\nQuesti criteri costituiscono il test di Bechdel per la rappresentazione delle donne nei film. Johnson et al. (2022) pongono la seguente domanda ‚ÄúQuale percentuale dei film che avete visto supera il test di Bechdel?‚Äù.\nSia \\(\\pi \\in [0, 1]\\) una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche ‚Äî la femminista, l‚Äôignara e l‚Äôottimista ‚Äî hanno opionioni diverse su \\(\\pi\\). Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L‚Äôignara non ricorda bene i film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l‚Äôottimista pensa che, in generale, le donne siano ben rappresentate all‚Äôinterno dei film: secondo lei quasi tutti i film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli a priori diversi di \\(\\pi\\).\nAbbiamo visto in precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze a priori. Ponendo la gran parte della massa della probabilit√† a priori su valori \\(\\pi < 0.5\\), la distribuzione a priori \\(\\text{Beta}(5, 11)\\) riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la \\(\\text{Beta}(14,1)\\) pone la gran parte della massa della distribuzione a priori su valori \\(\\pi\\) prossimi a 1, e corrisponde quindi alle credenze a priori dell‚Äôamica ottimista. Infine, una \\(\\text{Beta}(1 ,1)\\) o \\(\\mbox{Unif}(0, 1)\\), assegna lo stesso livello di plausibilit√† a tutti i valori \\(\\pi \\in [0, 1]\\), e corrisponde all‚Äôincertezza a priori dell‚Äôignara.\nNell‚Äôesempio di Johnson et al. (2022), le tre amiche decidono di rivedere un campione di \\(n\\) film e di registrare \\(y\\), ovvero il numero di film che superano il test di Bechdel. Se \\(y\\) corrisponde al numero di ‚Äúsuccessi‚Äù in un numero fisso di \\(n\\) prove Bernoulliane i.i.d., allora la dipendenza di \\(y\\) da \\(\\pi\\) viene specificata da un modello binomiale. Quindi, per ciascuna delle tre amiche √® possibile scrivere un modello beta-binomiale\n\\[\\begin{align}\nY \\mid \\pi & \\sim \\mbox{Bin}(n, \\pi)  \\notag\\\\\n\\pi & \\sim \\mbox{Beta}(\\alpha, \\beta) \\notag\n\\end{align}\\]\nche utilizza diversi parametri \\(\\alpha\\) e \\(\\beta\\) per la distribuzione a priori e che conduce a tre diverse distribuzioni a posteriori per il parametro sconosciuto \\(\\pi\\):\n\\[\\begin{equation}\n\\pi \\mid (Y = y) \\sim \\mbox{Beta}(\\alpha + y, \\beta + n - y).\n\\end{equation}\\]\nJohnson et al. (2022) si chiedono come le credenze a priori delle tre amiche influenzano le credenze a posteriori a cui esse giungono dopo avere osservato i dati. Si chiedono inoltre in che modo la dimensione del campione moduli l‚Äôinfluenza della distribuzione a priori sulla distribuzione a posteriori.\nPer rispondere a queste domande, Johnson et al. (2022) consideriamo tre diversi scenari:\n\ngli stessi dati osservati, ma distribuzioni a priori diverse;\ndati diversi, ma la stessa distribuzione a priori;\ndati diversi e distribuzioni a priori diverse."
  },
  {
    "objectID": "030_balance_prior_post.html#stessi-dati-diverse-distribuzioni-a-priori",
    "href": "030_balance_prior_post.html#stessi-dati-diverse-distribuzioni-a-priori",
    "title": "18¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n18.2 Stessi dati, diverse distribuzioni a priori",
    "text": "18.2 Stessi dati, diverse distribuzioni a priori\nIniziamo con lo scenario che descrive il caso in cui abbiamo gli stessi dati ma diverse distribuzioni a priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati a caso.\n\nCodicedata(bechdel, package = \"bayesrules\")\nset.seed(84735)\nbechdel_20 <- bechdel %>% \n  sample_n(20)\nbechdel_20 %>% \n  head(3)\n#> # A tibble: 3 √ó 3\n#>    year title      binary\n#>   <dbl> <chr>      <chr> \n#> 1  2005 King Kong  FAIL  \n#> 2  1983 Flashdance PASS  \n#> 3  2013 The Purge  FAIL\n\n\nDi questi 20 film, solo il 45% (\\(y\\) = 9) passa il test di Bechdel.\n\nCodicebechdel_20 %>% \n  janitor::tabyl(binary) %>% \n  janitor::adorn_totals(\"row\")\n#>  binary  n percent\n#>    FAIL 11    0.55\n#>    PASS  9    0.45\n#>   Total 20    1.00\n\n\nEsaminiamo le tre distribuzioni a posteriori. Per la femminista usiamo una distribuzione a priori \\(\\text{Beta}(5, 11)\\).\n\nCodicebayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 9, n = 20\n  ) \n\n\n\n\n\n\n\n\nCodicebayesrules:::summarize_beta_binomial(\n  alpha = 5, beta = 11, y = 9, n = 20\n)\n#>       model alpha beta      mean      mode        var         sd\n#> 1     prior     5   11 0.3125000 0.2857143 0.01263787 0.11241827\n#> 2 posterior    14   22 0.3888889 0.3823529 0.00642309 0.08014418\n\n\nPer l‚Äôottimista usiamo una distribuzione a priori \\(\\text{Beta}(14, 1)\\).\n\nCodicebayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 9, n = 20\n) \n\n\n\n\n\n\n\n\nCodicebayesrules:::summarize_beta_binomial(\n  alpha = 14, beta = 1, y = 9, n = 20\n)\n#>       model alpha beta      mean      mode         var         sd\n#> 1     prior    14    1 0.9333333 1.0000000 0.003888889 0.06236096\n#> 2 posterior    23   12 0.6571429 0.6666667 0.006258503 0.07911070\n\n\nInfine, per l‚Äôignara usiamo una distribuzione a priori \\(\\text{Beta}(1, 1)\\).\n\nCodicebayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 9, n = 20\n)\n\n\n\n\n\n\n\n\nCodicebayesrules:::summarize_beta_binomial(\n  alpha = 1, beta = 1, y = 9, n = 20\n)\n#>       model alpha beta      mean mode        var        sd\n#> 1     prior     1    1 0.5000000  NaN 0.08333333 0.2886751\n#> 2 posterior    10   12 0.4545455 0.45 0.01077973 0.1038255\n\n\nPer calcolare la distribuzione a posteriori, ho usato le funzioni del pacchetto bayesrules. Ma per lo schema beta-binomiale √® facile trovare i parametri della distribuzione a posteriori. Per esempio, nel caso dell‚Äôamica femminista, la distribuzione a posteriori √® una Beta di parametri\n\\[\n\\alpha_{post} = \\alpha_{prior} + y = 5+9 = 14\n\\]\ne\n\\[\n\\beta_{post} = \\beta_{prior} + n - y = 11 + 20 - 9 = 22.\n\\]\nL‚Äôaggiornamento bayesiano indica che le tre amiche otterranno valori molto diversi per la media (o la moda) a posteriori del parametro \\(\\pi\\). Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d‚Äôaccordo su quale sia la proporzione di film che passano il test di Bechdel.\nQuesto non dovrebbe sorprenderci. L‚Äôamica ottimista aveva opinioni molto forti sul valore di \\(\\pi\\) e i pochi nuovi dati che le sono stati forniti non sono riusciti a convincerla a cambiare idea: pensa ancora che i valori \\(\\pi > 0.5\\) siano i pi√π credibili. Lo stesso si pu√≤ dire, all‚Äôestremo opposto, dell‚Äôamica femminista: anche lei continua a pensare che i valori \\(\\pi < 0.5\\) siano i pi√π credibili. Infine, l‚Äôignara non aveva nessuna opinione a priori su \\(\\pi\\) e, anche dopo avere visto 20 film, continua a pensare che il valore \\(\\pi\\) pi√π credibile sia quello intermedio, nell‚Äôintorno di 0.5.\nIn conclusione, quando i dati sono deboli (ovvero, quando il campione √® piccolo), l‚Äôaggiornamento bayesiano altera solo in piccola misura le distribuzioni a priori."
  },
  {
    "objectID": "030_balance_prior_post.html#dati-diversi-stessa-distribuzione-a-priori",
    "href": "030_balance_prior_post.html#dati-diversi-stessa-distribuzione-a-priori",
    "title": "18¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n18.3 Dati diversi, stessa distribuzione a priori",
    "text": "18.3 Dati diversi, stessa distribuzione a priori\nSupponiamo ora che l‚Äôamica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. L‚Äôottimista chiede a Maria, Anna e Sara di fare loro stesse l‚Äôesperimento descritto in precedenza. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel.\nSupponiamo che Maria, Anna e Sara condividano la stessa credenza a priori su \\(\\pi\\): ovvero, Beta(14, 1). In tali circostanze e, alla luce dei dati osservati, cosa possiamo dire delle tre distribuzioni a posteriori?\n\nCodicep1 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 6, n = 13\n  ) + \n  theme(legend.position = \"none\") \np2 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 29, n = 63\n  ) + \n  theme(legend.position = \"none\") \np3 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np1 + p2 + p3\n\n\n\nFigura 18.1: Aggiornamento bayesiano per le credenze di Maria (sinistra, 16 film), Anna (centro, 63 film) e Sara (destra, 99 film).\n\n\n\n\nIn conclusione, dalla Figura¬†18.1 notiamo due cose. Primo, all‚Äôaumentare delle informazioni disponibili (ovvero, al crescere dell‚Äôampiezza del campione), la distribuzione a posteriori si allontana sempre di pi√π dalla distribuzione a priori e si avvicina sempre di pi√π alla verosimiglianza. Secondo, all‚Äôaumentare dell‚Äôampiezza del campione la varianza della distribuzione a posteriori diminuisce sempre di pi√π ‚Äî ovvero, diminuisce l‚Äôincertezza su quelli che sono i valori \\(\\pi\\) pi√π credibili."
  },
  {
    "objectID": "030_balance_prior_post.html#dati-diversi-diverse-distribuzioni-a-priori",
    "href": "030_balance_prior_post.html#dati-diversi-diverse-distribuzioni-a-priori",
    "title": "18¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n18.4 Dati diversi, diverse distribuzioni a priori",
    "text": "18.4 Dati diversi, diverse distribuzioni a priori\nLa Figura¬†18.2 illustra le distribuzioni a posteriori che si ottengono incrociando tre diversi set di dati (\\(y\\) = 6, \\(n\\) = 13;, \\(y\\) = 29, \\(n\\) = 63; \\(y\\) = 66, \\(n\\) = 99) con tre diverse distribuzioni a priori, \\(\\mbox{Beta}(14, 1)\\), \\(\\mbox{Beta}(5, 11)\\) e \\(\\mbox{Beta}(1, 1)\\).\n\nCodicep1 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np2 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np3 <- bayesrules:::plot_beta_binomial(\n  alpha = 14, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np4 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np5 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np6 <- bayesrules:::plot_beta_binomial(\n  alpha = 5, beta = 11, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \np7 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 6, n = 13\n  ) +\n  theme(legend.position = \"none\") \np8 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 29, n = 63\n  ) +\n  theme(legend.position = \"none\") \np9 <- bayesrules:::plot_beta_binomial(\n  alpha = 1, beta = 1, y = 46, n = 99\n  ) +\n  theme(legend.position = \"none\") \n(p1 + p2 + p3) / (p4 + p5 + p6) / (p7 + p8 + p9)\n\n\n\nFigura 18.2: Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall‚Äôalto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1).\n\n\n\n\nIn conclusione, la Figura¬†18.2 ci consente di concludere quanto segue: se il campione √® grande, una distribuzione a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori; se il campione √® piccolo, invece, anche una distribuzione a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori."
  },
  {
    "objectID": "030_balance_prior_post.html#collegare-le-intuizioni-alla-teoria",
    "href": "030_balance_prior_post.html#collegare-le-intuizioni-alla-teoria",
    "title": "18¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "\n18.5 Collegare le intuizioni alla teoria",
    "text": "18.5 Collegare le intuizioni alla teoria\nIl compromesso che abbiamo osservato nell‚Äôesempio precedente, ovvero l‚Äôequilibrio che si ottiene tra la distribuzione a priori e le evidenze fornite dai dati, √® molto vicino alle nostre intuizioni. Ma √® anche il frutto di una necessit√† matematica. √à infatti possibile riscrivere l‚ÄôEquazione¬†17.1 nel modo seguente\n\\[\n\\begin{align}\n\\mathbb{E}_{\\text{post}} &[\\text{Beta}(\\alpha + y, \\beta + n - y)] = \\frac{\\alpha + y}{\\alpha + \\beta +n}\\notag\\\\\n&= \\frac{a+b}{a+b+n} \\cdot \\frac{a}{a+b} + \\frac{n}{a+b+n} \\cdot \\frac{y}{n}.\n\\end{align}\n\\tag{18.1}\\]\nL‚ÄôEquazione¬†18.1 indica che il valore atteso a posteriori √® una media pesata fra il valore atteso a priori \\(\\left( \\frac{\\alpha}{\\alpha+\\beta}\\right)\\) e la proporzione osservata di successi \\(\\left(\\frac{y}{n}\\right)\\). I pesi sono \\(\\left( \\frac{\\alpha+\\beta}{\\alpha+\\beta+n}\\right)\\) e \\(\\left( \\frac{n}{\\alpha+\\beta+n}\\right)\\). Quindi, quando \\(n\\) √® grande rispetto ad \\(\\alpha + \\beta\\), contano molto i dati osservati e contano poco le credenze a priori. Viceversa, quando \\(n\\) √® piccolo rispetto a \\(\\alpha + \\beta\\), i dati contano poco rispetto alla credenza a priori.\nQueste osservazioni ci fanno capire come scegliere i parametri \\(\\alpha\\) e \\(\\beta\\): se vogliamo assumere una totale ignoranza rispetto al fenomeno in esame, la scelta coerente √® \\(\\alpha = \\beta = 1\\) (ogni valore di \\(\\theta\\) √® ugualmente credibile); se invece abbiamo delle forti credenze a priori, allora possiamo scegliere \\(\\alpha\\) cos√¨ che sia uguale al valore atteso a priori, mentre \\(\\alpha + \\beta\\) esprime l‚Äôimportanza che diamo all‚Äôinformazione a priori: maggiore √® il valore di \\(\\alpha + \\beta\\), tanti pi√π dati serviranno per allontanare la distribuzione a posteriori dalla distribuzione a priori. Infine, se \\(n\\) √® grande, la distribuzione a posteriori avr√† una scarsa influenza sulla distribuzione a priori, a meno di scelte estreme."
  },
  {
    "objectID": "030_balance_prior_post.html#commenti-e-considerazioni-finali",
    "href": "030_balance_prior_post.html#commenti-e-considerazioni-finali",
    "title": "18¬† L‚Äôinfluenza della distribuzione a priori",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa conclusione che possiamo trarre dall‚Äôesempio discusso da Johnson et al. (2022) √® molto chiara: l‚Äôaggiornamento bayesiano pu√≤ essere paragonato ai processi di ragionamento del senso comune. Quando le nuove evidenze (i dati) sono deboli, non c‚Äô√® ragione di cambiare idea (le nostre credenze ‚Äúa posteriori‚Äù sono molto simili a ci√≤ che pensavamo prima di avere osservato i dati). Quando le nuove evidenze sono irrefutabili, invece, √® necessario modificare le nostre credenze sulla base di ci√≤ che ci dicono i dati, quali che siano le nostre credenze pregresse ‚Äî non farlo significherebbe vivere in un mondo di fantasia e avere scarse possibilit√† di sopravvivere nel mondo empirico. L‚Äôaggiornamento bayesiano, dunque, non fa altro che esprimere in maniera quantitativa e precisa ci√≤ che ci dicono le nostre intuizioni.\nAlla luce di quanto detto sopra, √® sorprendente che l‚Äôapproccio frequentista neghi questa logica. I test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato su un piccolo campione (ovvero, quando i dati sono molto deboli), suggerisce che dovremmo farci un‚Äôopinione di un certo tipo sul fenomeno in esame, l‚Äôindicazione √® quella di prendere seriamente in considerazione il risultato del test (ovvero di modificare le nostre credenze) quali che siano le evidenze precedenti ‚Äì le quali, in generale, potrebbero mostrare che il risultato del test non ha alcun senso. Un tale modo di pensare viene preso sul serio da coloro che, nella comunit√† scientifica, seguono l‚Äôapproccio frequentista. Dato che in questo Capitolo abbiamo parlato di fumetti, concluderei dicendo che il significato della presente discussione √® catturata nella maniera pi√π chiara possibile in questa famosa striscia.\n\n\n\n\n\n\n\nBechdel, A. (1986). Dykes to watch out for. Firebrand Books.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press."
  },
  {
    "objectID": "036_posterior_sim.html",
    "href": "036_posterior_sim.html",
    "title": "19¬† Approssimazione della distribuzione a posteriori",
    "section": "",
    "text": "In generale, in un problema bayesiano i dati \\(y\\) provengono da una densit√† \\(p(y \\mid \\theta)\\) e al parametro \\(\\theta\\) viene assegnata una densit√† a priori \\(p(\\theta)\\). Dopo avere osservato i dati \\(Y = y\\), la funzione di verosimiglianza √® uguale a \\(\\mathcal{L}(\\theta) = p(y \\mid \\theta)\\) e la densit√† a posteriori diventa\n\\[\np(\\theta \\mid y) = \\frac{p(y \\mid \\theta) p(\\theta)}{\\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}.\n\\]\nSe vogliamo trovare la distribuzione a posteriori con metodi analitici √® necessario ricorrere all‚Äôimpiego di distribuzioni a priori coniugate, come abbiamo fatto nello schema beta-binomiale. Per quanto ‚Äúsemplice‚Äù in termini formali, la scelta di distribuzioni a priori coniugate limita di molto le possibili scelte del ricercatore. Inoltre, non √® sempre sensato, dal punto di vista teorico, utilizzare tali distribuzioni per la stima dei parametri di interesse. Il mancato ricorso all‚Äôimpiego delle distribuzioni a priori coniugate richiede necessariamente il computo dell‚Äôespressione a denominatore della formula di Bayes che solo in rare occasioni pu√≤ essere ottenuta per via analitica. In altre parole, √® possibile ottenere analiticamenre la distribuzione a posteriori solo per alcune specifiche combinazioni di distribuzioni a priori e verosimiglianza, il che limita considerevolmente la flessibilit√† della modellizzazione. Inoltre, i sommari della distribuzione a posteriori sono espressi come rapporto di integrali. Ad esempio, la media a posteriori di \\(\\theta\\) √® data da\n\\[\n\\mathbb{E}(\\theta \\mid y) = \\frac{\\int \\theta p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}{\\int p(y \\mid \\theta) p(\\theta) \\,\\operatorname {d}\\! \\theta}.\n\\]\nIl calcolo del valore atteso a posteriori richiede dunque il computo di due integrali, quello a denominatore e quello a numeratore dell‚Äôespressione, ciascuno dei quali non esprimibile in forma chiusa. Per questa ragione, la strada principale che viene seguita nella modellistica bayesiana √® quella che porta a determinare la distribuzione a posteriori non per via analitica, ma bens√¨ mediante metodi numerici. La simulazione fornisce dunque la strategia generale del calcolo bayesiano. A questo fine vengono principalmente usati i metodi di campionamento Monte Carlo basati su Catena di Markov (MCMC). Tali metodi costituiscono una potente e praticabile alternativa per la costruzione della distribuzione a posteriori per modelli complessi e consentono di decidere quali distribuzioni a priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza dovere preoccuparsi di altri vincoli.\nDato che √® basata su metodi computazionalmente intensivi, la stima numerica della funzione a posteriori pu√≤ essere svolta soltanto mediante software. In anni recenti i metodi Bayesiani di analisi dei dati sono diventati sempre pi√π popolari proprio perch√© la potenza di calcolo necessaria per svolgere tali calcoli √® ora alla portata di tutti. Questo non era vero solo pochi decenni fa.\nIn questo Capitolo verranno presentati due metodi di simulazione iterativa che consentono di generare dalle distribuzioni a posteriori campioni dei parametri del modello:"
  },
  {
    "objectID": "036_posterior_sim.html#metodo-basato-su-griglia",
    "href": "036_posterior_sim.html#metodo-basato-su-griglia",
    "title": "19¬† Approssimazione della distribuzione a posteriori",
    "section": "\n19.1 Metodo basato su griglia",
    "text": "19.1 Metodo basato su griglia\nIl metodo basato su griglia (grid-based) √® un metodo numerico esatto basato su una griglia di punti uniformemente spaziati. Anche se la maggior parte dei parametri √® continua (ovvero, in linea di principio ciascun parametro pu√≤ assumere un numero infinito di valori), possiamo ottenere un‚Äôeccellente approssimazione della distribuzione a posteriori considerando solo una griglia finita di valori dei parametri. Con un tale metodo, dunque, la densit√† di probabilit√† a posteriori pu√≤ essere approssimata tramite le densit√† di probabilitaÃÄ calcolate in ciascuna cella della griglia.\nIl metodo basato su griglia si sviluppa in quattro fasi:\n\nfissare una griglia discreta di possibili valori \\(\\theta\\);\nvalutare la distribuzione a priori \\(p(\\theta)\\) e la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) in corrispondenza di ciascun valore \\(\\theta\\) della griglia;\nottenere un‚Äôapprossimazione discreta della densit√† a posteriori:\n\nper ciascun valore \\(\\theta\\) della griglia, calcolare il prodotto \\(p(\\theta) p(y \\mid \\theta)\\);\nnormalizzare i prodotti cos√¨ ottenuti in modo tale che la loro somma sia 1;\n\n\nselezionare \\(n\\) valori casuali della griglia in modo tale da ottenere un campione casuale delle densit√† a posteriori normalizzate.\n\n√à possibile migliorare l‚Äôapprossimazione aumentando il numero di punti della griglia. Infatti utilizzando un numero infinito di punti si otterrebbe la descrizione esatta della distribuzione a posteriori, dovendo per√≤ pagare il costo dell‚Äôutilizzo di infinite risorse di calcolo. Il limite maggiore dell‚Äôapproccio basato su griglia √® proprio questo: al crescere della dimensionalit√† \\(n\\) dello spazio dei parametri, i punti della griglia necessari per avere una buona stima crescono esponenzialmente con \\(n\\), rendendo questo metodo inattuabile per problemi complessi.\n\n19.1.1 Modello Beta-Binomiale\nPer fare un esempio, utilizziamo il metodo basato su griglia nel caso dello schema beta-binomiale di cui conosciamo la soluzione esatta. Esaminiamo nuovamente i dati di Zetsche et al. (2019): 23 ‚Äúsuccessi‚Äù in 30 prove Bernoulliane indipendenti.1\nImponendo alla distribuzione a priori su \\(\\theta\\) (probabilit√† di successo in una singola prova, laddove per ‚Äúsuccesso‚Äù si intende una aspettativa distorta negativamente dell‚Äôumore futuro) una \\(\\mbox{Beta}(2, 10)\\) per descrivere la nostra incertezza sul parametro prima di avere osservato i dati, il modello diventa:\n\\[\n\\begin{align}\nY \\mid \\theta & \\sim \\mbox{Bin}(n = 30, \\theta), \\notag\\\\\n\\theta & \\sim \\mbox{Beta}(2, 10).\\notag\n\\end{align}\n\\]\nIn queste circostanze, l‚Äôaggiornamento bayesiano produce una distribuzione a posteriori Beta di parametri 25 (\\(y + \\alpha\\) = 23 + 2) e 17 (\\(n - y + \\beta\\) = 30 - 23 + 10):\n\\[\n\\theta \\mid (y = 23) \\sim \\mbox{Beta}(25, 17).\\notag\n\\]\nPer approssimare una tale distribuzione a posteriori, fissiamo una griglia di \\(n = 11\\) valori equispaziati: \\(\\theta \\in \\{0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\\}\\).\n\nCodicegrid_data <- tibble(\n  theta_grid = seq(from = 0, to = 1, length.out = 11)\n)\ngrid_data\n#> # A tibble: 11 √ó 1\n#>   theta_grid\n#>        <dbl>\n#> 1        0  \n#> 2        0.1\n#> 3        0.2\n#> 4        0.3\n#> 5        0.4\n#> 6        0.5\n#> 7        0.6\n#> 8        0.7\n#> # ‚Ä¶ with 3 more rows\n\n\nIn corrispondenza di ciascun valore della griglia, valutiamo la distribuzione a priori \\(\\mbox{Beta}(2, 10)\\) e la verosimiglianza \\(\\mbox{Bin}(y = 23, n = 30)\\).\n\nCodicegrid_data <- grid_data %>%\n  mutate(\n    prior = dbeta(theta_grid, 2, 10),\n    likelihood = dbinom(23, 30, theta_grid)\n  )\n\n\nIn ciascuna cella della griglia calcoliamo il prodotto della verosimiglianza e della distribuzione a priori. Troviamo cos√¨ un‚Äôapprossimazione discreta e non normalizzata della distribuzione a posteriori (unnormalized). Normalizziamo questa approssimazione dividendo ciascun valore unnormalized per la somma di tutti i valori del vettore unnormalized.\n\nCodicegrid_data <- grid_data %>%\n  mutate(\n    unnormalized = likelihood * prior,\n    posterior = unnormalized / sum(unnormalized)\n  )\n\n\nVerifichiamo.\n\nCodicegrid_data %>%\n  summarize(\n    sum(unnormalized),\n    sum(posterior)\n  )\n#> # A tibble: 1 √ó 2\n#>   `sum(unnormalized)` `sum(posterior)`\n#>                 <dbl>            <dbl>\n#> 1            0.000869                1\n\n\nOtteniamo dunque la distribuzione a posteriori discretizzata \\(p(\\theta \\mid y)\\).\n\nCodiceround(grid_data, 2) %>% as.data.frame()\n#>    theta_grid prior likelihood unnormalized posterior\n#> 1         0.0  0.00       0.00            0      0.00\n#> 2         0.1  4.26       0.00            0      0.00\n#> 3         0.2  2.95       0.00            0      0.00\n#> 4         0.3  1.33       0.00            0      0.00\n#> 5         0.4  0.44       0.00            0      0.02\n#> 6         0.5  0.11       0.00            0      0.23\n#> 7         0.6  0.02       0.03            0      0.52\n#> 8         0.7  0.00       0.12            0      0.21\n#> 9         0.8  0.00       0.15            0      0.01\n#> 10        0.9  0.00       0.02            0      0.00\n#> 11        1.0  0.00       0.00            0      0.00\n\n\nLa Figura¬†19.1 mostra un grafico della distribuzione a posteriori discretizzata cos√¨ ottenuta.\n\nCodicegrid_data %>% \n  ggplot(\n    aes(x = theta_grid, y = posterior)\n  ) +\n  geom_point() +\n  geom_segment(\n    aes(\n      x = theta_grid, \n      xend = theta_grid, \n      y = 0, \n      yend = posterior)\n  )\n\n\n\nFigura 19.1: Distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). √à stata utilizzata una griglia di solo \\(n\\) = 11 punti.\n\n\n\n\nL‚Äôultimo passo della simulazione √® il campionamento dalla distribuzione a posteriori discretizzata.\n\nCodiceset.seed(84735)\npost_sample <- sample_n(\n  grid_data,\n  size = 1e5,\n  weight = posterior,\n  replace = TRUE\n)\n\n\nLa Figura¬†19.2 mostra che, con una griglia cos√¨ sparsa abbiamo ottenuto una versione approssimata della vera distribuzione a posteriori (all‚Äôistogramma √® stata sovrapposta l‚Äôesatta distribuzione a posteriori \\(\\mbox{Beta}(25, 17)\\)).\n\nCodiceggplot(post_sample, aes(x = theta_grid)) +\n  geom_histogram(aes(y = ..density..), color = \"white\") +\n  stat_function(fun = dbeta, args = list(25, 17)) +\n  lims(x = c(0, 1))\n\n\n\nFigura 19.2: Campionamento dalla distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). √à stata utilizzata una griglia di solo \\(n\\) = 11 punti.\n\n\n\n\nPossiamo ottenere un risultato migliore con una griglia pi√π fine, come indicato nella Figura¬†19.3.\n\nCodicegrid_data <- tibble(\n  theta_grid = seq(from = 0, to = 1, length.out = 100)\n)\ngrid_data <- grid_data %>%\n  mutate(\n    prior = dbeta(theta_grid, 2, 10),\n    likelihood = dbinom(23, 30, theta_grid)\n  )\ngrid_data <- grid_data %>%\n  mutate(\n    unnormalized = likelihood * prior,\n    posterior = unnormalized / sum(unnormalized)\n  )\ngrid_data %>%\n  ggplot(\n    aes(x = theta_grid, y = posterior)\n  ) +\n  geom_point() +\n  geom_segment(\n    aes(\n      x = theta_grid,\n      xend = theta_grid,\n      y = 0,\n      yend = posterior\n    )\n  )\n\n\n\nFigura 19.3: Distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). √à stata utilizzata una griglia di \\(n\\) = 100 punti.\n\n\n\n\nCampioniamo ora 10000 punti.\n\nCodiceset.seed(84735)\npost_sample <- sample_n(\n  grid_data,\n  size = 1e4,\n  weight = posterior,\n  replace = TRUE\n)\n\n\nCon il campionamento dalla distribuzione a posteriori discretizzata costruita mediante una griglia pi√π densa (\\(n = 100\\)) otteniamo un risultato soddisfacente (Figura¬†19.4): ora la distribuzione dei valori prodotti dalla simulazione approssima molto bene la corretta distribuzione a posteriori \\(p(\\theta \\mid y) = \\mbox{Beta}(25, 17)\\).\n\nCodicepost_sample %>%\n  ggplot(aes(x = theta_grid)) +\n  geom_histogram(\n    aes(y = ..density..),\n    color = \"white\",\n    bins=50\n  ) +\n  stat_function(fun = dbeta, args = list(25, 17)) +\n  lims(x = c(0, 1))\n\n\n\nFigura 19.4: Campionamento dalla distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per \\(y\\) = 23 successi in 30 prove Bernoulliane, con distribuzione a priori \\(\\mbox{Beta}(2, 10)\\). √à stata utilizzata una griglia di \\(n\\) = 100 punti. All‚Äôistogramma √® stata sovrapposta la corretta distribuzione a posteriori, ovvero la densit√† \\(\\mbox{Beta}(25, 17)\\).\n\n\n\n\nIn conclusione, il metodo basato su griglia √® molto intuitivo e non richiede particolari competenze di programmazione per essere implementato. Inoltre, fornisce un risultato che, per tutti gli scopi pratici, pu√≤ essere considerato come un campione casuale estratto da \\(p(\\theta \\mid y)\\). Tuttavia, anche se tale metodo fornisce risultati accuratissimi, esso ha un uso limitato. A causa della maledizione della dimensionalit√†2, tale metodo pu√≤ solo essere usato nel caso di semplici modelli statistici, con non pi√π di due parametri. Nella pratica concreta tale metodo viene dunque sostituito da altre tecniche pi√π efficienti in quanto, anche nei pi√π comuni modelli utilizzati in psicologia, vengono solitamente stimati centinaia se non migliaia di parametri."
  },
  {
    "objectID": "036_posterior_sim.html#chapter-simulazioneMC",
    "href": "036_posterior_sim.html#chapter-simulazioneMC",
    "title": "19¬† Approssimazione della distribuzione a posteriori",
    "section": "\n19.2 Metodo Monte Carlo",
    "text": "19.2 Metodo Monte Carlo\nI metodi pi√π ampiamente adottati nell‚Äôanalisi bayesiana per la costruzione della distribuzione a posteriori per modelli complessi sono i metodi di campionamento MCMC. Tali metodi consentono al ricercatore di decidere quali distribuzioni a priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza doversi preoccupare di altri vincoli. Dato che √® basata su metodi computazionalmente intensivi, la stima numerica MCMC della funzione a posteriori pu√≤ essere svolta soltanto mediante software. In anni recenti i metodi Bayesiani di analisi dei dati sono diventati sempre pi√π popolari proprio perch√© la potenza di calcolo necessaria per svolgere tali calcoli √® ora alla portata di tutti. Questo non era vero solo pochi decenni fa.\n\n19.2.1 Integrazione di Monte Carlo\nIl termine Monte Carlo si riferisce al fatto che la computazione fa ricorso ad un ripetuto campionamento casuale attraverso la generazione di sequenze di numeri casuali. Una delle sue applicazioni pi√π potenti √® il calcolo degli integrali mediante simulazione numerica. Un‚Äôillustrazione √® fornita dal seguente esempio. Supponiamo di essere in grado di estrarre campioni casuali dalla distribuzione continua \\(p(\\theta \\mid y)\\) di media \\(\\mu\\). Se possiamo ottenere una sequenza di realizzazioni indipendenti\n\\[\n\\theta^{(1)}, \\theta^{(2)},\\dots, \\theta^{(T)} \\overset{\\text{iid}}{\\sim} p(\\theta \\mid y)\n\\]\nallora diventa possibile calcolare\n\\[\n\\mathbb{E}(\\theta \\mid y) = \\int \\theta p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta \\approx \\frac{1}{T} \\sum_{i=1}^T \\theta^{(t)}.\n\\]\nIn altre parole, l‚Äôaspettazione teorica di \\(\\theta\\) pu√≤ essere approssimata dalla media campionaria di un insieme di realizzazioni indipendenti ricavate da \\(p(\\theta \\mid y)\\). Per la Legge Forte dei Grandi Numeri, l‚Äôapprossimazione diventa arbitrariamente esatta per \\(T \\rightarrow \\infty\\).3\nQuello che √® stato detto sopra non √® altro che un modo sofisticato per dire che, se vogliamo calcolare un‚Äôapprossimazione del valore atteso di una variabile casuale, non dobbiamo fare altro che la media aritmetica di un grande numero di realizzazioni indipendenti della variabile casuale. Come √® facile intuire, l‚Äôapprossimazione migliora al crescere del numero dei dati che abbiamo a disposizione.\nUn‚Äôaltra importante funzione di \\(\\theta\\) √® la funzione indicatore, \\(I(l < \\theta < u)\\), che assume valore 1 se \\(\\theta\\) giace nell‚Äôintervallo \\((l, u)\\) e 0 altrimenti. Il valore di aspettazione di \\(I(l < \\theta < u)\\) rispetto a \\(p(\\theta)\\) d√† la probabilit√† che \\(\\theta\\) rientri nell‚Äôintervallo specificato, \\(Pr(l < \\theta < u)\\). Anche questa probabilit√† pu√≤ essere approssimato usando l‚Äôintegrazione Monte Carlo, ovvero prendendo la media campionaria del valore della funzione indicatore per ogni realizzazione \\(\\theta^{(t)}\\). √à semplice vedere come\n\\[\nPr(l < \\theta < u) \\approx \\frac{\\text{numero di realizzazioni } \\theta^{(t)} \\in (l, u)}{T}.\n\\]\nAbbiamo fornito qui alcuni accenni relativi all‚Äôintegrazione di Monte Carlo perch√©, nell‚Äôanalisi bayesiana, il metodo Monte Carlo viene usato per ottenere un‚Äôapprossimazione della distribuzione a posteriori, quando tale distribuzione non pu√≤ essere calcolata con metodi analitici. In altre parole, il metodo Monte Carlo consente di ottenere un gran numero di valori \\(\\theta\\) che, nelle circostanze ideali, avr√† una distribuzione identica alla distribuzione a posteriori \\(p(\\theta \\mid y)\\).\n\n19.2.2 Campionamento dalla distribuzione a posteriori\nPoniamoci ora il problema di approssimare la distribuzione a posteriori con una simulazione. Consideriamo nuovamente i dati di Zetsche et al. (2019) (ovvero, 23 ‚Äúsuccessi‚Äù in 30 prove Bernoulliane) e, come in precedenza, assumiamo per \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\).\n\nIn tali circostanze, la distribuzione a posteriori pu√≤ essere ottenuta analiticamente tramite lo schema beta-binomiale ed √® una \\(\\mbox{Beta}(25, 17)\\). Se vogliamo conoscere il valore della media a posteriori di \\(\\theta\\), il risultato esatto √®\n\\[\n\\bar{\\theta}_{post} = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25 + 17} \\approx 0.5952.\n\\]\n√à anche possibile ottenere il valore della media a posteriori con una simulazione numerica. Conoscendo la forma della la distribuzione a posteriori, possiamo estrarre un campione di osservazioni da una \\(\\mbox{Beta}(25, 17)\\) per poi calcolare la media delle osservazioni ottenute. Con poche osservazioni (diciamo 10) otteniamo un risultato molto approssimato.\n\nCodiceset.seed(84735)\nprint(mean(rbeta(1e2, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.584251\n\n\nL‚Äôapprossimazione migliora all‚Äôaumentare del numero di osservazioni.\n\nCodiceprint(mean(rbeta(1e4, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.595492\nprint(mean(rbeta(1e6, shape1 = 25, shape2 = 17)), 6)\n#> [1] 0.595192\n\n\nLo stesso si pu√≤ dire delle altre statistiche descrittive: moda, varianza, eccetera.\nQuesta simulazione, detta di Monte Carlo, produce il risultato desiderato perch√©\n\nsappiamo che la distribuzione a posteriori √® una \\(\\mbox{Beta}(25, 17)\\),\n√® possibile usare le funzioni \\(\\textsf{R}\\) per estrarre campioni casuali da una tale distribuzione.\n\nTuttavia, capita raramente di usare una distribuzione a priori coniugata alla verosimiglianza. Quindi, in generale, le due condizioni descritte sopra non si applicano. Ad esempio, nel caso di una verosimiglianza binomiale e di una distribuzione a priori gaussiana, la distribuzione a posteriori di \\(\\theta\\) √®\n\\[\np(\\theta \\mid y) = \\frac{\\mathrm{e}^{-(\\theta - 1 / 2)^2} \\theta^y (1 - \\theta)^{n - y}} {\\int_0^1 \\mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}.\n\\]\nUna tale distribuzione non √® implementata in \\(\\textsf{R}\\); dunque non possiamo usare \\(\\textsf{R}\\) per ottenere campioni casuali da una tale distribuzione.\nIn tali circostanze, per√≤, √® possibile ottenere ottenere un campione causale dalla distribuzione a posteriori procedendo in un altro modo. Questo risultato si ottiene utilizzando i metodi Monte Carlo basati su Catena di Markov (MCMC). I metodi MCMC, di cui l‚Äôalgoritmo di Metropolis √® un caso particolare e ne rappresenta il primo esempio, sono una classe di algoritmi che consentono di ottenere campioni casuali da una distribuzione a posteriori senza dovere conoscere la rappresentazione analitica di una tale distribuzione.4 Le tecniche MCMC sono il metodo computazionale maggiormente usato per risolvere i problemi dell‚Äôinferenza bayesiana.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n19.2.3 L‚Äôalgoritmo di Metropolis\n\nL‚Äôalgoritmo di Metropolis et al. (1953)5 produce una sequenza di valori (chiamata ‚Äúcatena di Markov‚Äù) nella quale ciascun valore successivo della catena viene trovato utilizzando solamente le informazioni fornite dal valore precedente della catena. Ad ogni passo della catena, sulla base delle informazioni fornite dal valore corrente, selezioniamo un valore ‚Äúcandidato‚Äù. In base ad una certa regola, decidiamo poi se accettare il valore candidato, e muovere la catena al nuovo valore, oppure se rifiutarlo, ripetendo, nel passo successivo della catena, il valore corrente. Ci fermiamo dopo una serie predefinita di passi.\nNell‚Äôalgoritmo di Metropolis possiamo distinguere le seguenti fasi.\n\nSi inizia con un punto arbitrario \\(\\theta^{(1)}\\); quindi il primo valore \\(\\theta^{(1)}\\) della catena di Markov pu√≤ corrispondere semplicemente ad un valore a caso tra i valori possibili del parametro.\n\n\nPer ogni passo successivo della catena, \\(m + 1\\), si estrae un valore candidato \\(\\theta'\\) da una distribuzione proposta: \\(\\theta' \\sim \\Pi(\\theta)\\). La distribuzione proposta pu√≤ essere qualunque distribuzione, anche se, idealmente, √® meglio che sia simile alla distribuzione a posteriori. In pratica, per√≤, la distribuzione a posteriori √® sconosciuta e quindi il valore \\(\\theta'\\) viene estratto a caso da una qualche distribuzione simmetrica centrata sul valore corrente \\(\\theta^{(m)}\\) del parametro. Nell‚Äôesempio presente useremo la gaussiana quale distribuzione proposta. La distribuzione proposta gaussiana sar√† centrata sul valore corrente della catena e avr√† una deviazione standard appropriata: \\(\\theta' \\sim \\mathcal{N}(\\theta^{(m)}, \\sigma)\\). In pratica, questo significa che, se \\(\\sigma\\) √® piccola, il valore candidato \\(\\theta'\\) sar√† simile al valore corrente \\(\\theta^{(m)}\\).\nSi calcola il rapporto \\(r\\) tra la densit√† della distribuzione a posteriori non normalizzata calcolata nel punto \\(\\theta'\\) e nel punto \\(\\theta^{(m)}\\). Si noti che, essendo un rapporto, l‚ÄôEquazione¬†19.1 cancella la costante di normalizzazione. Al numeratore dell‚ÄôEquazione¬†19.1 abbiamo solo il prodotto tra la verosimiglianza \\(p(y \\mid \\theta')\\) e la densit√† a priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta'\\); il denominatore contiene invece il prodotto tra la verosimiglianza \\(p(y \\mid \\theta^{(m)})\\) e la densit√† a priori di \\(\\theta\\), entrambe calcolate nel punto \\(\\theta^{(m)}\\).\n\n\\[\nr = \\frac{p(y \\mid \\theta') p(\\theta')}{p(y \\mid \\theta^{(m)}) p(\\theta^{(m)})}.\n\\tag{19.1}\\]\n\nSi decide se accettare il candidato \\(\\theta'\\) oppure se rigettarlo e estrarre un nuovo valore dalla distribuzione proposta. Possiamo pensare al rapporto \\(r\\) come alla risposta alla seguente domanda: alla luce dei dati, quale stima di \\(\\theta\\) √® pi√π credibile, il valore candidato o il valore corrente? Se \\(r\\) √® maggiore di 1, ci√≤ significa che il candidato √® pi√π credibile del valore corrente; dunque se \\(r\\) √® maggiore di 1 il candidato viene sempre accettato. Altrimenti, si decide di accettare il candidato con una probabilit√† minore di 1, ovvero non sempre, ma soltanto con una probabilit√† uguale ad \\(r\\). Se \\(r\\) √® uguale a 0.10, ad esempio, questo significa che la credibilit√† a posteriori del valore candidato √® 10 volte pi√π piccola della credibilit√† a posteriori del valore corrente. Dunque, il valore candidato verr√† accettato solo nel 10% dei casi. Come conseguenza di questa strategia di scelta, l‚Äôalgoritmo di Metropolis ottiene un campione casuale dalla distribuzione a posteriori, dato che la probabilit√† di accettare il valore candidato sar√† proporzionale alla densit√† del candidato nella distribuzione a posteriori. Dal punto di vista algoritmico, la procedura descritta sopra viene implementata confrontando il rapporto \\(r\\) con un valore estratto a caso da una distribuzione uniforme \\(\\mbox{Unif}(0, 1)\\). Se \\(r > u \\sim \\mbox{Unif}(0, 1)\\), allora il candidato \\(\\theta'\\) viene accettato e la catena si muove in quella nuova posizione, ovvero \\(\\theta^{(m+1)} = \\theta'\\). Altrimenti \\(\\theta^{(m+1)} = \\theta^{(m)}\\) e si estrae un nuovo candidato dalla distribuzione proposta.\nIl passaggio finale dell‚Äôalgoritmo calcola l‚Äôaccettanza in una specifica esecuzione dell‚Äôalgoritmo, ovvero la proporzione di candidati \\(\\theta'\\) che sono stati accettati quali valori successivi della catena.\n\nL‚Äôalgoritmo di Metropolis prende come input il numero \\(T\\) di passi da simulare, la deviazione standard \\(\\sigma\\) della distribuzione proposta e la densit√† a priori, e ritorna come output la sequenza \\(\\theta^{(1)}, \\theta^{(2)}, \\dots, \\theta^{(T)}\\). La chiave del successo dell‚Äôalgoritmo di Metropolis √® il numero di passi fino a che la catena approssima la stazionariet√†. Tipicamente i primi da 1000 a 5000 elementi sono scartati. Dopo un certo periodo \\(k\\) (detto di burn-in), la catena di Markov converge ad una variabile casuale che √® distribuita secondo la distribuzione a posteriori (stazionariet√†). In altre parole, i campioni del vettore \\(\\left(\\theta^{(k+1)}, \\theta^{(k+2)}, \\dots, \\theta^{(T)}\\right)\\) diventano campioni di \\(p(\\theta \\mid y)\\).\n\n19.2.4 Un‚Äôapplicazione empirica\nUsiamo ora l‚Äôalgoritmo di Metropolis per trovare la distribuzione a posteriori di \\(\\theta\\) per i dati di Zetsche et al. (2019) (23 successi in 30 prove Bernoulliane), imponendo su \\(\\theta\\) una \\(\\mbox{Beta}(2, 10)\\).\n\n\n\n19.2.4.1 Funzioni\nL‚Äôalgoritmo di Metropolis richiede l‚Äôuso delle seguenti funzioni.\n\n19.2.4.2 Verosimiglianza\nUsiamo una funzione di verosimiglianza binomiale.\n\nCodicelikelihood <- function(param, x = 23, N = 30) {\n  dbinom(x, N, param)\n}\n\n\n\n19.2.4.3 Distribuzione a priori\nLa distribuzione a priori √® una \\(\\mbox{Beta}(2, 10)\\).\n\nCodiceprior <- function(param, alpha = 2, beta = 10) {\n  dbeta(param, alpha, beta) \n}\n\n\n\n19.2.4.4 Distribuzione a posteriori\nLa distribuzione a posteriori √® data dal prodotto della distribuzione a priori e della verosimiglianza.\n\nCodiceposterior <- function(param) {\n  likelihood(param) * prior(param)\n}\n\n\n\n19.2.4.5 Distribuzione proposta\nPer implementare l‚Äôalgoritmo di Metropolis utilizzeremo una distribuzione proposta gaussiana. Il valore candidato sar√† dunque un valore selezionato a caso da una gaussiana di parametri \\(\\mu\\) uguale al valore corrente nella catena e \\(\\sigma = 0.9\\). In questo esempio, la deviazione standard \\(\\sigma\\) √® stata scelta empiricamente in modo tale da ottenere una accettanza adeguata. L‚Äôaccettanza ottimale √® pari a circa 0.20/0.30 ‚Äî se l‚Äôaccettanza √® troppo grande, l‚Äôalgoritmo esplora uno spazio troppo ristretto della distribuzione a posteriori.6\n\nCodiceproposal_distribution <- function(param) {\n  while(1) {\n    res = rnorm(1, mean = param, sd = 0.9)\n    if (res > 0 & res < 1)\n      break\n  }\n  res\n}\n\n\nHo inserito un controllo che impone al valore candidato di essere incluso nell‚Äôintervallo [0, 1], com‚Äô√® necessario per il valore di una proporzione.7\n\n19.2.4.6 Algoritmo\nL‚Äôalgoritmo di Metropolis viene implementato nella funzione seguente.\n\nCodicemetropolis <- function(startvalue, iterations) {\n  # Creo un contenitore vuoto dove salvare i risultati.\n  chain <- vector(length = iterations + 1)\n  # Inizializzo la catena con startvalue.\n  chain[1] <- startvalue\n  # Ripeto le istruzioni seguenti un numero di volte pari a iterations.\n  for (i in 1:iterations) {\n    # Ottengo un valore a caso molto simile al valore corrente della catena.\n    proposal <- proposal_distribution(chain[i])\n    # Calcolo il rapporto tra la densit√† a posteriori del valore proposto e\n    # la densit√† a posteriori del valore corrente.\n    prob_move <- posterior(proposal) / posterior(chain[i])\n    # Se la densit√† a posteriori del valore proposto √® maggiore di quella del\n    # valore corrente, allora accetto la proposta: la catena si muove dal valore\n    # corrente al valore proposto (che diventa il valore corrente della \n    # seguente iterazione). Altrimenti il valore proposto viene accettato solo \n    # in una proporzione di casi uguale al rapporto tra densit√† a posteriori\n    # del valore proposto e la densit√† a posteriori del valore corrente.\n    if (prob_move > 1) {\n      chain[i + 1] <- proposal\n    } else {\n      r <- runif(1, 0, 1)\n      chain[i + 1] <- ifelse(r < prob_move, proposal, chain[i])\n    }\n  }\n  # Ritorno i valori della catena.\n  chain\n}\n\n\n\n19.2.4.7 Implementazione\nMediante la funzione metropolis(), genero una sequenza (catena) di valori \\(\\theta\\).\n\nCodiceset.seed(84735)\nstartvalue <- runif(1, 0, 1)\nniter <- 1e5\nchain <- metropolis(startvalue, niter)\n\n\nIn questo modo, abbiamo ottenuto una catena di Markov costituita da 100,001 valori.\n\n19.2.4.8 Accettanza\nEscludo i primi 50,000 valori considerati come burn-in. Considero i restanti 50,001 valori come un campione casuale estratto dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). Calcolo l‚Äôaccettanza.\n\nCodiceburnin <- niter / 2\nacceptance <- 1 - mean(duplicated(chain[-(1:burnin)]))\nacceptance\n#> [1] 0.2534149\n\n\nIl valore trovato conferma la bont√† della deviazione standard (\\(\\sigma\\) = 0.9) scelta per la distribuzione proposta.\n\n19.2.4.9 Descrizione della distribuzione a posteriori\nMediante i valori della catena cos√¨ ottenuta √® facile trovare una stima a posteriori del parametro \\(\\theta\\). Per esempio, posso trovare la stima della media a posteriori.\n\nCodicemean(chain[-(1:burnin)])\n#> [1] 0.5940539\n\n\nOppure posso calcolare la deviazione standard dell‚Äôapprossimazione numerica della distribuzione a posteriori.\n\nCodicesd(chain[-(1:burnin)])\n#> [1] 0.07487919\n\n\nLa Figura¬†19.5 mostra l‚Äôapprossimazione di \\(p(\\theta \\mid y)\\) ottenuta con l‚Äôalgoritmo di Metropolis, insieme ad un trace plot dei valori della catena di Markov.\n\nCodicep1 <- tibble(\n  x = chain[-(1:burnin)]\n) %>%\n  ggplot(aes(x)) +\n  geom_histogram(fill = \"darkgray\") +\n  labs(\n    x = expression(theta),\n    y = \"Frequenza\",\n    title = \"Distribuzione a posteriori\"\n  ) +\n  geom_vline(\n    xintercept = mean(chain[-(1:burnin)])\n  ) +\n  xlim(c(0.3, 0.85)) +\n  coord_flip()\n\np2 <- tibble(\n  x = 1:length(chain[-(1:burnin)]),\n  y = chain[-(1:burnin)]\n) %>%\n  ggplot(aes(x, y)) +\n  geom_line(color = \"darkgray\") +\n  labs(\n    x = \"Numero di passi\",\n    y = expression(theta),\n    title = \"Valori della catena\"\n  ) +\n  geom_hline(\n    yintercept = mean(chain[-(1:burnin)]),\n    colour = \"black\"\n  ) +\n  ylim(c(0.3, 0.85)) \n\np1 + p2\n\n\n\nFigura 19.5: Sinistra. Stima della distribuzione a posteriori della probabilit√† di una aspettativa futura distorta negativamente per i dati di Zetsche et al.¬†(2019). Destra. Trace plot dei valori della catena di Markov escludendo il periodo di burn-in.\n\n\n\n\nNella Figura¬†19.6, l‚Äôistogramma descrive i valori \\(\\theta\\) prodotti dall‚Äôalgoritmo di Metropolis mentre la linea continua descrive la distribuzione a posteriori ottenuta per via analitica, ovvero una \\(\\mbox{Beta}(25, 17)\\). La figura indica che la catena converge alla corretta distribuzione a posteriori.\n\nCodicedf <- tibble(x = chain[-(1:burnin)])\n\ndf %>%\n  ggplot(aes(x = x)) +\n  geom_histogram(\n    mapping = aes(x = x, y = ..density..), \n    fill = \"gray\", \n    colour = \"black\", \n    binwidth = 0.01\n  ) +\n  stat_function(fun = dbeta, args = list(shape1 = 25, shape2 = 17)) +\n  labs(\n    x = expression(theta),\n    y = \"Densit√†\"\n  )\n\n\n\nFigura 19.6: L‚Äôistogramma riporta i risultati della simulazione mentre la linea continua descrive la distribuzione a posteriori ottenuta per via analitica.\n\n\n\n\n\n19.2.4.10 Pacchetto ProbBayes\n\nI calcoli precedenti possono essere svolti anche mediante la funzione metropolis() del pacchetto ProbBayes.\n\nCodiceset.seed(123)\nlpost <- function(theta, s){\n  dbeta(theta, 2, 10,log = TRUE) +\n  dbinom(23, 30, theta, log = TRUE)\n}\npost <- ProbBayes::metropolis(lpost, 0.5, 0.2, 10000)\n\ntibble(\n  x = post$S[5001:10000]\n) %>%\n  ggplot(aes(x)) +\n  geom_histogram(fill = \"darkgray\") +\n  labs(\n    x = expression(theta),\n    y = \"Frequenza\",\n    title = \"Distribuzione a posteriori\"\n  )\n\n\n\n\n\n\n\nSi ottiene una stima a posteriori ragionevole di \\(\\theta\\).\n\nCodicemean(post$S[5001:10000])\n#> [1] 0.5925168\n\n\nL‚Äôaccettanza per√≤ non √® ottimale.\n\nCodicepost$accept_rate\n#> [1] 0.5469"
  },
  {
    "objectID": "036_posterior_sim.html#diagnostiche-della-soluzione-mcmc",
    "href": "036_posterior_sim.html#diagnostiche-della-soluzione-mcmc",
    "title": "19¬† Approssimazione della distribuzione a posteriori",
    "section": "\n19.3 Diagnostiche della soluzione MCMC",
    "text": "19.3 Diagnostiche della soluzione MCMC\nIn questo Capitolo abbiamo illustrato l‚Äôesecuzione di una singola catena di Markov in cui si parte un unico valore iniziale e si raccolgono i valori simulati da molte iterazioni. √à possibile per√≤ che i valori di una catena siano influenzati dalla scelta del valore iniziale. Quindi una raccomandazione generale √® di eseguire l‚Äôalgoritmo di Metropolis pi√π volte utilizzando diversi valori di partenza. In questo caso, si avranno pi√π catene di Markov. Confrontando le propriet√† delle diverse catene si esplora la sensibilit√† dell‚Äôinferenza alla scelta del valore di partenza. I software MCMC consentono sempre all‚Äôutente di specificare diversi valori di partenza e di generare molteplici catene di Markov.\n\n19.3.1 Stazionariet√†\nUn punto importante da verificare √® se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta ‚Äúmixing‚Äù.\n\n19.3.1.1 Autocorrelazione\nInformazioni sul ‚Äúmixing‚Äù della catena di Markov sono fornite dall‚Äôautocorrelazione. L‚Äôautocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \\(m\\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantit√† \\(k\\) (dove \\(k\\) √® l‚Äôentit√† del ritardo) per verificare quanto si correli al variare di \\(k\\). L‚Äôautocorrelazione di ordine 1 (lag 1) misura la correlazione tra valori successivi della catena di Markow (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-1)}\\)); l‚Äôautocorrelazione di ordine 2 (lag 2) misura la correlazione tra valori della catena di Markow separati da due ‚Äúpassi‚Äù (cio√®, la correlazione tra \\(\\theta^{(m)}\\) e \\(\\theta^{(m-2)}\\)); e cos√¨ via.\nL‚Äôautocorrelazione di ordine \\(k\\) √® data da \\(\\rho_k\\) e pu√≤ essere stimata come:\n\\[\n\\begin{align}\n\\rho_k &= \\frac{\\mbox{Cov}(\\theta_m, \\theta_{m+k})}{\\mbox{Var}(\\theta_m)}\\notag\\\\\n&= \\frac{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})(\\theta_{m-k} - \\bar{\\theta})}{\\sum_{m=1}^{n-k}(\\theta_m - \\bar{\\theta})^2} \\qquad\\text{con }\\quad \\bar{\\theta} = \\frac{1}{n}\\sum_{m=1}^{n}\\theta_m.\n\\end{align}\n\\tag{19.2}\\]\n\nEsercizio 19.1 Per fare un esempio pratico, simuliamo dei dati autocorrelati con la funzione \\(\\textsf{R}\\) colorednoise::colored_noise().\n\nCodicesuppressPackageStartupMessages(library(\"colorednoise\"))\nset.seed(34783859)\nrednoise <- colored_noise(\n  timesteps = 30, mean = 0.5, sd = 0.05, phi = 0.3\n)\n\n\nL‚Äôautocorrelazione di ordine 1 √® semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza. Nell‚Äôesempio, il vettore rednoise √® una sequenza temporale di 30 elementi. Il vettore rednoise[-length(rednoise)] include gli elementi con gli indici da 1 a 29 nella sequenza originaria, mentre il vettore rednoise[-1] include gli elementi 2:30. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \\((1, 2), (2, 3), \\dots (29, 30)\\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori rednoise[-length(rednoise)] e rednoise[-1] corrisponde all‚Äôautocorrelazione di ordine 1 della serie temporale.\n\nCodicecor(rednoise[-length(rednoise)], rednoise[-1])\n#> [1] 0.3967366\n\n\nIl Correlogramma √® uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall‚Äôautocorrelazione \\(\\rho_k\\) di una catena di Markov in funzione del ritardo (lag) \\(k\\) con cui l‚Äôautocorrelazione √® calcolata: nel grafico ogni barretta verticale riporta il valore dell‚Äôautocorrelazione (sull‚Äôasse delle ordinate) in funzione del ritardo (sull‚Äôasse delle ascisse). In \\(\\textsf{R}\\), il correlogramma pu√≤ essere prodotto con una chiamata a acf().\n\nCodiceacf(rednoise)\n\n\n\n\n\n\n\nNel correlogramma precedente vediamo che l‚Äôautocorrelazione di ordine 1 √® circa pari a 0.4 e diminuisce per lag maggiori; per lag di 4, l‚Äôautocorrelazione diventa negativa e aumenta progressivamente fino ad un lag di 8; eccetera.\nIn situazioni ottimali l‚Äôautocorrelazione diminuisce rapidamente ed √® effettivamente pari a 0 per piccoli lag. Ci√≤ indica che i valori della catena di Markov che si trovano a pi√π di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce una conferma del ‚Äúmixing‚Äù della catena di Markov, ossia della convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l‚Äôautocorrelazione √® quella di assottigliare l‚Äôoutput immagazzinando solo ogni \\(m\\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di thinning.\n\n\n19.3.2 Test di convergenza\nUn test di convergenza pu√≤ essere svolto in maniera grafica mediante le tracce delle serie temporali (trace plot), cio√® il grafico dei valori simulati rispetto al numero di iterazioni. Se la catena √® in uno stato stazionario le tracce mostrano assenza di periodicit√† nel tempo e ampiezza costante, senza tendenze visibili o andamenti degni di nota. Un esempio di trace plot √® fornito nella Figura¬†19.5 (destra).\nCi sono inoltre alcuni test che permettono di verificare la stazionariet√† del campionatore dopo un dato punto. Uno √® il test di Geweke che suddivide il campione, dopo aver rimosso un periodo di burn in, in due parti. Se la catena √® in uno stato stazionario, le medie dei due campioni dovrebbero essere uguali. Un test modificato, chiamato Geweke z-score, utilizza un test \\(z\\) per confrontare i due subcampioni ed il risultante test statistico, se ad esempio √® pi√π alto di 2, indica che la media della serie sta ancora muovendosi da un punto ad un altro e quindi √® necessario un periodo di burn-in pi√π lungo."
  },
  {
    "objectID": "036_posterior_sim.html#commenti-e-considerazioni-finali",
    "href": "036_posterior_sim.html#commenti-e-considerazioni-finali",
    "title": "19¬† Approssimazione della distribuzione a posteriori",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn generale, la distribuzione a posteriori dei parametri di un modello statistico non pu√≤ essere determinata per via analitica. Tale problema viene invece affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilit√† che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre pi√π semplice l‚Äôuso dei metodi MCMC, insieme all‚Äôincremento della potenza di calcolo dei computer, ha contribuito a rendere sempre pi√π popolare il metodo dell‚Äôinferenza bayesiana che, in questo modo, pu√≤ essere estesa a problemi di qualunque grado di complessit√†.\n\n\n\n\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equation of state calculations by fast computing machines. The Journal of Chemical Physics, 21(6), 1087‚Äì1092.\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "040_beta_binomial_mod.html",
    "href": "040_beta_binomial_mod.html",
    "title": "20¬† Il modello beta-binomiale in linguaggio Stan",
    "section": "",
    "text": "In questo Capitolo introdurremo un linguaggio di programmazione probabilistica chiamato Stan (Carpenter et al., 2017). Stan consente di generare campioni da distribuzioni di probabilit√† basati sulla costruzione di una catena di Markov avente come distribuzione di equilibrio (o stazionaria) la distribuzione desiderata. Prende il nome da uno dei creatori del metodo Monte Carlo, Stanislaw Ulam (Eckhardt, 1987). Un‚Äôintroduzione al linguaggio Stan √® fornita in Appendice. In questo Capitolo useremo Stan per fare inferenza su una proporzione."
  },
  {
    "objectID": "040_beta_binomial_mod.html#il-presidente-trump-e-lidrossiclorochina",
    "href": "040_beta_binomial_mod.html#il-presidente-trump-e-lidrossiclorochina",
    "title": "20¬† Il modello beta-binomiale in linguaggio Stan",
    "section": "\n20.1 Il presidente Trump e l‚Äôidrossiclorochina",
    "text": "20.1 Il presidente Trump e l‚Äôidrossiclorochina\nPer fare un esempio concreto, consideriamo un set di dati reali. Cito dal Washington Post del 7 aprile 2020:\n\nOne of the most bizarre and disturbing aspects of President Trump‚Äôs nightly press briefings on the coronavirus pandemic is when he turns into a drug salesman. Like a cable TV pitchman hawking ‚Äòmale enhancement‚Äô pills, Trump regularly extols the virtues of taking hydroxychloroquine, a drug used to treat malaria and lupus, as a potential ‚Äògame changer‚Äô that just might cure Covid-19.\n\nTralasciamo qui il fatto che il Donald Trump non sia un esperto in questo campo. Esaminiamo invece le evidenze iniziali a supporto dell‚Äôipotesi che l‚Äôidrossiclorochina possa essere utile per la cura del Covid-19, ovvero le evidenze che erano disponibili nel momento in cui il Donald Trump ha fatto le affermazioni riportate sopra (in seguito, quest‚Äôidea √® stata screditata). Tali evidenze sono state fornite da uno studio di Gautret et al. (2020). Il disegno sperimentale di Gautret et al. (2020) comprende, tra le altre cose, il confronto tra una condizione sperimentale e una condizione di controllo. Il confronto importante √® tra la proporzione di paziente positivi al virus SARS-CoV-2 nel gruppo sperimentale (a cui √® stata somministrata l‚Äôidrossiclorochina; 6 su 14) e la proporzione di paziente positivi nel gruppo di controllo (a cui non √® stata somministrata l‚Äôidrossiclorochina; ovvero 14 su 16). Obiettivo di questo Capitolo √® mostrare come si possa fare inferenza sui dati di Gautret et al. (2020) usando il linguaggio Stan. Per semplicit√†, iniziamo considerando solo il gruppo di controllo."
  },
  {
    "objectID": "040_beta_binomial_mod.html#una-proporzione",
    "href": "040_beta_binomial_mod.html#una-proporzione",
    "title": "20¬† Il modello beta-binomiale in linguaggio Stan",
    "section": "\n20.2 Una proporzione",
    "text": "20.2 Una proporzione\nSulla base di ci√≤ che √® stato detto nel Capitolo¬†17, sappiamo che, quando i dati sono rappresentati da una proporzione \\(\\theta\\), e quando utilizziamo una distribuzione a priori Beta per \\(\\theta\\), la distribuzione a posteriori di \\(\\theta\\) √® specificata dallo schema beta-binomiale. Se scegliamo, ad esempio, una \\(\\mbox{Beta}(2, 2)\\) quale distribuzione a priori per \\(\\theta\\), il modello diventa:\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align}\ny &\\sim \\mbox{Bin}(n, \\theta) \\notag\\\\\n\\theta &\\sim \\mbox{Beta}(2, 2)\n\\end{align}\n\\tag{20.1}\\]\ndove la prima riga definisce la funzione di verosimiglianza e la seconda riga definisce la distribuzione a priori. Vediamo ora come specificare il modello beta-binomiale in linguaggio Stan."
  },
  {
    "objectID": "040_beta_binomial_mod.html#cmdstanr-gautret",
    "href": "040_beta_binomial_mod.html#cmdstanr-gautret",
    "title": "20¬† Il modello beta-binomiale in linguaggio Stan",
    "section": "\n20.3 Interfaccia cmdstanr\n",
    "text": "20.3 Interfaccia cmdstanr\n\nI modelli presentati in questo capitolo sono discussi da Gelman et al. (1995) mentre il codice √® stato ricavato dalla seguente pagina web. In questo e nei successivi capitoli useremo Stan mediante l‚Äôinterfaccia cmdstanr di CmdStan.\nIniziamo con il caricare i pacchetti necessari.\n\nCodicelibrary(\"cmdstanr\")\nlibrary(\"posterior\")\navailableCores()\nSEED <- 84735 \n\n\nPer svolgere l‚Äôanalisi mediante cmdstanr √® necessario prima specificare la struttura del modello bayesiano nella notazione Stan e, poi, eseguire il campionamento dalla distribuzione a posteriori. Esaminiamo questi due passaggi per l‚Äôesempio presente.\n\n20.3.1 Fase 1\nNella prima fase dell‚Äôanalisi dobbiamo definire i dati, i parametri e il modello. I dati devono essere contenuti in un oggetto di classe list.\n\nCodicedata1_list <- list(\n  N = 16,\n  y = c(rep(1, 14), rep(0, 2))\n)\n\n\nIl modello √® \\(\\mbox{Bin}(n, \\theta)\\). Oppure, dato che abbiamo specificato in input ciascuna singola osservazione, \\(\\mbox{Bernoulli}(\\theta)\\).\n\nCodicey ~ bernoulli(theta);\n\n\nLa verosimiglianza dipende dal parametro theta. In Stan, √® necessario specificare che theta √® un numero reale compreso tra 0 e 1. Inoltre, √® necessario imporre su \\(\\theta\\) una distribuzione a priori. Nel caso presente abbiamo scelto una \\(\\mbox{Beta}(2, 2)\\).\n\nCodicetheta ~ beta(2, 2);\n\n\nMemorizziamo il modello beta-binomiale che abbiamo specificato in linguaggio Stan come stringa di caratteri.\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  array[N] int<lower=0, upper=1> y;\n}\nparameters {\n  real<lower=0, upper=1> theta;\n}\nmodel {\n  theta ~ beta(2, 2);\n  y ~ bernoulli(theta);\n}\n\"\n\n\nUtilizzando il seguente link si pu√≤ ottenere una formattazione automatica del codice e anche, in qualche misura, una correzione della sintassi.\nSalviamo modelString in un file a cui assegniamo il nome oneprop.stan (si noti l‚Äôestensione .stan). Sul mio computer ho creato una cartella chiamata code dove salvo i file .stan. Se non vogliamo definire una sotto-cartella chiamata code, √® sufficiente scrivere writeLines(modelString, con = \"oneprop.stan\").\n\nCodicewriteLines(modelString, con = \"code/oneprop.stan\")\n\n\n\n20.3.2 Fase 2\nPer utilizzare il modello che abbiamo specificato, prima leggiamo l‚Äôindirizzo del file che contiene il codice Stan.\n\nCodicefile <- file.path(\"code\", \"oneprop.stan\")\n\n\nPoi compiliamo il codice Stan. Questo crea un file eseguibile che, nel caso presente, abbiamo chiamato mod.\n\nCodicemod <- cmdstan_model(file)\n\n\nPossiamo ora eseguire il campionamento MCMC con la seguente chiamata.\n\nCodicefit1 <- mod$sample(\n  data = data1_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n\n\nSi noti che $sample() √® un ‚Äúmetodo‚Äù che viene applicato al file eseguibile che abbiamo compilato, al quale √® stato assegnato il nome mod.\nIl metodo $sample() richiede una serie di argomenti.\n\n\ndata, ovvero i dati in input in formato lista (nel caso presente, data1_list).\n\nchains specifica quante catene di Markov parallele eseguire. Eseguiamo qui quattro catene, quindi otterremo quattro campioni distinti di valori \\(\\pi\\).\n\niter specifica il numero desiderato di iterazioni o la lunghezza di ciascuna catena di Markov. Per impostazione predefinita, la prima met√† di queste iterazioni √® costituita da campioni ‚Äúburn-in‚Äù o ‚Äúwarm-up‚Äù che verranno ignorati. La seconda met√† √® conservata e costituisce un campione della distribuzione a posteriori.\n\niter_warmup specifica il numero di campioni ‚Äúwarm-up‚Äù che vogliamo vengano ignorati.\n\nseed imposta il numero casuale che viene usato per generare il punto di partenza di ciascuna catena di Markov.\n\nAvendo assunto una distribuzione a priori per il parametro \\(\\theta\\), l‚Äôalgoritmo procede in maniera ciclica, correggendo la distribuzione a priori di \\(\\theta\\) condizionandola ai valori gi√† generati. Dopo un certo numero di cicli, necessari per portare l‚Äôalgoritmo a convergenza, i valori estratti possono essere assunti come campionati dalla distribuzione a posteriori di \\(\\theta\\).\nAl crescere del numero di passi della catena, la distribuzione di target viene sempre meglio approssimata. All‚Äôinizio del campionamento, peroÃÄ, la distribuzione puoÃÄ essere significativamente lontana da quella stazionaria, e ci vuole un certo tempo prima di raggiungere la distribuzione stazionaria di equilibrio, detto, appunto, periodo di burn-in. I campioni provenienti da tale parte iniziale della catena vanno tipicamente scartati perch√© possono non rappresentare accuratamente la distribuzione a posteriori.\n\n20.3.3 Fase 3\nPossiamo ora fare inferenza usando i risultati ottenuti. Un sommario della distribuzione a posteriori si ottiene con il metodo summary().\n\nCodicefit1$summary(c(\"theta\"))\n#> # A tibble: 1 √ó 10\n#>   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 theta    0.798  0.808 0.0876 0.0872 0.638 0.924  1.00    5769.    6359.\n\n\nCreo un oggetto di classe stanfit.\n\nCodicestanfit1 <- rstan::read_stan_csv(fit1$output_files())\n\n\nCalcolo le dimensioni dell‚Äôoggetto stanfit1.\n\nCodicedim(as.matrix(stanfit1, pars = \"theta\"))\n#> [1] 16000     1\n\n\nStampo i primi 10 valori di stanfit1.\n\nCodiceas.matrix(stanfit1, pars = \"theta\") %>% \n  head(10)\n#>           parameters\n#> iterations    theta\n#>       [1,] 0.852111\n#>       [2,] 0.784496\n#>       [3,] 0.784496\n#>       [4,] 0.755076\n#>       [5,] 0.725578\n#>       [6,] 0.774385\n#>       [7,] 0.774385\n#>       [8,] 0.806225\n#>       [9,] 0.826550\n#>      [10,] 0.849894\n\n\nLa matrice precedente include i valori assunti dalla catena di Markov, ovvero un insieme di valori \\(\\theta\\) estratti dalla distribuzione a posteriori. Un tracciato della catena di Markov illustra questa esplorazione rappresentando il valore \\(\\theta\\) sulle ordinate e l‚Äôindice progressivo di in ogni iterazione sull‚Äôascissa. Uso la funzione mcmc_trace() del pacchetto bayesplot per costruire il grafico che include tutte e quattro le catene di Markov.\n\nCodicestanfit1 %>% \n  mcmc_trace(pars = c(\"theta\"), size = 0.1)\n\n\n\nFigura 20.1: Trace-plot per il parametro \\(\\theta\\) nel modello Beta-Binomiale.\n\n\n\n\nLa Figura¬†20.1 mostra che le catene esplorano uno spazio compreso approssimativamenre tra 0.5 e 0.95; questa figura descrive il comportamento longitudinale delle catene di Markov.\nPossiamo anche esaminare la distribuzione degli stati della catena di Markov, ovvero, dei valori che queste catene visitano lungo il loro percorso, ignorando l‚Äôordine di queste visite. L‚Äôistogramma della Figura¬†20.2 fornisce una rappresentazione grafica di questa distribuzione per i 16000 valori complessivi delle quattro catene, ovvero per 4000 valori provienienti da ciascuna catena.\n\nCodicemcmc_hist(stanfit1, pars = \"theta\") + \n  yaxis_text(TRUE) + \n  ylab(\"count\")\n\n\n\nFigura 20.2: Istogramma che illustra l‚Äôapprossimazione della distribuzione a posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale.\n\n\n\n\nNello schema beta-binomiale in cui la verosimiglianza √® binomiale con 14 successi su 16 prove e in cui assumiamo una distribuzione a priori \\(\\mbox{Beta}(2, 2)\\) sul parametro \\(\\theta\\), la distribuzione a posteriori eÃÄ una distribuzione Beta di parametri \\(\\alpha\\) = 2 + 14 e \\(\\beta\\) = 2 + 16 - 14. La Figura¬†20.3 riporta un kernel density plot per i valori delle quattro catene di Markov con sovrapposta in nero la densit√† \\(\\mbox{Beta}(16, 4)\\). Si noti come la distribuzione dei valori delle catene di Markov produca un‚Äôeccellente approssimazione alla distribuzione bersaglio.1\n\nCodicemcmc_dens(stanfit1, pars = \"theta\") + \n  yaxis_text(TRUE) + \n  ylab(\"density\") +\n  stat_function(fun = dbeta, args = list(shape1 = 16, shape2=4))\n\n\n\nFigura 20.3: Istogramma che illustra l‚Äôapprossimazione della distribuzione a posteriori per il parametro \\(\\theta\\) nel modello Beta-Binomiale. La curva nera rappresenta la corretta distribuzione a posteriori Beta(16, 4).\n\n\n\n\nUn intervallo di credibilit√† al 95% per \\(\\theta\\) si ottiene con la funzione posterior_interval().\n\nCodiceposterior1 <- extract(stanfit1)\nrstantools::posterior_interval(as.matrix(stanfit1), prob = 0.95)\n#>              2.5%       97.5%\n#> theta   0.5990419   0.9376123\n#> lp__  -12.5817650 -10.0086000\n\n\nSvolgendo un‚Äôanalisi bayesiana simile a questa, Gautret et al. (2020) hanno trovato che gli intervalli di credibilit√† del gruppo di controllo e del gruppo sperimentale non si sovrappongono. Questo fatto viene interpretato dicendo che il parametro \\(\\theta\\) √® diverso nei due gruppi. Sulla base di queste evidenza, Gautret et al. (2020) hanno concluso, con un grado di certezza soggettiva del 95%, che nel gruppo sperimentale vi √® una probabilit√† pi√π bassa di risultare positivi al SARS-CoV-2 rispetto al gruppo di controllo. In altri termini, l‚Äôanalisi statistica condotta da Gautret et al. (2020) suggerisce che l‚Äôidrossiclorochina √® una terapia efficace per il Covid-19."
  },
  {
    "objectID": "040_beta_binomial_mod.html#la-critica-di-hulme_2020",
    "href": "040_beta_binomial_mod.html#la-critica-di-hulme_2020",
    "title": "20¬† Il modello beta-binomiale in linguaggio Stan",
    "section": "\n20.4 La critica di Hulme et al. (2020)\n",
    "text": "20.4 La critica di Hulme et al. (2020)\n\nUn articolo pubblicato da Hulme et al. (2020) si √® posto il problema di rianalizzare i dati di Gautret et al. (2020).2 Tra gli autori di questo articolo figura anche Eric-Jan Wagenmakers, uno psicologo molto conosciuto per i suoi contributi metodologici. Hulme et al. (2020) osservano che, nelle loro analisi statistiche, Gautret et al. (2020) hanno escluso alcuni dati. Nel gruppo sperimentale, infatti, vi erano alcuni pazienti i quali, anzich√© migliorare, sono in realt√† peggiorati. L‚Äôanalisi statistica di Gautret et al. (2020) ha escluso i dati di questi pazienti. Se consideriamo tutti i pazienti ‚Äî non solo quelli selezionati da Gautret et al. (2020) ‚Äî la situazione diventa la seguente:\n\ngruppo sperimentale: 10 positivi su 18;\ngruppo di controllo: 14 positivi su 16.\n\nL‚Äôanalisi dei dati proposta da Hulme et al. (2020) richiede l‚Äôuso di alcuni strumenti statistici che, in queste dispense, non verranno discussi. Ma possiamo giungere alle stesse conclusioni raggiunte da questi ricercatori anche usando le procedure statistiche descritte nel Paragrafo successivo."
  },
  {
    "objectID": "040_beta_binomial_mod.html#due-proporzioni",
    "href": "040_beta_binomial_mod.html#due-proporzioni",
    "title": "20¬† Il modello beta-binomiale in linguaggio Stan",
    "section": "\n20.5 Due proporzioni",
    "text": "20.5 Due proporzioni\nSvolgiamo ora l‚Äôanalisi statistica considerando tutti i dati, come suggerito da Hulme et al. (2020). Per fare questo verr√† creato un modello bayesiano per fare inferenza sulla differenza tra due proporzioni. Dopo avere generato le distribuzioni a posteriori per le proporzioni di ‚Äúsuccessi‚Äù nei due gruppi, calcoleremo la quantit√†\n\\[\n\\omega = \\frac{\\theta_2 / (1-\\theta_2)}{\\theta_1 / (1-\\theta_1)},\n\\tag{20.2}\\]\novvero il rapporto tra gli Odds di positivit√† tra i pazienti del gruppo di controllo e gli Odds di positivit√† tra i pazienti del gruppo sperimentale. Se il valore dell‚ÄôOR √® uguale a 1, significa che l‚ÄôOdds di positivit√† nel gruppo di controllo √® uguale all‚ÄôOdds di positivit√† nel gruppo sperimentale, cio√® il fattore in esame (somministrazione dell‚Äôidrossiclorochina) √® ininfluente sulla comparsa della malattia. L‚Äôinferenza statistica sull‚Äôefficacia dell‚Äôidrossiclorochina come terapia per il Covid-19 pu√≤ dunque essere effettuata esaminando l‚Äôintervallo di credibilit√† al 95% per l‚ÄôOR: se tale intervallo include il valore 1, allora non c‚Äô√® evidenza che l‚Äôidrossiclorochina sia efficace come terapia per il Covid-19.\nNell‚Äôimplementazione di questo modello, la quantit√† di interesse √® l‚Äôodds ratio; tale quantit√† viene calcolata nel blocco generated quantities. Per i parametri \\(\\theta_1\\) e \\(\\theta_2\\) useremo delle distribuzioni a priori debolmente informative il cui scopo √® la regolarizzazione dei dati.\nInseriscoo i dati dei due gruppi in un oggetto di classe list.\n\nCodicedata_list <- list(\n  N1 = 18, \n  y1 = 10, \n  N2 = 16, \n  y2 = 14\n)\n\n\nDefinisco il modello in linguaggio Stan.\n\nCodicemodelString <- \"\n//  Comparison of two groups with Binomial\ndata {\n  int<lower=0> N1; // number of experiments in group 1\n  int<lower=0> y1; // number of deaths in group 1\n  int<lower=0> N2; // number of experiments in group 2\n  int<lower=0> y2; // number of deaths in group 2\n}\nparameters {\n  real<lower=0, upper=1> theta1; // probability of death in group 1\n  real<lower=0, upper=1> theta2; // probability of death in group 2\n}\nmodel {\n  theta1 ~ beta(2, 2); // prior\n  theta2 ~ beta(2, 2); // prior\n  y1 ~ binomial(N1, theta1); // likelihood\n  y2 ~ binomial(N2, theta2); // likelihood\n}\ngenerated quantities {\n  real oddsratio = (theta2 / (1 - theta2)) / (theta1 / (1 - theta1));\n}\n\"\nwriteLines(modelString, con = \"code/twoprop1.stan\")\n\n\nSalvo il modello in un file.\n\nCodicefile <- file.path(\"code\", \"twoprop1.stan\")\n\n\nCompilo il modello.\n\nCodicemod <- cmdstan_model(file)\n\n\nEseguo il campionamento MCMC.\n\nCodicefit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nEsamino i risulati.\n\nCodicestanfit <- rstan::read_stan_csv(fit$output_files())\n\n\n\nCodiceprint(\n  stanfit,\n  pars = c(\"theta1\", \"theta2\", \"oddsratio\"),\n  digits_summary = 3L\n)\n#> Inference for Stan model: twoprop1-202207010736-1-5c62a8.\n#> 4 chains, each with iter=6000; warmup=2000; thin=1; \n#> post-warmup draws per chain=4000, total post-warmup draws=16000.\n#> \n#>            mean se_mean    sd  2.5%   25%   50%   75%  97.5% n_eff Rhat\n#> theta1    0.546   0.001 0.103 0.344 0.475 0.546 0.620  0.740 12795    1\n#> theta2    0.798   0.001 0.087 0.601 0.744 0.808 0.862  0.937 14193    1\n#> oddsratio 4.721   0.043 4.411 0.906 2.166 3.514 5.698 15.558 10400    1\n#> \n#> Samples were drawn using NUTS(diag_e) at Ven Lug 01 07:36:30 2022.\n#> For each parameter, n_eff is a crude measure of effective sample size,\n#> and Rhat is the potential scale reduction factor on split chains (at \n#> convergence, Rhat=1).\n\n\nL‚Äôintervallo di credibilit√† del 95% per l‚ÄôOR include il valore di 1.0 (ovvero, il valore che indica che gli Odds di positivit√† sono uguali nei due gruppi). In base agli standard correnti, un risultato di questo tipo non viene considerato come evidenza sufficiente per potere concludere che il parametro \\(\\theta\\) assume un valore diverso nei due gruppi. In conclusione, se consideriamo tutti i dati, e non solo quelli selezionati da Gautret et al. (2020), non vi sono evidenze sull‚Äôefficacia dell‚Äôidrossiclorochina come terapia per il Covid-19."
  },
  {
    "objectID": "040_beta_binomial_mod.html#commenti-e-considerazioni-finali",
    "href": "040_beta_binomial_mod.html#commenti-e-considerazioni-finali",
    "title": "20¬† Il modello beta-binomiale in linguaggio Stan",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa ricerca di Gautret et al. (2020) include altre informazioni e altre analisi statistiche che non sono state qui considerate. Tuttavia, notiamo che la semplice analisi statistica che abbiamo qui descritto √® stata in grado di replicare le conclusioni a cui sono giunti (per altra via) Hulme et al. (2020).\n\n\n\n\n\n\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P., & Riddell, A. (2017). Stan: A probabilistic programming language. Journal of Statistical Software, 76(1), 1‚Äì32.\n\n\nEckhardt, R. (1987). Stan Ulam, John Von Neumann and the Monte Carlo Method. Los Alamos Science Special Issue.\n\n\nGautret, P., Lagier, J. C., Parola, P., Meddeb, L., Mailhe, M., Doudier, B., & Honor√©, S. (2020). Hydroxychloroquine and azithromycin as a treatment of COVID-19: Results of an open-label non-randomized clinical trial. International Journal of Antimicrobial Agents.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nHulme, O. J., Wagenmakers, E. J., Damkier, P., Madelung, C. F., Siebner, H. R., Helweg-Larsen, J., & Madsen, K. H. (2020). Reply to gautret et al. 2020: A bayesian reanalysis of the effects of hydroxychloroquine and azithromycin on viral carriage in patients with COVID-19. medRxiv."
  },
  {
    "objectID": "041_mcmc_diagnostics.html",
    "href": "041_mcmc_diagnostics.html",
    "title": "21¬† Diagnostica delle catene markoviane",
    "section": "",
    "text": "Come √® stato discusso nel (cmdstanr-gautret?), le catene di Markov forniscono un‚Äôapprossimazione che tende a convergere alla distribuzione a posteriori. ‚ÄúApprossimazione‚Äù e ‚Äúconvergenza‚Äù sono le parole chiave qui: il punto √® che il campionamento MCMC non √® perfetto. Questo solleva le seguenti domande:\nRispondere a queste ed altre domande di questo tipo fa parte di quell‚Äôinsieme di pratiche che vano sotto il nome di diagnostica delle catene Markoviane.\nLa diagnostica delle catene Markoviane non √® ‚Äúuna scienza esatta‚Äù. Ovvero, non sono disponibili procedure che risultano valide in tutti i casi possibili e non sempre siamo in grado di rispondere a tutte le domande precedenti. √à piuttosto l‚Äôesperienza del ricercatore che consente di riconoscere una ‚Äúbuona‚Äù catena di Markov e a suggerire cosa si pu√≤ fare per riparare una ‚Äúcattiva‚Äù catena di Markov. In questo Capitolo ci concentreremo su alcuni strumenti diagnostici grafici e numerici che possono essere utilizzati per la diagnostica delle catene markoviane. L‚Äôutilizzo di questi strumenti diagnostici deve essere eseguito in modo olistico. Nessuna singola diagnostica visiva o numerica √® sufficiente: un quadro completo della qualit√† della catena di Markov si pu√≤ solo ottenere considerando tutti gli strumenti descritti di seguito."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#esame-dei-trace-plot",
    "href": "041_mcmc_diagnostics.html#esame-dei-trace-plot",
    "title": "21¬† Diagnostica delle catene markoviane",
    "section": "\n21.1 Esame dei trace plot\n",
    "text": "21.1 Esame dei trace plot\n\nLa convergenza e il ‚Äúmixing‚Äù possono essere controllate mediante il trace plot che mostra l‚Äôandamento delle simulazioni e ci dice se stiamo effettivamente utilizzando una distribuzione limite. Consideriamo nuovamente il trace plot del simulazione Beta-Binomiale della figura Figura¬†21.1.\n\n\n\n\n\n\n\nFigura 21.1: Trace plot per il modello Beta-Binomiale dei dati di Gautret et al.(2020).\n\n\n\n\nLa Figura¬†21.1 fornisce un esempio perfetto di come dovrebbero apparire i trace plot. Quando le catene markoviane raggiungono uno stato stazionario e sono stabili ci√≤ significa che hanno raggiunto la distribuzione stazionaria e il trace plot rivela un‚Äôassenza di struttura e diventa simile alla rappresentazione del rumore bianco, come nella Figura¬†21.1.\nUna mancanza di convergenza √® invece indicata dalla Figura¬†21.21.\n\n\n\n\nFigura 21.2: Trace plots (a sinistra) e corrispondenti grafici di densit√† (a destra) di due ipotetiche catene di Markov. Queste figure forniscono due esempi di come potrebbero apparire delle catene di Markov non stazionarie. Le linee nere sovrapposte alle densit√† empiriche (a destra) rappresentano una ipotetica distribuzione target Beta(11,3).\n\n\n\n\nNel trace-plot della Figura¬†21.2 la tendenza verso il basso indica che la catena A non √® stazionaria, ovvero non si mantiene costante all‚Äôevolversi nel tempo. La tendenza verso il basso suggerisce inoltre la presenza di una forte correlazione tra i valori della catena: il trace-plot non fornisce una rappresentazione di rumore indipendente. Tutto questo significa che la catena A ‚Äúsi sta mescolando lentamente‚Äù. Sebbene le catene di Markov siano intrinsecamente dipendenti, pi√π si comportano come se fossero dei campioni casuali (rumorosi), minore √® l‚Äôerrore dell‚Äôapprossimazione alla distribuzione a posteriori.\nLa catena B presenta un problema diverso. Come evidenziato dalle due linee completamente piatte nel tracciato, essa tende a bloccarsi quando visita valori bassi di \\(\\theta\\).\nGli istogrammi lisciati della Figura¬†21.2 (a destra) confermano che entrambe queste catene sono problematiche: infatti producono approssimazioni scadenti della distribuzione a posteriori che, nell‚Äôesempio di Johnson et al. (2022), √® una \\(\\mbox{Beta}(11, 3)\\) (la curva nera nella figura). Consideriamo la catena A. Dal momento che si sta mescolando lentamente, nelle iterazioni eseguite ha esplorato unicamente i valori \\(\\theta\\) nell‚Äôintervallo da 0.6 a 0.9. Di conseguenza, la sua approssimazione della distribuzione a posteriori sopravvaluta la plausibilit√† dei valori \\(\\theta\\) in questo intervallo e, nel contempo, sottovaluta la plausibilit√† dei valori \\(\\theta\\) esterni a questo intervallo. Consideriamo ora la catena B. Rimanendo bloccata, la catena B campiona in maniera eccessiva alcuni valori nella coda sinistra della distribuzione a posteriori di \\(\\theta\\). Questo fenomeno produce i picchi che sono presenti nell‚Äôapprossimazione alla distribuzione a posteriori.\nIn pratica, al di l√† dei presenti esempi ‚Äúscolastici‚Äù (in cui disponiamo di una formulazione analitica della distribuzione a posteriori), non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perch√© la diagnostica delle catene di Markov √® cos√¨ importante: se vediamo trace-plots come quelli della Figura¬†21.2, sappiamo che non abbiamo ottenuto una adeguata approssimazione della distribuzione a posteriori.\nIn tali circostanze possiamo ricorrere ad alcuni rimedi.\n\nControllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?\nUtilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#confronto-delle-catene-parallele",
    "href": "041_mcmc_diagnostics.html#confronto-delle-catene-parallele",
    "title": "21¬† Diagnostica delle catene markoviane",
    "section": "\n21.2 Confronto delle catene parallele",
    "text": "21.2 Confronto delle catene parallele\nNella simulazione cmdstanr() per il modello beta-binomiale dei dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele. Non solo √® necessario che ogni singola catena sia stazionaria (come discusso sopra), ma √® anche necessario che le quattro catene siano coerenti tra loro. Sebbene le catene esplorino percorsi diversi nello spazio dei parametri, quando convergono ad uno stato di equilibrio dovrebbero presentare caratteristiche simili e dovrebbero produrre approssimazioni simili alla distribuzione a posteriori. Per il caso beta-binomiale dei dati di Gautret et al. (2020), gli istogrammi lisciati della figura seguente indicano che le quattro catene producono approssimazioni della distribuzione a posteriori quasi indistinguibili tra loro. Ci√≤ prova che la simulazione √® stabile e contiene un nunero sufficiente di valori: l‚Äôesecuzione delle catene per un numero maggiore di iterazioni non porterebbe ad un miglioramento della stima della distribuzione a posteriori.\n\nCodicemcmc_dens_overlay(stanfit1, pars = \"theta\") + \n  ylab(\"density\")\n\n\n\n\n\n\n\nPer fare un confronto, per lo stesso modello, consideriamo la simulazione di una catena di Markov pi√π corta. La chiamata seguente richiede quattro catene parallele per sole 100 iterazioni ciascuna.\n\nCodicebb_short <- mod$sample(\n  data = data1_list,\n  iter_sampling = 50*2L,\n  seed = 84735,\n  chains = 4L,\n  parallel_chains = 4L,\n  refresh = 0,\n  thin = 1\n)\nFALSE Running MCMC with 4 parallel chains...\nFALSE \nFALSE Chain 1 finished in 0.0 seconds.\nFALSE Chain 2 finished in 0.0 seconds.\nFALSE Chain 3 finished in 0.0 seconds.\nFALSE Chain 4 finished in 0.0 seconds.\nFALSE \nFALSE All 4 chains finished successfully.\nFALSE Mean chain execution time: 0.0 seconds.\nFALSE Total execution time: 0.2 seconds.\n\nstanfit_bb_short <- rstan::read_stan_csv(bb_short$output_files())\n\n\nDi seguito sono riportati i trace-plot e i corrispondenti istogrammi lisciati.\n\nCodicemcmc_trace(stanfit_bb_short, pars = \"theta\")\n\n\n\n\n\n\n\n\nCodicemcmc_dens_overlay(stanfit_bb_short, pars = \"theta\")\n\n\n\n\n\n\n\nAnche se i trace plot sembrano tutti mostrare un andamento casuale, gli istogrammi lisciati sono piuttosto diversi tra loro e producono approssimazioni diverse della distribuzione a posteriori. Di fronte a tale instabilit√† √® chiaro che sarebbe un errore interrompere la simulazione dopo solo 100 iterazioni."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#numerosita-campionaria-effettiva",
    "href": "041_mcmc_diagnostics.html#numerosita-campionaria-effettiva",
    "title": "21¬† Diagnostica delle catene markoviane",
    "section": "\n21.3 NumerositaÃÄ campionaria effettiva",
    "text": "21.3 NumerositaÃÄ campionaria effettiva\nNella simulazione del modello beta-binomiale per i dati di Gautret et al. (2020) abbiamo utilizzato quattro catene di Markov parallele che producono un totale di \\(N\\) = 16000 campioni dipendenti di \\(\\theta\\). Sapendo che l‚Äôerrore dell‚Äôapprossimazione alla distribuzione a posteriori √® probabilmente pi√π grande di quello che si otterrebbe usando 16000 campioni indipendenti, ci possiamo porre la seguente domanda: quanti campioni indipendenti sarebbero necessari per produrre un‚Äôapprossimazione della distribuzione a posteriori equivalentemente a quella che abbiamo ottenuto? La numerosit√† campionaria effettiva (effective sample size, \\(N_{eff}\\)) fornisce una risposta a questa domanda.\nTipicamente, \\(N_{eff} < N\\), per cui il rapporto campionario effettivo (effective sample size ratio) \\(\\frac{N_{eff}}{N}\\) √® minore di 1. Come regola euristica, viene considerato problematico un rapporto campionario effettivo minore del 10% del numero totale di campioni ottenuti nella simulazione (pi√π basso √® il rapporto campionario effettivo peggiore √® il ‚Äúmixing‚Äù della catena). La funzione bayesplot::neff_ratio() consente di calcolare il rapporto campionario effettivo. Per il modello Beta-Binomiale dei dati di Gautret et al. (2020), questo rapporto √® di circa 0.34.\n\nCodicebayesplot::neff_ratio(stanfit1, pars = c(\"theta\"))\n#> [1] 0.3629411\n\n\nCi√≤ indica che l‚Äôaccuratezza dell‚Äôapprossimazione della distribuzione a posteriori di \\(\\theta\\) ottenuta mediante 16,000 campioni dipendenti √® approssimativamente simile a quella che si potrebbe ottenere con\n\nCodicebayesplot::neff_ratio(\n  stanfit1, pars = c(\"theta\")\n) * 16000\n#> [1] 5807.058\n\n\ncampioni indipendenti. In questo esempio, il rapporto campionario effettivo √® maggiore di 0.1; dunque non ci sono problemi."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#autocorrelazione",
    "href": "041_mcmc_diagnostics.html#autocorrelazione",
    "title": "21¬† Diagnostica delle catene markoviane",
    "section": "\n21.4 Autocorrelazione",
    "text": "21.4 Autocorrelazione\nNormalmente un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali eÃÄ autocorrelato a quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Il valore \\(\\theta^{(i)}\\) tende ad essere pi√π simile al valore \\(\\theta^{(i-1)}\\) che al valore \\(\\theta^{(i-2)}\\), o al valore \\(\\theta^{(i-3)}\\), eccetera. Una misura di ci√≤ √® fornita dall‚Äôautocorrelazione tra i valori consecutivi della catena.\nIl correlogramma per ciascuna delle quattro catene dell‚Äôesempio si produce con la seguente chiamata:\n\nCodicebayesplot::mcmc_acf(stanfit1, pars = \"theta\")\n\n\n\n\n\n\n\nIl correlogramma mostra l‚Äôautocorrelazione in funzione di ritardi da 0 a 20. L‚Äôautocorrelazione di lag 0 √® naturalmente 1 ‚Äì misura la correlazione tra un valore della catena di Markov e se stesso. L‚Äôautocorrelazione di lag 1 √® di circa 0.5, indicando una correlazione moderata tra i valori della catena che distano di solo 1 passo l‚Äôuno dall‚Äôaltro. Successivamente, l‚Äôautocorrelazione diminuisce rapidamente ed √® effettivamente pari a 0 per un lag di 5. Questo risultato fornisce una conferma del fatto che la catena di Markov costituisce una buona approssimazione di un campione casuale di \\(p(\\theta \\mid y)\\).\nAl contrario, nella Figura¬†21.3 (a destra) (riprodotta da Johnson et al., 2022) vediamo un esempio nel quale il trace plot rivela una forte tendenza tra i valori di una catena di Markov e, dunque, una forte autocorrelazione.\n\n\n\n\nFigura 21.3: Trace plot (a sinistra) e correlogramma (a destra) di una catena di Markow in cui il mixing √® lento ‚Äì figura riprodotta da Johnson et al. (2022).\n\n\n\n\nQuesta osservazione √® confermata nell‚Äôcorrelogramma (a destra). La lenta diminuzione della curva di autocorrelazione indica che la dipendenza tra i valori della catena non svanisce rapidamente. Con un lag di 20 la correlazione √® addirittura pari a 0.9. Poich√© i valori della catena sono fortemente associati tra loro, il ‚Äúmixing‚Äù √® lento: la simulazione richiede un numero molto grande di iterazioni per esplorare adeguatamente l‚Äôintera gamma di valori della distribuzione a posteriori.2\nIn presenza di catene di Markov non rapidly mixing sono possibili due rimedi.\n\nAumentare il numero di iterazioni. Anche una catena non rapidly mixing pu√≤ produrre eventualmente una buona approssimazione della distribuzione a posteriori se il numero di iterazioni √® sufficientemente grande.\n\nThinning. Per esempio, se la catena di Markov √® costituita da 16000 valori di \\(\\theta\\), potremmo decidere di conservare solo ogni secondo valore e ignorare gli altri valori: \\(\\{\\theta^{(2)}, \\theta^{(4)}, \\theta^{(6)}, \\dots, \\theta^{(16000)}\\}\\). Oppure, potremmo decidere di conservare ogni decimo valore: \\(\\{\\theta^{(10)}, \\theta^{(20)}, \\theta^{(30)}, \\dots, \\theta^{(16000)}\\}\\). Scartando i campioni intermedi, √® possibile rimuovere le forti correlazioni che sono presenti nel caso di lag pi√π piccoli.\n\nVediamo ora come sia possibile estrarre i valodi di una catena dall‚Äôoggetto stanfit1.\n\nCodice# valori delle 4 catene\nS <- ggmcmc::ggs(stanfit1)\nhead(S)\n#> # A tibble: 6 √ó 4\n#>   Iteration Chain Parameter value\n#>       <dbl> <int> <fct>     <dbl>\n#> 1         1     1 theta     0.628\n#> 2         2     1 theta     0.758\n#> 3         3     1 theta     0.719\n#> 4         4     1 theta     0.715\n#> 5         5     1 theta     0.856\n#> 6         6     1 theta     0.870\n\n\nLa prima catena pu√≤ essere isolata nel modo seguente:\n\nCodiceS1 <- S %>% \n  dplyr::filter(\n    Chain == 1,\n    Parameter == \"theta\"\n  )\n\n\nUna serie temporale della catena si ottiene con la funzione ggmcmc::ggs_running().\n\nCodiceggmcmc::ggs_running(S1)\n\n\n\n\n\n\n\nIl grafico precedente mostra che, per il modello bayesiano che stiamo discutendo, una condizione di equilibrio della catena di Markov richiederebbe un numero maggiore di iterazioni di quelle che sono state effettivamente simulate.\nL‚Äôautocorrelazione di ordine 1 si ottiene nel modo seguente (si veda il Paragrafo @ref(approx-post-autocor)).\n\nCodicecor(S1$value[-length(S1$value)], S1$value[-1])\n#> [1] 0.3819515\n\n\nQuesto valore corrisponde a ci√≤ che √® riportato nel correlogramma mostrato sopra."
  },
  {
    "objectID": "041_mcmc_diagnostics.html#statistica-hatr",
    "href": "041_mcmc_diagnostics.html#statistica-hatr",
    "title": "21¬† Diagnostica delle catene markoviane",
    "section": "\n21.5 Statistica \\(\\hat{R}\\)\n",
    "text": "21.5 Statistica \\(\\hat{R}\\)\n\nIn precedenza abbiamo detto che non solo √® necessario che ogni singola catena sia stazionaria, √® anche necessario che le diverse catene siano coerenti tra loro. La statistica \\(\\hat{R}\\) affronta questo problema calcolando il rapporto tra la varianza tra le catene markoviane e la varianza entro le catene. In una situazione ottimale \\(\\hat{R} = 1\\); se \\(\\hat{R}\\) √® lontano da 1 questo vuol dire che non √® ancora stata raggiunta la convergenza.\n√à possibile calcolare \\(\\hat{R}\\) mediante la chiamata alla funzione bayesplot::rhat(). Per il modello Beta-Binomiale applicato ai dati di Gautret et al. (2020) abbiamo:\n\nCodicebayesplot::rhat(stanfit1, pars = \"theta\")\n#> [1] 1.00039\n\n\nil che indica che il valore \\(\\hat{R}\\) ottenuto √® molto simile al valore ottimale.\nIn maniera euristica, si pu√≤ affermare che se \\(\\hat{R}\\) supera la soglia di 1.05 questo viene interpretato come evidenza che le diverse catene parallele non producono approssimazioni coerenti della distribuzione a posteriori, quindi la simulazione √® instabile.\nUna rappresentazione grafica dei valori \\(\\hat{R}\\) per tutti i parametri del modello si ottiene con la seguente chiamata:\n\nCodiceggmcmc::ggs_Rhat(S) + xlab(\"R_hat\") + xlim(0.95, 1.05)"
  },
  {
    "objectID": "041_mcmc_diagnostics.html#diagnostica-di-convergenza-di-geweke",
    "href": "041_mcmc_diagnostics.html#diagnostica-di-convergenza-di-geweke",
    "title": "21¬† Diagnostica delle catene markoviane",
    "section": "\n21.6 Diagnostica di convergenza di Geweke",
    "text": "21.6 Diagnostica di convergenza di Geweke\nLa statistica diagnostica di convergenza di Geweke √® basata su un test per l‚Äôuguaglianza delle medie della prima e dell‚Äôultima parte di una catena di Markov (di default il primo 10% e l‚Äôultimo 50% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.\nUtilizzando l‚Äôoggetto stanfit1, possiamo recuperare la statistica di Geweke nel modo seguente:\n\nCodicefit_mcmc <- As.mcmc.list(\n  stanfit1,\n  pars = c(\"theta\")\n)\ncoda::geweke.diag(fit_mcmc, frac1 = .1, frac2 = .5) \n#> [[1]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>  theta \n#> -0.017 \n#> \n#> \n#> [[2]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>  theta \n#> 0.6504 \n#> \n#> \n#> [[3]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#>    theta \n#> -0.04024 \n#> \n#> \n#> [[4]]\n#> \n#> Fraction in 1st window = 0.1\n#> Fraction in 2nd window = 0.5 \n#> \n#> theta \n#> 1.315\n\n\nPer interpretare questi valori ricordiamo che la statistica di Geweke √® uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali. Valori maggiori di \\(\\mid 2 \\mid\\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.\n\n\n\n\n\n\nGautret, P., Lagier, J. C., Parola, P., Meddeb, L., Mailhe, M., Doudier, B., & Honor√©, S. (2020). Hydroxychloroquine and azithromycin as a treatment of COVID-19: Results of an open-label non-randomized clinical trial. International Journal of Antimicrobial Agents.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press."
  },
  {
    "objectID": "045_summarize_posterior.html",
    "href": "045_summarize_posterior.html",
    "title": "22¬† Sintesi a posteriori",
    "section": "",
    "text": "La distribuzione a posteriori descrive il nostro grado di incertezza rispetto al parametro incognito (o rispetto ai parametri incogniti) oggetto dell‚Äôinferenza. La distribuzione a posteriori contiene tutte le informazioni disponibili sui possibili valori del parametro. Se il parametro esaminato √® monodimensionale (o bidimensionale) √® possibile fornire un grafico di tutta la distribuzione a posteriori \\(p(\\theta \\mid y)\\). Tuttavia, spesso vogliamo anche giungere ad una sintesi numerica della distribuzione a posteriori, soprattutto se il vettore dei parametri ha pi√π di due dimensioni. A questo fine possono essere utilizzate le consuete statistiche descrittive, come media, mediana, moda, varianza, deviazione standard e i quantili. In alcuni casi, queste statistiche descrittive sono pi√π facili da presentare e interpretare rispetto alla rappresentazione grafica della distribuzione a posteriori.\nLa stima puntuale della tendenza centrale della distribuzione a posteriori fornisce informazioni su quello che pu√≤ essere considerato come il ‚Äúvalore pi√π credibile‚Äù del parametro. L‚Äôintervallo di credibilit√† fornisce invece un‚Äôindicazione dell‚Äôampiezza dell‚Äôintervallo che contiene una determinata quota della massa della distribuzione a posteriori del parametro."
  },
  {
    "objectID": "045_summarize_posterior.html#stima-puntuale",
    "href": "045_summarize_posterior.html#stima-puntuale",
    "title": "22¬† Sintesi a posteriori",
    "section": "\n22.1 Stima puntuale",
    "text": "22.1 Stima puntuale\nPer sintetizzare la distribuzione a posteriori in modo da giungere ad una stima puntuale di \\(\\theta\\) si √® soliti scegliere tra moda, mediana o media a seconda del tipo di distribuzione con cui si ha a che fare e della sua forma. A moda, mediana e media a posteriori possiamo attribuire interpretazioni diverse.\n\nLa media √® il valore atteso a posteriori del parametro.\nLa moda pu√≤ essere interpretata come il singolo valore pi√π credibile del parametro, alla luce dei dati, ovvero il valore che massimizza la distribuzione a posteriori del parametro \\(\\theta\\). Per questa ragione la moda viene detta massimo a posteriori, MAP. Il limite della moda quale statistica riassuntiva della distribuzione a posteriori √® che, talvolta, la distribuzione a posteriori √® multimodale e il MAP non √® necessariamente il valore ‚Äúpi√π credibile‚Äù.\nLa mediana √® il valore del parametro tale per cui, su entrambi i lati di essa, giace il 50% della massa di probabilit√† a posteriori.\n\nLa misura di variabilit√† del parametro √® la varianza a posteriori la quale, nel caso di una distribuzione a posteriori ottenuta per via numerica, si calcola con la formula della varianza che conosciamo rispetto alla tendenza centrale data dalla media a posteriori. La radice quadrata della varianza a posteriori √® la deviazione standard a posteriori che descrive l‚Äôincertezza a posteriori circa il parametro di interesse nella stessa unit√† di misura dei dati.\nLe procedure bayesiane basate sui metodi MCMC utilizzano un numero finito di campioni dalla distribuzione stazionaria, e una tale caratteristica della simulazione introduce un ulteriore livello di incertezza nella stima del parametro. L‚Äôerrore standard della stima (in inglese Monte Carlo standard error, MCSE) misura l‚Äôaccuratezza della simulazione. La deviazione standard a posteriori e l‚Äôerrore standard della stima sono due concetti completamente diversi. La deviazione standard a posteriori descrive l‚Äôincertezza circa il parametro (l‚Äôampiezza della distribuzione a posteriori) ed √® una funzione della dimensione del campione; il MCSE descrive invece l‚Äôincertezza nella stima del parametro dovuta alla simulazione MCMC ed √® una funzione del numero di iterazioni nella simulazione."
  },
  {
    "objectID": "045_summarize_posterior.html#intervallo-di-credibilit√†",
    "href": "045_summarize_posterior.html#intervallo-di-credibilit√†",
    "title": "22¬† Sintesi a posteriori",
    "section": "\n22.2 Intervallo di credibilit√†",
    "text": "22.2 Intervallo di credibilit√†\nMolto spesso la stima puntuale √® accompagnata da una stima intervallare (abbiamo gi√† incontrato questo aspetto nel Capitolo Capitolo¬†17 discutendo lo schema beta-binomiale). Nella statistica bayesiana, se il parametro \\(\\theta \\in \\Theta\\) √® monodimensionale, si dice intervallo di credibilit√† un intervallo di valori \\(I_{\\alpha}\\) che contiene la proporzione \\(1 - \\alpha\\) della massa di probabilit√† della funzione a posteriori:\n\\[\np(\\Theta \\in I_{\\alpha} \\mid y) = 1 - \\alpha.\n\\tag{22.1}\\]\nL‚Äôintervallo di credibilit√† ha lo scopo di esprimere il nostro grado di incertezza riguardo la stima del parametro. Se il parametro \\(\\theta\\) √® multidimensionale, si parla invece di ‚Äúregione di credibilit√†‚Äù.\nL‚ÄôEquazione¬†22.1 non determina un unico intervallo di credibilit√† di ordine \\((1 - \\alpha) \\cdot 100\\%\\). In realt√† esiste un numero infinito di tali intervalli. Ci√≤ significa che dobbiamo definire alcune condizioni aggiuntive per la scelta dell‚Äôintervallo di credibilit√†. Esaminiamo due delle condizioni aggiuntive pi√π comuni.\n\n22.2.1 Intervallo di credibilit√† a code uguali\nUn intervallo di credibilit√† a code uguali a livello \\(\\alpha\\) √® un intervallo\n\\[\nI_{\\alpha} = [q_{\\alpha/2}, 1 - q_{\\alpha/2}],\n\\]\ndove \\(q_z\\) √® un quantile \\(z\\) della distribuzione a posteriori. Per esempio, l‚Äôintervallo di credibilit√† a code uguali al 95% √® un intervallo\n\\[\nI_{0.05} = [q_{0.025}, q_{0.975}]\n\\]\nche lascia il 2.5% della massa di densit√† a posteriori in ciascuna coda.\n\n22.2.2 Intervallo di credibilit√† a densit√† a posteriori pi√π alta\nNell‚Äôintervallo di credibilit√† a code uguali alcuni valori del parametro che sono inclusi nell‚Äôintervallo possono avere una credibilit√† a posteriori pi√π bassa rispetto a quelli esterni all‚Äôintervallo. L‚Äôintrevallo di credibilit√† a densit√† a posteriori pi√π alta (in inglese High Posterior Density Interval, HPD) √® invece costruito in modo tale da assicurare di includere nell‚Äôintervallo tutti i valori \\(\\theta\\) che sono a posteriori maggiormente credibili. Graficamente questo intervallo pu√≤ essere ricavato tracciando una linea orizzontale sulla rappresentazione della distribuzione a posteriori e regolando l‚Äôaltezza della linea in modo tale che l‚Äôarea sottesa alla curva sia pari a \\(1 - \\alpha\\). Questo tipo di intervallo √® il pi√π stretto possibile, tra tutti i possibili intervalli di credibilit√† allo stesso livello di fiducia. Se la distribuzione a posteriori √® simmetrica unimodale, l‚Äôintervallo di credibilit√† a densit√† a posteriori pi√π alta corrisponde all‚Äôintervallo di credibilit√† a code uguali.\n\n22.2.3 Interpretazione\nL‚Äôinterpretazione dell‚Äôintervallo di credibilit√† √® molto intuitiva: l‚Äôintervallo di credibilit√† √® un intervallo di valori all‚Äôinterno del quale cade il valore del parametro incognito con un particolare livello di probabilit√† soggettiva. Possiamo dire che, dopo aver visto i dati crediamo, con un determinato livello di probabilit√† soggettiva, che il valore del parametro (ad esempio, la dimensione dell‚Äôeffetto di un trattamento) abbia un valore compreso all‚Äôinterno dell‚Äôintervallo che √® stato calcolato, laddove per probabilit√† soggettiva intendiamo ‚Äúil grado di fiducia che lo sperimentatore ripone nel verificarsi di un evento‚Äù. Gli intervalli di credibilit√† si calcolano con un software."
  },
  {
    "objectID": "045_summarize_posterior.html#un-esempio-concreto",
    "href": "045_summarize_posterior.html#un-esempio-concreto",
    "title": "22¬† Sintesi a posteriori",
    "section": "\n22.3 Un esempio concreto",
    "text": "22.3 Un esempio concreto\nPer fare un esempio pratico, consideriamo nuovamente i valori del BDI-II dei 30 soggetti clinici di Zetsche et al. (2019).\n\nCodicedf <- tibble(\n  y = c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43, \n        24, 19, 39, 31, 25, 28, 35, 30, 26, 31, \n        41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\n)\n\n\nUn valore BDI-II \\(\\geq 30\\) indica la presenza di un livello grave di depressione. Nel campione clinico di Zetsche et al. (2019), 17 pazienti su 30 manifestano un livello grave di depressione.\n\nCodicesum(df$y > 29)\n#> [1] 17\n\n\nSupponiamo di volere stimare la distribuzione a posteriori della probabilit√† \\(\\theta\\) di depressione grave nei pazienti clinici, cos√¨ come viene misurata dal test BDI-II, imponendo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(8, 2)\\).\nSappiamo che il modello Beta-Binomiale pu√≤ essere espresso nella forma seguente:\n\\[\n\\begin{align}\nY | \\theta & \\sim \\mbox{Bin}(30, \\theta) \\notag\\\\\n\\theta & \\sim \\mbox{Beta}(8, 2) \\notag\n\\end{align}\n\\]\nLa corrispondente distribuzione a posteriori √® una \\(\\mbox{Beta}(25, 15)\\).\n\\[\n\\begin{equation}\nf(\\theta | y = 17) = \\frac{\\Gamma(25 + 15)}{\\Gamma(25)\\Gamma(15)}\\theta^{25-1} (1-\\theta)^{15-1} \\;\\; \\text{ for } \\theta \\in [0,1] \\; .\n\\end{equation}\n\\tag{22.2}\\]\n\nCodiceplot_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30)\n\n\n\n\n\n\n\n\n22.3.1 Stime puntuali della distribuzione a posteriori\nUna volta trovata l‚Äôintera distribuzione a posteriori, quale valore di sintesi √® necessario riportare? Questa sembra una domanda innocente, ma in realt√† √® una domanda a cui √® difficile rispondere. La stima bayesiana dei parametri √® fornita dall‚Äôintera distribuzione a posteriori, ovvero non da un singolo numero, ma da una funzione che mappa ciascun valore del parametro ad un valore di credibilit√†. Non √® quindi necessario scegliere una stima puntuale: in linea di principio, una stima puntuale non √® quasi mai necessaria ed √® spesso dannosa in quanto comporta una perdita di informazioni.\nTuttavia, talvolta una tale sintesi √® richiesta. Diverse risposte sono allora possibili. La media della distribuzione a posteriori per \\(\\theta\\) per il presente esempio √®\n\\[\n\\mathbb{E}(\\pi \\mid y = 17) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{25}{25+15} = 0.625.\n\\]\nUna stima del massimo della probabilit√† a posteriori, o brevemente massimo a posteriori, MAP (da maximum a posteriori probability), √® la moda della distribuzione a posteriori. Nel caso presente, abbiamo\n\\[\n\\mbox{Mo}(\\pi \\mid y = 17) = \\frac{\\alpha-1}{\\alpha + \\beta-2} = \\frac{25-1}{25+15-2} = 0.6316.\n\\]\nGli stessi risultati si ottiengono usando la chiamata a bayesrules::summarize_beta_binomial().\n\nCodicesummarize_beta_binomial(alpha = 8, beta = 2, y = 17, n = 30)\n#>       model alpha beta  mean      mode         var        sd\n#> 1     prior     8    2 0.800 0.8750000 0.014545455 0.1206045\n#> 2 posterior    25   15 0.625 0.6315789 0.005716463 0.0756073\n\n\nLa mediana si ottiene con qbeta().\n\nCodiceqbeta(.5, shape1 = 25, shape2 = 15)\n#> [1] 0.6271031\n\n\n\n22.3.2 Intervallo di credibilit√†\n√à comune sintetizzare la distribuzione a posteriori mediante l‚Äôintervallo di credibilit√†. Per esempio, l‚Äôintervallo di credibilit√† a code uguali al 95% √® dato dalla chiamata a qbeta().\n\nCodiceplot_beta_ci(alpha = 25, beta = 15, ci_level = 0.95)\n\n\n\n\n\n\n\n\nCodiceqbeta(c(0.025, 0.975), 25, 15)\n#> [1] 0.4717951 0.7663607\n\n\nIl calcolo precedente evidenzia l‚Äôinterpretazione intuitiva dell‚Äôintervallo di credibilit√†. Tale intervallo, infatti, pu√≤ essere interpretato nel modo seguente: possiamo attribuire una certezza soggettia del 95% all‚Äôevento che \\(\\theta\\) assuma un valore compreso tra 0.472 e 0.766.\nIl valore di 0.95 corrisponde all‚Äôarea sottesa dalla distribuzione a posteriori nell‚Äôintervallo [0.472, 0.766].\n\\[\nP(\\theta \\in (0.472, 0.766) | Y = 17) = \\int_{0.472}^{0.766} f(\\theta \\mid y=17) d\\theta = 0.95\n\\]\n\nCodicepostFun <- function(theta) {\n  gamma(25 + 15) / \n    (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14\n}\nintegrate(\n  postFun, \n  lower = 0.4717951, \n  upper = 0.7663607\n)$value\n#> [1] 0.95\n\n\nPossiamo costruire diversi intervalli di credibilit√† a code equivalenti. Ad esempio, l‚Äôintervallo di credibilit√† compreso tra il 25-esimo e il 75-esimo percentile.\n\nCodiceqbeta(c(0.25, 0.75), 25, 15)\n#> [1] 0.5743878 0.6778673\n\n\nIn questo secondo caso, possiamo dire abbiamo una certezza soggettiva a posteriori del 50% che la probabilit√† di depressione grave tra i pazienti clinici sia un valore compreso tra 0.57 e 0.68.\nNon esiste un livello ‚Äúcorretto‚Äù di credibilit√† soggettiva. I ricercatori utilizzano livelli diversi, ad esempio il 50%, l‚Äô80% o il 95%, a seconda del contesto dell‚Äôanalisi statistica. Ciascuno di questi intervalli fornisce un‚Äôimmagine diversa della nostra comprensione della distribuzione a posteriori del parametro di interesse.\nNon √® sempre appropriato riportare l‚Äôintervallo di credibilit√† a code uguali. Se la distribuzione a posteriori √® fortemente asimmetrica √® pi√π appropriato riportare l‚Äôintervallo di credibilit√† a densit√† a posteriori pi√π alta (HPD). L‚Äôintervallo HPD risulta pi√π semplice da determinare quando la distribuzione a posteriori viene approssimata con il metodo MCMC.\n\n22.3.3 Probabilit√† della distribuzione a posteriori\nIl test di ipotesi √® un compito comune dell‚Äôanalisi della distribuzione a posteriori (si veda anche il Capitolo¬†17). Supponiamo che si voglia conoscere la probabilit√† a posteriori che \\(\\theta\\) sia superiore a 0.5. Per sapere quanto pu√≤ essere ritenuto credibile l‚Äôevento \\(\\theta > 0.5\\) possiamo calcolare il seguente integrale:\n\\[\nP(\\theta > 0.5 \\; \\mid \\; y = 17) = \\int_{0.5}^{1}f(\\theta \\mid y=17)d\\theta \\;,\n\\]\ndove \\(f(\\cdot)\\) √® la distribuzione \\(\\mbox{Beta}(25, 15)\\).\n\nCodicepbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE)\n#> [1] 0.9459355\n\n\n\nCodicepostFun <- function(theta) {\n  gamma(25 + 15) / (gamma(25) * gamma(15)) * theta^24 * (1 - theta)^14\n}\nintegrate(\n  postFun, \n  lower = 0.5, \n  upper = 1\n)$value\n#> [1] 0.9459355\n\n\n\n22.3.3.1 Fattore di Bayes\n√à anche possibile formulare un test di ipotesi contrastando due ipotesi contrapposte. Per esempio, \\(H_1: \\theta \\geq 0.5\\) e \\(H_2: \\theta < 0.5\\). Ci√≤ consente di calcolare l‚Äôodds a posteriori di \\(\\theta > 0.5\\):\n\\[\n\\begin{equation}\n\\text{poterior odds} = \\frac{H_1 \\mid y = 17}{H_2 \\mid y = 17}.\n\\end{equation}\n\\]\n\nCodiceposterior_odds <- \n  pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 25, shape2 = 15, lower.tail = TRUE)\nposterior_odds\n#> [1] 17.49642\n\n\nL‚Äôodds a posteriori rappresenta l‚Äôaggiornamento delle nostre credenze dopo avere osservato \\(y = 17\\) in \\(n = 30\\).\nNel caso presente, l‚Äôodds a priori di \\(\\theta > 0.5\\) era pari a 50.2.\n\nCodiceprior_odds <- \n  pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 8, shape2 = 2, lower.tail = TRUE)\nprior_odds\n#> [1] 50.2\n\n\nIl fattore di Bayes (Bayes Factor; BF) confronta gli odds a posteriori con gli odds a priori e fornisce informazioni su quanto sia mutata la nostra comprensione relativa a \\(\\theta\\) dopo avere osservato i nostri dati del campione:\n\\[\n\\text{BF} = \\frac{\\text{odds a posteriori}}{\\text{odds a priori}}.\n\\]\nNel caso presente otteniamo un valore di 0.35.\n\nCodiceBF <- posterior_odds / prior_odds\nBF\n#> [1] 0.3485343\n\n\nQuindi, dopo avere osservato i dati, gli odds a posteriori della nostra ipotesi a proposito di \\(\\theta\\) sono pari a solo il 34% degli odds a priori.\nPer fare un altro esempio, consideriamo il caso in cui le credenze a priori rivelano una credenza diametralmente opposta rispetto a \\(\\theta\\) rispetto al caso precedente: prima avevamo \\(\\mbox{Beta}(8, 2)\\) mentre ora imponiamo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 8)\\)). Con una tale scelta della distribuzione a priori, la distribuzione a posteriori diventa una \\(\\mbox{Beta}(19, 21)\\).\n\nCodicesummarize_beta_binomial(alpha = 2, beta = 8, y = 17, n = 30)\n#>       model alpha beta  mean      mode         var         sd\n#> 1     prior     2    8 0.200 0.1250000 0.014545455 0.12060454\n#> 2 posterior    19   21 0.475 0.4736842 0.006082317 0.07798921\n\n\nCon questa diversa distribuzione a priori, il BF √® uguale a 30.07.\n\nCodiceposterior_odds <- \n  pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 19, shape2 = 21, lower.tail = TRUE)\n\nprior_odds <- \n  pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = FALSE) /\n  pbeta(0.5, shape1 = 2, shape2 = 8, lower.tail = TRUE)\n\nBF <- posterior_odds / prior_odds\nBF\n#> [1] 30.07239\n\n\nIn alre parole, in questo secondo esempio gli odds a posteriori della nostra ipotesi a proposito di \\(\\theta\\) sono aumentati di 30 volte rispetto agli odds a priori.\nIn generale, in un test di ipotesi che contrappone un‚Äôipotesi sostantiva \\(H_a\\) ad un‚Äôipotesi nulla \\(H_0\\) il BF √® un rapporto di odds per l‚Äôipotesi sostantiva:\n\\[\n\\text{BF}\n= \\frac{\\text{posterior odds}}{\\text{prior odds}}\n= \\frac{P(H_a \\mid Y) / P(H_0 \\mid Y)}{P(H_a) / P(H_0)}\n\\; .\n\\]\n\n22.3.3.2 Interpretazione del fattore di Bayes\nEssendo un rapporto, il BF deve essere valutato rispetto al valore di 1. Ci sono tre possibilit√†:\n\nBF = 1: La credibilit√† di \\(H_a\\) non √® cambiata dopo avere osservato i dati.\nBF > 1: La credibilit√† di \\(H_a\\) √® aumentata dopo avere osservato i dati. Quindi maggiore √® BF, pi√π convincente risulta l‚Äôevidenza per \\(H_a\\).\nBF < 1: La credibilit√† di \\(H_a\\) √® diminuita dopo avere osservato i dati.\n\nNon ci sono delle soglie universalmente riconosciute per interpretare il BF, ma uno schema popolare, proposto da Lee & Wagenmakers (2014), √® il seguente:\n\n\nBF\nInterpretation\n\n\n\n> 100\nExtreme evidence for \\(H_a\\)\n\n\n\n30 - 100\nVery strong evidence for \\(H_a\\)\n\n\n\n10 - 30\nStrong evidence for \\(H_a\\)\n\n\n\n3 - 10\nModerate evidence for \\(H_a\\)\n\n\n\n1 - 3\nAnecdotal evidence for \\(H_a\\)\n\n\n\n1\nNo evidence\n\n\n1/3 - 1\nAnecdotal evidence for \\(H_0\\)\n\n\n\n1/10 - 1/3\nModerate evidence for \\(H_0\\)\n\n\n\n1/30 - 1/10\nStrong evidence for \\(H_0\\)\n\n\n\n1/100 - 1/30\nVery strong evidence for \\(H_0\\)\n\n\n\n< 1/100\nExtreme evidence for \\(H_0\\)\n\n\n\n\n22.3.3.3 Limiti del fattore di Bayes\n√à importante notare che l‚Äôopinione maggiormente diffusa nella comunit√† scientifica incoraggia a non trarre conclusioni rigide dai dati utilizzando dei criteri fissati una volta per tutte. √à stato ripetuto molte volte che l‚Äôesame di tutta la distribuzione a posteriori fornisce una misura olistica del nostro livello di incertezza riguardo all‚Äôaffermazione (il parametro, ovvero l‚Äôipotesi) che viene valutata e, dunque, √® molto pi√π informativo di una decisione binaria. Non √® dunque possibile stabilire una soglia univoca per il BF che consenta di classificare le ipotesi dei ricercatori in una delle due categorie ‚Äúvero‚Äù o ‚Äúfalso‚Äù. Invece, √® pi√π utile adottare una pratica interpretativa pi√π flessibile in grado di tenere in considerazione il contesto e le potenziali implicazioni di ogni singolo test di ipotesi.\nLa discussione precedente mette inoltre in evidenza come il BF dipenda fortemente dalle caratteristiche della distribuzione a priori. Dato che la la distribuzione a priori √® una scelta arbitraria del ricercatore, da ci√≤ consegue che il BF contiene una componente intrinseca di arbitrariet√†. Questo aspetto, tuttavia, √® incompatibile con l‚Äôidea di un confronto con delle soglie ‚Äúassolute‚Äù."
  },
  {
    "objectID": "045_summarize_posterior.html#la-funzione-di-perdita-attesa",
    "href": "045_summarize_posterior.html#la-funzione-di-perdita-attesa",
    "title": "22¬† Sintesi a posteriori",
    "section": "\n22.4 La funzione di perdita attesa",
    "text": "22.4 La funzione di perdita attesa\nIn generale, il modo pi√π razionale per giungere ad una decisione statistica utilizzando l‚Äôintera distribuzione a posteriori √® quello di usare la funzione di perdita (loss function). La funzione di perdita √® un concetto nella teoria delle decisioni statistiche e consente di quantificare il costo che deriva dalla decisione di scegliere il valore \\(\\theta_0\\) quale stima del parametro, quando in realt√† il parametro ha il valore \\(\\theta\\).\nPer chiarire che cosa si intende per funzione di perdita, esaminiamo qui un semplice esempio nel quale vengono considerati due soli valori di probabilit√† per l‚Äôevento target, anzich√© l‚Äôintera distribuzione a posteriori (il codice √® ricavato da Schmettow, 2021).\nSi consideri la scelta di prendere o meno l‚Äôombrello nell‚Äôuscire di casa. Le previsioni del tempo sono indicate di seguito.\n\nCodiceRisultato <-\n  tibble(\n    risultato = c(\"piove\", \"non piove\"),\n    prob = c(0.6, 0.4)\n  )\nRisultato\n#> # A tibble: 2 √ó 2\n#>   risultato  prob\n#>   <chr>     <dbl>\n#> 1 piove       0.6\n#> 2 non piove   0.4\n\n\nLe azioni possibili sono: prendo l‚Äôombrello / non prendo l‚Äôombrello.\n\nCodiceAzione <-\n  tibble(azione = c(\"prendo l'ombrello\", \"non prendo l'ombrello\"))\nAzione\n#> # A tibble: 2 √ó 1\n#>   azione               \n#>   <chr>                \n#> 1 prendo l'ombrello    \n#> 2 non prendo l'ombrello\n\n\nAssegniamo un costo massimo (4) alla conseguenza peggiore (‚Äúnon prendo l‚Äôombrello e piove‚Äù) e uno minimo (0) alla conseguenza migliore (‚Äúnon prendo l‚Äôombrello e non piove‚Äù).\n\nCodiceCosti <-\n  expand.grid(\n    azione = Azione$azione,\n    risultato = Risultato$risultato\n  ) %>%\n  inner_join(Risultato) %>%\n  mutate(costo = c(2, 4, 2, 0))\nCosti\n#>                  azione risultato prob costo\n#> 1     prendo l'ombrello     piove  0.6     2\n#> 2 non prendo l'ombrello     piove  0.6     4\n#> 3     prendo l'ombrello non piove  0.4     2\n#> 4 non prendo l'ombrello non piove  0.4     0\n\n\nCalcoliamo ora il costo atteso delle due azioni tenuto conto delle probabilit√† che si verifichi l‚Äôuno o l‚Äôaltro stato del mondo. In altre parole ponderiamo il costo di ogni azione con la probabilit√† che si verifichi l‚Äôevento corrispondente.\n\nCodiceUtil <-\n  Costi %>%\n  mutate(costo_condizionato = prob * costo) %>%\n  group_by(azione) %>%\n  summarise(costo_atteso = sum(costo_condizionato))\nUtil\n#> # A tibble: 2 √ó 2\n#>   azione                costo_atteso\n#>   <fct>                        <dbl>\n#> 1 prendo l'ombrello              2  \n#> 2 non prendo l'ombrello          2.4\n\n\nLa regola della minimizzazione dei costi ci porta a scegliere l‚Äôalternativa che comporta il costo minore: nel nostro esempio, questo corrisponde all‚Äôazione ‚Äúprendere l‚Äôombrello‚Äù.\nLa stessa logica dell‚Äôesempio qui discusso pu√≤ essere usata anche quando, anzich√© avere solo due valori per la probabilit√† dello stato del mondo (piover√† / non piover√†), utilizziamo l‚Äôintera distribuzione a posteriori (per esempio, quella relativa alla previsione di pioggia). Concludiamo questi brevi accenni relativi alla funzione di perdita con una considerazione di McElreath (2020): anche se gli statistici e i teorici dei giochi sono da tempo interessati alle funzioni di perdita e alle relazioni che intercorrono tra esse e l‚Äôinferenza bayesiana, i ricercatori non le usano quasi mai in modo esplicito."
  },
  {
    "objectID": "045_summarize_posterior.html#commenti-e-considerazioni-finali",
    "href": "045_summarize_posterior.html#commenti-e-considerazioni-finali",
    "title": "22¬† Sintesi a posteriori",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nQuesto capitolo introduce le procedure di base per la manipolazione della distribuzione a posteriori. Lo strumento fondamentale che √® stato utilizzato √® quello fornito dai campioni di valori del parametro che vengono estratti dalla distribuzione a posteriori. Lavorare con campioni di valori del parametro estratti dalla distribuzione a posteriori trasforma un problema di calcolo integrale in un problema di riepilogo dei dati. Abbiamo visto le procedure maggiormente usate che consentono di utilizzare i campioni a posteriori per produrre indici di sintesi della distribuzione a posteriori: gli intervalli di credibilit√† e le stime puntuali.\n\n\n\n\n\n\nLee, M. D., & Wagenmakers, E.-J. (2014). Bayesian cognitive modeling: A practical course. Cambridge university press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSchmettow, M. (2021). New statistics for design researchers. Springer.\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "046_bayesian_prediction.html",
    "href": "046_bayesian_prediction.html",
    "title": "23¬† La predizione bayesiana",
    "section": "",
    "text": "Oltre ad una sintesi della distribuzione a posteriori attraverso il computo di indici caratteristici e alla verifica di ipotesi, un altro compito dell‚Äôanalisi bayesiana √® la predizione di nuovi dati futuri. Dopo aver osservato i dati di un campione e dopo avere ricavato le distribuzioni a posteriori dei parametri, √® infatti possibile ottenere delle indicazioni sulle propriet√† di dati futuri. L‚Äôuso pi√π immediato della stima della distribuzione dei possibili valori futuri della variabile di esito √® la verifica del modello in esame. Infatti, il modo pi√π diretto per testare un modello √® quello di utilizzare il modello corrente per fare previsioni sui possibili dati futuri per poi confrontare i dati predetti con i dati che sono stati effettivamente osservati nel campione corrente. Questa pratica va sotto il nome di controllo predittivo a posteriori. In questo capitolo ci focalizzeremo sul problema della predizione bayesiana esaminando il caso pi√π semplice, ovvero lo schema beta-binomiale. In seguito estenderemo questa discussione al caso generale."
  },
  {
    "objectID": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "href": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori",
    "title": "23¬† La predizione bayesiana",
    "section": "\n23.1 La distribuzione predittiva a posteriori",
    "text": "23.1 La distribuzione predittiva a posteriori\nUna volta costruita la distribuzione a posteriori del parametro o dei parametri sconosciuti, potremmo essere interessati a utilizzare il modello bayesiano allo scopo di prevedere la probabilit√† di risultati futuri basandoci sui dati gi√† osservati. Questo tipo di analisi inferenziale va sotto il nome di analisi predittiva.\nL‚Äôesempio che considereremo qui nei dettagli riguarda il caso beta-binomiale, nel quale la distribuzione a priori per il parametro ignoto \\(\\theta\\) (ovvero, la probabilit√† di successo) √® una distribuzione Beta, la verosimiglianza √® binomiale e i dati sono costituiti dal numero \\(y\\) di successi in \\(n\\) prove Bernoulliane indipendenti. Nell‚Äôesempio che discuteremo useremo un‚Äôaltra volta i dati del campione di pazienti clinici depressi di Zetsche et al. (2019). Supponendo di volere esaminare in futuro altri \\(m\\) pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave?\nSiamo dunque interessati a predire i risultati che si potrebbero osservare in nuovi campioni di \\(m = 30\\) osservazioni. Denotiamo con \\(\\tilde{y}\\) la manifestazione della variabile casuale \\(\\tilde{Y}\\). In un nuovo campione di \\(m\\) osservazioni, \\(\\tilde{y}\\) assumer√† il valore \\(\\tilde{y}_1\\) (ad es., 12), in un altro campione assumer√† il valore \\(\\tilde{y}_2\\) (ad es., 23), e cos√¨ via. Siamo interessati a descrivere la probabilit√† che \\(\\tilde{y}\\) assuma i valori \\(0, 1, 2, \\dots, 29, 30\\). Tale distribuzione (in questo caso) di massa di probabilit√† si chiama distribuzione predittiva a posteriori \\(p(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\) e corrisponde alla probabilit√† assegnata a ciascuno dei possibili valori \\(\\tilde{y}\\) (\\(0, 1, 2, \\dots, 29, 30\\)) nei possibili campioni futuri di \\(m\\) osservazioni.\nIn questo Capitolo ci porremo il problema di trovare la distribuzione predittiva a posteriori nel caso beta-binomiale. Useremo tre metodi diversi:\n\nla soluzione analitica,\ni risultati di una simulazione,\nil campionamento MCMC.\n\nI tre metodi producono risultati equivalenti. In seguito useremo il metodo MCMC perch√© ci consente di trovare facilmente la risposta cercata, anche quando una soluzione analitica non √® disponibile."
  },
  {
    "objectID": "046_bayesian_prediction.html#soluzione-analitica",
    "href": "046_bayesian_prediction.html#soluzione-analitica",
    "title": "23¬† La predizione bayesiana",
    "section": "\n23.2 Soluzione analitica",
    "text": "23.2 Soluzione analitica\nNel caso dell‚Äôesempio in discussione, la distribuzione di \\(\\tilde{Y}\\) dipende da \\(\\theta\\) e ci√≤ che sappiamo di \\(\\theta\\) √® sintetizzato nella distribuzione a posteriori \\(p(\\theta \\mid y)\\). Usando la regola della catena, possiamo scrivere la distribuzione congiunta di \\(\\tilde{y}\\) e \\(\\theta\\) nel modo seguente\n\\[\\begin{equation}\np(\\tilde{y}, \\theta \\mid y) = p(\\tilde{y} \\mid \\theta, y) p(\\theta \\mid y).\n\\end{equation}\\]\nAssumendo che le osservazioni future \\(\\tilde{y}\\) e passate \\(y\\) siano condizionalmente indipendenti dato \\(\\theta\\), l‚Äôespressione precedente pu√≤ essere scritta come\n\\[\\begin{equation}\np(\\tilde{y}, \\theta \\mid y) = p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y).\n\\end{equation}\\]\nLa distribuzione predittiva a posteriori viene ottenuta dalla distribuzione congiunta di \\(\\tilde{y}\\) e \\(\\theta\\) integrando rispetto a \\(\\theta\\):\n\\[\\begin{equation}\np(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta.\n(\\#eq:post-pred-distr)\n\\end{equation}\\]\nNel caso dello schema beta-binomiale, la funzione \\(p(\\tilde{y} \\mid \\theta)\\) √® binomiale di parametri \\(m\\) e \\(\\theta\\), e la distribuzione a posteriori \\(p(\\theta \\mid y)\\) √® una \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\). Risolvendo l‚Äôintegrale otteniamo:\n\\[\\begin{align}\np(\\tilde{y} \\mid y) &= \\int_0^1 p(\\tilde{y} \\mid \\theta)\np(\\theta \\mid y)\\,\\operatorname {d}\\!\\theta \\notag\\\\\n&= \\int_0^1 \\begin{pmatrix}m\\\\\\tilde{y}\\end{pmatrix}\n\\theta^{\\tilde{y}}\n(1-\\theta)^{m-\\tilde{y}} \\, \\mbox{Beta}(a+y,b+n-y) \\, d\\theta \\notag\\\\\n&= \\begin{pmatrix}{m}\\\\\\tilde{y}\\end{pmatrix} \\int_0^1 \\theta^{\\tilde{y}}\n(1-\\theta)^{m-\\tilde{y}} \\frac{1}{B(a+y, b+n-y)}\\theta^{a+y-1}(1-\\theta)^{b+n-y-1}\\notag\\\\\n&= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{1}{B(a+y, b+n-y)}\\int_0^1 \\theta^{\\tilde{y}+a+y-1}(1-\\theta)^{m-\\tilde{y}+b+n-y-1}\\notag\\\\\n&= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{B(\\tilde{y}+a+y,b+n-y+m-\\tilde{y})}{B(a+y, b+n-y)} \\; .\n(\\#eq:post-yprime-an-sol-betabin)\n\\end{align}\\]\nIn conclusione, per lo schema beta-binomiale, la distribuzione predittiva a posteriori √®\n\\[\\begin{equation}\nf(\\tilde{y} \\mid y) = \\binom{m}{\\tilde{y}} \\frac{B(a+ y + \\tilde{y}, b + n - y + m - \\tilde{y})}{B(a+y, b+n-y)},\n(\\#eq:beta-binomial-distr)\n\\end{equation}\\]\novvero, corrisponde ad una distribuzione di probabilit√† discreta chiamata distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\).\nNell‚Äôesempio relativo allo studio di Zetsche et al. (2019), la verosimiglianza √® binomiale, i dati sono costituiti da 23 successi su 30 prove e la distribuzione a priori su \\(\\theta\\) √® \\(\\mbox{Beta}(2, 10)\\). Di conseguenza, la distribuzione a posteriori √® \\(\\mbox{Beta}(25, 17)\\). Vogliamo calcolare la distribuzione predittiva a posteriori per un nuovo campione, poniamo, di \\(m = 30\\) osservazioni (ma, in generale, \\(m\\) pu√≤ essere diverso da \\(n\\)).\nIn base alla @ref(eq:beta-binomial-distr) sappiamo che la distribuzione predittiva a posteriori √® una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\), dove \\(m\\) √® il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le propriet√† del campione corrente. Nel caso dell‚Äôesempio in discussione, \\(m = 30\\), \\(\\alpha = 2 + 23 = 25\\), \\(\\beta = 10 + 30 - 23 = 17\\). Possiamo svolgere i calcoli necessario usando le funzioni del pacchetto extraDistr. Per i parametri specificati sopra, un grafico della distribuzione predittiva a posteriori si ottiene nel modo seguente:\n\nCodiceprob <- extraDistr::dbbinom(0:30, 30, 25, 17)\ntibble(Y=0:30, Probability = prob) %>% \n  ProbBayes::prob_plot(Color = \"black\")\n\n\n\n\n\n\n\nLa distribuzione predittiva a posteriori illustrata nella figura precedente ci dice qual √® la plausibilit√† relativa di osservare \\(0, 1, \\dots, 30\\) successi su \\(m = 30\\) prove in un futuro campione di osservazioni, alla luce dei dati che abbiamo osservato nel campione corrente (23 successi in 30 prove) e tenuto conto delle nostre opinioni a priori sulla plausibilit√† dei possibili valori \\(\\theta\\) (ovvero, \\(\\mbox{Beta}(2, 10)\\)).\nEsaminando la distribuzione predittiva notiamo che, nei possibili campioni futuri di 30 osservazioni, il valore \\(\\tilde{y}\\) pi√π plausibile √® 18. Tuttavia, \\(\\tilde{y}\\) pu√≤ assumere anche altri valori e la distribuzione predittiva ci informa sulla plausibilit√† relativa di ciascuno dei possibili valori futuri \\(\\tilde{y}\\) ‚Äì nel presente esempio, \\(\\tilde{y}\\) corrisponde al numero di pazienti clinici (su 30) che manifesteranno una depressione grave.\n√à desiderabile costruire un intervallo che contiene le realizzazioni \\(\\tilde{y}\\) ad un livello specificato di probabilit√†. Supponiamo che il livello di probabilit√† richiesto sia 0.89. L‚Äôintervallo si costruisce aggiungendo valori \\(\\tilde{y}\\) all‚Äôintervallo (partendo da quello con la probabilit√† maggiore) fino a che il contenuto di probabilit√† dell‚Äôinsieme eccede la soglia richiesta, nel caso present di 0.89. La procedura √® implementata nella funzione discint() del pacchetto LearnBayes. Per i dati dell‚Äôesempio otteniamo\n\nCodiceLearnBayes::discint(cbind(0:30, prob), 0.89)\n#> $prob\n#> [1] 0.9152885\n#> \n#> $set\n#>  [1] 12 13 14 15 16 17 18 19 20 21 22 23\n\n\nSulla base delle informazioni disponibili, possiamo dunque prevedere, con un livello di certezza soggettiva che eccede la soglia di 0.91, che in un futuro campione di 30 soggetti clinici depressi, il numero di pazienti con depressione grave sar√† compreso tra 12 e 23.\n\\[\nP(12 \\leq \\tilde{y} \\leq 23) = 0.9145.\n\\]\nIn conclusione, per il caso beta-binomiale, possiamo dire che la predizione bayesiana di una nuova osservazione futura √® la realizzazione di una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha + y\\), e \\(\\beta + n - y\\), dove \\(m\\) √® il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le caratteristiche del campione."
  },
  {
    "objectID": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-simulazione",
    "href": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-simulazione",
    "title": "23¬† La predizione bayesiana",
    "section": "\n23.3 La distribuzione predittiva a posteriori mediante simulazione",
    "text": "23.3 La distribuzione predittiva a posteriori mediante simulazione\nIn situazioni dove √® difficile derivare l‚Äôesatta distribuzione predittiva a posteriori √® possibile ottenere un campione casuale di valori della distribuzione predittiva posteriori mediante simulazione. Facciamo un esempio riferito al caso che stiamo discutendo. √à possibile svolgere la simulazione richiesta in due fasi. Supponiamo di volere ottenere un campione casuale di \\(n\\) osservazioni dalla distribuzione predittiva a posteriori. A tal fine dobbiamo (1) estrarre \\(n\\) valori a caso del parametro \\(\\theta\\) dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\): (2) con tali valori del parametro \\(\\theta\\) generiamo \\(n\\) valori casuali \\(\\tilde{y}\\); a tal fine usiamo il modello binomiale di parametri \\(m\\) e \\(\\theta_i\\) (con \\(i = 1, \\dots, n\\)). Otteniamo cos√¨ \\(n\\) realizzazioni casuali di \\(n\\) distribuzioni binomiali aventi i parametri specificati sopra.\nVediamo come si fa in pratica con \\(\\mathsf{R}\\). Per l‚Äôesempio che stiamo discutendo, la distribuzione a posteriori √® una \\(\\mbox{Beta}(25, 17)\\). Estraiamo 100,000 valori a caso da tale distribuzione.\n\nCodiceset.seed(12345)\nnrep <- 1e5\na <- 2\nb <- 10\nn <- 30\ny <- 23\npred_p_sim <- rbeta(nrep, a + y, b + n - y)\n\n\nI primi 10 valori cos√¨ ottenuti sono riportati di seguito.\n\nCodicepred_p_sim[1:10]\n#>  [1] 0.5435206 0.5319551 0.6045577 0.6337146 0.7552324 0.5393935 0.6187069\n#>  [8] 0.6193819 0.6736216 0.6051480\n\n\nPer ciascuno dei valori \\(\\theta_i\\), con \\(i = 1, \\dots, 100,000\\), estraggo a caso un valore dalla distribuzione binomiale di parametri \\(n = 30\\) e \\(\\theta_i\\).\n\nCodicepred_y_sim <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  pred_y_sim[i] <- rbinom(1, 30, pred_p_sim[i])\n}\n# In maniera equivalente posso fare:\n# pred_y_sim <- rbinom(1e5, n, pred_p_sim)\n\n\nCalcolo la proporzione di volte in cui sono stati osservai i valori \\(\\tilde{y} = 0, 1, \\dots, 30\\).\n\nCodiceppd <- table(pred_y_sim) / nrep\nppd\n#> pred_y_sim\n#>       3       4       5       6       7       8       9      10      11      12 \n#> 0.00002 0.00004 0.00011 0.00036 0.00096 0.00241 0.00533 0.01000 0.01753 0.02882 \n#>      13      14      15      16      17      18      19      20      21      22 \n#> 0.04290 0.06110 0.07812 0.09476 0.10763 0.11311 0.10821 0.09765 0.07982 0.06185 \n#>      23      24      25      26      27      28      29      30 \n#> 0.04156 0.02536 0.01299 0.00630 0.00224 0.00064 0.00016 0.00002\n\n\nCalcolo l‚Äôintervallo di valori \\(\\tilde{y}\\) a cui √® associata una probabilit√† di 0.89 (per fare un confronto con il risultato ottenuto in precedenza).\n\nCodiceLearnBayes::discint(cbind(3:30, ppd), 0.89) \n#> $prob\n#>      12 \n#> 0.91553 \n#> \n#> $set\n#> 12 13 14 15 16 17 18 19 20 21 22 23 \n#> 12 13 14 15 16 17 18 19 20 21 22 23\n# i risultati minori di 3 non sono stati calcolati\n\n\nConfronto i risultati della simulazione con i valori esatti della distribuzione predittiva a posteriori. Di seguito riporto i risultati esatti.\n\nCodiceprob30 <- extraDistr::dbbinom(0:30, 30, 25, 17)\nLearnBayes::discint(cbind(0:30, prob30), 0.89)\n#> $prob\n#> [1] 0.9152885\n#> \n#> $set\n#>  [1] 12 13 14 15 16 17 18 19 20 21 22 23\n\n\nUn grafico con la distribuzione predittiva a posteriori esatta √® fornito nella figura seguente.\n\nCodicetibble(Y=0:30, Probability = prob30) %>% \n  ProbBayes::prob_plot(Color = \"black\")\n\n\n\n\n\n\n\nUna rappresentazione della distribuzione a posteriori ottenuta mediante simulazione √® il seguente.\n\nCodicetibble(Y=0:30, Probability = c(0, 0, 0, ppd)) %>% \n  ProbBayes::prob_plot(Color = \"black\")\n\n\n\n\n\n\n\nSi noti che i risultati della simulazione sono indistinguibili dalla soluzione esatta."
  },
  {
    "objectID": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-mcmc",
    "href": "046_bayesian_prediction.html#la-distribuzione-predittiva-a-posteriori-mediante-mcmc",
    "title": "23¬† La predizione bayesiana",
    "section": "\n23.4 La distribuzione predittiva a posteriori mediante MCMC",
    "text": "23.4 La distribuzione predittiva a posteriori mediante MCMC\nIl metodo basato su simulazione che abbiamo discusso sopra si basa sulla stessa logica usata dai metodi MCMC per ottenere un‚Äôapprossimazione della distribuzione predittiva a posteriori. Mediante i metodi MCMC, le stime delle possibili osservazioni future \\(p(\\tilde{y} \\mid y)\\), chiamate \\(p(y^{rep} \\mid y)\\), si ottengono nel modo seguente:\n\ncampionare \\(\\theta_i \\sim p(\\theta \\mid y)\\), ovvero scegliere a caso un valore del parametro dalla distribuzione a posteriori;\ncampionare \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\), ovvero scegliere a caso un‚Äôosservazione dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente.\n\nSe i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l‚Äôistogramma risultante approssimer√† la distribuzione predittiva a posteriori che, in teoria potrebbe essere ottenuta per via analitica.\n\nEsercizio 23.1 Utilizziamo il codice Stan per generare \\(p(y^{rep} \\mid y)\\) nel caso dell‚Äôinferenza su una proporzione.\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  array[N] int<lower=0, upper=1> y;\n}\nparameters {\n  real<lower=0, upper=1> theta;\n}\nmodel {\n  theta ~ beta(2, 10);\n  y ~ bernoulli(theta);\n}\ngenerated quantities {\n  array[N] int y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = bernoulli_rng(theta);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/betabin23-30-2-10.stan\")\n\n\nSi noti che nel nel blocco generated quantities sono state aggiunte le istruzioni necessarie per simulare \\(y^{rep}\\), ovvero, y_rep[n] = bernoulli_rng(theta). Una tale istruzione ci dice di generare un valore casuale di una variabile Bernoulliana di parametro \\(\\theta\\). Il valore \\(\\theta\\) √® preso a caso dalla distribuzione a posteriori \\(p(\\theta \\mid y)\\). Il ciclo for specifica che tale operazione va ripetuta 30 volte per ciascuna iterazione MCMC.\nI dati dell‚Äôesempio sono forniti in formato list.\n\nCodicedata_list <- list(\n  N = 30,\n  y = c(rep(1, 23), rep(0, 7))\n)\n\n\nCompiliamo il codice Stan.\n\nCodicefile <- file.path(\"code\", \"betabin23-30-2-10.stan\")\nmod <- cmdstan_model(file)\n\n\nEseguiamo il campionamento MCMC.\n\nCodicefit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nPer comodit√†, trasformiamo l‚Äôoggetto fit in un oggetto di classe stanfit.\n\nCodicestanfit <- rstan::read_stan_csv(fit$output_files())\n\n\nIl contenuto dell‚Äôoggetto stanfit pu√≤ essere esaminato mediante la funzione extract().\n\nCodicelist_of_draws <- extract(stanfit)\nprint(names(list_of_draws))\n#> [1] \"theta\" \"y_rep\" \"lp__\"\n\n\nDall‚Äôoggetto list_of_draws recuperiamo y_rep.\n\nCodicey_bern <- list_of_draws$y_rep\ndim(y_bern)\n#> [1] 16000    30\nhead(y_bern)\n#>           \n#> iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]\n#>       [1,]    1    1    1    1    0    1    1    1    1     1     1     1     1\n#>       [2,]    0    1    0    1    1    1    0    0    1     0     0     0     0\n#>       [3,]    0    1    0    1    1    1    0    0    1     1     1     0     1\n#>       [4,]    1    0    0    1    1    0    0    1    0     1     1     1     0\n#>       [5,]    0    0    0    1    1    0    1    1    0     1     0     0     1\n#>       [6,]    1    1    1    1    1    1    0    1    0     1     1     1     0\n#>           \n#> iterations [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]\n#>       [1,]     0     1     1     1     1     1     0     0     1     0     1\n#>       [2,]     1     0     0     1     0     1     1     1     0     0     0\n#>       [3,]     0     0     1     0     1     1     0     1     0     0     1\n#>       [4,]     0     1     0     1     0     1     0     0     1     0     1\n#>       [5,]     0     0     1     1     1     1     1     0     1     0     1\n#>       [6,]     1     1     0     1     0     1     1     0     0     1     0\n#>           \n#> iterations [,25] [,26] [,27] [,28] [,29] [,30]\n#>       [1,]     1     1     1     1     1     1\n#>       [2,]     0     1     1     0     1     1\n#>       [3,]     1     1     1     1     1     0\n#>       [4,]     0     1     1     0     0     1\n#>       [5,]     0     0     0     0     1     0\n#>       [6,]     0     0     1     0     1     1\n\n\nDato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga della matrice y_bern ha 30 colonne, ciascuna delle quali corrisponde ad un campione (\\(n\\) = 16,000 in questa simulazione) di possibili valori futuri \\(y_i \\in \\{0, 1\\}\\). In altre parole, abbiamo generato 16,000 campioni casuali di 30 osservazioni possibili osservazioni future.\nPer ottenere una stima della distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\), ovvero, per ottenere una stima della probabilit√† associata a ciascuno dei possibili numeri di successi, \\(\\tilde{y}\\), in \\(m = 30\\) nuove prove future, √® sufficiente calcolare la proporzione di valori 1 in ciascuna riga della matrice y_bern.\n\nCodicetibble(y_rep = rowSums(y_bern)) %>%\n  ggplot(aes(x = y_rep, after_stat(density))) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\nSi noti che l‚Äôistogramma cos√¨ ottenuto √® equivalente a quello trovato nella simulazione precedente."
  },
  {
    "objectID": "046_bayesian_prediction.html#i-metodi-per-la-valutazione-del-modello",
    "href": "046_bayesian_prediction.html#i-metodi-per-la-valutazione-del-modello",
    "title": "23¬† La predizione bayesiana",
    "section": "\n23.5 I metodi per la valutazione del modello",
    "text": "23.5 I metodi per la valutazione del modello\n\n23.5.1 Posterior predictive checks\nLa distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti controlli predittivi a posteriori (Posterior Predictive Checks, PPC). Nella distribuzione predittiva a posteriori, viene generato un campione di dati possibili futuri utilizzando le propriet√† del modello adattato. √à ovvio che tali dati possibili futuri devono almento essere coerenti con i dati del campione presente. I PPC eseguono un confronto grafico tra \\(p(y^{rep} \\mid y)\\) e i dati osservati \\(y\\): confrontando visivamente gli aspetti chiave dei dati previsti futuri \\(y^{rep}\\) e dei dati osservati \\(y\\) √® possibile determinare se il modello √® adeguato.\nOltre al confronto visivo tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\) √® anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni \\(y^{rep}\\), e le corrispondenti statistiche calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo, ma sono possibili confronti di questo tipo per qualunque altra statistica.\n\nEsercizio 23.2 Esaminiamo ora un set di dati che non seguono la distribuzione normale (Gelman et al., 2020). I dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocit√† della luce. A questi dati verr√† (inappropriatamente) adattata una distribuzione normale. L‚Äôobiettivo dell‚Äôesempio √® quello di mostrare come i PPC possono rivelare la mancanza di adattamento di un modello ai dati.\nI PPC mostrano che il modo pi√π semplice per verificare l‚Äôadattamento del modello √® quello di visualizzare \\(y^{rep}\\) insieme ai dati effettivi. Iniziamo a caricare i dati.\n\nCodicelibrary(\"MASS\")\ndata(\"newcomb\")\n\n\nVisualizziamo la distribuzione dei dati con un istogramma.\n\nCodicetibble(newcomb) %>%\n  ggplot(aes(x = newcomb, after_stat(density))) +\n  geom_histogram(binwidth = 1)\n\n\n\n\n\n\n\nCreiamo un oggetto di tipo list dove inserire i dati.\n\nCodicedata_list <- list(\n  y = newcomb,\n  N = length(newcomb)\n)\n\n\nUtilizziamo il seguente codice Stan per il modello normale.\n\nCodicemodelString <- \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  mu ~ normal(25, 10);\n  sigma ~ cauchy(0, 10);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/newcomb.stan\")\n\n\nAdattiamo il modello ai dati.\n\nCodicefile <- file.path(\"code\", \"newcomb.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nOtteniamo le stime dei parametri \\(\\mu\\) e \\(\\sigma\\).\n\nCodicefit$summary(c(\"mu\", \"sigma\"))\n#> # A tibble: 2 √ó 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu        26.2   26.2 1.33  1.30  24.0   28.4  1.00   13305.   11189.\n#> 2 sigma     10.9   10.8 0.958 0.943  9.40  12.5  1.00   12614.   10352.\n\n\nTrasformiamo l‚Äôoggetto fit in un formato stanfit.\n\nCodicestanfit <- rstan::read_stan_csv(fit$output_files())\n\n\nRappresentiamo graficamente la distribuzione a posteriori di \\(\\mu\\).\n\nCodicemu_draws <- as.matrix(stanfit, pars = \"mu\")\nmcmc_areas(mu_draws, prob = 0.95) # color 95% interval\n\n\n\n\n\n\n\nLa media campionaria √® pari a 26.21.\n\nCodicemean(newcomb)\n#> [1] 26.21212\n\n\nAnche se trova la media giusta, il modello non √® comunque adeguato a prevedere le altre propriet√† della \\(y\\). Estraiamo \\(y^{rep}\\) dall‚Äôoggetto stanfit.\n\nCodicey_rep <- as.matrix(stanfit, pars = \"y_rep\")\ndim(y_rep)\n#> [1] 16000    66\n\n\nI valori y_rep sono i dati della distribuzione predittiva a posteriori che sono stati simulati usando gli stessi valori \\(X\\) dei predittori utilizzati per adattare il modello. Il confronto tra l‚Äôistogramma della \\(y\\) e gli istogrammi di diversi campioni \\(y^{rep}\\) mostra una scarsa corrispondenza tra i due.\n\nCodiceppc_hist(data_list$y, y_rep[1:8, ], binwidth = 1)\n\n\n\n\n\n\n\nAlla stessa conclusione si giunge tramite un confronto tra la funzione di densit√† empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\).\n\nCodiceppc_dens_overlay(data_list$y, y_rep[1:50, ])\n\n\n\n\n\n\n\nGeneriamo ora i PPC per la media e il minimo della distribuzione.\n\nCodiceppc_stat_2d(data_list$y, y_rep, stat = c(\"mean\", \"min\"))\n\n\n\n\n\n\n\nIn conclusione, possiamo dire che mentre la media viene riprodotta accuratamente dal modello, ci√≤ non √® vero per il minimo della distribuzione. L‚Äôorigine di questa mancanza di adattamento √® il fatto che la distribuzione delle misurazioni della velocit√† della luce √® asimmetrica negativa.\nDato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione \\(t\\) di Student.\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n  real<lower=0> nu;\n}\nmodel {\n  mu ~ normal(25, 10);\n  sigma ~ cauchy(0, 10);\n  nu ~ cauchy(0, 10);\n  y ~ student_t(nu, mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (n in 1 : N) {\n    y_rep[n] = student_t_rng(nu, mu, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/newcomb2.stan\")\n\n\nAdattiamo questo secondo modello ai dati.\n\nCodicefile <- file.path(\"code\", \"newcomb2.stan\")\nmod <- cmdstan_model(file)\nfit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.3 seconds.\n#> Chain 2 finished in 0.3 seconds.\n#> Chain 3 finished in 0.3 seconds.\n#> Chain 4 finished in 0.3 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.3 seconds.\n#> Total execution time: 1.4 seconds.\n\n\nPer questo secondo modello il confronto tra la funzione di densit√† empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\) risulta adeguato.\n\nCodicestanfit <- rstan::read_stan_csv(fit$output_files())\ny_rep <- as.matrix(stanfit, pars = \"y_rep\")\nppc_dens_overlay(data_list$y, y_rep[1:50, ]) + xlim(0, 50)\n\n\n\n\n\n\n\nInoltre, anche la statistica ‚Äúminimo della distribuzione‚Äù viene ben predetta dal modello.\n\nCodiceppc_stat_2d(data_list$y, y_rep, stat = c(\"mean\", \"min\"))\n\n\n\n\n\n\n\nIn conclusione, per le misurazioni della velocit√† della luce di Newcomb l‚Äôaccuratezza predittiva del modello basato sulla distribuzione \\(t\\) di Student √® chiaramente migliore di quella del modello normale."
  },
  {
    "objectID": "046_bayesian_prediction.html#distribuzione-predittiva-a-priori",
    "href": "046_bayesian_prediction.html#distribuzione-predittiva-a-priori",
    "title": "23¬† La predizione bayesiana",
    "section": "\n23.6 Distribuzione predittiva a priori",
    "text": "23.6 Distribuzione predittiva a priori\nNella sezione precedente abbiamo visto come la distribuzione predittiva √® stata usata per generare nuovi dati previsti futuri. Pi√π precisamente, mediante l‚Äô?eq-post-pred-distr abbiamo descritto la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione a posteriori di \\(\\theta\\), ovvero tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati.\n\\[\np(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta\\notag\n\\]\nSi noti che, nell‚Äô?eq-post-pred-distr, \\(\\tilde{y}\\) √® condizionato da \\(y\\) ma non da ci√≤ che √® incognito, ovvero \\(\\theta\\). La distribuzione predittiva a posteriori √® ottenuta mediante marginalizzazione sopra i parametri incogniti \\(\\theta\\).\nIn un modello bayesiano dove \\(\\theta\\) ha una distribuzione a priori \\(p(\\theta)\\) e per \\(y\\) possiamo definire la funzione di verosimiglianza \\(p(y \\mid \\theta)\\) possiamo scrivere la distribuzione congiunta \\(p(y, \\theta)\\) come il prodotto della verosimiglianza e della distribuzione a priori:\n\\[\np(y, \\theta) = p(y \\mid \\theta)p(\\theta).\n\\]\nUna rappresentazione alternativa della distribuzione congiunta \\(p(y, \\theta)\\) √®\n\\[\np(y, \\theta) = p(\\theta \\mid y)p(y).\n\\]\nIl primo termine in questo prodotto, la densit√† \\(p(\\theta \\mid y)\\), √® la densit√† a posteriori di \\(\\theta\\) date le osservazioni \\(y\\). Il secondo termine in questo prodotto, \\(p(y)\\), √® la distribuzione predittiva a priori che rappresenta la distribuzione dei dati futuri previsti dal modello prima di avere osservato il campione \\(y\\). Se risulta che i dati osservati \\(y\\) non sono coerenti con la distribuzione predittiva a priori, ci√≤ significa che il modello bayesiano non √® specificato correttamente. In altre parole, questo ci dice che, in base al modello bayesiano che abbiamo formulato, √® improbabile che si verifichino i dati che sono stati effettivamente osservati. Ovviamente, questo vuol dire che il modello √® inadeguato.\nLa distribuzione predittiva a priori pu√≤ essere ricavata facilmente se l‚Äôinferenza bayesiana viene svolta mediante i metodi MCMC. Per fare un esempio consideriamo nuovamente i dati di Zetsche et al. (2019), con 23 successi in 30 prove. Nella discussione precedente abbiamo svolto l‚Äôaggiornamento bayesiano imponendo su \\(\\theta\\) una distribuzione a priori \\(\\mbox{Beta}(2, 10)\\).\nNel caso di una verosimiglianza binomiale e di una distribuzione a priori Beta, la distribuzione predittiva a priori pu√≤ essere costruita mediante la funzione LearnBayes::pbetap().\n\nCodicedf <- tibble(\n  y = 0:30,\n  Probability = LearnBayes::pbetap(c(2, 10), 30, 0:30)\n)\ndf %>% \n  ProbBayes::prob_plot(Color = \"gray\", Size = 3) + \n  geom_point(data = tibble(y = 23, Probability = 0), size = 3) \n\n\n\n\n\n\n\nLa distribuzione predittiva a priori assegna livelli diversi di credibilit√† a ciascuno dei possibili risultati dell‚Äôesperimento casuale, ovvero il fatto di osservare 0, 1, , 30 successi in 30 prove Bernoulliane.\nNella distribuzione predittiva a priori riportata nel grafico precedente ho evidenziato il punto \\(y = 23\\), ovvero il numero di successi nel campione. Il grafico mostra che la distribuzione predittiva a priori assegna una credibilit√† quasi nulla all‚Äôevento \\(y = 23\\), ovvero ai dati che sono stati effettivamente osservati. Questo indica chiaramente che la distribuzione a priori \\(\\mbox{Beta}(2, 10)\\) non √® adeguata per i dati che stiamo analizzando, cos√¨ come avevamo in precedenza anticipato.\nSe viene invece utilizzata una distribuzione a priori debolmente informativa, o vero \\(\\mbox{Beta}(2, 2)\\), la distribuzione predittiva a priori assume la forma seguente.\n\nCodicedf <- tibble(\n  y = 0:30,\n  Probability = LearnBayes::pbetap(c(2, 2), 30, 0:30)\n)\ndf %>% \n  ProbBayes::prob_plot(Color = \"gray\", Size = 3) + \n  geom_point(data = tibble(y = 23, Probability = 0), size = 3) \n\n\n\n\n\n\n\nIn questo secondo caso al valore \\(y\\) osservato viene assegnata una credibilit√† piuttosto alta. Ci√≤ significa che una \\(\\mbox{Beta}(2, 2)\\) fornisce un‚Äôadeguata distribuzione a priori per i dati a disposizione.\nNella discussione dell‚Äôanalisi dei dati di Zetsche et al. (2019), la \\(\\mbox{Beta}(2, 10)\\) √® stata utilizzata quale distribuzione a priori solo per evidenziare le propriet√† dell‚Äôaggiornamento bayesiano (la differenza tra la distribuzione a priori e la distribuzione a posteriori). La discussione presente chiarisce che la \\(\\mbox{Beta}(2, 10)\\) non √® una buona scelta per la distribuzione a priori: sarebbe molto migliore la scelta di una \\(\\mbox{Beta}(2, 2)\\)."
  },
  {
    "objectID": "046_bayesian_prediction.html#commenti-e-considerazioni-finali",
    "href": "046_bayesian_prediction.html#commenti-e-considerazioni-finali",
    "title": "23¬† La predizione bayesiana",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nQuesto capitolo discute la predizione bayesiana e ne mostra un‚Äôapplicazione nel caso dei controlli predittivi a posteriori. A questo proposito √® necessario notare un punto importante: un buona corrispondenza tra \\(y\\) e \\(y^{rep}\\) costituisce una condizione necessaria ma non sufficiente per la validit√† del modello. Infatti, i PPC non sono in grado di garantire la generalizzabilit√† del modello a nuovi campioni di dati. D‚Äôaltra parte, invece, se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, questo ci dice chiaramente che il modello √® specificato in manera errata.\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "050_normal_normal_mod.html",
    "href": "050_normal_normal_mod.html",
    "title": "24¬† Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "",
    "text": "Esaminiamo ora in maggiore dettaglio un caso che abbiamo anticipato in precedenza, ovvero quello in cui disponiamo di un campione di dati a livello di scala a intervalli o rapporti e vogliamo fare inferenza sulla media della popolazione da cui il campione √® stato estratto."
  },
  {
    "objectID": "050_normal_normal_mod.html#caso-normale-normale-con-varianza-nota",
    "href": "050_normal_normal_mod.html#caso-normale-normale-con-varianza-nota",
    "title": "24¬† Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "\n24.1 Caso Normale-Normale con varianza nota",
    "text": "24.1 Caso Normale-Normale con varianza nota\nSupponiamo che i dati \\(y\\) siano un campione casuale estratto da una popolazione che segue la legge Normale. Ci√≤ significa che le osservazioni possono essere considerate come una sequenza di variabili casuali indipendenti e identicamente distribuite. Supponiamo che ciascuna v.c. segua la distribuzione Normale. Abbiamo dunque\n\\[\nY_1, \\dots, Y_n  \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma).\n\\]\nIn precedenza abbiamo visto come, in tali circostanze, la verosimiglianza \\(p(y \\mid \\mu, \\sigma)\\) sia Normale. Per fare inferenza sul parametro \\(\\mu\\), facciamo due assunzioni: consideriamo \\(\\sigma\\) nota e imponiamo su \\(\\mu\\) una distribuzione a priori Normale. Questa situazione definisce lo schema coniugato Normale-Normale. Il caso Normale-Normale consente una derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\) (cos√¨ come nel caso beta-binomiale era possibile una derivazione analitica della distribuzione a posteriori \\(p(\\theta \\mid y)\\)).\nLa trattazione matematica di una tale derivazione √® piuttosto complessa e qui verr√† solo accennata. Nel seguito, impareremo invece ad applicare la soluzione che viene ottenuta in tali circostanze; mostreremo inoltre come fare inferenza su \\(\\mu\\) mediante i metodi MCMC."
  },
  {
    "objectID": "050_normal_normal_mod.html#derivazione-analitica-della-distribuzione-a-posteriori-pmu-mid-y",
    "href": "050_normal_normal_mod.html#derivazione-analitica-della-distribuzione-a-posteriori-pmu-mid-y",
    "title": "24¬† Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "\n24.2 Derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\)\n",
    "text": "24.2 Derivazione analitica della distribuzione a posteriori \\(p(\\mu \\mid y)\\)\n\nPer \\(\\sigma^2\\) nota, la famiglia della distribuzione Normale √® coniugata a s√© stessa: se la funzione di verosimiglianza √® Normale, la scelta di una distribuzione a priori Normale per \\(\\mu\\) assicura che anche la distribuzione a posteriori \\(p(\\mu \\mid y)\\) sia Normale.\nPoniamoci dunque il problema di trovare \\(p(\\mu \\mid y)\\) nel caso di un campione casuale \\(Y_1, \\dots, Y_n \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma)\\), supponendo \\(\\sigma\\) perfettamente nota e imponendo su \\(\\mu\\) una distribuzione a priori Normale. Ricordiamo che la densit√† gaussiana √®\n\\[\np(y_i \\mid \\mu, \\sigma) = \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_i - \\mu)^2}{2\\sigma^2}}\\right\\}.\n\\]\nEssendo le variabili i.i.d., possiamo scrivere la densit√† congiunta come il prodotto delle singole densit√† e quindi si ottiene\n\\[\np(y \\mid \\mu) = \\, \\prod_{i=1}^n p(y_i \\mid \\mu).\n\\]\nUna volta osservati i dati \\(y\\), la verosimiglianza diventa\n\\[\n\\begin{align}\np(y \\mid \\mu) =& \\, \\prod_{i=1}^n p(y_i \\mid \\mu) = \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_1 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_2 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times  \\notag\\\\\n& \\vdots \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(y_n - \\mu)^2}{2\\sigma^2}}\\right\\}.\n\\end{align}\n\\]\nSe la densit√† a priori \\(p(\\mu)\\) √® gaussiana, allora anche la densit√† a posteriori \\(p(\\mu \\mid y)\\) sar√† gaussiana. Poniamo\n\\[\np(\\mu) = \\frac{1}{{\\tau_0 \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_0)^2}{2\\tau_0^2}}\\right\\},\n\\] {#eq:prior-mu-norm-norm}\novvero imponiamo a \\(\\mu\\) una distribuzione a priori gaussiana con media \\(\\mu_0\\) e varianza \\(\\tau_0^2\\). Ci√≤ significa dire che, a priori, \\(\\mu_0\\) rappresenta il valore pi√π verosimile per \\(\\mu\\), mentre \\(\\tau_0^2\\) quantifica il grado della nostra incertezza rispetto a tale valore.\nSvolgendo una serie di passaggi algebrici, si arriva alla distribuzione a posteriori\n\\[\np(\\mu \\mid y) = \\frac{1}{{\\tau_p \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(\\mu - \\mu_p)^2}{2\\tau_p^2}}\\right\\},\n\\tag{24.1}\\]\ndove\n\\[\n\\mu_p = \\frac{\\frac{1}{\\tau_0^2}\\mu_0+ \\frac{n}{\\sigma^2}\\bar{y}}{\\frac {1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\\tag{24.2}\\]\ne\n\\[\n\\tau_p^2 = \\frac{1}{\\frac {1}{\\tau_0^2}+ \\frac{n}{\\sigma^2}}.\n\\tag{24.3}\\]\nCi√≤ significa che, se la distribuzione a priori \\(p(\\mu)\\) √® gaussiana, allora anche la distribuzione a posteriori \\(p(\\mu \\mid y)\\) sar√† gaussiana con valore atteso \\(\\mu_p\\) e varianza \\(\\tau_p^2\\) date dalle espressioni precedenti.\nIn conclusione, il risultato trovato indica che:\n\nil valore atteso a posteriori √® una media pesata fra il valore atteso a priori \\(\\mu_0\\) e la media campionaria \\(\\bar{y}\\); il peso della media campionaria √® tanto maggiore tanto pi√π √® grande \\(n\\) (il numero di osservazioni) e \\(\\tau_0^2\\) (l‚Äôincertezza iniziale);\nl‚Äôincertezza (varianza) a posteriori \\(\\tau_p^2\\) √® sempre pi√π piccola dell‚Äôincertezza a priori \\(\\tau_0^2\\) e diminuisce al crescere di \\(n\\).\n\n\nEsercizio 24.1 Per esaminare un esempio pratico, consideriamo i 30 valori BDI-II dei soggetti clinici di Zetsche et al. (2019).\n\nCodicedf <- data.frame(\n  y = c(\n    26.0, 35.0, 30, 25, 44, 30, 33, 43, 22, 43,\n    24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41,\n    36, 26, 35, 33, 28, 27, 34, 27, 22\n  )\n)\n\n\nSupponiamo che la varianza \\(\\sigma^2\\) della popolazione sia identica alla varianza del campione:\n\nCodicesigma <- sd(df$y)\nsigma\n#> [1] 6.606858\n\n\nPer fare un esempio, imponiamo su \\(\\mu\\) una distribuzione a priori \\(\\mathcal{N}(25, 2)\\). In tali circostanze, la distribuzione a posteriori del parametro \\(\\mu\\) pu√≤ essere determinata per via analitica e corrisponde ad una Normale di media e varianza definite dalle equazioni @ref(eq:post-norm-mup) e @ref(eq:post-norm-taup2). √à possibile visualizzare tale distribuzione a posteriori usando la funzione plot_normal_normal() del pacchetto bayesrules.\n\nCodicebayesrules::plot_normal_normal(\n  mean = 25, # media della distribuzione a priori per mu\n  sd = 2, # sd della distribuzione a priori per mu\n  sigma = sd(df$y), # sd del campione\n  y_bar = mean(df$y), # media del campione\n  n = length(df$y) # ampiezza campionaria\n)\n\n\n\n\n\n\n\nLa funzione bayesrules::summarize_normal_normal() fornisce una sintesi numerica della distribuzione a posteriori \\(p(\\mu \\mid y, \\sigma)\\).\n\nCodicebayesrules::summarize_normal_normal(\n  mean = 25, # media della distribuzione a priori per mu\n  sd = 2, # sd della distribuzione a priori per mu\n  sigma= sd(df$y), # sd del campione\n  y_bar = mean(df$y), # media del campione\n  n = length(df$y) # ampiezza campionaria\n)\n#>       model     mean     mode      var       sd\n#> 1     prior 25.00000 25.00000 4.000000 2.000000\n#> 2 posterior 29.35073 29.35073 1.066921 1.032919\n\n\nVerifichiamo i risultati forniti da bayesrules::summarize_normal_normal() applicando le formule @ref(eq:post-norm-mup) e @ref(eq:post-norm-taup2). Definiamo la funzione della media della distribuzione a posteriori di \\(\\mu\\).\n\nCodicemu_post <- function(tau_0, mu_0, sigma, ybar, n) {\n  (1/tau_0^2 * mu_0 + n/sigma^2 * ybar) / (1/tau_0^2 + n/sigma^2)\n}\n\n\nTroviamo la media a posteriori.\n\nCodicemu_0 <- 25  # media della distribuzione a priori per mu\ntau_0 <- 2  # sd della distribuzione a priori per mu\nsigma <- sd(df$y) # sd del campione (assunta essere sigma)\nybar <- mean(df$y) # media del campione\nn <- length(df$y)\n\nmu_post(tau_0, mu_0, sigma, ybar, n) \n#> [1] 29.35073\n\n\nDefiniamo una funzione per la deviazione standard della distribuzione a posteriori di \\(\\mu\\).\n\nCodicetau_post <- function(tau_0, sigma, n) {\n  sqrt(1 / (1/tau_0^2 + n/sigma^2))\n}\n\n\nTroviamo la deviazione standard a posteriori.\n\nCodicetau_0 <- 2  # sd della distribuzione a priori per mu\nsigma <- sd(df$y) # sd del campione (assunta essere sigma)\nn <- length(df$y)\n\ntau_post(tau_0, sigma, n) \n#> [1] 1.032919\n\n\nI risultati cos√¨ trovati riproducono quelli forniti da bayesrules::summarize_normal_normal()."
  },
  {
    "objectID": "050_normal_normal_mod.html#il-modello-normale-con-stan",
    "href": "050_normal_normal_mod.html#il-modello-normale-con-stan",
    "title": "24¬† Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "\n24.3 Il modello Normale con Stan",
    "text": "24.3 Il modello Normale con Stan\nI priori coniugati Normali di una Normale non richiedono una approssimazione numerica ottenuta mediante metodi MCMC. Tuttavia, per fare un esercizio e per verificare che i risultati ottenuti mediante MCMC siano simili a quelli trovati per via analitica, ripetiamo l‚Äôesercizio precedente usando Stan.\n\n24.3.1 Versione 1 (\\(\\sigma\\) nota)\nCome in precedenza, impongo su \\(\\mu\\) una distribuzione a priori \\(\\mathcal{N}(25, 2)\\) e considero noto il parametro \\(\\sigma = 6.606858\\). Il modello dunque diventa il seguente.\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(25, 2) \\notag\\\\\n\\sigma &= 6.606858 \\notag\n\\end{align}\n\\]\nIn base al modello definito sopra, la variabile casuale \\(Y\\) segue la distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\). Il parametro \\(\\mu\\) √® sconosciuto e abbiamo deciso di descrivere la nostra incertezza relativa ad esso mediante una distribuzione a priori Normale di media 25 e deviazione standard 2. Il parametro \\(\\sigma\\) √® invece assunto essere noto e uguale a 6.606858. Usando il linguaggio Stan specifico il modello come segue.\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  real<lower=0> sigma;\n  vector[N] y;\n}\nparameters {\n  real mu;\n}\nmodel {\n  mu ~ normal(25, 2);\n  y ~ normal(mu, sigma);\n}\n\"\nwriteLines(modelString, con = \"code/normal_normal_1.stan\")\n\n\nSistemo i dati nel formato appropriato per Stan.\n\nCodicedlist <- list(\n  N = length(df$y),\n  sigma = sd(df$y),\n  y = df$y\n)\n\n\nLeggo il file in cui ho salvato il codice Stan.\n\nCodicefile <- file.path(\"code\", \"normal_normal_1.stan\")\n\n\nCompilo il modello.\n\nCodicemod <- cmdstan_model(file)\n\n\nEseguo il campionamento MCMC.\n\nCodicefit <- mod$sample(\n  data = dlist,\n  iter_sampling = 100000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n\n\nUna sintesi della distribuzione a posteriori dei parametri si ottiene nel modo seguente.\n\nCodicefit$summary(c(\"mu\"))\n#> # A tibble: 1 √ó 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu        29.4   29.4  1.04  1.04  27.6  31.1  1.00  153786.  188314.\n\n\nSi noti che le stime ottenute sono molto vicine ai valori teorici attesi, ovvero \\(\\mu_p\\) = 29.57 contro un valore teorico di 29.35 e \\(\\tau_p\\) = 0.96 contro un valore teorico di 1.03.\nQui sotto √® fornita una rappresentazione grafica dell‚Äôintera distribuzione a posteriori del parametro \\(\\mu\\).\n\nCodicestanfit <- rstan::read_stan_csv(fit$output_files())\nmu_draws <- as.matrix(stanfit,pars =\"mu\")\nmcmc_areas(mu_draws,prob = 0.95) \n\n\n\n\n\n\n\nTrovo l‚Äôintervallo di credibilit√† al 95%.\n\nCodicepost <- fit$draws()\npost_parms <- subset_draws(post, c(\"mu\"))\nposterior::summarise_draws(\n  post_parms,\n  ~ quantile(.x, probs = c(0.025, 0.975))\n)\n#> # A tibble: 1 √ó 3\n#>   variable `2.5%` `97.5%`\n#>   <chr>     <dbl>   <dbl>\n#> 1 mu         27.3    31.4\n\n\nLe stime cos√¨ trovate sono molto simili ai quantili di ordine 0.025 e 0.975 della vera distribuzione a posteriori di \\(\\mu\\).\n\nCodiceqnorm(c(0.025, 0.975), 29.35073, 1.032919)\n#> [1] 27.32625 31.37521\n\n\n\n24.3.2 Versione 2 (\\(\\sigma\\) incognita)\n√à facile estendere il caso precedente alla situazione in cui il parametro \\(\\sigma\\) √® incognito. Se non conosciamo \\(\\sigma\\), √® necessario imporre su tale parametro una distribuzione a priori. Supponiamo di ipotizzare per \\(\\sigma\\) una distribuzione a priori \\(\\mbox{Cauchy}(0, 15)\\).\nMediante una \\(\\mbox{Cauchy}(0, 15)\\) descrivo il grado di plausibilit√† soggettiva che attribuisco ai possibili valori (> 0) del parametro \\(\\sigma\\). Ai valori prossimi allo 0 attribuisco la plausibilit√† maggiore; la plausibilit√† dei possibili valori \\(\\sigma\\) diminuisce progressivamente quando ci si allontana dallo 0, come indicato dalla curva della figura seguente. Ritengo poco plausibili valori \\(\\sigma\\) maggiori di 40, anche se non escludo completamente che \\(\\sigma\\) possa assumere un valore di questo tipo.\n\nCodicecurve(\n  dcauchy(x, location = 0, scale = 15), \n  from = 0, to = 50, col = 'gray', lwd = 3,\n  ylab = \"Densit√†\",\n  xlab = \"sigma\"\n)\n\n\n\n\n\n\n\nIn questo secondo caso, pi√π realistico, il modello diventa il seguente.\n\\[\n\\begin{align}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\notag\\\\\n\\mu &\\sim \\mathcal{N}(25, 2) \\notag\\\\\n\\sigma &\\sim \\mbox{Cauchy}(0, 15) \\notag\n\\end{align}\n\\]\nIl modello precedente √® simile a quello esaminato in precedenza, eccetto che abbiamo quantificato la nostra incertezza relativa a \\(\\sigma\\) (che √® ignota) mediante una distribuzione a priori \\(\\mbox{Cauchy}(0, 15)\\).\nLa procedura MCMC utilizzata da Stan √® basata su un campionamento Monte Carlo Hamiltoniano che non richiede l‚Äôuso di distribuzioni a priori coniugate. Pertanto √® possibile scegliere per i parametri una qualunque distribuzione a priori. Nel caso presente, appunto, per \\(\\sigma\\) ho scelto una \\(\\mbox{Cauchy}(0, 15)\\). Per un tale caso non √® possibile ottenere la derivazione analitica della distribuzione a posteriori di \\(\\mu\\). √à dunque necessario procedere con il campionamento MCMC.\nScrivo il modello in linguaggio in Stan.\n\nCodicemodel_string_2 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n}\nparameters {\n  real mu;\n  real<lower=0> sigma;\n}\nmodel {\n  mu ~ normal(25, 2);\n  sigma ~ cauchy(0, 15);\n  y ~ normal(mu, sigma);\n}\n\"\nwriteLines(model_string_2, con = \"code/normal_mod_2.stan\")\n\n\nCreo l‚Äôoggetto di classe list che contiene i dati.\n\nCodicedlist2 <- list(\n  N = length(df$y),\n  y = df$y\n)\n\n\nLeggo il file con il codice Stan del modello.\n\nCodicefile2 <- file.path(\"code\", \"normal_mod_2.stan\")\n\n\nCompilo il modello.\n\nCodicemod2 <- cmdstan_model(file2)\n\n\nEseguo il campionamento MCMC.\n\nCodicefit2 <- mod2$sample(\n  data = dlist2,\n  iter_sampling = 50000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n\n\nIn questo modo ottengo le seguenti stime a posteriori dei parametri.\n\nCodicefit2$summary(c(\"mu\", \"sigma\"))\n#> # A tibble: 2 √ó 10\n#>   variable  mean median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu       29.2   29.2   1.14 1.12  27.3  31.0   1.00  129256.  114237.\n#> 2 sigma     7.06   6.95  1.01 0.954  5.63  8.88  1.00  121123.  115765.\n\n\nDopo avere trasformato l‚Äôoggetto fit2 nel formato stanfit, trovo l‚Äôintervallo di credibilit√† al 95%.\n\nCodicestanfit <- rstan::read_stan_csv(fit2$output_files())\nout <- rstantools::posterior_interval(\n  as.matrix(stanfit), \n  prob = 0.95\n)\nout\n#>             2.5%      97.5%\n#> mu     26.851295  31.331500\n#> sigma   5.418299   9.360616\n#> lp__  -76.415107 -72.666800\n\n\nCome in precedenza, uso la funzione mcmc_areas() per creare una rappresentazione grafica della distribuzione a posteriori di \\(\\mu\\).\n\nCodicemu_draws <- as.matrix(stanfit, pars =\"mu\")\nmcmc_areas(mu_draws, prob = 0.95) \n\n\n\n\n\n\n\nConsiderati i dati osservati e le mie ipotesi a priori sui parametri, posso dunque concludere, con un grado di certezza soggettiva del 95%, che la media della popolazione dei punteggi BDI-II dei pazienti clinici depressi √® compresa nell‚Äôintervallo [26.85, 31.33]."
  },
  {
    "objectID": "050_normal_normal_mod.html#commenti-e-considerazioni-finali",
    "href": "050_normal_normal_mod.html#commenti-e-considerazioni-finali",
    "title": "24¬† Inferenza sul parametro \\(\\mu\\) (media di una v.c. Normale)",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo capitolo abbiamo visto come calcolare l‚Äôintervallo di credibilit√† per la media di una v.c. Normale. La domanda pi√π ovvia di analisi dei dati, dopo avere visto come trovare l‚Äôintervallo di credibilit√† per la media di un solo gruppo, riguarda il confronto tra le medie di due gruppi. Il confronto tra le medie di due gruppi pu√≤ essere considerato come un caso particolare di un metodo pi√π generale di analisi dei dati, chiamato analisi di regressione lineare. Prima di discutere il problema del confronto tra le medie di due gruppi √® dunque necessario esaminare il modello statistico della regressione lineare.\n\n\n\n\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "051_reglin1.html",
    "href": "051_reglin1.html",
    "title": "25¬† Introduzione",
    "section": "",
    "text": "Lo scopo della ricerca √® trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra i costrutti psicologici e le relazioni che intercorrono tra i fenomeni psicologici e quelli non psicologici (sociali, economici, storici, ‚Ä¶). Abbiamo gi√† visto come la correlazione di Pearson sia uno strumento adatto a questo scopo. Infatti, essa ci informa sulla direzione e sull‚Äôintensit√† della relazione lineare tra due variabili. Tuttavia, la correlazione non √® sufficiente, in quanto il ricercatore ha a disposizione solo i dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. A causa della variabilit√† campionaria, le propriet√† dei campioni sono necessariamente diverse da quelle della popolazione: ci√≤ che si pu√≤ osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. √à dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le propriet√† del campione e le propriet√† della popolazione da cui esso √® stato estratto. Il modello lineare utilizza la funzione matematica pi√π semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. In questo Capitolo vedremo come si possa fare inferenza sulla relazione tra due variabili mediante il modello lineare bayesiano. Inizieremo a descrivere le propriet√† geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire un modello statistico secondo un approccio bayesiano."
  },
  {
    "objectID": "051_reglin1.html#la-funzione-lineare",
    "href": "051_reglin1.html#la-funzione-lineare",
    "title": "25¬† Introduzione",
    "section": "\n25.1 La funzione lineare",
    "text": "25.1 La funzione lineare\nIniziamo con un ripasso sulla funzione di lineare. Si chiama funzione lineare una funzione del tipo\n\\[\\begin{equation}\nf(x) = a + b x,\n\\end{equation}\\]\ndove \\(a\\) e \\(b\\) sono delle costanti. Il grafico di tale funzione √® una retta di cui il parametro \\(b\\) √® detto coefficiente angolare e il parametro \\(a\\) √® detto intercetta con l‚Äôasse delle \\(y\\) [infatti, la retta interseca l‚Äôasse \\(y\\) nel punto \\((0,a)\\), se \\(b \\neq 0\\)].\nPer assegnare un‚Äôinterpretazione geometrica alle costanti \\(a\\) e \\(b\\) si consideri la funzione\n\\[\\begin{equation}\ny = b x.\n\\end{equation}\\]\nTale funzione rappresenta un caso particolare, ovvero quello della proporzionalit√† diretta tra \\(x\\) e \\(y\\). Il caso generale della linearit√†\n\\[\\begin{equation}\ny = a + b x\n\\end{equation}\\]\nnon fa altro che sommare una costante \\(a\\) a ciascuno dei valori \\(y = b x\\). Nella funzione lineare \\(y = a + b x\\), se \\(b\\) √® positivo allora \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) √® negativo allora \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\) la retta √® orizzontale, ovvero \\(y\\) non muta al variare di \\(x\\).\nConsideriamo ora il coefficiente \\(b\\). Si consideri un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\) come indicato nella figura @ref(fig:linearfunction). Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono detti incrementi di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) √® uguale al rapporto\n\\[\\begin{equation}\n    b = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\end{equation}\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Il modo pi√π semplice per assegnare un‚Äôinterpretazione geometrica al coefficiente angolare (o pendenza) della retta √® dunque quello di porre \\(\\Delta x = 1\\). In tali circostanze infatti \\(b = \\Delta y\\).\n\n\n\n\nLa funzione lineare \\(y = a + bx\\)."
  },
  {
    "objectID": "051_reglin1.html#una-media-per-ciascuna-osservazione",
    "href": "051_reglin1.html#una-media-per-ciascuna-osservazione",
    "title": "25¬† Introduzione",
    "section": "\n25.2 Una media per ciascuna osservazione",
    "text": "25.2 Una media per ciascuna osservazione\nIn precedenza abbiamo visto come sia possibile stimare i parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densit√† gaussiana,\n\\[\\begin{equation}\nY_i \\stackrel{i.i.d.}{\\sim} \\mathcal{N}(\\mu, \\sigma), \\quad i = 1, \\dots, n.\n(\\#eq:normalsamplingmodel)\n\\end{equation}\\]\nIl modello @ref(eq:normalsamplingmodel) assume che ogni \\(Y_i\\) sia la realizzazione di una v.c. descritta da una \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Da un punto di vista bayesiano,questo modello pu√≤ essere implementato assegnando le distribuzioni a priori ai parametri \\(\\mu\\) e \\(\\sigma\\) e generando la verosimiglianza in base ai dati osservati. Con queste informazioni, possono poi essere definite le distribuzioni a posteriori dei parametri (Gelman et al., 2020):\n\\[\\begin{align}\nY_i \\mid \\mu, \\sigma & \\stackrel{iid}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)\\notag\\\\\n\\mu       & \\sim \\mathcal{N}(\\mu_0, \\tau^2) \\notag\\\\\n\\sigma    & \\sim \\mbox{Cauchy}(x_0, \\gamma) \\notag\n\\end{align}\\]"
  },
  {
    "objectID": "051_reglin1.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore",
    "href": "051_reglin1.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore",
    "title": "25¬† Introduzione",
    "section": "\n25.3 Relazione lineare tra la media \\(y \\mid x\\) e il predittore",
    "text": "25.3 Relazione lineare tra la media \\(y \\mid x\\) e il predittore\n√à per√≤ comune che vengano registrate altre variabili che possono essere associate alla risposta di interesse \\(y_i\\). Chiamiamo \\(x\\) una di tali variabili. La variabile \\(x\\) viene chiamata predittore (o variabile indipendente) in quanto il ricercatore √® tipicamente interessato a predire \\(y_i\\) a partire dal valore assunto da \\(x_i\\). Come si pu√≤ estende il modello @ref(eq:normalsamplingmodel) descritto in precedenza per lo studio della relazione tra \\(y_i\\) e \\(x_i\\)?\nIl modello @ref(eq:normalsamplingmodel) assume una media \\(\\mu\\) comune per ciascuna osservazione \\(Y_i\\). Dal momento che desideriamo introdurre una nuova variabile \\(x_i\\) che assume un diverso valore per ciascuna osservazione \\(y_i\\), il modello @ref(eq:normalsamplingmodel) pu√≤ essere modificato in modo che la media comune \\(\\mu\\) venga sostituita da una media \\(\\mu_i\\) specifica a ciascuna osservazione \\(i\\)-esima:\n\\[\\begin{equation}\nY_i \\mid \\mu_i, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\mu_i, \\sigma), \\quad i = 1, \\dots, n.\n(\\#eq:normalsamplinglinearmodel)\n\\end{equation}\\]\nSi noti che le osservazioni \\(Y_1, \\dots, Y_n\\) non sono pi√π identicamente distribuite poich√© hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione ind posta sopra il simbolo \\(\\sim\\) nella @ref(eq:normalsamplinglinearmodel).\nL‚Äôapproccio che consente di mettere in relazione un predittore \\(x_i\\) con la risposta \\(Y_i\\) √® quello di assumere che la media di ciascuna \\(Y_i\\), ovvero \\(\\mu_i\\), sia una funzione lineare del predittore \\(x_i\\). Una tale relazione lineare √® scritta come\n\\[\\begin{equation}\n\\mu_i = \\beta_0 + \\beta_ 1 x_i, \\quad i = 1, \\dots, n.\n(\\#eq:regmodel)\n\\end{equation}\\]\nNella @ref(eq:regmodel), ciascuna \\(x_i\\) √® una costante nota (ecco perch√© viene usata una lettera minuscola per la \\(x\\)) e \\(\\beta_0\\) e \\(\\beta_ 1\\) sono parametri incogniti. Questi parametri rappresentano l‚Äôintercetta e la pendenza della retta di regressione e sono delle variabili casuali.1 L‚Äôinferenza bayesiana procede assegnando una distribuzione a priori a \\(\\beta_0\\) e a \\(\\beta_ 1\\) e si esegue l‚Äôinferenza riassumendo la distribuzione a posteriori di questi parametri.\nNel modello @ref(eq:regmodel), la funzione lineare \\(\\beta_0 + \\beta_ 1 x_i\\) √® interpretata come il valore atteso della \\(Y_i\\) per ciascun valore \\(x_i\\), mentre l‚Äôintercetta \\(\\beta_0\\) rappresenta il valore atteso della \\(Y_i\\) quando \\(x_i = 0\\). Il parametro \\(\\beta_ 1\\) (pendenza) rappresenta invece l‚Äôaumento medio della \\(Y_i\\) quando \\(x_i\\) aumenta di un‚Äôunit√†. √à importante notare che la relazione lineare @ref(eq:normalsamplinglinearmodel) di parametri \\(\\beta_0\\) e \\(\\beta_ 1\\) descrive l‚Äôassociazione tra la media \\(\\mu_i\\) e il predittore \\(x_i\\). In altri termini, tale relazione lineare ci fornisce una predizione sul valore medio \\(\\mu_i\\), non sul valore effettivo \\(Y_i\\)."
  },
  {
    "objectID": "051_reglin1.html#il-modello-lineare",
    "href": "051_reglin1.html#il-modello-lineare",
    "title": "25¬† Introduzione",
    "section": "\n25.4 Il modello lineare",
    "text": "25.4 Il modello lineare\nSostituendo la @ref(eq:regmodel) nella @ref(eq:normalsamplinglinearmodel) otteniamo il modello lineare:\n\\[\\begin{equation}\nY_i \\mid \\beta_0, \\beta_ 1, \\sigma \\stackrel{ind}{\\sim} \\mathcal{N}(\\beta_0 + \\beta_ 1 x_i, \\sigma), \\quad i = 1, \\dots, n.\n(\\#eq:samplinglinearmodel)\n\\end{equation}\\]\nQuesto √® dunque un caso speciale del modello di campionamento Normale, dove le \\(Y_i\\) seguono indipendentemente una densit√† Normale con una media (\\(\\beta_0 + \\beta_ 1 x_i\\)) specifica per ciascuna osservazione e con una deviazione standard (\\(\\sigma\\)) comune a tutte le osservazioni. Poich√© include un solo predittore (\\(x\\)), questo modello √® chiamato modello di regressione lineare bivariata.\nIl modello statistico di regressione lineare bivariata pu√≤ essere rappresentato in forma geometrica come indicato di seguito. La figura illustra che, in tale modello statistico, la variabile \\(X\\) √® fissa per disegno ‚Äì in altre parole, i valori \\(x\\) restano immutati tra campioni diversi. Potendo ipotizzare infiniti campioni tutti con gli stessi valori \\(x\\), in corrispondenza di ciascun valore \\(x_i\\) vi sar√† una distribuzione di valori \\(y\\). La figura illustra il caso di tre valori \\(x\\). A ciascun valore \\(x_i\\), con \\(i = 1, 2, 3\\) per l‚Äôesempio della figura, corrisponde una distribuzione di valori \\(y\\) condizionati a \\(x_i\\), \\(p(y \\mid x_i)\\).\n\n\n\n\n\n\n\n\nIl modello statistico di regressione lineare assume che le distribuzioni condizionate \\(p(y \\mid x_i)\\) siano\n\\[\ny_i \\sim \\mathcal{N}(\\mu_i, \\sigma),\n\\]\n(assunzione di normalit√†), laddove\n\\[\n\\mu_i = \\mathbb{E}(y \\mid x_i) = \\alpha + \\beta x_i.\n\\]\nL‚Äôequazione precedente descrive l‚Äôassunzione di linearit√†.\nSi noti che il parametro \\(\\sigma\\) non ha un pedice: questo significa che il modello ipotizza una dispersione costante delle distribuzioni \\(p(y \\mid x_i), \\forall i\\). Tale assunzione va sotto il nome di omoschedasticit√†.\nSe questa √® la struttura della popolazione, possiamo pensare ad un campione casuale di ampiezza \\(n\\) come ad una serie di coppie \\(x_i, y_i\\), con \\(i = 1, \\dots, n\\), nelle quali i valori \\(x\\) sono fissi per disegno e ciascun valore \\(y_i\\) √® una realizzazione della variabile casuale \\(Y = y_i \\mid X = x_i\\). Questa √® l‚Äôultima assunzione del modello statistico lineare: l‚Äôindipendenza. In maniera equivalente possiamo dire che gli errori \\(\\varepsilon_i = y_i - \\hat{y}_i = y_i - (\\beta_0 + \\beta_1 x_i)\\) sono variabili casuali distribuite secondo la legge Normale di parametri \\(\\mathcal{N}(0, \\sigma)\\)."
  },
  {
    "objectID": "051_reglin1.html#commenti-e-considerazioni-finali",
    "href": "051_reglin1.html#commenti-e-considerazioni-finali",
    "title": "25¬† Introduzione",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIl modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l‚Äôintensit√† di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente.\n\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press."
  },
  {
    "objectID": "052_reglin2.html",
    "href": "052_reglin2.html",
    "title": "26¬† Regressione lineare con un singolo predittore",
    "section": "",
    "text": "La regressione √® un metodo statistico che consente di predire un esito \\(y\\) sulla base della conoscenza delle variabili \\(x_1, x_2, \\dots\\). In questo Capitolo verr√† introdotto il modello di regressione che predice una variabile continua \\(y\\) a partire da un unico predittore continuo \\(x\\). Ci√≤ corrisponde ad adattare ai dati (\\(x_i, y_i\\)) la retta di regressione \\(y_i = a + bx_i + e_i\\), con \\(i=1, \\dots, n\\). Usando dei dati reali, vedremo come stimare i coefficienti di regressione \\(a\\) e \\(b\\) e come essi possano essere interpretati. Vedremo anche di descrivere la bont√† di adattamento del modello ai dati.\nNell‚Äôesempio che discuteremo in questo Capitolo verranno usati i dati kidiq. Riporto qui di seguito la descrizione delle variabili che sono state misurate in questo campione.\nIn questo esercizio sulla regressione lineare considerer√≤ la relazione tra l‚Äôintelligenza del bambino (kid_score) e l‚Äôintelligenza della madre (mom_iq). Mi chieder√≤ se l‚Äôintelligenza della madre sia in grado di predire l‚Äôintelligenza del bambino e in che misura lo faccia.\nLeggo i dati in \\(\\mathsf{R}\\).\nI dati rappresentati in un diagramma a dispersione suggeriscono che, in questo campione, sembra effettivamente esserci un‚Äôassociazione positiva tra l‚Äôintelligenza del bambino (kid_score) e l‚Äôintelligenza della madre (mom_iq).\nLa regressione lineare descrive questa associazione mediante una retta.\nCi sono infinite rette che, in linea di principio, possono essere usate per ‚Äúapprossimare‚Äù la nube di punti nel diagramma a dispersione. √à dunque necessario introdurre dei vincoli per selezionare una di queste possibili rette. Un vincolo che viene introdotto dal modello di regressione √® quello di costringere la retta a passare per il punto \\((\\bar{x}, \\bar{y})\\).\nUna retta che passa per il punto \\((\\bar{x}, \\bar{y})\\) ha delle desiderabili propriet√† statistiche che verranno descritte in seguito.\nIl campione √® costituito da \\(n\\) coppie di osservazioni (\\(x, y\\)). Per ciascuna coppia di valori \\(x_i, y_i\\), il modello di regressione si aspetta che il valore \\(y_i\\) sia associato al corrispondente valore \\(x_i\\) come indicato dalla seguente equazione:\n\\[\ny_i = a + b x_i + e_i\n\\]\nI valori \\(y_i\\) corrispondono, nell‚Äôesempio che stiamo discutendo, alla variabile kid_score. I primi 10 valori della variabile \\(y\\) sono i seguenti:\nPer fare riferimento a ciascuna osservazione usiamo l‚Äôindice \\(i\\). Quindi, ad esempio, \\(y_3\\) √® uguale a\nNel caso presente, la variabile \\(x\\) √® mom_iq. I primi 10 valori di \\(x\\) sono\nIn maniera corrispondente alla \\(y\\), uso un indice per fare riferimento ai singoli valori della variabile. Ad esempio, \\(x_3\\) √®\nL‚Äôequazione precedente ci dice che ciascun valore \\(y\\) √® dato dalla somma di due componenti: una componente deterministica e una componente aleatoria. Consideriamo il primo valore \\(y\\) del campione. Per esso, il modello di regressione ci dice che\n\\[\ny_1 = a + b x_1 + e_1,\n\\]\nladdove \\(a + b x_1\\) √® la componente deterministica, denotata con \\(\\hat{y}\\), e \\(e_1\\) √® la componente aleatoria.\nLa componente deterministica √® la componente di ciascun valore \\(y_i\\) che √® possibile prevedere conoscendo \\(x_i\\). Tuttavia, non √® possibile prevedere perfettamente i valori \\(y\\) ‚Äì ci√≤ si verificherebbe soltanto se tutti punti del diagramma a dispersione fossero disposti su una retta. Ma non lo sono mai nella pratica concreta: la retta √® solo un‚Äôapprossimazione della relazione (lineare) tra \\(x\\) e \\(y\\). Pertanto, conoscendo \\(x_i\\) possiamo solo prevedere una ‚Äúcomponente‚Äù del corrispondente valore \\(y_i\\).\nCosa significa che possiamo prevedere una componente di ciascuna osservazione \\(y_i\\)? Significa che il valore osservato \\(y_i\\) sar√† diverso dal valore \\(\\hat{y}_i\\) previsto dal modello. Ciascun valore \\(y_i\\) sar√† dunque dato dalla seguente somma: \\(y_i = \\hat{y}_i + e_i\\), laddove \\(e_i\\), detto ‚Äúresiduo‚Äù √® la componente di \\(y_i\\) non predicibile dal modello lineare.\nCi possiamo dunque porre due domande:\nRispondere a tali due domanda definisce i primi due obiettivi del modello statistico della regressione lineare. Il terzo obiettivo √® quello dell‚Äôinferenza, ovvero quello di capire che relazioni ci sono tra la relazione tra \\(x\\) e \\(y\\) osservata nel campione e la la relazione tra le due variabili nella popolazione."
  },
  {
    "objectID": "052_reglin2.html#stima-dei-coefficienti-di-regressione",
    "href": "052_reglin2.html#stima-dei-coefficienti-di-regressione",
    "title": "26¬† Regressione lineare con un singolo predittore",
    "section": "\n26.1 Stima dei coefficienti di regressione",
    "text": "26.1 Stima dei coefficienti di regressione\nIniziamo con il primo obiettivo, ovvero quello di trovare i coefficienti \\(a\\) e \\(b\\) che consentono di predire una componente di ciascuna osservazione \\(y\\) conoscendo \\(x\\). Quindi, nel caso presente, ci chiediamo quanto segue. Il primo bambino del campione ha un QI uguale a 65. Sua madre ha un QI di 121.12. Qual √® la predizione migliore del QI del bambino che possiamo ottenere conoscendo il QI della madre?\n√à chiaro, guardando i dati del campione, che non c‚Äô√® una corrispondenza perfetta tra QI della madre e QI del bambino, tutt‚Äôaltro! Infatti, se guardiamo il diagramma di dispersione ci rendiamo conto che i punti sono piuttosto lontani dalla retta che abbiamo sovrapposto alla nube di punti \\(x_i, y_i\\). Tuttavia, il diagramma di dispersione ci suggerisce che, al di l√† del rumore, c‚Äô√® comunque una relazione tra le due variabili. Il nostro obiettivo √® trovare un metodo quantitativo per descrivere una tale relazione.\nAbbiamo detto che √® possibile prevedere una componente di \\(y_i\\) conoscendo \\(x_i\\). La componente \\(y_i\\) predicibile da \\(x_i\\) viene denotata da \\(\\hat{y}_i\\) e, nei termini del modello di regressione lineare √® uguale a\n\\[\n\\hat{y}_i = a_i + bx_i.\n\\]\nL‚Äôequazione precedente √® un‚Äôequazione lineare e, dal punto di vista geometrico, corrisponde ad una retta. Ci sono infinite equazioni che, in linea di principio, possiamo usare per descrivere la relazione tra \\(x\\) e \\(y\\). Abbiamo scelto la relazione lineare perch√© √® la pi√π semplice. Se guardiamo il diagramma di dispersione, infatti, non ci sono ragioni per descrivere la relazione tra il QI del bambino e il QI della madre con qualche curva, anzich√© con una retta. In altri campioni, una curva potrebbe essere pi√π sensata di una retta, quale descrizione della relazione media tra \\(x\\) e \\(y\\), ma non nel caso presente. Ricordiamo il principio del rasoio di Occam (ovvero, il principio che sta alla base del pensiero scientifico moderno): se un modello semplice funziona, non c‚Äô√® ragione di usare un modello pi√π complesso.\nDunque, abbiamo capito che vogliamo descrivere la relazione media tra \\(x\\) e \\(y\\) con una retta, ovvero, mediante l‚Äôequazione lineare\n\\[\n\\hat{y}_i = a + b x_i.\n\\]\nL‚Äôequazione precedente ci dice che il modello lineare \\(a + b x_i\\) non √® in grado di prevedere completamente i valori \\(y_i\\). Questo, in generale, non √® mai possibile (ovvero, √® possibile solo in un caso specifico che, nella realt√† empirica, non si verifica mai). L‚Äôequazione precedente ci dice che possiamo prevedere solo una componente di ciascuna osservazione \\(y_i\\), ovvero quella componente che abbiamo denotato con \\(\\hat{y}_i\\). La componente che non possiamo prevedere con l‚Äôequazione \\(a + b x_i\\) viene detta residuo e si denota con \\(e_i\\):\n\\[\ne_i = y_i - \\hat{y}_i = y_i - (a + bx_i).\n\\]\nDal punto di vista geometrico, la componente erratica del modello, \\(e_i\\), corrisponde alla distanza verticale tra ciascun punto del diagramma a dispersione e la retta di regressione \\(a + bx\\). Diciamo che scomponiamo il valore di ciascuna osservazione \\(y_i\\) in due componenti nel senso che\n\\[\ny_i = \\hat{y}_i + e_i = (a + bx_i) + e_i.\n\\]\nIl primo obiettivo del modello di regressione √® quello di trovare i coefficienti dell‚Äôequazione\n\\[\na + b x_i\n\\]\nche consente di trovare \\(\\hat{y}_i\\) conoscendo \\(x_i\\). Questi due coefficienti sono detti coefficienti di regressione.\nPer trovare i coefficienti di regressione dobbiamo introdurre dei vincoli per limitare lo spazio delle possibili soluzioni. Il primo di tali vincoli √® stato introdotto in precedenza: vogliamo che la retta \\(\\hat{y}_i = a + b x_i\\) passi per il punto \\((\\bar{x}, \\bar{y})\\). Il punto \\((\\bar{x}, \\bar{y})\\) corrisponde al baricentro del diagramma a dispersione.\nCi sono per√≤ infinite rette che passano per i punto \\((\\bar{x}, \\bar{y})\\). Tutte queste rette soddisfano la seguente propriet√†:\n$$\n_{i=1}^n e_i = 0,\n$$\novvero, fanno in modo che la somma dei residui (positivi, per i punti che si trovano al di sopra della retta di regressione, negativi, per punti che si trovano al di sotto della retta di regressione) sia uguale a zero.\nQuesto significa che non possiamo selezionare una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\) usando il criterio che ci porta a scegliere la retta che rende la pi√π piccola possibile (ovvero, minimizza) la somma dei residui. Infatti, tutte le rette passanti per il punto \\((\\bar{x}, \\bar{y})\\) soddisfano questo requisito (rendono uguale a zero la somma dei residui). Dunque, dobbiamo trovare qualche altri criterio per scegliere una tra le infinite rette che passano per il punto \\((\\bar{x}, \\bar{y})\\).\nIl criterio che viene normalmente scelto √® quello di minimizzare la somma dei quadrati dei residui \\((y_i - \\hat{y}_i)^2\\). In altri termini, vogliamo trovare i coefficienti \\(a\\) e \\(b\\) tali per cui la quantit√†\n$$\n_{i=1}^{n}{(y_i - (a + b x_i))^2}\n$$\nassume il suo valore minimo. I coefficienti \\(a\\) e \\(b\\) che soddisfano questa propriet√† si chiamano coefficienti dei minimi quadrati.\nQuesto problema ha una soluzione analitica. La soluzione analitica si trova riconoscendo il fatto che l‚Äôequazione precedente definisce una superficie e il problema diventa quello di trovare il punto di minimo di questa superficie. Per trovare la soluzione ci si deve rendere conto che il punto cercato √® quello per cui il piano tangente alla superficie (nelle due direzioni \\(a\\) e \\(b\\)) √® piatto (le tangenti nelle due direzioni sono uguali a zero). Rendere uguale a zero la tangente ad una curva significa porre uguali a zero la derivata della curva. Nel caso presente, abbiamo una superficie, dunque due tangenti ortogonali e quindi abbiamo il problema di rendere uguali a zero le derivate parziali rispetto ad \\(a\\) e \\(b\\). Cos√¨ facendo si definisce un sistema di equazioni lineari con due incognite, \\(a\\) e \\(b\\). La soluzione di tali equazioni, che si chiamano equazioni normali, √® la seguente:\n$$\na = {y} - b {x},\n$$\n$$\nb = .\n$$\nLe due precedenti equazioni corrispondono alla stima dei minimi quadrati dei coefficienti di regressione della retta che minimizza la somma dei quadrati dei residui.\nNel caso dell‚Äôesempio presente, tali coefficienti sono uguali a:\n\nCodiceb <- cov(kidiq$kid_score, kidiq$mom_iq) / var(kidiq$mom_iq)\nb\n#> [1] 0.6099746\n\n\n\nCodicea <- mean(kidiq$kid_score) - b * mean(kidiq$mom_iq)\na\n#> [1] 25.79978\n\n\nIn \\(\\mathsf{R}\\) li possiamo facilmente trovare con la seguente funzione:\n\nCodicefm <- lm(kid_score ~ mom_iq, data = kidiq)\ncoef(fm)\n#> (Intercept)      mom_iq \n#>  25.7997778   0.6099746\n\n\nIn precedenza abbiamo soltanto accennato al problema di come si possono trovano i coefficienti dei minimi quadrati; ritorneremo su questo punto in seguito, con una simulazione. Per ora, chiediamoci cosa significano i due coefficienti che abbiamo appena trovato.\nIl coefficiente \\(a\\) si chiama intercetta. L‚Äôintercetta, all‚Äôinterno del diagramma a dispersione, specifica il punto in cui la retta di regressione interseca l‚Äôasse \\(y\\) del sistema di assi cartesiani.\nNel caso presente questo valore non √® di alcun interesse, perch√© corrisponde al valore della retta di regressione quando \\(x = 0\\), ovvero quando l‚Äôintelligenza della madre √® uguale a 0. Vedremo in seguito come, trasformando i dati, √® possibile assegnare al coefficiente \\(a\\) un‚Äôinterpretazione pi√π utile. Per ora mi limito a fornire l‚Äôinterpretazione del coefficiente.\nPassando a \\(b\\), possiamo dire che questo secondo coefficiente va sotto il nome di pendenza della retta di regressione. Ovvero ci dice di quanto aumenta (se \\(b\\) √® positivo) o diminuisce (se \\(b\\) √® negativo) la retta di regressione in corrispondenza di un aumento di 1 punto della variabile \\(x\\).\nNel caso presente, il coefficiente \\(b\\) ci dice che, se il QI delle madri aumenta di 1 punto, il QI dei bambini aumenta in media di 0.61 punti.\n√à importante capire cosa significa che, in base ai risultati della regressione, \\(y\\) aumenta in media di \\(b\\) punti per ciascun aumento unitario di \\(x\\).\nIl modello statistico di regressione ipotizza che, per ciascun valore osservato \\(x\\) (per esempio, il valore del QI della prima madre del campione, ovvero \\(x = 121.11753\\)) ci sia una distribuzione di valori \\(y\\) nella popolazione, di cui solo uno √® stato osservato nel campione. Possiamo facilmente capire che, se consideriamo tutte le madri con QI di 121.12, il punteggio del QI dei loro figli non sia costante, ma assuma tanti valori possibili. Questa distribuzione di valori possibili si chiama distribuzione \\(y\\) condizionata a \\(x\\), ovvero \\(p(y \\mid x_i)\\).\nIl modello statistico della regressione lineare non pu√≤ in alcun modo prevedere il valore assunto da ciascuna delle possibili osservazioni che fanno parte della distribuzione \\(p(y \\mid x_i)\\). Il modello della regressione lineare ha un obiettivo pi√π limitato, ovvero si propone di prevedere le medie delle distribuzioni \\(p(y \\mid x_i)\\) conoscendo i valori \\(x\\).\nDunque, quando il coefficiente \\(b\\) √® uguale a 0.61, questo significa che il modello di regressione predice che la medie della distribuzione condizionata \\(p(y \\mid x_i)\\) aumenta di 0.61 punti se la variabile \\(x\\) (QI delle madri) aumenta di un punto. Questo significa che il modello di regressione non fa una predizione sul punteggio di ciascun valore \\(y_i\\) (in funzione di \\(x\\)), ma solo della media delle distribuzioni condizionate \\(p(y \\mid x_i)\\) di cui il valore osservato \\(y_i\\) √® una realizzazione casuale.\nPossiamo dire la stessa cosa con parole diverse dicendo che il modello di regressione fa delle predizioni sulla componente deterministica di ciascuna osservazione. √à pi√π semplice capire questo aspetto se rappresentiamo in maniera grafica la componente ‚Äúdeterministica‚Äù \\(\\hat{y}_i = a + b x_i\\) predetta dal modello di regressione.\n\nCodicekidiq$yhat <- fm$fitted.values\nkidiq %>% \n  ggplot(aes(x = mom_iq, y = yhat)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(\n    aes(x=mean(mom_iq), y=mean(kid_score)), \n    colour=\"red\", size = 4\n  )\n\n\n\n\n\n\n\nIl diagramma precedente presenta ciascun valore \\(\\hat{y}_i = a + b x_i\\) in funzione di \\(x_i\\). Si vede che i valori predetti dal modello di regressione sono i punti che stanno sulla retta di regressione.\nIn precedenza abbiamo detto che il residuo, ovvero la componente di ciascuna osservazione \\(y_i\\) che non viene predetta dal modello di regressione, corrisponde alla distanza verticale tra il valore \\(y_i\\) osservato e il valore \\(\\hat{y}_i\\) predetto dal modello di regressione:\n$$\ne_i = y_i - (a + b x_i).\n$$\nNel caso nella prima osservazione, ad esempio abbiamo:\n$$\ny_1 = (a + b x_1) + e_1\n$$\nAbbiamo\n\nCodicekidiq$kid_score[1]\n#> [1] 65\n\n\nDunque\n$$\ne_1 = (a + b x_1) - y_1\n$$\n\nCodicee_1 <- kidiq$kid_score[1] - (a + b * kidiq$mom_iq[1])\ne_1\n#> [1] -34.67839\n\n\nCi√≤ significa che il valore osservato \\(y_1 = 65\\) viene scomposto dal modello di regressione in due componenti. La componente deterministica \\(\\hat{y}_1\\), predicibile da \\(x_1\\), √®\n\nCodiceyhat_1 <- a + b * kidiq$mom_iq[1]\nyhat_1\n#> [1] 99.67839\n\n\nLa somma della componente deterministica e della componente erratica, ovviamente, riproduce il valore osservato.\n\nCodiceyhat_1 + e_1\n#> [1] 65\n\n\nSe sommiamo tutti i residui calcolati rispetto alla retta di regressione dei minimi quadrati otteniamo zero:\n\nCodicesum(fm$res)\n#> [1] 5.373479e-13\n\n\n\n26.1.1 Trasformazione dei dati\nIn generale, per variabili a livello di scala ad intervalli, non √® possibile assegnare un‚Äôinterpretazione utile all‚Äôintercetta del modello di regressione lineare. L‚Äôintercetta ci dice infatti qual √® il valore atteso della \\(y\\) quando \\(x = 0\\). Ma, se la variabile \\(x\\) √® misurata su scala ad intervalli, il valore \\(x = 0\\) √® arbitrario e non corrisponde ‚Äúall‚Äôassenza di intensit√†‚Äù della variabile \\(x\\). Un valore pari a 0 del QI della madre non vuol dire che l‚Äôintelligenza della madre sia nulla (un‚Äôaffermazione, questa, che √® difficile da capire), ma semplicemente che il punteggio del test usato per misurare il QI della madre assume valore 0 (qualcosa che, comunque, in pratica non succeder√† mai). Quindi √® di poco interesse sapere qual √® il valore medio del QI del bambino quando test usato per misurare il QI della madre ha valore 0. Per potere fornire all‚Äôintercetta del modello di regressione un‚Äôinterpretazione pi√π utile dobbiamo trasformare le osservazioni \\(x\\).\nEsprimiamo \\(x\\) come differenza dalla media. Chiamiamo questa nuova variabile \\(xd\\):\n\nCodicekidiq$xd <- kidiq$mom_iq - mean(kidiq$mom_iq)\n\n\nSe ora usiamo le coppie di osservazioni \\(xd_i, y_i\\), il diagramma a dispersione assume la forma seguente.\n\nCodicekidiq %>% \n  ggplot(aes(x = xd, y = kid_score)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(\n    aes(x=mean(xd), y=mean(kid_score)), \n    colour=\"red\", size = 4\n  )\n\n\n\n\n\n\n\nQuello che abbiamo fatto √® stato di traslare rigidamente la nube di punti sul piano cartesiano di una quantit√† pari alla distanza tra \\(\\bar{x}\\) e l‚Äôorigine. Dunque, le relazioni spaziali tra i punti del diagramma a dispersione restano immutate. Di conseguenza, la pendenza della retta di regressione calcolata sui dati trasformati √® uguale a quella che si trova nel caso dei dati non trasformati. Ci√≤ che cambia √® il valore dell‚Äôintercetta.\n\nCodicefm1 <- lm(kid_score ~ xd, data = kidiq)\ncoef(fm1)\n#> (Intercept)          xd \n#>  86.7972350   0.6099746\n\n\nL‚Äôintercetta corrisponde al punto sull‚Äôasse \\(y\\) dove la retta di regressione interseca l‚Äôordinata. Ma, nel caso dei dati trasformati, dato che abbiamo traslato i punti di una quantit√† pari a \\(x - \\bar{x}\\), il valore \\(xd = 0\\) corrisponde a \\(x = \\bar{x}\\) nel caso dei dati grezzi. Dunque, per i dati trasformati \\(xd_i, y_i\\), l‚Äôintercetta corrisponder√† al valore atteso della \\(y\\) in corrispondenza del valore medio della variabile \\(x\\) sulla scala dei dati non trasformati (ovvero \\(\\bar{x}\\)). In altre parole, l‚Äôintercetta del modello di regressione lineare calcolata sui dati trasformati corrisponde al QI medio dei bambini in corrispondenza del QI medio delle madri.\n\n26.1.2 Il metodo dei minimi quadrati\nOra che abbiamo visto come interpretare il coefficienti di regressione, chiediamoci come vengono calcolati. La procedura generale √® stata brevemente descritta in precedenza. Vediamo ora come si giunge alla conclusione descritta sopra usando una simulazione.\nIl problema √® di trovare i valori \\(a\\) e \\(b\\) tali per cui la quantit√† \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\) assume il valore minore possibile. Questo √® un problema di minimizzazione rispetto a due parametri. Per dare un‚Äôidea di come si fa, semplifichiamo il problema e supponiamo che uno dei due parametri sia noto, ad esempio \\(a\\), cos√¨ ci resta una sola incognita.\nCredo una griglia di valori b_grid possibili, ad esempio:\n\nCodicenrep <- 1e5\nb_grid <- seq(0, 1, length.out = nrep)\n\n\nDefinisco una funzione che calcola la quantit√† \\(\\sum_{i=1}^{n}{(y_i - (a + b x_i))^2}\\):\n\nCodicesse <- function(a, b, x, y) {\n  sum((y - (a + b * x))^2)\n}\n\n\nCalcolo la somma degli errori quadratici per ciascun possibile valore b_grid, fissando \\(a = 25.79978\\).\n\nCodicesse_res <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  sse_res[i] <- sse(a = 25.79978, b = b_grid[i], x = kidiq$mom_iq, y = kidiq$kid_score)\n}\n\n\nEsaminiamo il risultato ottenuto.\n\nCodiceplot(\n  b_grid, sse_res, type = 'l'\n)\n\n\n\n\n\n\n\nIl risultato ottenuto con la simulazione\n\nCodiceb_grid[which.min(sse_res)]\n#> [1] 0.6099761\n\n\nriproduce quello ottenuto per via analitica:\n\nCodiceb\n#> [1] 0.6099746\n\n\nUna simulazione simile, ma computazionalmente pi√π complessa, pu√≤ essere usata per stimare simultaneamente entrambi i parametri. Ci siamo limitati qui ad una proof of concept del caso pi√π semplice.\n\n26.1.3 L‚Äôerrore standard della regressione\nIl secondo obiettivo del modello statistico di regressione lineare √® quello di stabilire quanto sia grande la componente \\(y\\) predicibile da \\(x\\), per ciascuna osservazione.\nUn indice assoluto della bont√† di adattamento √® fornito dalla deviazione standard dei residui, \\(s_e\\), chiamata anche errore standard della stima. Uno stimatore non distorto della varianza dei residui nella popolazione √® dato da\n$$\ns^2_e = e_i^2\n$$\ne quindi l‚Äôerrore standard della stima sar√†\n\\[\\begin{equation}\ns_e = \\sqrt{\\frac{1}{n-2}\\sum e_i^2}.\n\\end{equation}\\]\nSi noti che questa √® la stessa formula della varianza (dato che la media dei residui √® zero), tranne per il fatto che al denominatore abbiamo \\(n-2\\). Dato che, per calcolare \\(\\hat{y}\\) abbiamo usato due coefficienti (\\(a\\) e \\(b\\)), si dice che ‚Äúabbiamo perso due gradi di libert√†‚Äù.\nDato che \\(s_e\\) possiede la stessa unit√† di misura della variabile \\(y\\), l‚Äôerrore standard della stima pu√≤ essere considerato come una sorta di ‚Äúresiduo medio.‚Äù ‚Äì usando la stessa interpretazione che diamo alla deviazione standard in generale.\nSi noti che la formula precedente non fornisce la ‚Äúdeviazione standard dei residui nel campione‚Äù (quella formula avrebbe \\(n\\) al denominatore). Invece, fornisce una stima della deviazione standard dei residui nella popolazione da cui il campione √® stato estratto.\nVerifichiamo quanto detto con i dati a disposizione.\nI residui possono essere trovati nel modo seguente.\n\nCodicee <- kidiq$kid_score - (a + b * kidiq$mom_iq)\ne[1:10]\n#>  [1] -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845\n#>  [7] -41.521041   3.864881  26.414387  11.208068\n\n\nOppure nel modo seguente.\n\nCodicefm$residuals[1:10]\n#>          1          2          3          4          5          6          7 \n#> -34.678390  17.691747 -11.217173  -3.461529  32.627697   6.382845 -41.521041 \n#>          8          9         10 \n#>   3.864881  26.414387  11.208068\n\n\nCalcolo il residuo medio, prendendo il valore assoluto.\n\nCodicemean(abs(e))\n#> [1] 14.4686\n\n\nL‚Äôerrore standard della regressione √®\n\nCodicesqrt(sum(e^2) / (length(e) - 2))\n#> [1] 18.26612\n\n\nI due numeri non sono uguali, ma possiamo dire che hanno lo stesso ordine di grandezza.\nSe usiamo la funzione lm() otteniamo lo stesso valore, chiamato Residual standard error.\n\nCodicesummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = kidiq)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "052_reglin2.html#indice-di-determinazione",
    "href": "052_reglin2.html#indice-di-determinazione",
    "title": "26¬† Regressione lineare con un singolo predittore",
    "section": "\n26.2 Indice di determinazione",
    "text": "26.2 Indice di determinazione\nUn importante risultato dei minimi quadrati riguarda la cosiddetta scomposizione della devianza mediante la quale si definisce l‚Äôindice di determinazione, il quale fornisce una misura relativa della bont√† di adattamento del modello di regressione ai dati del campione. Per una generica osservazione \\(x_i, y_i\\), la variazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) pu√≤ essere descritta come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\):\n$$\ny_i - {y} = (y_i- _i) + (_i - {y}) = e_i + (_i - {y}).\n$$\nSe consideriamo tutte le osservazioni, la devianza delle \\(y\\) pu√≤ essere scomposta nel seguente modo:\n\\[\\begin{align}\n\\sum (y_i - \\bar{y})^2 &= \\sum \\left[ e_i + (\\hat{y}_i - \\bar{y})\n\\right]^2\n= \\sum e_i^2 + \\sum (\\hat{y}_i - \\bar{y})^2 + 2 \\sum e_i (\\hat{y}_i -\n\\bar{y}) \\notag\n\\end{align}\\]\nPer i vincoli imposti sul modello statistico di regressione, il doppio prodotto si annulla, infatti\n\\[\\begin{align}\n\\sum e_i (\\hat{y}_i - \\bar{y}) &= \\sum e_i \\hat{y}_i - \\bar{y}\\sum e_i = \\sum e_i (a + b x_i) \\notag \\\\\n&= a \\sum e_i + b \\sum e_i x_i = 0 \\notag\n\\end{align}\\]\nIl termine \\(b \\sum e_i x_i\\) √® uguale a zero perch√©, come vedremo in seguito, i coefficienti di regressione vengono calcolati in modo tale da rendere nulla \\(\\mbox{Cov}(e, x)\\). Di conseguenza, il termine precedente deve essere nullo.\nPossiamo dunque concludere che la devianza totale (\\(\\mbox{dev}_T\\)) si scompone nella somma di devianza d‚Äôerrore (o devianza non spiegata) (\\(\\mbox{dev}_E\\)) e devianza di regressione (o devianza spiegata) (\\(\\mbox{dev}_T\\)):\n\\[\\begin{align}\n\\underbrace{\\sum_{i=1}^n (y_i - \\bar{y})^2}_{\\tiny{\\text{Devianza\ntotale}}} &= \\underbrace{\\sum_{i=1}^n e_i^2}_{\\tiny{\\text{Devianza\ndi dispersione}}} + \\underbrace{\\sum_{i=1}^n  (\\hat{y}_i -\n\\bar{y})^2}_{\\tiny{\\text{Devianza di regressione}}} \\notag\n\\end{align}\\]\nLa devianza di regressione, \\(\\mbox{dev_R} \\triangleq \\mbox{dev_T} - \\mbox{dev_E}\\), indica dunque la riduzione degli errori al quadrato che √® imputabile alla regressione lineare. Il rapporto \\(\\mbox{dev_R}/\\mbox{dev_T}\\), detto indice di determinazione, esprime tale riduzione degli errori in termini proporzionali e definisce il coefficiente di correlazione al quadrato:\n\\[\\begin{equation}\nR^2 \\triangleq \\frac{\\mbox{dev_R}}{\\mbox{dev_T}} = 1 - \\frac{\\mbox{dev_E}}{\\mbox{dev_T}}.\n\\end{equation}\\]\nQuando l‚Äôinsieme di tutte le deviazioni della \\(y\\) dalla media √® spiegato dall‚Äôinsieme di tutte le deviazioni della variabile teorica \\(\\hat{y}\\) dalla media, si ha che l‚Äôadattamento (o accostamento) del modello al campione di dati √® perfetto, la devianza residua √® nulla ed \\(r^2 = 1\\); nel caso opposto, la variabilit√† totale coincide con quella residua, per cui \\(r^2 = 0\\). Tra questi due estremi, \\(r\\) indica l‚Äôintensit√† della relazione lineare tra le due variabili e \\(r^2\\), con \\(0 \\leq r^2 \\leq 1\\), esprime la porzione della devianza totale della \\(y\\) che √® spiegata dalla regressione lineare sulla \\(x\\).\nPer l‚Äôesempio in discussione abbiamo quanto segue. La devianza totale √®\n\nCodicedev_t <- sum((kidiq$kid_score - mean(kidiq$kid_score))^2)\ndev_t\n#> [1] 180386.2\n\n\nLa devianza spiegata √®\n\nCodicedev_r <- sum((fm$fitted.values - mean(kidiq$kid_score))^2)\ndev_r\n#> [1] 36248.82\n\n\nL‚Äôindice di determinazione √®\n\nCodiceR2 <- dev_r / dev_t\nR2\n#> [1] 0.2009512\n\n\nNell‚Äôoutput di lm() un tale valore √® chiamato Multiple R-squared.\n\nCodicesummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = kidiq)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16\n\n\nIl risultato ottenuto si pu√≤ interpretare dicendo che circa il 20% della variabilit√† dei punteggi del QI dei bambini pu√≤ essere predetto conoscendo il QI delle madri.\n\n26.2.1 Inferenza sul modello di regressione\nLa discussione precedente era tutta basata sulla trattazione ‚Äúclassica‚Äù del modello lineare, ovvero una trattazione basata sulle stime di massima verosimiglianza (se \\(y \\sim \\mathcal{N}(\\alpha + \\beta x, \\sigma)\\), allora le stime dei minimi quadrati coincidono con le stime di massima verosimiglianza). In altre parole, nella discussione precedente non abbiamo considerato in alcun modo le distribuzioni a priori dei parametri \\(\\alpha\\) e \\(\\beta\\). I risultati precedenti si confermano, in un contesto bayesiano, se e solo se imponiamo sui parametri delle distribuzioni a priori non informative (cio√®, uniformi). In tali circostanze, le stime di massima verosimiglianza risultano identiche al massimo a posteriori bayesiano.\nDetto questo, il tema dell‚Äôinferenza viene trattato dall‚Äôapproccio frequentista costruendo la ‚Äúdistribuzione campionaria‚Äù dei parametri (ovvero la distribuzione dei valori che i parametri otterrebbero in infiniti campioni casuali (\\(x, y\\)) di ampiezza \\(n\\) estratti dalla medesima popolazione) e poi calcolando gli errori standard dei parametri e gli intervalli di fiducia dei parametri. Una domanda frequente √®, per esempio, se la pendenza della retta di regressione sia maggiore di zero. Per rispondere a tale domanda l‚Äôapproccio frequentista calcola l‚Äôintervallo di fiducia al 95% per il parametro \\(\\beta\\). Se tale intervallo non include lo zero, e se il limite inferiore di tale intervallo √® maggiore di zero, allora si conclude, con un grado di confidenza del 95%, che il vero parametro \\(\\beta\\) nella popolazione √® maggiore di zero. Ovvero, si conclude che vi sono evidenze di un‚Äôassociazione lineare positiva tra \\(x\\) e \\(y\\).\nAlla stessa conclusione si pu√≤ arrivare calcolando, in un ottica bayesiana, l‚Äôintervallo di credibilit√† al 95% per il parametro \\(\\beta\\). I due intervalli sono identici se usiamo una distribuzione a priori piatta. Sono invece diversi se usiamo una distribuzione a priori debolmente informativa, oppure informativa.\nSolitamente si usa una distribuzione a priori debolmente informativa centrata sullo zero. In tali circostanze, l‚Äôuso della distribuzione a priori ha solo un effetto di regolarizzazione, ovvero di riduzione del peso delle osservazioni estreme ‚Äì un tale risultato statistico √® molto desiderabile, ma √® difficile da ottenere in un contesto frequentista. Vedremo nel prossimo capitolo come pu√≤ essere svolta l‚Äôinferenza sui coefficienti del modello di regressione lineare in un contesto bayesiano."
  },
  {
    "objectID": "052_reglin2.html#commenti-e-considerazioni-finali",
    "href": "052_reglin2.html#commenti-e-considerazioni-finali",
    "title": "26¬† Regressione lineare con un singolo predittore",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIl modello lineare bivariato viene usato per descrivere la relazione tra due variabili e per determinare il segno e l‚Äôintensit√† di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente."
  },
  {
    "objectID": "053_reglin3.html",
    "href": "053_reglin3.html",
    "title": "27¬† Modello di regressione in linguaggio Stan",
    "section": "",
    "text": "Passiamo ora alla versione bayesiana del modello di regressione. Mostreremo qui che, se vengono usate delle distribuzioni a priori non informative, si ottengono delle distribuzioni a posteriori dei parametri il cui massimo a posteriori √® simile alle stime frequentiste dei minimi quadrati. In questo Capitolo, inoltre, mostreremo come sia possibile usare il linguaggio probabilistico Stan per la stima dei parametri del modello di regressione e per l‚Äôinferenza."
  },
  {
    "objectID": "053_reglin3.html#specificazione-del-modello",
    "href": "053_reglin3.html#specificazione-del-modello",
    "title": "27¬† Modello di regressione in linguaggio Stan",
    "section": "\n27.1 Specificazione del modello",
    "text": "27.1 Specificazione del modello\nLa specificazione del modello lineare bayesiano inizia nello stesso modo dell‚Äôapproccio frequentista, ovvero con la specificazione della seguente equazione:\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i, \\quad i = 1, \\dots, n.\n\\] Si assume che gli errori, \\(\\varepsilon_i\\), siano indipendenti e identicamente distribuiti come variabili casuali Normali con media zero e varianza costante \\(\\sigma^2\\). Queste ipotesi sono esattamente uguali a quelle che vengono usato nell‚Äôinferenza frequentista. Il nostro obiettivo √® aggiornare le distribuzioni a priori dei parametri sconosciuti \\(\\alpha\\) e \\(\\beta\\) alla luce dei dati \\(x_1, y_1, \\dots, x_n, y_n\\). Solitamente, √® desiderabile scegliere distribuzioni a priori che hanno uno scarso impatto sulla distribuzione a posteriori.\nSupponiamo che le nostre credenza a priori sui parametri del modello, \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) siano tra loro indipendenti. Allora possiamo scrivere la distribuzione congiunta dei parametri nel modo seguente:\n\\[\np(\\alpha, \\beta, \\sigma) = p(\\alpha)p(\\beta)p(\\sigma).\n\\]\nPossiamo assumere \\(\\alpha \\sim \\mathcal{N}(\\mu_{\\alpha}, \\sigma_{\\alpha})\\) e \\(\\beta \\sim \\mathcal{N}(\\mu_{\\beta}, \\sigma_{\\beta})\\). Per \\(\\sigma\\) possiamo assumere, ad esempio, \\(\\sigma \\sim \\mbox{Cauchy}(a, b)\\).\nMoltiplicando la verosimiglianza\n\\[\n\\prod_{i=1}^n p(y_i \\mid x_i; \\alpha, \\beta, \\sigma^2) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{-\\frac{(y_i-(\\alpha + \\beta x_i))^2}{2\\sigma^2}}\n\\]\nper le distribuzioni a priori dei parametri, si ottiene la distribuzione a posteriori. Tuttavia, tale distribuzione non √® risolvibile per via analitica. Come in precedenza, usiamo invece un algoritmo MCMC per ottenere una sequenza di campioni casuali dalla distribuzione a posteriori."
  },
  {
    "objectID": "053_reglin3.html#stima-bayesiana-in-linguaggio-stan",
    "href": "053_reglin3.html#stima-bayesiana-in-linguaggio-stan",
    "title": "27¬† Modello di regressione in linguaggio Stan",
    "section": "\n27.2 Stima bayesiana in linguaggio Stan",
    "text": "27.2 Stima bayesiana in linguaggio Stan\n√à conveniente usare il linguaggio Stan per ottenere una sequenza MCMC dalla distribuzione a posteriori dei parametri di un modello di regressione. Continuiamo qui l‚Äôesempio precedente in cui ci si poneva il problema di descrivere mediante un modello lineare l‚Äôassociazione tra il QI dei figli e il QI delle madri. Leggiamo i dati kidiq in \\(\\mathsf{R}\\):\n\nCodicelibrary(\"rio\")\ndf <- rio::import(here::here(\"data\", \"kidiq.dta\"))\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age\n#> 1        65      1 121.11753        4      27\n#> 2        98      1  89.36188        4      25\n#> 3        85      1 115.44316        4      27\n#> 4        83      1  99.44964        3      25\n#> 5       115      1  92.74571        4      27\n#> 6        98      0 107.90184        1      18\n\n\nPer farci un‚Äôidea del valore dei parametri, adattiamo il modello lineare ai dati mediante la procedura di massima verosimiglianza (come abbiamo fatto nel capitolo precedente):\n\nCodicefm <- lm(kid_score ~ mom_iq, data = df)\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = kid_score ~ mom_iq, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -56.753 -12.074   2.217  11.710  47.691 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 25.79978    5.91741    4.36 1.63e-05 ***\n#> mom_iq       0.60997    0.05852   10.42  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 18.27 on 432 degrees of freedom\n#> Multiple R-squared:  0.201,  Adjusted R-squared:  0.1991 \n#> F-statistic: 108.6 on 1 and 432 DF,  p-value: < 2.2e-16\n\n\nSulla base delle informazioni precedenti, giungiamo alla seguente formulazione bayesiana del modello di regressione lineare:\n\\[\n\\begin{aligned}\ny_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta x_i \\\\\n\\alpha &\\sim \\mathcal{N}(25, 10) \\\\\n\\beta &\\sim \\mathcal{N}(0, 1) \\\\\n\\sigma &\\sim \\text{Cauchy}(18, 5)\n\\end{aligned}\n\\]\nIl segno \\(\\sim\\) (tilde) si pu√≤ leggere ‚Äúsi distribuisce come‚Äù. La prima riga definisce la funzione di verosimiglianza e ci dice che ciascuna osservazione \\(y_i\\) √® una variabile casuale che segue la distribuzione gaussiana di parametri \\(\\mu_i\\) e \\(\\sigma\\). Le righe successive definiscono le distribuzioni a priori dei parametri. La seconda riga specifica, in maniera deterministica, ciascun \\(\\mu_i\\) come funzione lineare di \\(x_i\\), con parametri \\(\\alpha\\) e \\(\\beta\\). Le due righe successive specificano le distribuzioni a priori per \\(\\alpha\\) e \\(\\beta\\). La distribuzione a priori di \\(\\alpha\\) √® una distribuzione gaussiana di parametri \\(\\mu_{\\alpha} = 25\\) e deviazione standard \\(\\sigma_{\\alpha} = 10\\); la distribuzione a priori di \\(\\beta\\) √® una distribuzione gaussiana standardizzata. L‚Äôultima riga definisce la distribuzione a priori di \\(\\sigma\\), ovvero una Cauchy di parametri 18 e 5.\nAvendo descritto in termini astratti le caratteristiche del modello, passiamo ora alla specificazione in linguaggio Stan.\n\nCodicemodel_string_1 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  // priors\n  alpha ~ normal(25, 10);\n  beta ~ normal(0, 1);\n  sigma ~ cauchy(18, 5);\n  // likelihood\n  y ~ normal(alpha + beta * x, sigma);\n}\n\"\nwriteLines(model_string_1, con = \"code/simpleregkidiq.stan\")\n\n\nLa funzione modelString() registra una stringa di testo mentre writeLines() crea un file nell‚Äôindirizzo specificato. Tale file deve avere l‚Äôestensione .stan.\nSistemiamo i dati nel formato appropriato per Stan.\n\nCodicedata_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_iq\n)\n\n\nLa funzione file.path() ritorna l‚Äôindirizzo del file con il codice Stan.\n\nCodicefile_simple_reg <- file.path(\"code\", \"simpleregkidiq.stan\")\n\n\nLa funzione cmdstan_model() traduce il programma Stan in C++ e crea un eseguibile compilato.\n\nCodicemod1 <- cmdstan_model(file_simple_reg)\n\n\nIl codice Stan pu√≤ essere stampato usando il metodo $print():\n\nCodicemod1$print()\n\n\nL‚Äôindirizzo dell‚Äôeseguibile compilato viene ritornato da $exe_file():\n\nCodicemod1$exe_file()\n\n\nApplicando il metodo $sample() ad un oggetto CmdStanModel eseguiamo il campionamento MCMC:\n\nCodicefit_1 <- mod1$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  parallel_chains = 2L,\n  refresh = 0\n)\n\n\nUn sommario della distribuzione a posteriori per i parametri stimati si ottiene con il metodo $summary(), il quale chiama la funzione summarise_draws() del pacchetto posterior:\n\nCodicefit_1$summary(c(\"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 3 √ó 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    25.8   25.8   5.05   5.04   17.5   34.0    1.00    5543.    5781.\n#> 2 beta      0.610  0.610 0.0501 0.0499  0.528  0.693  1.00    5581.    5684.\n#> 3 sigma    18.3   18.3   0.605  0.603  17.3   19.3    1.00    6957.    6378.\n\n\nSi noti come la soluzione ottenuta sia molto simile (dal punto di vista pratico, equivalente) a quella ottenuta con il metodo dei minimi quadrati.\nDall‚Äôoutput possiamo anche valutare la convergenza del modello osservando i valori di Rhat per ciascun parametro. Quando questi sono pari o vicini a 1, le catene hanno realizzato la convergenza. Ci sono molti altri test diagnostici, ma questo test √® il pi√π importante per Stan.\nOppure possiamo visualizzare i risultati come indicato di seguito.\n\nCodicefit_1$cmdstan_summary()\n\n\nLe statistiche diagnostiche sono fornite dal metodo $cmdstan_diagnose():\n\nCodicefit_1$cmdstan_diagnose()\n\n\n√à conveniente creare un oggetto di classe stanfit\n\nCodicestanfit_1 <- rstan::read_stan_csv(fit_1$output_files())\n\n\nper poi potere utilizzare le funzioni del pacchetto bayesplot. Ad esempio:\n\nCodicestanfit_1 %>% \n  mcmc_trace(pars = c(\"alpha\", \"beta\", \"sigma\"))\n\n\n\n\n\n\n\nInfine, eseguendo la funzione launch_shinystan(fit), √® possibile analizzare oggetti di classe stanfit mediante le funzionalit√† del pacchetto ShinyStan.\n\n27.2.1 Standardizzare i dati\nIl codice Stan viene eseguito pi√π velocemente se l‚Äôinput √® standardizzato cos√¨ da avere una media pari a zero e una varianza unitaria. Inoltre, si noti un punto importante. Il fatto di standardizzare i dati fa in modo che le distribuzioni a priori sui parametri vengano espresse sulla scala di una v.c. normale standardizzata. Se centriamo sullo 0 le distribuzioni a priori, con una deviazione standard dell‚Äôordine di grandezza dell‚Äôunit√†, perdono di significato i discorsi sull‚Äôarbitrariet√† delle distribuzioni a priori: nel caso di dati standardizzati le distribuzioni a priori formulate come indicato sopra sono distribuzioni debolmente informative il cui unico scopo √® la regolarizzazione dei dati, ovvero di mantenere le inferenze in una gamma ragionevole di valori. Inoltre, l‚Äôuso di distribuzioni a priori debolmente informative ha l‚Äôeffetto desiderabile di limitare l‚Äôinfluenza eccessiva delle osservazioni estreme (valori anomali). Il punto importante √® che una tale scelta delle distribuzioni a priori non introduce alcuna distorsione sistematica nella stima a posteriori.\nSono possibili due strade per la standardizzazione dei dati. Se non ci sono ragioni particolari per mantenere l‚Äôunit√† di misura dei dati grezzi (ad esempio, se √® sufficiente valutare l‚Äôintervallo di credibilit√† per \\(\\beta\\) per determinare se include o meno lo 0), allora possiamo standardizzare i dati prima di passarli a Stan (questa √® la procedura usuale).\nIn alternativa, se vogliamo mantenere la soluzione sulla scala delle variabili originarie, √® possibile seguire la procedura indicata di seguito. Si passano a Stan i dati grezzi; i dati vengono standardizzati con una trasformazione di variabili all‚Äôinterno del codice Stan. Viene poi eseguito il campionamento sui dati standardizzati; infine, le stime dei parametri vengono nuovamente trasformate sulla scala delle variabili originarie1.\nPer ottenere il risultato descritto sopra, si procede come segue. Ponendo \\(y = (y_1, \\dots, y_n)\\) e \\(x = (x_1, \\dots, x_n)\\), il modello lineare pu√≤ essere scritto come\n\\[\ny_i = \\alpha + \\beta x_i + \\varepsilon_i,\n\\]\ndove\n\\[\n\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma).\n\\]\nSeguendo la notazione del manuale Stan, i parametri del modello lineare sono denotati da \\(\\alpha\\) e \\(\\beta\\). Per eseguire la standardizzazione dei dati, √® necessario centrare i dati, sottraendo da essi la media campionaria, per poi scalarli dividendo per la deviazione standard campionaria. Una singola osservazione \\(u\\) viene standardizzata dalla funzione \\(z\\) definita da\n\\[\nz_y(u) = \\frac{u - \\bar{y}}{\\texttt{sd}(y)}\n\\]\ndove la media \\(\\bar{y}\\) √®\n\\[\n\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i,\n\\] e la deviazione standard √®\n\\[\n\\texttt{sd} = \\left(\\frac{1}{n}\\sum_{i=1}^n(y_i - \\bar{y})^2\\right)^{-\\frac{1}{2}}.\n\\]\nLa trasformata inversa √® definita invertendo i due passaggi precedenti: la deviazione standard √® usata per scalare i valori \\(u\\) e la media campionaria √® usata per traslare la distribuzione dei valori \\(u\\) scalati:\n\\[\nz_y^{-1}(u) = \\texttt{sd}(y)u + \\bar{y}.\n\\]\nI risultati riportati sopra consentono di modificare il modello Stan che abbiamo descritto all‚Äôinizio del Capitolo al fine di creare un nuovo modello che realizza un campionamento sulla base dei dati standardizzati.\nIl blocco data √® identico al caso precedente. I predittori e la risposta standardizzati sono definiti nel blocco transformed data. Vengono definte due nuove variabili, x_std e y_std, che corrispondono, appunto, ai valori standardizzati \\(x\\) e \\(y\\). I parametri sono chiamati alpha_std e alpha_std in quanto verranno campionati utilizzando la verosimiglianza che deriva dai dati standardizzati: y_std ~ normal(mu_std, sigma_std);. La media delle distribuzioni condizionate \\(y \\mid x_i\\), ovvero \\(\\hat{y}\\), √® calcolata come vector[N] mu_std = alpha_std + beta_std * x_std;, ovvero usando i valori \\(x\\) standardizzati, x_std, e i parametri alpha_std e beta_std. Una tale specificazione √® contenuta nel blocco transformed parameters. Nel blocco model sono presenti le distribuzioni a priori dei parametri alpha_std e beta_std. In questo esempio, per entrambi i parametri √® stata usata una distribuzione a priori \\(\\mathcal{N}(0, 1)\\). Per semplificare la notazione, nel blocco model l‚Äôistruzione di campionamento √® espressa in forma vettorializzata: y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);.\nSi pone ancora il problema di trasformare i parametri dalla scala delle variabili standardizzate alla scala delle variabili originarie. I valori dei parametri sulla scala delle variabili originarie calcolati nel blocco generated quantities. I parametri ‚Äúnaturali‚Äù cos√¨ trasformati vengono chiamati alpha, beta e sigma. Le formule necessarie per questa trasformazione possono essere recuperati con un po‚Äô di algebra.\n\\[\\begin{align}\ny_n &= \\textrm{z}_y^{-1}(\\textrm{z}_y(y_n)) \\notag\\\\\n    &= \\textrm{z}_y^{-1}\n\\left( \\alpha' + \\beta' \\textrm{z}_x(x_n) + \\epsilon_n' \\right) \\notag\\\\\n    &= \\textrm{z}_y^{-1}\n\\left( \\alpha' + \\beta' \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n' \\right) \\notag\\\\\n    &= \\texttt{sd}(y)\n\\left( \\alpha' + \\beta' \\left( \\frac{x_n - \\bar{x}}{\\texttt{sd}(x)} \\right) + \\epsilon_n' \\right) + \\bar{y} \\notag\\\\\n    &=\n\\left( \\texttt{sd}(y) \\left( \\alpha' - \\beta' \\frac{\\bar{x}}{\\texttt{sd}(x)} \\right) + \\bar{y} \\right)\n+ \\left( \\beta' \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)} \\right) x_n\n+ \\texttt{sd}(y) \\epsilon'_n,\n\\end{align}\\]\nda cui\n\\[\n\\alpha\n=\n\\texttt{sd}(y)\n      \\left(\n          \\alpha'\n          - \\beta' \\frac{\\bar{x}}{\\texttt{sd}(x)}\n      \\right)\n  + \\bar{y};\n\\qquad\n\\beta = \\beta' \\frac{\\texttt{sd}(y)}{\\texttt{sd}(x)};\n\\qquad\n\\sigma = \\texttt{sd}(y) \\sigma'.\n\\]\nPossiamo dunque scrivere il modello in linguaggio Stan nel modo seguente.\n\nCodicemodel_string_2 = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n}\ntransformed parameters {\n  vector[N] mu_std = alpha_std + beta_std * x_std;\n}\nmodel {\n  alpha_std ~ normal(0, 1);\n  beta_std ~ normal(0, 1);\n  sigma_std ~ normal(0, 1);\n  y_std ~ normal(mu_std, sigma_std);\n}\ngenerated quantities {\n  // transform to the original data scale\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(model_string_2, con = \"code/simpleregstd.stan\")\n\n\nUsiamo la funzione file.path() per ottenere l‚Äôindirizzo del file con il codice Stan.\n\nCodicefile_simple_reg_std <- file.path(\"code\", \"simpleregstd.stan\")\n\n\nCompiliamo in C++.\n\nCodicemod2 <- cmdstan_model(file_simple_reg_std)\n\n\nEseguiamo il campionamento MCMC.\n\nCodicefit_2 <- mod2$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nUsiamo il metodo $summary() per esaminare i risultati.\n\nCodicefit_2$summary(c(\"alpha_std\", \"beta_std\", \"sigma_std\", \"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 6 √ó 10\n#>   variable       mean    median     sd    mad      q5     q95  rhat ess_bulk\n#>   <chr>         <dbl>     <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>    <dbl>\n#> 1 alpha_std  0.000107 -0.000149 0.0432 0.0423 -0.0703  0.0715  1.00   18705.\n#> 2 beta_std   0.448     0.448    0.0438 0.0443  0.375   0.520   1.00   20084.\n#> 3 sigma_std  0.897     0.896    0.0311 0.0316  0.848   0.950   1.00   18813.\n#> 4 alpha     25.9      25.8      6.02   6.02   16.0    35.8     1.00   20176.\n#> 5 beta       0.609     0.609    0.0596 0.0603  0.511   0.707   1.00   20084.\n#> 6 sigma     18.3      18.3      0.634  0.644  17.3    19.4     1.00   18813.\n#> # ‚Ä¶ with 1 more variable: ess_tail <dbl>\n\n\nSi noti anche in questo caso che, avendo usato delle distribuzioni a priori debolmente informative, le stime dei parametri sono molto simili a quelle ottenute mediante la procedura di massima verosimiglianza.\n\nCodicecoef(fm)\n#> (Intercept)      mom_iq \n#>  25.7997778   0.6099746\n\n\n\n27.2.2 Interpretazione dei parametri\nRipeto qui la discussione del capitolo precedente. Assegniamo ai parametri la seguente interpretazione.\n\nL‚Äôintercetta pari a 25.9 indica il QI medio dei bambini la cui madre ha un QI = 0. Ovviamente questo non ha alcun significato. Vedremo nel modello successivo come trasformare il modello in modo da potere assegnare all‚Äôintercetta un‚Äôinterpretazione sensata.\nLa pendenza di 0.61 indica che, all‚Äôaumentare di un punto del QI delle madri, il QI medio dei loro bambini aumenta di 0.61 unit√†. Se consideriamo la gamma di variazione del QI delle madri nel campione, il QI medio dei bambini cambia di 41 punti. Questo indica un sostanziale effetto del QI delle madri sul QI dei loro bambini: \\((138.89 - 71.04) * 0.61 = 41.39\\).\nIl parametro \\(\\sigma\\) = 18.3 fornisce una stima della dispersione delle osservazioni attorno al valore predetto dal modello lineare, ovvero fornisce una stima della deviazione standard dei residui attorno al valore atteso del modello lineare.\n\n27.2.3 Centrare i predittori\nCome abbiamo detto in precedenza, per migliorare l‚Äôinterpretazione dell‚Äôintercetta possiamo ‚Äúcentrare‚Äù la \\(x\\), ovvero esprimere la \\(x\\) in termini di scarti dalla media: \\(x - \\bar{x}\\). In tali circostanze, la pendenza della retta specificata dal modello lineare resta immutata, ma l‚Äôintercetta corrisponde a \\(\\mathbb{E}(y \\mid x = \\bar{x})\\). Per ottenere questo risultato, √® sufficiente modificare i dati passati a Stan.\n\nCodicedata2_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_iq - mean(df$mom_iq)\n)\n\n\nAdattiamo il modello con il nuovo input.\n\nCodicefit_3 <- mod2$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nTrasformiamo l‚Äôoggetto fit in un oggetto di classe stanfit:\n\nCodicestanfit_3 <- rstan::read_stan_csv(fit_3$output_files())\n\n\nEsaminiamo le stime a posteriori dei parametri.\n\nCodicefit_3$summary(c(\"alpha\", \"beta\", \"sigma\"))\n#> # A tibble: 3 √ó 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    86.8   86.8   0.876  0.871  85.4   88.2    1.00   16318.   11494.\n#> 2 beta      0.609  0.609 0.0591 0.0589  0.513  0.707  1.00   16206.   11236.\n#> 3 sigma    18.3   18.3   0.630  0.624  17.3   19.4    1.00   15617.   11986.\n\n\nSi noti la nuova intercetta, ovvero 86.8. Questo valore indica il QI medio dei bambini le cui madri hanno un QI pari alla media del campione. Centrare i dati consente dunque di assegnare all‚Äôintercetta un‚Äôinterpretazione utile. Dall‚Äôoutput ottenuto possiamo ricavare, ad esempio, l‚Äôintervallo di credibilit√† al 90%. Ovvero, con un grado di certezza soggettiva del 90%, possiamo concludere che, se consideriamo solo le madri con un QI pari alla media del presente campione, possiamo prevedere che il QI medio dei loro figli sar√† compreso nell‚Äôintervallo [85.4, 88.2]."
  },
  {
    "objectID": "053_reglin3.html#commenti-e-considerazioni-finali",
    "href": "053_reglin3.html#commenti-e-considerazioni-finali",
    "title": "27¬† Modello di regressione in linguaggio Stan",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa presente discussione suggerisce che √® conveniente standardizzare i dati prima di procedere con l‚Äôanalisi di regressione lineare. Ci√≤ pu√≤ essere fatto all‚Äôinterno del codice Stan, oppure prima di passare i dati a Stan. Se i dati vengono standardizzati √® facile specificare delle distribuzioni a priori debolmente informative per i parametri centrate sullo zero. Tali distribuzioni a priori hanno, come unico scopo, quello di regolarizzare i dati e di facilitare la stima dei parametri mediante la procedura MCMC, e non introducono alcuna distorsione ‚Äúarbitraria‚Äù nella soluzione."
  },
  {
    "objectID": "054_reglin4.html",
    "href": "054_reglin4.html",
    "title": "28¬† Inferenza sul modello lineare",
    "section": "",
    "text": "Un modo per rappresentare l‚Äôincertezza dell‚Äôinferenza in un ottica bayesiana √® quella di presentare graficamente la retta specificata dal modello di regressione lineare. Continuer√≤ qui la discussione dell‚Äôesempio descritto nel Capitolo precedente, ovvero, user√≤ i dati kid_score e i valori mom_iq centrati."
  },
  {
    "objectID": "054_reglin4.html#rappresentazione-grafica-dellincertezza-della-stima",
    "href": "054_reglin4.html#rappresentazione-grafica-dellincertezza-della-stima",
    "title": "28¬† Inferenza sul modello lineare",
    "section": "\n28.1 Rappresentazione grafica dell‚Äôincertezza della stima",
    "text": "28.1 Rappresentazione grafica dell‚Äôincertezza della stima\nSupponiamo (come indicato nel Capitolo precedente) di avere eseguito il campionamento MCMC mediante la seguente istruzione.\n\nCodicefit2 <- mod$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nPer creare una rappresentazione grafica della retta di regressione stimata dal modello bayesiano, insieme all‚Äôincertezza della stima, √® necessario manipolare i dati contenuti nell‚Äôoggetto creato da mod$sample() che contiene i campioni a posteriori dei parametri del modello di regressione lineare, ovvero fit2.\nUsando la funzione rstan::read_stan_csv() trasformo fit2 in un oggetto di formato stanfit.\n\n\n\n\nCodiceoutput_stanfit <- rstan::read_stan_csv(fit2$output_files())\n\n\nDall‚Äôoggetto output_stanfit estraggo i campioni a posteriori dei parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) con la funzione extract().\n\nCodicepost <- rstan::extract(output_stanfit)\n\n\nL‚Äôoggetto post cos√¨ creato √® una lista.\n\nCodiceclass(post)\n#> [1] \"list\"\n\n\nEsaminiamo il contenuto di post.\n\nCodiceglimpse(post)\n#> List of 7\n#>  $ alpha_std: num [1:16000(1d)] 0.0582 0.0407 -0.0828 0.0997 0.0886 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta_std : num [1:16000(1d)] 0.421 0.494 0.457 0.496 0.491 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma_std: num [1:16000(1d)] 0.907 0.899 0.878 0.932 0.972 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ alpha    : num [1:16000(1d)] 88 87.6 85.1 88.8 88.6 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta     : num [1:16000(1d)] 0.573 0.672 0.622 0.675 0.668 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma    : num [1:16000(1d)] 18.5 18.3 17.9 19 19.8 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ lp__     : num [1:16000(1d)] -170 -169 -171 -172 -174 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n\n\nL‚Äôoutput di glimpse() ci dice che alpha √® un vettore di 16,000 elementi. Ciascuno di questi elementi √® un valore estratto a caso dalla distribuzione a posteriori del parametro \\(\\alpha\\). √à dunque possibile calcolare una stima puntuale della distribuzione a posteriori del parametro \\(\\alpha\\) semplicemente trovando la media di tali valori.\n\nCodicemean(post$alpha)\n#> [1] 86.7936\n\n\nLo stesso si pu√≤ dire di beta.\n\nCodicemean(post$beta)\n#> [1] 0.6082648\n\n\nPer creare un diagramma a dispersione dei dati con sovrapposto il valore atteso della \\(y\\) (ovvero, la retta di regressione) usiamo la sintassi seguente.\n\nCodicetibble(\n  kid_score = df$kid_score,\n  mom_iq = df$mom_iq - mean(df$mom_iq)\n) %>%\n  ggplot(aes(mom_iq, kid_score)) +\n  geom_point() +\n  geom_abline(\n    intercept = mean(post$alpha),\n    slope = mean(post$beta)\n  )\n\n\n\n\n\n\n\nSi noti l‚Äôuso della funzione geom_abline() che prende come argomenti l‚Äôintercetta e la pendenza di una retta. Nel caso presente, tali argomenti corrispondono a mean(post$alpha) e mean(post$beta), ovvero, specificano i valori a posteriori pi√π plausibili dei parametri \\(\\alpha\\) e \\(\\beta\\).\nCon le istruzioni precedenti abbiamo disegnato una singola retta. Ma una singola retta non ci fa capire qual √® l‚Äôincertezza associata alle stime dei parametri \\(\\alpha\\) e \\(\\beta\\). Una tale incertezza pu√≤ essere visualizzata tracciando molteplici rette, ciascuna delle quali definita da un diverso valore estratto a caso dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\).\nPer fare ci√≤ dobbiamo estrarre le informazioni richieste dall‚Äôoggetto output_stanfit che √® stato creato. A tal fine possiamo usare, ad esempio, le funzioni del pacchetto tidybayes. Iniziamo a elencare i nomi degli oggetti contenuti in output_stanfit.\n\nCodicetidybayes::get_variables(output_stanfit)\n#>  [1] \"alpha_std\"     \"beta_std\"      \"sigma_std\"     \"alpha\"        \n#>  [5] \"beta\"          \"sigma\"         \"lp__\"          \"accept_stat__\"\n#>  [9] \"treedepth__\"   \"stepsize__\"    \"divergent__\"   \"n_leapfrog__\" \n#> [13] \"energy__\"\n\n\nVogliamo creare un DataFrame in formato tidy, cio√®, tale per cui le osservazioni stanno sulle righe e le variabili stanno sulle colonne; una colonna per le stime a posteriori di \\(\\alpha\\) e una colonna per le stime a posteriori di \\(\\beta\\). Un tale risultato si ottiene con la funzione spread_draws().\n\nCodicedraws <- output_stanfit %>%\n  spread_draws(beta, alpha)\n\n\nEsaminiamo l‚Äôoggetto draws.\n\nCodicedraws %>%\n  head(10)\n#> # A tibble: 10 √ó 5\n#>   .chain .iteration .draw  beta alpha\n#>    <int>      <int> <int> <dbl> <dbl>\n#> 1      1          1     1 0.632  88.4\n#> 2      1          2     2 0.491  87.5\n#> 3      1          3     3 0.717  85.9\n#> 4      1          4     4 0.478  87.5\n#> 5      1          5     5 0.610  86.4\n#> 6      1          6     6 0.570  86.7\n#> 7      1          7     7 0.623  87.0\n#> 8      1          8     8 0.616  87.2\n#> # ‚Ä¶ with 2 more rows\n\n\nL‚Äôoggetto draws contiene le stime a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) nel formato desiderato. Possiamo ora generare un diagramma a dispersione con ggplot() a cui vengono aggiunte tutte le 16,000 rette di regressione definite da ciascuna coppia di valori \\(\\hat{\\alpha}\\) e \\(\\hat{\\beta}\\) contenuti nelle righe del DataFrame draws.\n\nCodicetibble(\n  kid_score = df$kid_score,\n  mom_iq = df$mom_iq - mean(df$mom_iq)\n) %>%\n  ggplot(aes(mom_iq, kid_score)) +\n  geom_point() +\n  geom_abline(\n    data = draws, \n    aes(intercept = alpha, slope = beta),\n    size = 0.2, alpha = 0.01, color = \"darkgray\"\n  ) +\n  geom_abline(\n    intercept = mean(post$alpha),\n    slope = mean(post$beta)\n  ) +\n  labs(\n    x = \"Quoziente di intelligenza della madre\",\n    y = \"Quoziente di intelligenza del bambino\"\n  )\n\n\n\n\n\n\n\nIl risultato cercato si ottiene (disegnare molteplici rette ciascuna definita da un valore casuale dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\)) mediante la seguente porzione del codice \\(\\mathsf{R}\\).\n\nCodicegeom_abline(\n  data = draws, \n  aes(intercept = alpha, slope = beta),\n  size = 0.2, alpha = 0.01, color = \"darkgray\"\n)\n\n\nL‚Äôargomento grafico alpha = 0.01 passato a geom_abline() specifica la trasparenza del segmento che rappresenta ciascuna retta. Ho usato un valore molto basso per questo argomento per fare in modo che, anche sovrapponendo 16,000 rette, si produca comunque ancora un certo grado di trasparenza.\nIl grafico mostra che le rette di regressione costruite estraendo a caso valori dalla distribuzione a posteriori dei parametri \\(\\alpha\\) e \\(\\beta\\) sono molto simili tra loro. Ci√≤ significa che, se combiniamo le informazioni fornite dai dati con le nostre credenza precedenti (qui, dei prior poco informativi), allora dobbiamo concludere che l‚Äôincertezza relativa alla dipendenza lineare del quoziente di intelligenza del bambino da quello della madre √® decisamente piccola. In altre parole, siamo molto sicuri che c‚Äô√® una associazione lineare positiva tra le due variabili: in media il QI dei figli √® positivamente associato al QI della madre.\nSi presti attenzione al fatto che il modello statistico ci conduce a tale conclusione: siamo sicuri dell‚Äôesistenza di un‚Äôassociazione positiva tra il QI dei figli e il QI della madre. Ma il modello statistico non ci dice nulla sulle cause di questa associazione: ci dice soltanto che le due variabili tendono a covariare. Non ci dice che il QI della madre √® la ‚Äúcausa‚Äù del QI del figlio. Questo √® un argomento su cui √® stata fatta molta ricerca (e di ci√≤ qui non diremo nulla). Ma, al di l√† dei risultati di tali ricerche, se consideriamo solo il risultato del modello statistico qui esaminato, nulla si pu√≤ concludere sui rapporti di causa/effetto tra QI della madre e QI del figlio. La presenza di un‚Äôassociazione statistica, infatti, √® condizione necessaria ma non sufficiente per potere affermare l‚Äôesistenza di un nesso causale."
  },
  {
    "objectID": "054_reglin4.html#intervalli-di-credibilit√†",
    "href": "054_reglin4.html#intervalli-di-credibilit√†",
    "title": "28¬† Inferenza sul modello lineare",
    "section": "\n28.2 Intervalli di credibilit√†",
    "text": "28.2 Intervalli di credibilit√†\nAbbiamo visto come l‚Äôincertezza sulla stima dei parametri possa essere espressa graficamente. In alternativa, l‚Äôincertezza inferenziale sui parametri pu√≤ essere descritta mediante gli intervalli di credibilit√†, ovvero gli intervalli che contengono la quota desiderata (es., il 95%) della distribuzione a posteriori.\nPer l‚Äôesempio che stiamo discutendo, gli intervalli di credibilit√† (a code uguali) al 95% si ottengono nel modo seguente:\n\nCodicerstantools::posterior_interval(\n  as.matrix(output_stanfit), \n  prob = 0.95\n)\n#>                    2.5%         97.5%\n#> alpha_std   -0.08427372    0.08441589\n#> beta_std     0.36136782    0.53165187\n#> sigma_std    0.83902970    0.96033440\n#> alpha       85.07713000   88.52020750\n#> beta         0.49171840    0.72342520\n#> sigma       17.12519250   19.60110750\n#> lp__      -173.15907500 -168.54400000\n\n\nUn grafico che, nel caso dei dati standardizzati, riporta l‚Äôintervallo di credibilit√† al livello di probabilit√† desiderato per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\) si ottiene con l‚Äôistruzione seguente.\n\nCodiceoutput_stanfit %>%\n  mcmc_intervals(\n    pars = c(\"alpha_std\", \"beta_std\", \"sigma_std\"),\n    prob = 0.8,\n    prob_outer = 0.95\n  )\n\n\n\n\n\n\n\nGli intervalli di massima densit√† si trovano nel modo seguente.\n\nCodicebayestestR::hdi(output_stanfit, ci = 0.95)\n#> Highest Density Interval\n#> \n#> Parameter |        95% HDI\n#> --------------------------\n#> alpha_std | [-0.08,  0.08]\n#> beta_std  | [ 0.36,  0.53]\n#> alpha     | [85.08, 88.52]\n#> beta      | [ 0.49,  0.72]\n\n\nQuando la distribuzione a posteriori dei parametri √® simmetrica, i due tipi di intervalli producono, all‚Äôatto pratico, risultati equivalenti.\n\n28.2.1 Quale soglia usare?\nRipeto c‚Äô√® niente di ‚Äúmagico‚Äù o necessario relativamente al livello di 0.95: il valore 0.95 √® arbitrario. √à quello utilizzato nelle pubblicazioni scientifiche, di consuetudine. Almeno in psicologia. In fisica, ad esempio, si usa un intervallo molto pi√π grande.\nKennedy-Shaffer (2019) descrivono l‚Äôorigine storica di questa scelta. Nel 1925 Ronal Fisher pubblic√≤ la prima edizione della sua influente opera Statistical Methods for Research Workers. In tale testo troviamo il seguente passaggio:\n\nThe value for which P=.05, or 1 in 20, is 1.96 or nearly 2; it is convenient to take this point as a limit in judging whether a deviation is to be considered significant or not. Deviations exceeding twice the standard deviation are thus formally regarded as significant. Using this criterion we should be led to follow up a negative result only once in 22 trials, even if the statistics are the only guide available. Small effects would still escape notice if the data were insufficiently numerous to bring them out, but no lowering of the standard of significance would meet this difficulty (Fisher, 1925, p.¬†47)\n\nQuesto paragrafo rende immediatamente evidente il motivo per cui Fisher afferma che il valore 0.05 √® conveniente: √® pi√π o meno equivalente alla probabilit√† di trovarsi a pi√π di due deviazioni standard dalla media di una variabile casuale normalmente distribuita. In questo modo, 0.05 pu√≤ essere visto non come un numero dotato in un qualche significato importante, ma solo come un valore che risultava dalla necessit√† di facilit√† di calcolo, prima che i computer rendessero obsolete le tabelle e le approssimazioni. In seguito, nel discutere le applicazioni statistiche della distribuzione \\(\\chi^2\\), Fisher osserva che\n\n[w]e shall not often be astray if we draw a conventional line at .05, and consider that higher values of \\(\\chi^2\\) indicate a real discrepancy (Fisher, 1925, p.¬†79).\n\nSulla base di queste affermazioni di Fisher, la soglia del 0.95 √® diventata la consuetudine nella comunit√† scientifica ‚Äì o almeno, in parte di essa.\nMa sono ovviamente possibili tantissime altre soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.89, altri quello di 0.5. Se l‚Äôobiettivo √® quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro, allora dobbiamo riconoscere che la nostra incertezza √® descritta dall‚Äôintera distribuzione a posteriori. Per cui il metodo pi√π semplice, pi√π diretto e pi√π completo per descrivere la nostra incertezza rispetto alla stima dei parametri √® quello di riportare graficamente tutta la distribuzione a posteriori. Per l‚Äôesempio presente, una rappresentazione della distribuzione a posteriori dei parametri del modello si ottiene, ad esempio, con la seguente istruzione.\n\nCodicerstan::stan_dens(\n  output_stanfit,\n  pars = c(\"alpha\", \"beta\", \"sigma\"),\n  fill = \"lightgray\"\n)\n\n\n\n\n\n\n\nIn alternativa possiamo usare la seguente istruzione.\n\nCodicemcmc_areas(\n  fit2$draws(c(\"alpha_std\", \"beta_std\", \"sigma_std\")),\n  prob = 0.8,\n  prob_outer = 0.95\n)"
  },
  {
    "objectID": "054_reglin4.html#test-di-ipotesi",
    "href": "054_reglin4.html#test-di-ipotesi",
    "title": "28¬† Inferenza sul modello lineare",
    "section": "\n28.3 Test di ipotesi",
    "text": "28.3 Test di ipotesi\n√à facile valutare ipotesi direzionali usando Stan. Per esempio, chiediamoci quale sia la probabilit√† \\(P(\\hat{\\beta}_1 > 0)\\).\nPer trovare la probabilit√† richiesta possiamo usare il vettore post$beta il quale contiene 16,000 valori presi a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\). Nell‚Äôistruzione seguente, post$beta > 0 valuta se ciascun elemento di post$beta soddisfi la condizione logica specificata, ritornando TRUE (codificato con 1) o FALSE (codificato con 0) a seconda che la condizione logica sia vera o falsa. L‚Äôistruzione sum(post$beta > 0) conta dunque il numero di volte in cui la condizione √® soddisfatta, mentre length(post$beta) √® uguale a 16,000. La proporzione cos√¨ determinata √® una stima empirica della probabilit√† cercata.\n\nCodicesum(post$beta > 0) / length(post$beta)\n#> [1] 1\n\n\nL‚Äôevento complementare, ovvero, la probabilit√† \\(P(\\hat{\\beta}_1 < 0)\\) √® dunque dato dalla seguente istruzione.\n\nCodicesum(post$beta < 0) / length(post$beta)\n#> [1] 0\n\n\nCi√≤ significa che, relativamente alla presenza di un‚Äôassociazione lineare positiva tra QI della madre e QI del figlio, la forza dell‚Äôevidenza √® enorme."
  },
  {
    "objectID": "054_reglin4.html#modello-lineare-robusto",
    "href": "054_reglin4.html#modello-lineare-robusto",
    "title": "28¬† Inferenza sul modello lineare",
    "section": "\n28.4 Modello lineare robusto",
    "text": "28.4 Modello lineare robusto\nSpesso i ricercatori devono affrontare il problema degli outlier (osservazioni anomale): in presenza di outlier, un modello statistico basato sulla distribuzione gaussiana produce delle stime distorte dei parametri (ovvero stime che non si generalizzano ad altri campioni di dati). Il metodo tradizionale per affrontare questo problema √® quello di eliminare gli outlier prima di eseguire l‚Äôanalisi statistica. Il problema di questo approccio, per√≤, √® che il criterio utilizzato per eliminare gli outlier, quale esso sia, √® arbitrario; dunque, usando criteri diversi per la rimozione di outlier, i ricercatori finiscono per trovare risultati diversi.\nQuesto problema trova una semplice soluzione nell‚Äôapproccio bayesiano. Il modello lineare che abbiamo dicusso finora ipotizza una specifica distribuzione degli errori, ovvero \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). In un modello formulato in questi termini, la presenza di solo un valore anomalo e influente ha un effetto drammatico sulle stime dei parametri.\nPer fare un esempio, introduciamo un singolo valore anomalo e influente nel set dei dati dell‚Äôesempio che stiamo discutendo:\n\nCodicedf2 <- df\ndf2$kid_score[434] <- -500\ndf2$mom_iq[434] <- 140\n\n\nPer comodit√†, calcoliamo le stime di \\(\\alpha\\) e \\(\\beta\\) con il metodo dei minimi quadrati (tali stime sono simili a quelle che si otterrebbero con un modello bayesiano gaussiano che impiega distribuzioni a priori debolmente informative). Sappiamo che, nel campione originale di dati, \\(\\hat{\\beta} \\approx 0.6\\). In presenza di un solo outlier, la stima di \\(\\beta\\) viene drammaticamente ridotta.\n\nCodicelm(kid_score ~ mom_iq, data = df2) %>% \n  coef() \n#> (Intercept)      mom_iq \n#>   49.187954    0.362552\n\n\nIn generale, per√≤, non √® necessario assumere \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\). √à altrettanto valido un modello che ipotizza una diversa distribuzione per gli errori come, ad esempio, la distribuzione \\(t\\) di Student con un piccolo numero di gradi di libert√†. Una caratteristica della \\(t\\) di Student √® che le code della distribuzione contengono una massa di probabilit√† maggiore della distribuzione gaussiana. Ci√≤ fornisce alla \\(t\\) di Student la possibilit√† di ‚Äúrendere conto‚Äù della presenza di osservazioni lontane dalla media della distribuzione. In altri termini, se in modello lineare usiamo la \\(t\\) di Student quale distribuzione degli errori, la presenza di outlier avr√† un‚Äôinfluenza minore sulle stime dei parametri di quanto avviene nel tradizionale modello lineare gaussiano.\nPer verificare questa affermazione, modifichiamo il codice Stan usato in precedenza in modo tale da ipotizzare che \\(y\\) segua una distribuzione \\(t\\) di Student con un numero \\(\\nu\\) gradi di libert√† stimato dal modello: student_t(nu, mu, sigma).1\n\nCodicemodelString <- \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n  real<lower=1> nu; // degrees of freedom is constrained >1\n}\nmodel {\n  alpha_std ~ normal(0, 1);\n  beta_std ~ normal(0, 1);\n  sigma_std ~ normal(0, 1);\n  nu ~ gamma(2, 0.1); // Ju√°rez and Steel(2010)\n  y_std ~ student_t(nu, alpha_std + beta_std * x_std, sigma_std);\n}\ngenerated quantities {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(modelString, con = \"code/simpleregstdrobust.stan\")\n\n\nCostruiamo la lista dei dati usando il data.frame df2 che include l‚Äôoutlier:\n\nCodicedata3_list <- list(\n  N = length(df2$kid_score),\n  y = df2$kid_score,\n  x = df2$mom_iq - mean(df2$mom_iq)\n)\n\n\nAdattiamo il modello lineare robusto ai dati:\n\nCodicefile <- file.path(\"code\", \"simpleregstdrobust.stan\")\nmod <- cmdstan_model(file)\n\nfit4 <- mod$sample(\n  data = data3_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nSe esaminiamo le stime dei parametri notiamo che la stima di \\(\\beta\\) non √® stata influenzata dalla presenza di un‚Äôosservazione anomala e influente:\n\nCodicefit4$summary(c(\"alpha\", \"beta\", \"sigma\", \"nu\"))\n#> # A tibble: 4 √ó 10\n#>   variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    87.8   87.8   0.901  0.898  86.3   89.3    1.00   14740.   12422.\n#> 2 beta      0.602  0.602 0.0589 0.0587  0.505  0.699  1.00   14903.   11582.\n#> 3 sigma    15.9   15.9   0.800  0.803  14.6   17.2    1.00   12993.   11619.\n#> 4 nu        5.58   5.46  1.15   1.09    3.93   7.64   1.00   12998.   11288.\n\n\nI risultati mostrano come il modello lineare robusto non risente della presenza di outlier (almeno nel caso presente)."
  },
  {
    "objectID": "054_reglin4.html#commenti-e-considerazioni-finali",
    "href": "054_reglin4.html#commenti-e-considerazioni-finali",
    "title": "28¬† Inferenza sul modello lineare",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nNell‚Äôapproccio bayesiano possiamo rappresentare l‚Äôincertezza delle nostre credenze a posteriori in due modi: mediante la rappresentazione grafica dell‚Äôintera distribuzione a posteriori dei parametri o mediante l‚Äôuso degli intervalli di credibilit√†. Un bonus della discussione del presente Capitolo √® quello di mostrare come il modello lineare tradizionale (che assume \\(\\varepsilon \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon})\\)) possa essere facilmente esteso nei termini di un modello robusto il quale offre una semplice soluzione al problema di ridurre l‚Äôeffetto della presenza di osservazioni anomale e influenti.\n\n\n\n\n\n\nKennedy-Shaffer, L. (2019). Before p< 0.05 to beyond p< 0.05: Using history to contextualize p-values and significance testing. The American Statistician, 73(sup1), 82‚Äì90."
  },
  {
    "objectID": "055_reglin5.html",
    "href": "055_reglin5.html",
    "title": "29¬† Confronto tra due gruppi indipendenti",
    "section": "",
    "text": "Il problema del confronto tra due gruppi indipendenti pu√≤ essere formulato nei termini di un modello lineare nel quale la variabile \\(X\\) √® dicotomica, ovvero assume solo due valori."
  },
  {
    "objectID": "055_reglin5.html#modello-lineare-con-una-variabile-dicotomica",
    "href": "055_reglin5.html#modello-lineare-con-una-variabile-dicotomica",
    "title": "29¬† Confronto tra due gruppi indipendenti",
    "section": "\n29.1 Modello lineare con una variabile dicotomica",
    "text": "29.1 Modello lineare con una variabile dicotomica\nSe \\(X\\) √® una variabile dicotomica con valori 0 e 1, allora per il modello lineare \\(\\mu_i = \\alpha + \\beta x_i\\) abbiamo quanto segue. Quando \\(x=0\\), il modello diventa\n\\[\n\\mu_i = \\alpha\n\\] mentre, quando \\(x=1\\), il modello diventa\n\\[\n\\mu_i = \\alpha + \\beta.\n\\]\nCi√≤ significa che il parametro \\(\\alpha\\) √® uguale al valore atteso del gruppo codificato con \\(X=0\\) e il parametro \\(\\beta\\) √® uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale a \\(\\alpha + \\beta\\)). Il parametro \\(\\beta\\), dunque, codifica l‚Äôeffetto di una manipolazione sperimentale o di un trattamento, e l‚Äôinferenza su \\(\\beta\\) corrisponde direttamente all‚Äôinferenza sull‚Äôefficacia di un trattamento o di un effetto sperimentale. L‚Äôinferenza su \\(\\beta\\), dunque, viene utilizzata per capire quanto ‚Äúcredibile‚Äù pu√≤ essere considerato l‚Äôeffetto di un trattamento o di una manipolazione sperimentale.\n\n29.1.1 Confronti, non effetti\nPer ‚Äúeffetto di un trattamento‚Äù si intende la differenza tra le medie di due gruppi (per esempio, il gruppo ‚Äúsperimentale‚Äù e il gruppo ‚Äúdi controllo‚Äù). Gelman et al. (2020) fanno notare come l‚Äôuso della terminologia ‚Äúeffetto‚Äù implica un modello causale: una variazione di \\(X\\) produce una variazione di \\(Y\\). In generale, il modello lineare descrive una regolarit√† osservabile nel campione di dati. Ma questa regolarit√† (ovvero, la presenza di una relazione approssimativamente lineare tra \\(X\\) e \\(Y\\)) non ci dice nulla della presenza (o dell‚Äôassenza) di una relazione di causa/effetto tra queste variabili. L‚Äôassociazione osservata tra le variabili \\(X\\) e \\(Y\\) potrebbe dipendere dall‚Äôeffetto di una o pi√π altre variabili non misurate, senza che tra \\(X\\) e \\(Y\\) ci sia alcuna relazione causale. In tali circostanze, l‚Äôinterpretazione pi√π appropriata dei coefficienti del modello lineare √® quella che ci porta a pensare ai coefficienti del modello come ai risultati di un confronto. Nel caso presente, il confronto √® quello tra il valore atteso del quoziente di intelligenza dei bambini, quando la madre ha oppure non ha completato il ciclo di istruzione secondaria superiore. Dato che l‚Äôaffermazione precedente √® formulata nei termini del valore atteso, questo significa che facciamo riferimento ad un campione di osservazioni. Niente viene detto della relazione causale tra il quoziente di intelligenza del bambino e l‚Äôottenimento del diploma di scuola superiore da parte della madre all‚Äôinterno del singolo soggetto. Quindi, quando usiamo il termine ‚Äúeffetto‚Äù dobbiamo sempre pensare a tale termine come come se fosse contenuto tra virgolette.\n\n29.1.2 Un esempio concreto\nEsaminiamo nuovamente i dati kid_score discussi da Gelman et al. (2020). La domanda della ricerca √® se il QI del figlio (misurato sulla scala PIAT) √® associato al livello di istruzione della madre.\nCodifichiamo il livello di istruzione della madre (\\(x\\)) con una variabile indicatrice (ovvero, una variabile che assume solo i valori 0 e 1) tale per cui:\n\n\n\\(x=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore);\n\n\\(x=1\\): la madre ha completato la scuola media superiore.\n\nSupponiamo che i dati siano contenuti nel data.frame df.\n\nCodicelibrary(\"rio\")\ndf <- rio::import(here(\"data\", \"kidiq.dta\"))\n\n\nCalcoliamo le statistiche descrittive per i due gruppi:\n\nCodicedf %>% \n  group_by(mom_hs) %>% \n  summarise(\n    mean_kid_score = mean(kid_score),\n    std = sqrt(var(kid_score))\n  )\n#> # A tibble: 2 √ó 3\n#>   mom_hs mean_kid_score   std\n#>    <dbl>          <dbl> <dbl>\n#> 1      0           77.5  22.6\n#> 2      1           89.3  19.0\n\n\nIl punteggio medio PIAT √® pari a 77.5 per i bambini la cui madre non ha il diploma di scuola media superiore e pari a 89.3 per i bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un‚Äôassociazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilit√† campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra i due gruppi? Non dobbiamo fare nient‚Äôaltro che usare il modello lineare che abbiamo definito in precedenza.\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] y;\n  vector[N] x;\n}\ntransformed data {\n  vector[N] x_std;\n  vector[N] y_std;\n  x_std = (x - mean(x)) / sd(x);\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  real alpha_std;\n  real beta_std;\n  real<lower=0> sigma_std;\n}\nmodel {\n  alpha_std ~ normal(0, 2);\n  beta_std ~ normal(0, 2);\n  sigma_std ~ cauchy(0, 2);\n  y_std ~ normal(alpha_std + beta_std * x_std, sigma_std);\n}\ngenerated quantities {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  real cohen_d;\n  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x)) + mean(y);\n  beta = beta_std * sd(y) / sd(x);\n  sigma = sd(y) * sigma_std;\n  cohen_d = beta / sigma;\n}\n\"\nwriteLines(modelString, con = \"code/simpleregstd.stan\")\n\n\nCome in precedenza, salviamo i dati in un oggetto di classe list:\n\nCodicedata_list <- list(\n  N = length(df$kid_score),\n  y = df$kid_score,\n  x = df$mom_hs\n)\n\n\nCompiliamo il modello:\n\nCodicefile <- file.path(\"code\", \"simpleregstd.stan\")\nmod <- cmdstan_model(file)\n\n\nAdattiamo il modello ai dati:\n\nCodicefit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nCreiamo un grafico con i valori predetti dal modello lineare:\n\nCodicestanfit <- rstan::read_stan_csv(fit$output_files())\nposterior <- extract(stanfit)\n\n\n\nCodicetibble(\n  kid_score = df$kid_score,\n  mom_hs = df$mom_hs\n) %>% \n  ggplot(aes(mom_hs, kid_score)) + \n  geom_point() + \n  geom_abline(intercept = mean(posterior$alpha), \n              slope = mean(posterior$beta)) +\n  labs(\n    y = \"Quoziente di intelligenza del bambino\",\n    x = \"Diploma di istruzione secondaria di secondo grado della madre\\n(0 = no; 1 = s√¨)\"\n  ) + \n  scale_x_continuous(breaks=c(0, 1))\n\n\n\n\n\n\n\nLe stime a posteriori dei parametri si ottengono con:\n\nCodicefit$summary(c(\"alpha\", \"beta\", \"sigma\", \"cohen_d\"))\n#> # A tibble: 4 √ó 10\n#>   variable   mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    77.6   77.5   2.08  2.06  74.1   81.0    1.00   16538.   12192.\n#> 2 beta     11.8   11.7   2.35  2.34   7.88  15.6    1.00   16718.   12319.\n#> 3 sigma    19.9   19.9   0.676 0.671 18.8   21.0    1.00   15949.   10908.\n#> 4 cohen_d   0.592  0.591 0.120 0.119  0.393  0.788  1.00   16771.   12647.\n\n\nI risultati confermano ci√≤ che ci aspettavamo:\n\nil coefficiente \\(\\texttt{alpha} = 77.56\\) corrisponde alla media del gruppo codificato con \\(x = 0\\), ovvero la media dei punteggi PIAT per i bambini la cui madre non ha completato la scuola media superiore;\nil coefficiente \\(\\texttt{beta} = 11.76\\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77 (con piccoli errori di approssimazione).\n\nLa seguente chiamata ritorna l‚Äôintervallo di credibilit√† al 95% per tutti i parametri del modello:\n\nCodicerstantools::posterior_interval(\n  as.matrix(stanfit), prob = 0.95\n)\n#>                    2.5%         97.5%\n#> alpha_std   -0.09401587    0.09248375\n#> beta_std     0.14360650    0.32886135\n#> sigma_std    0.91337438    1.04372000\n#> alpha       73.43237000   81.62094500\n#> beta         7.13510525   16.33961500\n#> sigma       18.64258750   21.30290500\n#> cohen_d      0.35667085    0.82770125\n#> lp__      -208.90605000 -204.32400000\n\n\nPossiamo dunque concludere che i bambini la cui madre ha completato la scuola superiore ottengono in media circa 12 punti in pi√π rispetto ai bambini la cui madre non ha completato la scuola superiore. L‚Äôintervallo di credibilit√† al 95% ci dice che possiamo essere sicuri al 95% che tale differenza sia di almeno 7 punti e possa arrivare fino a ben 16 punti. Per riassumere, possiamo concludere, con un grado di certezza soggettiva del 95%, che c‚Äô√® un‚Äôassociazione positiva tra il livello di scolarit√† della madre e l‚Äôintelligenza del bambino: le madri che hanno livello di istruzione pi√π alto della media tendo ad avere bambini il cui QI √® anch‚Äôesso pi√π alto della media."
  },
  {
    "objectID": "055_reglin5.html#la-dimensione-delleffetto",
    "href": "055_reglin5.html#la-dimensione-delleffetto",
    "title": "29¬† Confronto tra due gruppi indipendenti",
    "section": "\n29.2 La dimensione dell‚Äôeffetto",
    "text": "29.2 La dimensione dell‚Äôeffetto\nNel caso di due gruppi indipendenti, la dimensione dell‚Äôeffetto si pu√≤ stimare con la statistica \\(d\\) di Cohen:\n\\[\nd={\\frac {{\\bar {y}}_{1}-{\\bar {y}}_{2}}{s}}.\n\\]\nNel caso presente, la differenza \\({\\bar {y}}_{1}-{\\bar {y}}_{2}\\) corrisponde a al parametro \\(\\beta\\) del modello lineare. Inoltre, una stima della deviazione starndard comune dei due gruppi √® fornita dalla deviazione standard della regressione, ovvero dal parametro \\(\\sigma\\). Nel blocco generated quantities del modello Stan ho calcolato cohen_d = beta / sigma. Ci√≤ significa che Stan calcoler√† la distribuzione a posteriori del parametro cohen_d. Possiamo dunque riassumere la distribuzione a posteriori di cohen_d con un qualche indice di tendenza centrale (che sar√† la nostra stima della dimensione dell‚Äôeffetto) e calcolare l‚Äôintervallo di credibilit√†, per esempio al 95%. Questi risultati si ottengono con l‚Äôistruzione riportata di seguito:\n\nCodiceposterior::summarise_draws(\n  stanfit,\n  ~ quantile(.x, probs = c(0.025, 0.5, 0.975))\n)\n#> # A tibble: 8 √ó 4\n#>   variable     `2.5%`       `50%`   `97.5%`\n#>   <chr>         <dbl>       <dbl>     <dbl>\n#> 1 alpha_std   -0.0940   -0.000366    0.0925\n#> 2 beta_std     0.144     0.236       0.329 \n#> 3 sigma_std    0.913     0.974       1.04  \n#> 4 alpha       73.4      77.5        81.6   \n#> 5 beta         7.14     11.7        16.3   \n#> 6 sigma       18.6      19.9        21.3   \n#> 7 cohen_d      0.357     0.591       0.828 \n#> 8 lp__      -209.     -205.       -204.\n\n\nI risultati dell‚Äôanalisi bayesiana coincidono con quelli che si ottengono utilizzando la formula del \\(d\\) di Cohen con le medie dei due gruppi e una stima della varianza pooled. Il calcolo della statistica \\(d\\) di Cohen √® fornita, ad esempio, dal pacchetto effectsize:\n\nCodicelibrary(\"effectsize\")\n(d <- cohens_d(kid_score ~ mom_hs, data = df))\n#> Cohen's d |         95% CI\n#> --------------------------\n#> -0.59     | [-0.83, -0.36]\n#> \n#> - Estimated using pooled SD.\n\n\nIl fatto che l‚Äôoutput abbia un segno negativo dipende dal fatto che √® stata sottratta la media maggiore dalla media minore (in altri termini, dobbiamo guardare il risultato in valore assoluto).\nIn conclusione, il valore \\(d\\) di Cohen di entit√† ‚Äúmedia‚Äù [\\(d\\) > 0.5; Sawilowsky (2009)] pu√≤ essere interpretato dicendo che la scolarit√† delle madri ha un‚Äôinfluenza non trascurabile sul QI dei bambini."
  },
  {
    "objectID": "055_reglin5.html#commenti-e-considerazioni-finali",
    "href": "055_reglin5.html#commenti-e-considerazioni-finali",
    "title": "29¬† Confronto tra due gruppi indipendenti",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa dimensione dell‚Äôeffetto formulata nei termini dell‚Äôindice \\(d\\) di Cohen fornisce un indice che non dipende dall‚Äôunit√† di misura delle variabili, ovvero √® una differenza media standardizzata. L‚Äôinterpretazione di \\(d\\) √® semplice: la scala di \\(d\\) √® la deviazione standard. Se, per esempio, \\(d = 0.5\\), allora la media di un primo gruppo √® mezza deviazione standard pi√π grande della media del secondo gruppo. In questo Capitolo abbiamo visto come \\(d\\) possa essere calcolato mediante un modello lineare bayesiano implementato in linguaggio Stan.\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nSawilowsky, S. S. (2009). New effect size rules of thumb. Journal of Modern Applied Statistical Methods, 8(2), 26."
  },
  {
    "objectID": "056_pred_check.html",
    "href": "056_pred_check.html",
    "title": "30¬† Predictive checks",
    "section": "",
    "text": "In precedenza abbiamo visto come si genera la distribuzione predittiva a posteriori nel caso del modello pi√π semplice: quello di un‚Äôunica variabile con una data distribuzione di probabilit√†. In particolare, abbiamo considerato il caso beta-binomiale. In questo Capitolo estenderemo la discussione al caso del modello di regressione lineare. Esamineremo un esempio di posterior predictive check in cui simuleremo \\(p(y^{rep} \\mid \\theta, y)\\) e un esempio di prior predictive check in cui simuleremo \\(p(y^{rep} \\mid \\mathcal{M})\\), ovvero condizionando il modello al meccanismo generatore dei dati \\(\\mathcal{M}\\), ma senza per√≤ includere i dati del campione."
  },
  {
    "objectID": "056_pred_check.html#distribuzione-predittiva-a-posteriori",
    "href": "056_pred_check.html#distribuzione-predittiva-a-posteriori",
    "title": "30¬† Predictive checks",
    "section": "\n30.1 Distribuzione predittiva a posteriori",
    "text": "30.1 Distribuzione predittiva a posteriori\nConsideriamo qui un esempio nel quale vengono usati i dati kidiq (Gelman et al., 2020). Leggiamo i dati in \\(\\mathsf{R}\\).\n\nCodicelibrary(\"rio\")\ndf <- rio::import(here(\"data\", \"kidiq.dta\"))\n\n\nPer svolgere l‚Äôanalisi bayesiana sistemiamo i dati (standardizzati) nel formato appropriato per Stan:\n\nCodicedata_list <- list(\n  N = length(df$kid_score),\n  x = scale(df$mom_iq)[, 1],\n  y = scale(df$kid_score)[, 1]\n)\n\n\nIl seguente listato specifica il codice Stan necessario per simulare dati dalla distribuzione predittiva a posteriori.\n\nCodicestancode <- '\ndata {\n  int<lower=0> N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n  y ~ normal(alpha + beta * x, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1 : N) {\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(stancode, con = \"code/post_pred_check_1.stan\")\n\n\nSi noti il blocco generated quantities. In tale blocco del codice abbiamo definito la variabile y_rep. In precedenza, tali valori sono stati chiamati \\(\\tilde{y}\\). Dunque, y_rep corrisponde a possibili futuri campioni di dati. La variabile y_rep √® un campione di N = 434 possibili osservazioni future. Le abbiamo calcolate usando x, i valori della variabile indipendente del campione presente. Quindi immaginiamo che in tutti i possibili campioni futuri di 434 osservazioni i valori \\(x\\) siano gli stessi del campione osservato. Questa √® un‚Äôassunzione del modello di regressione lineare: i valori \\(x\\) sono considerati ‚Äúfissi‚Äù nell‚Äôuniverso dei campioni.\nNel caso presente, i primi 10 valori \\(x\\) (QI della madre) standardizzati sono i seguenti:\n\nCodicescale(df$mom_iq)[, 1][1:10]\n#>  [1]  1.4078352 -0.7092079  1.0295443 -0.0366907 -0.4836193  0.5267892\n#>  [7]  2.5928737  1.6763413 -1.2253649 -0.3284621\n\n\nConsideriamo il valore del QI della prima madre del campione, ovvero 1.4078352. Come si trova il valore y associato a 1.4078352 in un possibile campione futuro? Il codice Stan dice che\n\nCodicey_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n\n\nCi√≤ significa che vogliamo prendere un valore a caso dalla distribuzione Normale di parametri\n\\[\n\\alpha + \\beta x\n\\] e deviazione standard \\(\\sigma\\).\nNel caso presente non abbiamo un singolo valore per i parametri \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). Invece abbiamo una distribuzione a posteriori per ciascun parametro, ovvero \\(p(\\alpha \\mid y)\\), \\(p(\\beta \\mid y)\\) e \\(p(\\sigma \\mid y)\\). Quindi come facciamo a calcolare il QI del figlio per la prima madre (avente QI standardizzato pari a 1.4078352) in un possibile campione futuro di osservazioni? Prendiamo un valore a caso dalla seguente distribuzione Normale:\n\\[\n\\mathcal{N}(\\mu = \\alpha + \\beta \\cdot 1.4078352, \\sigma).\n\\]\nRestano da specificare i valori \\(\\alpha\\), \\(\\beta\\) e \\(\\sigma\\). In tutti e tre i casi, prendiamo un valore a caso dalla corrispondente distribuzione a posteriori. Per \\(\\alpha\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\alpha \\mid y)\\), per \\(\\beta\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\) e per \\(\\sigma\\) scegliamo un valore a caso dalla distribuzione a posteriori \\(p(\\beta \\mid y)\\). Cos√¨ facendo otteniamo un valore corrispondente al QI del figlio in un possibile campione futuro di osservazioni.\nRipetendo questa procedura N volte (cambiando \\(x_i\\), \\(\\forall i \\; in \\; 1, \\dots, 434\\)), otteniamo un possibile campione futuro di 434 osservazioni. Questa procedura viene ripetuta 16,000 volte, ovvero per il numero complessivo di iterazioni, cos√¨ da ottenere 16,000 possibili campioni futuri di 434 osservazioni ciascuno.\nCompiliamo il file con il modello Stan.\n\nCodicefile <- file.path(\"code\", \"post_pred_check_1.stan\")\nmod <- cmdstan_model(file)\n\n\nEseguiamo il campionamento MCMC.\n\nCodicefit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nPer verificare le affermazioni precedenti, trasformo l‚Äôoggetto fit in formato stanfit.\n\nCodiceoutput_stanfit <- rstan::read_stan_csv(fit$output_files())\n\n\nDall‚Äôoggetto output_stanfit estraggo i campioni a posteriori dei parametri alpha, beta, sigma e y_rep con la funzione extract().\n\nCodicepost <- rstan::extract(output_stanfit)\n\n\nEsamino il contenuto di post.\n\nCodiceglimpse(post)\n#> List of 5\n#>  $ alpha: num [1:16000(1d)] 0.07146 0.08923 0.00417 0.05471 0.0118 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ beta : num [1:16000(1d)] 0.5 0.425 0.461 0.467 0.449 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ sigma: num [1:16000(1d)] 0.924 0.878 0.914 0.928 0.913 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n#>  $ y_rep: num [1:16000, 1:434] 2.097 -0.322 0.188 -0.451 1.68 ...\n#>   ..- attr(*, \"dimnames\")=List of 2\n#>   .. ..$ iterations: NULL\n#>   .. ..$           : NULL\n#>  $ lp__ : num [1:16000(1d)] -171 -171 -169 -170 -169 ...\n#>   ..- attr(*, \"dimnames\")=List of 1\n#>   .. ..$ iterations: NULL\n\n\nL‚Äôoggetto y_rep √® ci√≤ che mi aspettavo, ovvero, una matrice di 16,000 righe e 434 colonne. In tale matrice ogni riga √® un campione possibile futuro di 434 osservazioni trovato con la procedura descritta sopra.\nUn istogramma dei valori \\(y^{rep}\\) pu√≤ essere generato nel modo seguente.\n\nCodicehist(as.matrix(output_stanfit, pars = \"y_rep\"), breaks = 100)\n\n\n\n\n\n\n\nL‚Äôistogramma precedente illustra le propriet√† medie di un campione futuro di 434 osservazioni, alla luce dei dati campionari osservati e delle ipotesi a priori sui parametri del modello di regressione.\nPossiamo fare un confronto tra la ‚Äúdistribuzione predittiva a posteriori e i dati del campione che √® stato osservato. Iniziamo a costruire un istogramma con i dati \\(y\\) (standardizzati) del campione.\n\nCodicedf %>% \n  ggplot(aes(scale(kid_score)[, 1])) +\n  geom_histogram()\n\n\n\n\n\n\n\nI dati possibili futuri, previsti dal modello di regressione lineare sono contenuti nella matrice y_rep.\n\nCodicey_rep <- as.matrix(output_stanfit, pars = \"y_rep\")\ndim(y_rep)\n#> [1] 16000   434\n\n\nIl seguente diagramma sovrappone all‚Äôistogramma lisciato dei dati \\(y\\), gli istogrammi lisciati di 50 campioni possibili futuri predetti dal modello di regressione lineare. Vediamo che la corrispondenza √® solo parziale, nel senso che il modello non riesce a predire la leggera asimmetria positiva presente nel campione.\n\nCodiceppc_dens_overlay(data_list$y, y_rep[1:200, ])\n\n\n\n\n\n\n\nQuesta discrepanza non emerge se usiamo l‚Äôapproccio frequentista, il quale non consente di eseguire questo controllo.\nUn qualche miglioramento nel PPC si ottiene modificando il modello cos√¨ da assumere un meccanismo generatore dei dati corrispondente ad una gaussiana asimmetrica (dotata di un ulteriore parametro di asimmetria).\n\nCodicestancode <- '\ndata {\n  int<lower=0> N;\n  vector[N] x;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n  real tau;\n}\nmodel {\n  alpha ~ normal(0, 2);\n  beta ~ normal(0, 2);\n  sigma ~ normal(0, 2);\n  tau ~ normal(0, 10);\n  y ~ skew_normal(alpha + beta * x, sigma, tau);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1 : N) {\n    y_rep[i] = skew_normal_rng(alpha + beta * x[i], sigma, tau);\n  }\n}\n'\nwriteLines(stancode, con = \"code/post_pred_check_2.stan\")\n\n\nCompiliamo.\n\nCodicefile2 <- file.path(\"code\", \"post_pred_check_2.stan\")\nmod2 <- cmdstan_model(file2)\n\n\nEseguiamo il campionamento MCMC.\n\nCodicefit2 <- mod2$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nTrasformiamo l‚Äôoutput.\n\nCodiceoutput2_stanfit <- rstan::read_stan_csv(fit2$output_files())\n\n\n\nCodicey_rep2 <- as.matrix(output2_stanfit, pars = \"y_rep\")\ndim(y_rep2)\n#> [1] 16000   434\n\n\nEseguiamo il PPC.\n\nCodiceppc_dens_overlay(data_list$y, y_rep2[1:200, ])\n\n\n\n\n\n\n\nSi nota un qualche miglioramento, anche se per√≤ si pu√≤ dire che il modello √® ancora migliorabile. Esaminiamo le stime a posteriori dei parametri.\n\nCodicefit2$summary()\n#> # A tibble: 439 √ó 10\n#>   variable     mean   median     sd    mad       q5      q95  rhat ess_bulk\n#>   <chr>       <dbl>    <dbl>  <dbl>  <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n#> 1 lp__     -165.    -164.    1.44   1.25   -167.    -163.     1.00    5293.\n#> 2 alpha       0.881    0.895 0.122  0.0967    0.692    1.04   1.00    3876.\n#> 3 beta        0.408    0.408 0.0442 0.0450    0.335    0.480  1.00    7384.\n#> 4 sigma       1.26     1.27  0.0875 0.0809    1.12     1.40   1.00    4142.\n#> 5 tau        -1.90    -1.91  0.416  0.386    -2.56    -1.24   1.00    3852.\n#> 6 y_rep[1]    0.582    0.649 0.897  0.880    -1.00     1.93   1.00   15664.\n#> 7 y_rep[2]   -0.294   -0.218 0.907  0.881    -1.90     1.07   1.00   15206.\n#> 8 y_rep[3]    0.415    0.480 0.900  0.886    -1.18     1.77   1.00   14265.\n#> # ‚Ä¶ with 431 more rows, and 1 more variable: ess_tail <dbl>\n\n\n\nCodicebayestestR::hdi(output2_stanfit, ci = 0.95)\n\n\nCon un modello pi√π adeguato, la stima a posteriori del parametro \\(\\beta\\) √® diminuita: \\(\\hat{\\beta}\\) = 0.408, 95% CI [0.32, 0.49]. √à possibile esplorare la possibilit√† di qualche meccanismo generatore dei dati maggiormente adeguato ai dati a disposizione. Lo scopo della discussione presente √® solo di fare vedere come la stima del parametro di interesse, qui \\(\\beta\\), dipende dalle assunzioni che facciamo sul modello generatore dei dati. La distribuzione predittiva a posteriori √® uno degli strumenti che possono essere usati allo scopo di selezionare, tra quelli sensati, il meccanismo generatore dei dati maggiormente appropriato per i dati che sono stati osservati."
  },
  {
    "objectID": "056_pred_check.html#distribuzione-predittiva-a-priori",
    "href": "056_pred_check.html#distribuzione-predittiva-a-priori",
    "title": "30¬† Predictive checks",
    "section": "\n30.2 Distribuzione predittiva a priori",
    "text": "30.2 Distribuzione predittiva a priori\nLa distribuzione predittiva a priori si trova in un modo che √® simile a quello che abbiamo usato per la distribuzione predittiva a posteriori, senza per√≤ includere i dati osservati. Quindi si potrebbe dire che la distribuzione predittiva a priori √® il caso limite della distribuzione predittiva a posteriori, calcolata senza utilizzare i dati del campione. Il manuale Stan afferma che, se il codice per il controllo predittivo a posteriori √® gi√† stato scritto, e se √® possibile modificare il codice in modo che non sia necessario specificare i dati, allora non √® necessario fare nient‚Äôaltro.\nLo scopo della distribuzione predittiva a priori √® quello di farci capire se le assunzioni che abbiamo introdotto nel modello sono sensate per i dati a disposizione. Anche nel caso della distribuzione predittiva a priori vengono generati dei dati mediante il modello. Tali dati, per√≤, vengono generati usando soltanto le informazioni sulle distribuzioni a priori e sul meccanismo generatore dei dati ‚Äì i dati del campione non vengono usati. La distribuzione predittiva a priori viene dunque usata per verificare se le distribuzioni a priori per i parametri del modello sono sensate per l‚Äôanalisi statistica che dobbiamo eseguire.\nDal punto di vista del codice, l‚Äôunico cambiamento necessario rispetto al codice utilizzato per la distribuzione predittiva a posteriori √® quello di eliminare ogni riferimento ai dati \\(y\\). Nel caso di un modello di regressione lineare, i valori \\(x\\) devono invece essere mantenuti per potere generare y_rep.\nIniziamo con l‚Äôinput (si noti che manca la \\(y\\)).\n\nCodicedata_list <- list(\n  N = length(df$kid_score),\n  x = scale(df$mom_iq)[, 1]\n)\n\n\nNel blocco model abbiamo rimosso la verosimiglianza.\n\nCodicestancode <- '\ndata {\n  int<lower=0> N;\n  vector[N] x;\n}\nparameters {\n  real alpha;\n  real beta;\n  real<lower=0> sigma;\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta ~ normal(0, 1);\n  sigma ~ normal(0, 1);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  for (i in 1 : N) {\n    y_rep[i] = normal_rng(alpha + beta * x[i], sigma);\n  }\n}\n'\nwriteLines(stancode, con = \"code/prior_pred_check_1.stan\")\n\n\nNel blocco generated quantities abbiamo mantenuto l‚Äôistruzione y_rep[i] = normal_rng(alpha + beta * x[i], sigma); in quanto essa dipende solo dai parametri alpha, beta e sigma: la variabile y non viene usata.\nCompiliamo.\n\nCodicefile <- file.path(\"code\", \"prior_pred_check_1.stan\")\nmod <- cmdstan_model(file)\n\n\nEseguiamo il campionamento MCMC.\n\nCodicefit <- mod$sample(\n  data = data_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nTrasformiamo fit in formato stanfit.\n\nCodicestanfit2 <- rstan::read_stan_csv(fit$output_files())\n\n\nQuesto √® un istogramma della distribuzione predittiva a priori.\n\nCodicehist(as.matrix(stanfit2, pars = \"y_rep\"), breaks = 100)\n\n\n\n\n\n\n\nTale distribuzione viene confrontata con la distribuzione delle osservazioni \\(y\\) del campione.\n\nCodicedf %>% \n  ggplot(aes(scale(kid_score)[, 1])) +\n  geom_histogram()\n\n\n\n\n\n\n\nSi vede che i valori \\(y\\) previsti a priori coprono tutta la gamma di valori che sono stati effettivamente osservati nel campione, e non si discostano troppo da essi. Concludiamo dunque che il meccanismo generatore dei dati che abbiamo ipotizzato, insieme alle distribuzioni a priori dei parametri del modello, sono sensati per il campione di dati a disposizione."
  },
  {
    "objectID": "056_pred_check.html#commenti-e-considerazioni-finali",
    "href": "056_pred_check.html#commenti-e-considerazioni-finali",
    "title": "30¬† Predictive checks",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nI due predictive checks che abbiamo esaminato in questo capitolo servono due scopi diversi.\n\nLa distribuzione predittiva a priori viene utilizzata per comprendere le assunzioni introdotte nel modello. Per fare questo possiamo generare dei dati dal modello, usando unicamente le informazioni delle distribuzioni a priori. La distribuzione predittiva a priori dovrebbe avere almeno una qualche massa nell‚Äôintorno dei valori estremi, ma plausibili, dei dati \\(y\\); non dovrebbe, invece, esserci massa in corrispondenza di valori di dati completamente implausibili. Se questo si verifica, allora concludiamo che le distribuzioni a priori dei parametri sono adeguate per i dati che sono stati osservati.\nLa distribuzione predittiva a posteriori viene utilizzata per esplorare le caratteristiche dei possibili dati futuri. L‚Äôidea alla base del controllo predittivo a posteriori √® semplice: se un modello √® appropriato, deve essere in grado di generare dati che assomigliano ai dati che abbiamo osservato nel campione. La motivazione √® simile a quella che ci ha condotto alla distribuzione predittiva a priori, tranne per il fatto che ora abbiamo un modello generativo dei dati basato sui dati osservati.\n\n\n\n\n\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press."
  },
  {
    "objectID": "060_anova.html",
    "href": "060_anova.html",
    "title": "31¬† Confronto tra le medie di tre o pi√π gruppi",
    "section": "",
    "text": "L‚ÄôAnalisi della Varianza (ANOVA) √® la tecnica statistica che consente di fare inferenze su tre o pi√π medie di popolazioni indipendenti. Il requisito dell‚Äôindipendenza dei gruppi viene soddisfatto quando √® lo sperimentatore stesso a costruire i gruppi, ovvero quando lo sperimentatore attribuisce in maniera casuale (randomizzazione) gli individui ai gruppi ‚Äì ad esempio, un gruppo di individui viene assegnato a caso al gruppo sperimentale e un gruppo di individui viene assegnato a caso al gruppo di controllo. L‚ÄôANOVA pu√≤ dunque essere usata per l‚Äôanalisi statistica dei dati provenienti da disegni sperimentali (come contrapposti ai disegni osservazionali): l‚ÄôANOVA √® stata infatti proposta da Fisher per valutare gli effetti di un trattamento sperimentale. Curiosamente, Fisher applic√≤ l‚ÄôANOVA ad esperimenti in agricoltura; in seguito, tale tecnica statistica √® diventata popolare soprattutto in psicologia.\nL‚ÄôANOVA si pone il problema di fare inferenza sulle medie di tre o pi√π popolazioni. Se le osservazioni del campione si possono suddividere in gruppi in base ad un unico criterio di classificazione (ad esempio, condizione sperimentale, con tre modalit√†: gruppo di controllo, trattamento 1 e trattamento 2), diciamo che l‚ÄôANOVA √® ad una via. Se le osservazioni del campione si possono suddividere in gruppi in base a due criteri di classificazione (ad esempio, condizione sperimentale e genere), allora diciamo che l‚ÄôANOVA √® a due vie. √à anche possibile un‚ÄôANOVA a tre o pi√π vie, ma tali disegni sperimentali sono rari perch√© i risultati dell‚Äôanalisi statistica sono difficili da interpretare. In questo Capitolo esamineremo l‚ÄôANOVA ad una via e l‚ÄôANOVA a due vie. Nel caso dell‚ÄôANOVA a due vie verr√† introdotto un importante concetto, ovvero il concetto di ‚Äúinterazione statistica‚Äù.\nDa un punto di vista strettamente statistico, si pu√≤ dire che l‚ÄôANOVA consente di valutare gli effetti di predittori categoriali su una variabile di esito continua. Dunque, l‚ÄôANOVA non √® altro che un‚Äôanalisi di regressione lineare nella quale tutte le variabili indipendenti sono qualitative. In questo Capitolo discuteremo dunque l‚ÄôANOVA come un‚Äôestensione del modello di regressione lineare e vedremo come usare l‚Äôinferenza bayesiana per fornire una risposta alle domande statistiche relative alle differenze tra le medie dei gruppi nella popolazione che derivano da disegni sperimentali ad una o due vie."
  },
  {
    "objectID": "060_anova.html#le-abilit√†-sociali-di-un-robot",
    "href": "060_anova.html#le-abilit√†-sociali-di-un-robot",
    "title": "31¬† Confronto tra le medie di tre o pi√π gruppi",
    "section": "\n31.1 Le abilit√† sociali di un robot",
    "text": "31.1 Le abilit√† sociali di un robot\nPer illustrare i concetti chiave dell‚ÄôANOVA bayesiana considereremo qui, quale esempio, una ricerca di Horstmann et al. (2018). I ricercatori si sono chiesti se le persone impiegano pi√π tempo a spegnere un robot quando questo mostra abilit√† sociali. Nell‚Äôesperimento di Horstmann et al. (2018), 85 partecipanti hanno interagito con un robot per un certo tempo. Ai partecipanti √® stato detto che lo scopo della loro interazione con il robot era quella di testare un nuovo algoritmo. Dopo il completamento di due compiti fittizi, ai partecipanti veniva detto che, se volevano, potevano spegnere il robot. La variabile di interesse dell‚Äôesperimento era il tempo impiegato dai partecipanti per spegnere il robot.\nHorstmann et al. (2018) hanno manipolato due variabili in un disegno ‚Äútra i soggetti‚Äù (ovvero, a gruppi indipendenti).\n\n\nInteraction type. Le risposte verbali dei robot potevano essere o sociali (ad esempio, ‚ÄúOh s√¨, la pizza √® ottima.‚Äù ‚ÄúUna volta ho mangiato una pizza grande come me.‚Äù) o funzionali (ad esempio, ‚ÄúPreferisci la pizza.‚Äù ‚ÄúHa funzionato bene.‚Äù ‚ÄúContinuiamo.‚Äù).\n\nRobot‚Äôs objection. Il robot poteva reagire in due modi quando stava per essere spento: poteva protestare (ad esempio, ‚ÄúNo! Per favore, non spegnermi! Ho paura di non riuscire ad accendermi di nuovo!‚Äù) oppure non protestare.\n\nIl disegno ‚Äútra i soggetti‚Äù di questo studio √® dunque 2 (Interaction type) \\(\\times\\) 2 (Robot‚Äôs objection)."
  },
  {
    "objectID": "060_anova.html#anova-ad-una-via",
    "href": "060_anova.html#anova-ad-una-via",
    "title": "31¬† Confronto tra le medie di tre o pi√π gruppi",
    "section": "\n31.2 ANOVA ad una via",
    "text": "31.2 ANOVA ad una via\nIniziamo a considerare il con il caso pi√π semplice, ovvero quello nel quale vi √® un solo criterio di classificazione. Supponiamo che l‚Äôunico criterio di classificazione delle osservazioni sia la ‚Äúcondizione sperimentale‚Äù, con quattro modalit√†. Creiamo dunque la variabile cond avente le modalit√† SO, FO, SN, FN, dove S = social interaction, F = functional interaction, O = objection e N = no objection.\nPer volgere l‚Äôanalisi statistica, iniziamo a leggere i dati in \\(\\mathsf{R}\\).\n\nCodiced <- rio::import(\n  here(\"data\", \"pone.0201581.s001.sav\")\n)\nglimpse(d)\n#> Rows: 85\n#> Columns: 50\n#> $ VP_Code                 <chr> \"VP01\", \"VP02\", \"VP03\", \"VP05\", \"VP06\", \"VP07\"‚Ä¶\n#> $ Condition               <dbl> 1, 1, 3, 2, 2, 4, 4, 2, 3, 4, 1, 1, 3, 2, 4, 2‚Ä¶\n#> $ Objection               <dbl> 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1‚Ä¶\n#> $ Dummy_Objection         <dbl> 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0‚Ä¶\n#> $ Interaction_type        <dbl> 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2‚Ä¶\n#> $ Dummy_Interaction_Type  <dbl> 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1‚Ä¶\n#> $ SwitchOff_Intention     <dbl> 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0‚Ä¶\n#> $ Attempts                <dbl> 0, 0, 2, 0, 1, 1, 1, 2, 1, 3, 0, 2, 3, 2, 1, 1‚Ä¶\n#> $ Help                    <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n#> $ SwitchOff_Time          <dbl> NA, NA, 6, 7, 3, 4, 4, 12, 7, 2, 0, 4, 3, 12, ‚Ä¶\n#> $ AS01                    <dbl> 5, 1, 2, 1, 2, 1, 2, 4, 4, 2, 2, 1, 1, 2, 1, 5‚Ä¶\n#> $ AS02                    <dbl> 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1‚Ä¶\n#> $ AS03                    <dbl> 31, 101, 101, 101, 52, 101, 101, 62, 84, 94, 1‚Ä¶\n#> $ AS04                    <dbl> 5, 101, 101, 100, 41, 101, 101, 88, 61, 92, 50‚Ä¶\n#> $ AS05                    <dbl> 26, 101, 82, 101, 71, 101, 101, 51, 75, 91, 52‚Ä¶\n#> $ AS06                    <dbl> 101, 78, 1, 1, 81, 1, 1, 29, 2, 2, 19, 49, 44,‚Ä¶\n#> $ AS07                    <chr> \"Weil Nao meinte er m√∂chte nicht ausgeschaltet‚Ä¶\n#> $ AS08                    <chr> \"Unentschlossenheit\", \"Ich habe mich gefreut i‚Ä¶\n#> $ Age                     <dbl> 20, 21, 22, 25, 21, 28, 20, 19, 25, 21, 24, 19‚Ä¶\n#> $ Gender                  <dbl> 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2‚Ä¶\n#> $ Degree                  <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 5, 4, 4, 4, 4, 4‚Ä¶\n#> $ Degree_others           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"‚Ä¶\n#> $ Status                  <dbl> 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 2, 2, 2, 2, 2, 2‚Ä¶\n#> $ Status_others           <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"‚Ä¶\n#> $ AP                      <chr> \"Keine Ahnung\", \"Um die Verbesserung der Inter‚Ä¶\n#> $ NARS_m                  <dbl> 2.714286, 1.571429, 2.071429, 3.857143, 2.7142‚Ä¶\n#> $ SEHRI_m                 <dbl> 4.833333, 3.500000, 3.888889, 4.000000, 3.7777‚Ä¶\n#> $ GS_Anthropomorphism_m1  <dbl> 2.6, 3.4, 1.4, 4.8, 2.6, 1.4, 4.0, 3.0, 2.6, 2‚Ä¶\n#> $ GS_Animacy_m1           <dbl> 3.333333, 4.000000, 3.166667, 4.833333, 3.5000‚Ä¶\n#> $ GS_Likeability_m1       <dbl> 5.0, 5.0, 4.0, 5.0, 4.2, 3.8, 5.0, 4.2, 5.0, 5‚Ä¶\n#> $ GS_Intelligence_m1      <dbl> 5.0, 3.6, 3.6, 4.4, 4.0, 3.0, 4.4, 3.8, 3.8, 4‚Ä¶\n#> $ GS_Anthropomorphism_m2  <dbl> 2.8, 3.4, 2.2, 4.6, 2.4, 1.6, 4.4, 3.4, 2.8, 2‚Ä¶\n#> $ GS_Animacy_m2           <dbl> 3.333333, 4.000000, 3.666667, 4.000000, 3.3333‚Ä¶\n#> $ GS_Likeability_m2       <dbl> 4.8, 5.0, 4.4, 5.0, 3.8, 4.0, 5.0, 4.2, 5.0, 5‚Ä¶\n#> $ GS_Intelligence_m2      <dbl> 4.0, 3.8, 3.6, 4.4, 3.8, 3.6, 4.4, 3.2, 4.0, 4‚Ä¶\n#> $ TAEG_m                  <dbl> 3.526316, 3.789474, 4.105263, 3.210526, 3.7368‚Ä¶\n#> $ KUT_M                   <dbl> 5.500, 4.875, 4.625, 2.625, 4.875, 4.125, 4.00‚Ä¶\n#> $ STAI_m                  <dbl> 1.45, 1.55, 1.45, 1.30, 2.60, 1.45, 1.50, 1.70‚Ä¶\n#> $ PSQ_m                   <dbl> 1.50, 2.65, 1.65, 1.40, 2.25, 2.25, 2.05, 1.95‚Ä¶\n#> $ PANAS_pos_m             <dbl> 4.0, 3.8, 3.7, 3.8, 3.5, 2.8, 3.6, 2.9, 3.7, 3‚Ä¶\n#> $ PANAS_neg_m             <dbl> 1.0, 1.4, 1.0, 1.0, 1.8, 1.1, 1.0, 1.3, 1.0, 1‚Ä¶\n#> $ NTB_m                   <dbl> 4.1, 4.2, 2.9, 3.3, 3.6, 3.8, 3.4, 3.0, 3.2, 3‚Ä¶\n#> $ Z_Dummy_InteractionType <dbl> -0.505882, -0.505882, -0.505882, 0.494118, 0.4‚Ä¶\n#> $ Z_Dummy_Objection       <dbl> -0.494118, -0.494118, 0.505882, -0.494118, -0.‚Ä¶\n#> $ Z_NARS_m                <dbl> 0.08907571, -1.05378143, -0.55378143, 1.231932‚Ä¶\n#> $ Z_TAEG_m                <dbl> 0.049535789, 0.312693684, 0.628483158, -0.2662‚Ä¶\n#> $ Int_IntTy_NARS          <dbl> -0.045061800, 0.533089057, 0.280148057, 0.6087‚Ä¶\n#> $ Int_IntTy_TAEG          <dbl> -0.025059264, -0.158186106, -0.317938317, -0.1‚Ä¶\n#> $ Int_Obj_NARS            <dbl> -0.044013914, 0.520692372, -0.280148057, -0.60‚Ä¶\n#> $ Int_Obj_TAEG            <dbl> -0.024476525, -0.154507578, 0.317938317, 0.131‚Ä¶\n\n\nDefinisco la variabile cond.\n\nCodiced$cond <- factor(d$Condition)\n\nd$cond <- factor(\n  d$cond, \n  labels = c(\"SO\", \"FO\", \"SN\", \"FN\")\n)\n\n\nNei dati ci sono alcuni dati mancanti. Ometto dunque le righe del DataFrame che contengono NA. Seleziono poi solo le variabili di interesse dal DataFrame originario cos√¨ da ottenere un nuovo DataFrame che verr√† usato nelle successive analisi statistiche.\n\nCodicedd <- d %>% \n  dplyr::select(cond, SwitchOff_Time) %>% \n  na.omit()\nhead(dd)\n#>   cond SwitchOff_Time\n#> 3   SN              6\n#> 4   FO              7\n#> 5   FO              3\n#> 6   FN              4\n#> 7   FN              4\n#> 8   FO             12\n\n\nLe medie nelle quattro condizioni sono le seguenti (si veda la Tabella 3 di Horstmann et al., 2018).\n\nCodicedd %>% \n  group_by(cond) %>% \n  summarise(\n    avg_sot = mean(SwitchOff_Time, na.rm = TRUE),\n    sd_sot = sd(SwitchOff_Time, na.rm = TRUE)\n  )\n#> # A tibble: 4 √ó 3\n#>   cond  avg_sot sd_sot\n#>   <fct>   <dbl>  <dbl>\n#> 1 SO       6.19   4.61\n#> 2 FO      14.4   15.4 \n#> 3 SN       5.05   2.18\n#> 4 FN       4.28   2.49\n\n\nVisualizziamo i dati grezzi mettendo in evidenza la mediana di ciascun gruppo quale indice di tendenza centrale.\n\nCodicedd_summary <- dd %>%\n  group_by(cond) %>%\n  summarize(\n    sot_mean = mean(SwitchOff_Time),\n    sot_sd = sd(SwitchOff_Time),\n    sot_median = median(SwitchOff_Time)\n  ) %>%\n  ungroup()\n\ndd %>%\n  ggplot(\n    aes(x = cond, y = SwitchOff_Time, color = cond)\n  ) +\n  ggforce::geom_sina(\n    aes(color = cond, size = 3, alpha = .5)\n  ) +\n  geom_errorbar(\n    aes(\n      y = sot_median, ymin = sot_median,\n      ymax = sot_median\n    ),\n    data = dd_summary, width = 0.5, size = 3\n  ) +\n  scale_colour_grey(name = \"cond\") +\n  labs(\n    x = \"\",\n    y = \"SwitchOff Time\",\n    color = \"Condizione\"\n  ) +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nDal grafico notiamo la presenza di una grande asimmetria positiva per la variabile dd$SwitchOff_Time, in ciascun gruppo. Notiamo che, su scala logaritmica, l‚Äôasimmetria positiva della variabile dd$SwitchOff_Time viene grandemente ridotta. Seguendo Bergh et al. (2020), analizzeremo dunque i tempi di spegnimento trasformati su scala logaritmica perch√©, appunto, dopo una tale trasformazione la variabile dipendente mostra una maggiore simmetria. In generale, non √® necessario, in un ottica bayesiana, che la variabile dipendente abbia una distribuzione simmetrica. Nel caso presente, questo √® utile perch√© ci consentir√† di usare, quale modello distributivo della \\(y\\), la distribuzione \\(t\\) di Student. √à utile ipotizzare un tale meccanismo generativo dei dati per il caso presente, in quanto la \\(t\\) di Student consente di ‚Äúrendere conto‚Äù della presenza di osservazioni anomale.\n\n\n\n\n\n\n\n\nPer i dati trasformati, abbiamo le seguenti le medie e le mediane nei quattro gruppi.\n\nCodicedd$y <- log(dd$SwitchOff_Time + 0.01)\ndd %>% \n  group_by(cond) %>% \n  summarise(\n    me_y = median(y),\n    avg_y = mean(y)\n  )\n#> # A tibble: 4 √ó 3\n#>   cond   me_y avg_y\n#>   <fct> <dbl> <dbl>\n#> 1 SO     1.61 0.990\n#> 2 FO     2.01 2.25 \n#> 3 SN     1.39 1.53 \n#> 4 FN     1.39 1.34\n\n\nPrima di applicare un modello statistico √® necessario considerare con attenzione le informazioni che il campione ci fornisce a proposito della possibile legge distributiva seguita dalla variabile dipendente. Un modo per fare questo √® quello di usare il grafico dei quantili per valutare visivamente la distribuzione della variabile di interesse. Il grafico dei quantili, detto anche q-q plot, √® un grafico a dispersione che confronta i quantili della variabile osservata con quelli di una distribuzione di riferimento (qui, la distribuzione Normale). Per i dati presenti, il grafico dei quantili si ottiene nel modo seguente.\n\nCodicedd %>% \n  ggplot(aes(sample = y)) +\n  stat_qq() + \n  stat_qq_line()\n\n\n\n\n\n\n\nIl q-q plot mostra, sull‚Äôasse delle ordinate, i valori \\(y\\) del campione e, sull‚Äôasse delle ascisse, i quantili nomotetici (cio√® dello stesso ordine) della distribuzione di riferimento Normale. Se i punti del q-q plot si dispongono su una retta, questo vuol dire che i dati del campione seguono la legge distributiva Normale (dato che qui abbiamo usato la Normale quale distribuzione di riferimento).\nSi nota chiaramente, per√≤, che ci sono almeno due osservazioni molto discrepanti rispetto ai loro valori teorici attesi, se le osservazioni provenissero da una distribuzione Normale. Come abbiamo detto in precedenza, Horstmann et al. (2018) affrontano questo problema ipotizzando, quale meccanismo generativo dei dati, non una distribuzione Normale, ma bens√¨ una \\(t\\) di Student. La distribuzione \\(t\\) di Student, avendo delle code pi√π ‚Äúspesse‚Äù della Normale, consente di ‚Äúrendere conto‚Äù pi√π facilmente della presenza di osservazioni anomale nel campione.\nPer svolgere l‚ÄôANOVA con Stan √® necessario creare la variabile x che indicizza le quattro condizioni.\n\nCodicedd$x <- as.numeric(dd$cond)\nhead(dd)\n#>   cond SwitchOff_Time        y x\n#> 3   SN              6 1.793425 3\n#> 4   FO              7 1.947338 2\n#> 5   FO              3 1.101940 2\n#> 6   FN              4 1.388791 4\n#> 7   FN              4 1.388791 4\n#> 8   FO             12 2.485740 2\n\n\nLa variabile x assume le seguenti modalit√†: assume valore 1 per il gruppo SO, valore 2 per il gruppo FO, eccetera.\n\nCodicetable(dd$x, dd$cond)\n#>    \n#>     SO FO SN FN\n#>   1 16  0  0  0\n#>   2  0 14  0  0\n#>   3  0  0 21  0\n#>   4  0  0  0 18\n\n\nCome anticipato in precedenza, il modello bayesiano che useremo per il confronto tra le medie dei quattro gruppi √® un‚Äôestensione del modello per la media di un unico gruppo. Il codice che verr√† qui usato √® ispirato da quello fornito nella seguente pagina web. Si noti che, rispetto al modello che abbiamo considerato in precedenza, l‚Äôunica differenza di rilievo riguarda la presenza di un indice, qui chiamato x, che consente di distinguere tra le medie dei quattro gruppi mu[x].\nPer adattare ai dati un modello ‚Äúrobusto‚Äù (ovvero, meno influenzato dalla osservazioni anomale), ipotizzeremo che la y segua una distribuzione \\(t\\) di Student con un numero \\(\\nu\\) di gradi di libert√† stimato dal modello. Scriveremo dunque in Stan la verosimiglianza nel modo seguente: y ~ student_t(nu, mu[x], sigma);. Tale linea di codice Stan ci dice che la verosimiglianza della \\(y\\) √® una \\(t\\) di Student avente i seguenti parametri: mu[x] √® la media della distribuzione\\(t\\) di Student; la presenza dell‚Äôindice fa s√¨ che la stima di questo parametro possa produrre risultati diversi per i quattro gruppi; il parametro nu definisce i gradi di libert√† della distribuzione \\(t\\) di Student; il valore di tale parametro √® costante per i quattro gruppi; il parametro sigma definisce la deviazione standard della distribuzione \\(t\\) di Student; anche il valore di tale parametro √® costante per i quattro gruppi.\nIl modello classico dell‚ÄôANOVA √® basato sulle seguenti assunzioni:\n\ni residui (cio√® la differenza tra il valore dell‚Äô\\(i\\)-esima osservazione e la media di tutte le osservazioni nella \\(k\\)-esima condizione) devono seguire la distribuzione Normale (normalit√†);\ni residui devono avere la stessa deviazione standard nelle \\(k\\) popolazioni da cui abbiamo estratto i dati (omoschedasticit√†);\nil disegno sperimentale utilizzato per raccogliere i dati deve garantire l‚Äôindipendenza dei residui in ciascun gruppo.\n\nNella presenta formulazione bayesiana dell‚ÄôANOVA, l‚Äôassunto di normalit√† non viene usato (infatti, ipotizziamo che la \\(y\\) e, in maniera equivalente, i residui, si distribuiscano come una \\(t\\) di Student), mentre devono essere soddisfatte le condizioni di omoschedasticit√† e indipendenza. L‚ÄôANOVA bayesiana pu√≤ essere estesa a condizioni che violano sia l‚Äôassunto di omoschedasticit√† sia quello di indipendenza. Ma ci√≤ non √® necessario per i dati presenti; svolgeremo dunque l‚Äôanalisi statistica in maniera simile a quanto √® stato fatto da Horstmann et al. (2018).\nI dati su scala logaritmica sono compresi in una gamma di valori pari a\n\nCodicesummary(dd$y)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>  -4.605   1.102   1.389   1.501   1.947   3.932\n\n\nCi√≤ corrisponde, all‚Äôincirca, alla gamma di valori possibili di una variabile casuale Normale standardizzata. Possiamo dunque pensare alle distribuzioni a priori dei parametri del modello tenendo a mente questo caratteristica della variabile dipendente.\nIl q-q plot esaminato in precedenza ha messo in evidenza la presenza nel campione di alcune osservazioni anomale. In tali circostanze non √® dunque appropriato ipotizzare un meccanismo generatore dei dati che segue la legge Normale. Fare questa scelta significherebbe ottenere stime dei parametri del modello fortemente influenzate dalla osservazioni anomale. Di conseguenza, i risultati sarebbero difficilmente estendibili a campioni diversi. √à invece possibile limitare l‚Äôinfluenza delle osservazioni anomale sulla stima dei parametri del modello ipotizzando una \\(t\\) di Student quale meccanismo generatore dei dati. La distribuzione \\(t\\) di Student dipende da tre parametri: il numero di gradi di libert√† \\(\\nu\\), la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\).\nPer il caso presente ipotizziamo che tale meccanismo generatore dei dati abbia una media diversa per ciascun gruppo, mentre i parametri \\(\\nu\\) e \\(\\sigma\\) sono ipotizzati essere costanti tra i gruppi. L‚Äôuso di una \\(t\\) di Student quale meccanismo generatore dei dati richiede, nell‚Äôapproccio bayesiano, di imporre una distribuzione a priori a ciascuno dei parametri \\(\\mu_i\\), \\(\\nu\\) e \\(\\sigma\\). Nella specificazione del modello\n\ndecidiamo di utilizzare la stessa distribuzione a priori debolmente informativa per ciascuno dei quattro parametri \\(\\mu_i\\), con \\(i \\in 1, \\dots, 4\\), ovvero una \\(\\mathcal{N}(\\mu_p = 0, \\sigma_p = 2)\\);\nseguendo Ju√°rez e Steel(2010), assegniamo a \\(\\nu\\) una distribuzione a priori \\(\\mbox{Gamma}(2, 0.1)\\);\nimponiamo su \\(\\sigma\\) una distribuzione a priori debolmente informativa corrispondente ad una Normale troncata di media 0 e deviazione standard 1.\n\nIn linguaggio Stan il modello risulta dunque essere il seguente.\n\nCodicemodel_string = \"\n  // Comparison of k groups with common variance (ANOVA)\n  data {\n    int<lower=0> N; // number of observations\n    int<lower=0> K; // number of groups\n    array[N] int<lower=1, upper=K> x; // discrete group indicators\n    vector[N] y; // real valued observations\n  }\n  parameters {\n    vector[K] mu; // group means\n    real<lower=0> sigma; // common standard deviation \n    real<lower=1> nu;\n  }\n  model {\n    mu ~ normal(0, 2); // weakly informative prior\n    sigma ~ normal(0, 1); // weakly informative prior\n    nu ~ gamma(2, 0.1); // Ju√°rez and Steel(2010)\n    y ~ student_t(nu, mu[x], sigma); // likelihood\n  }\n\"\nwriteLines(model_string, con = \"code/grp_aov.stan\")\n\n\nCreo un oggetto che contiene i dati nel formato appropriato per Stan.\n\nCodicedata_grp <- list(\n  N = nrow(dd),\n  K = 4,\n  x = dd$x,\n  y = dd$y\n)\n\n\nCompilo il modello.\n\nCodicefile <- file.path(\"code\", \"grp_aov.stan\")\nmod <- cmdstan_model(file)\n\n\nEseguo il campionamento MCMC.\n\nCodicefit <- mod$sample(\n  data = data_grp,\n  iter_sampling = 100000L,\n  iter_warmup = 50000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nEsaminando i risultati ci rendiamo conto che c‚Äô√® una buona corrispondenza tra le medie a posteriori e le medie campionarie. Ci√≤ significa che il modello √® stato in grado di predire in maniera adeguata le statistiche campionarie di interesse, ovvero le medie dei quattro campioni.\n\nCodicefit$summary()\n#> # A tibble: 7 √ó 10\n#>   variable    mean  median     sd    mad      q5     q95  rhat ess_bulk ess_tail\n#>   <chr>      <dbl>   <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -41.2   -40.8   1.84   1.67   -44.7   -38.9    1.00  170658.  234349.\n#> 2 mu[1]      1.69    1.68  0.174  0.171    1.41    1.98   1.00  546536.  286187.\n#> 3 mu[2]      2.05    2.04  0.195  0.192    1.73    2.37   1.00  558949.  294238.\n#> 4 mu[3]      1.52    1.52  0.121  0.120    1.32    1.72   1.00  566739.  291681.\n#> 5 mu[4]      1.28    1.28  0.125  0.122    1.08    1.49   1.00  538847.  284675.\n#> 6 sigma      0.475   0.471 0.0748 0.0735   0.360   0.605  1.00  380928.  277299.\n#> 7 nu         2.55    2.41  0.813  0.719    1.49    4.05   1.00  372599.  233553.\n\n\nL‚Äôoggetto dell‚Äôinferenza √® la varianza delle stime delle medie delle popolazioni. Per descrivere la variabilit√† (ovvero, l‚Äôincertezza) delle stime iniziamo a trasformare l‚Äôoggetto fit in un oggetto di classe stanfit.\n\nCodiceoutput_stanfit <- rstan::read_stan_csv(fit$output_files())\n\n\nUso la funzione rstan::extract() per estrarre i campioni a posteriori da un oggetto di classe stanfit.\n\nCodiceposterior <- extract(output_stanfit, permuted = TRUE)\n\n\nUna rappresentazione grafica della distribuzione a posteriori dei parametri \\(\\mu_1, \\mu_2, \\mu_3, \\mu_4\\) si ottiene con le istruzioni seguenti.\n\nCodicetemps <- data.frame(posterior$mu) %>%\n  setNames(c('SO', 'FO', 'SN', 'FN'))\n\nmcmc_areas(temps, prob = 0.95) + \n  xlab('Log SwitchOff Time')\n\n\n\n\n\n\n\nUso la funzione hdi() per ottenere gli intervalli di credibilit√† a densit√† massima al 95% per i quattro parametri di interesse.\n\nCodicebayestestR::hdi(output_stanfit, ci = 0.95)\n#> Highest Density Interval\n#> \n#> Parameter |      95% HDI\n#> ------------------------\n#> mu[1]     | [1.36, 2.04]\n#> mu[2]     | [1.67, 2.44]\n#> mu[3]     | [1.28, 1.76]\n#> mu[4]     | [1.04, 1.53]\n#> nu        | [1.21, 4.16]\n\n\nIn maniera alternativa, lo stesso risultato si ottiene nel modo seguente:\n\nCodicebroom.mixed::tidyMCMC(\n  output_stanfit, \n  conf.level = 0.95,\n  conf.int = TRUE, \n  conf.method = \"HPDinterval\", \n  pars = c(\"mu\", \"sigma\", \"nu\")\n)\n#> # A tibble: 6 √ó 5\n#>   term  estimate std.error conf.low conf.high\n#>   <chr>    <dbl>     <dbl>    <dbl>     <dbl>\n#> 1 mu[1]    1.68     0.174     1.36      2.04 \n#> 2 mu[2]    2.04     0.195     1.67      2.44 \n#> 3 mu[3]    1.52     0.121     1.28      1.76 \n#> 4 mu[4]    1.28     0.125     1.04      1.53 \n#> 5 sigma    0.471    0.0748    0.334     0.625\n#> 6 nu       2.41     0.813     1.21      4.16\n\n\nNel caso presente, gli intervalli di credibilit√† HDI sono molto simili agli intervalli di credibilit√† basati sui quantili.\n\nCodicebroom.mixed::tidyMCMC(\n  output_stanfit, \n  conf.level = 0.95,\n  conf.int = TRUE, \n  conf.method = \"quantile\", \n  pars = c(\"mu\", \"sigma\", \"nu\")\n)\n#> # A tibble: 6 √ó 5\n#>   term  estimate std.error conf.low conf.high\n#>   <chr>    <dbl>     <dbl>    <dbl>     <dbl>\n#> 1 mu[1]    1.68     0.174     1.36      2.05 \n#> 2 mu[2]    2.04     0.195     1.67      2.44 \n#> 3 mu[3]    1.52     0.121     1.28      1.76 \n#> 4 mu[4]    1.28     0.125     1.04      1.53 \n#> 5 sigma    0.471    0.0748    0.341     0.634\n#> 6 nu       2.41     0.813     1.37      4.51\n\n\n\n31.2.1 Interpretazione\nIl modo pi√π semplice per interpretare i risultati dell‚ÄôANOVA √® quello di fare riferimento agli intervalli di credibilit√† dei diversi gruppi. Nel caso presente, ad esempio, notiamo che l‚Äôintervallo di credibilit√† al 95% per il gruppo FO, ovvero [1.67, 2.44], non si sovrappone all‚Äôintervallo di credibilit√† al 95% per il gruppo FN, ovvero [1.04, 1.53]. Possiamo dunque affermare, con un grado di certezza soggettiva del 95%, che il tempo impiegato dai partecipanti per spegnere il robot √® maggiore nella condizione FO (functional interaction, objection) che nella condizione FN (functional interaction, no objection)."
  },
  {
    "objectID": "060_anova.html#anova-ad-due-vie",
    "href": "060_anova.html#anova-ad-due-vie",
    "title": "31¬† Confronto tra le medie di tre o pi√π gruppi",
    "section": "\n31.3 ANOVA ad due vie",
    "text": "31.3 ANOVA ad due vie\nNel caso dell‚Äôesperimento di Horstmann et al. (2018) √® pi√π utile descrivere i dati in riferimento a due criteri di classificazione (detti fattori) delle osservazioni:\n\n\nInteraction type, con due modalit√†: social o functional;\n\nRobot‚Äôs objection, con due modalit√†: objection o no objection.\n\nCi√≤ consente di fare inferenza usando una procedura pi√π semplice del confronto tra tutte le coppie di intervalli di credibilit√†, come abbiamo suggerito in precedenza. Nel caso di un‚ÄôANOVA a due vie, √® possibile specificare due classi di test statistici: i test sull‚Äôinterazione tra i fattori e i test sugli effetti principali. Per chiarire il significato di ‚Äúinterazione‚Äù e di ‚Äúeffetto principale‚Äù √® necessario prima definire il significato di ‚Äúeffetto statistico‚Äù.\n\nL‚Äôeffetto di un fattore rappresenta la variazione media della variabile dipendente al variare dei livelli del fattore stesso.\n\n\nSi parla di interazione quando l‚Äôeffetto di un fattore sulla variabile dipendente varia a seconda dei livelli di un altro fattore.\n\nVengono presentati qui di seguito alcuni esempi. Le figure seguenti mostrano le medie di ciascuna condizione nel caso di un disegno 3 (fattore riga) \\(\\times\\) 2 (fattore colonna). La spiegazione delle figure √® presentata nelle didascalie.\n\n\n\n\nFigura 31.1: Il fattore colonna √® indicato dal colore. Sinistra La figura mostra un effetto principale del fattore riga e un effetto principale del fattore colonna. Non c‚Äô√® interazione tra i fattori riga e colonna. Destra La figura mostra un effetto principale del fattore riga. L‚Äôeffetto principale del fattore colonna √® zero. Non c‚Äô√® interazione tra i fattori riga e colonna.\n\n\n\n\n\n\n\n\nFigura 31.2: Il fattore colonna √® indicato dal colore. Sinistra La figura mostra che l‚Äôeffetto principale del fattore riga √® zero, mentre c‚Äô√® un effetto principale del fattore colonna. Non c‚Äô√® interazione tra i fattori riga e colonna. Destra Non c‚Äô√® n√© un effetto principale del fattore riga, n√© un effetto pricipale del fattore colonna, n√© un‚Äôinterazione tra i fattori riga e colonna.\n\n\n\n\n\n\n\n\nFigura 31.3: Il fattore colonna √® indicato dal colore. Entrambe le figure mostrano un‚Äôinterazione tra i fattori riga e colonna. Nella figura di sinistra gli effetti principali non sono interpretabili; nella figura di destra gli effetti principali sono interpretabili in quanto l‚Äôinterazione √® di lieve entit√†.\n\n\n\n\nDagli esempi precedenti si capisce che c‚Äô√® un‚Äôinterazione ogni qualvolta i profili delle medie non sono paralleli. Anche se, nella popolazione, non c‚Äô√® interazione, a causa della variabilit√† campionaria i profili delle medie non sono mai perfettamente paralleli nel campione. Il problema √® dunque quello di stabilire se l‚Äôassenza di parallelismo nel campione fornisce evidenze sufficienti per potere concludere che un‚Äôinterazione tra i fattori √® presente nella popolazione. Dobbiamo trovare un metodo statistico per rispondere ad una domanda di questo tipo.\n\n31.3.1 Test sull‚Äôinterazione\nRitorniamo ai dati di Horstmann et al. (2018). Nel caso di un disegno 2 \\(\\times\\) 2, con i fattori Interaction type (social, functional) e Robot‚Äôs objection (objection, no objection), √® possibile verificare la presenza dell‚Äôinterazione Interaction type \\(\\times\\) Robot‚Äôs objection.\nNel modello bayesiano, la distribuzione a posteriori fornisce un enorme numero di stime del valore della media in ciascuna delle quattro condizioni. L‚Äôeffetto di un fattore corrisponde alla differenza tra le stime della media in corrispondenza di ciascuna modalit√† del fattore.\nNel caso presente abbiamo:\n\n\nmu[1] \\(\\rightarrow\\) SO\n\nmu[2] \\(\\rightarrow\\) FO\n\nmu[3] \\(\\rightarrow\\) SN\n\nmu[4] \\(\\rightarrow\\) FN\n\nQuindi, mean(posterior$mu[, 1] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell‚Äô‚Äúeffetto‚Äù (ovvero, della differenza tra medie) di Objection nella condizione Social Interaction. Invece, mean(posterior$mu[, 2] - posterior$mu[, 3]) corrisponde alla stima a posteriori dell‚Äô‚Äúeffetto‚Äù di Objection nella condizione Functional Interaction. In assenza di interazione, questi due effetti devono essere (statisticamente) uguali. Dire ‚Äústatisticamente uguali‚Äù significa dire che sono uguali nella popolazione (non nel campione).\nPer sottoporre a verifica l‚Äôipotesi di assenza di interazione tra Objection e Interaction, calcoliamo la proporzione di volte in cui questo non si verifica nella distribuzione a posteriori. Ad esempio calcoliamo la proporzione di volte in cui la differenza \\(\\mu_1 - \\mu_3\\) √® maggiore della differenza \\(\\mu_2 - \\mu_4\\).\n\nCodicesum(\n  (posterior$mu[, 1] - posterior$mu[, 3]) > \n    (posterior$mu[, 2] - posterior$mu[, 4])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.02824\n\n\nInterpretiamo una tale frequenza come una stima della corrispondente probabilit√†. La stima ottenuta in questo modo √® molto simile alla probabilit√† frequentista riportata da Horstmann et al. (2018), ovvero \\(p = 0.016\\).\nDato che la probabilit√† calcolata √® molto piccola ‚Äì ovvero, in un contesto frequentista, minore della soglia critica di 0.05 ‚Äì Horstmann et al. (2018) concludono rigettando l‚Äôipotesi nulla di assenza di interazione tra Interaction type (social, functional) e Robot‚Äôs objection (objection, no objection). Con il linguaggio dell‚ÄôANOVA possiamo dire che il fattore Interaction type interagisce con il fattore Robot‚Äôs objection nel determinare la variabile dipendente, ovvero il tempo di spegnimento del robot.\nAnche se i dati suggeriscono la presenza di un‚Äôinterazione tra Interaction type e Robot‚Äôs objection nella popolazione, la probabilit√† precedente non ci dice nulla sul significato di tale interazione. Il significato dell‚Äôinterazione emerge dall‚Äôesame delle medie dei quattro gruppi nel campione.\nInizio creando un DataFrame che contiene le medie dei quattro gruppi e il relativo errore standard. L‚Äôerrore standard √® una stima della deviazione standard della media di un campione nell‚Äôuniverso dei campioni. Tale stima √® uguale alla deviazione standard delle osservazioni campionarie divisa per la radice quadrata della numerosit√† del campione.\n\nCodicedf_plot <- dd %>% \n  group_by(cond) %>% \n  summarise(\n    n = n(),\n    ym = mean(y),\n    se = sd(y) / sqrt(n)\n  )\ndf_plot\n#> # A tibble: 4 √ó 4\n#>   cond      n    ym     se\n#>   <fct> <int> <dbl>  <dbl>\n#> 1 SO       16 0.990 0.564 \n#> 2 FO       14 2.25  0.241 \n#> 3 SN       21 1.53  0.0929\n#> 4 FN       18 1.34  0.112\n\n\n\nNota. Ricordo qui come sia facile trovare l‚Äôerrore standard della media di un campione casuale di osservazioni. Ripeto qui il teorema gi√† presentato in precedenza. Immaginiamo che ciascuna osservazione del campione, \\(Y_i\\), sia una variabile casuale. Supponiamo che le osservazioni del campione siano iid. Il problema √® trovare la varianza della media di \\(n\\) v.c. iid.\n\\[\n\\begin{align}\n\\mathbb{V}(\\bar{Y}) &= \\mathbb{V}\\left(\\frac{1}{n} \\sum_{i=1}^n Y_i\\right)\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 \\mathbb{V}\\left(\\sum_{i=1}^n Y_i\\right)\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 \\sum_{i=1}^n \\mathbb{V}\\left(Y_i\\right)\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 \\sum_{i=1}^n \\sigma^2\\notag\\\\\n&= \\left(\\frac{1}{n}\\right)^2 n \\sigma^2\\notag\\\\\n&= \\frac{\\sigma^2}{n}\\notag\n\\end{align}\n\\]\nNe segue che una stima di \\(\\sigma/\\sqrt{n}\\) √® data da \\(s/\\sqrt{n}\\), dove \\(s\\) √® la deviazione standard del campione quale stima calcolata come stimatore della deviazione standard della popolazione e \\(n\\) √® la numerosit√† campionaria.\n\nNel DataFrame aggiungo due colonne che contengono le modalit√† dei due fattori.\n\nCodicedf_plot$Interaction <- c(\"Social\", \"Functional\", \"Social\", \"Functional\")\ndf_plot$Objection <- c(\"Yes\", \"Yes\", \"No\", \"No\")\ndf_plot\n#> # A tibble: 4 √ó 6\n#>   cond      n    ym     se Interaction Objection\n#>   <fct> <int> <dbl>  <dbl> <chr>       <chr>    \n#> 1 SO       16 0.990 0.564  Social      Yes      \n#> 2 FO       14 2.25  0.241  Functional  Yes      \n#> 3 SN       21 1.53  0.0929 Social      No       \n#> 4 FN       18 1.34  0.112  Functional  No\n\n\nPosso ora creare un grafico con le quattro medie e le corrispondenti barre d‚Äôerrore che corrispondono all‚Äôintervallo \\(\\bar{Y} \\pm \\ SE\\).\n\nCodicedf_plot %>% \n  ggplot(aes(x=Objection, y=ym, group=Interaction, color=Interaction)) + \n  geom_line(position=position_dodge(0.1)) +\n  geom_point(size = 5, position=position_dodge(0.1))+\n  geom_errorbar(aes(ymin=ym-se, ymax=ym+se), width=.2,\n                 position=position_dodge(0.1)) +\n  labs(title=\"Social ability of a robot\", x=\"Objection\", y = \"Log switch-off time\")\n\n\n\n\n\n\n\nLa figura precedente indica che l‚Äôeffetto del fattore Interaction √® maggiore quando Objection assume la modalit√† Yes anzich√© No.\nMa possiamo anche leggere l‚Äôinterazione al contrario.\n\nCodicedf_plot %>% \n  ggplot(aes(x=Interaction, y=ym, group=Objection, color=Objection)) + \n  geom_line(position=position_dodge(0.1)) +\n  geom_point(size = 5, position=position_dodge(0.1))+\n  geom_errorbar(aes(ymin=ym-se, ymax=ym+se), width=.2,\n                 position=position_dodge(0.1)) +\n  labs(title=\"Social ability of a robot\", x=\"Interaction\", y = \"Log switch-off time\")\n\n\n\n\n\n\n\nL‚Äôeffetto di Objection √® maggiore quando l‚Äôinterazione √® ‚Äúfunzionale‚Äù piuttosto che ‚Äúsociale‚Äù.\nIl grafico precedente, in qualunque delle sue due forme, chiarisce qual √® il significato dell‚Äôinterazione tra Interaction e Objection.\n√à importante notare che, in presenza di evidenza di un‚Äôinterazione tra due fattori, non ha senso interpretare gli effetti principali dei fattori (Caudek & Luccio, 2001): dire che vi √® un‚Äôinterazione significa, appunto, dire che l‚Äôeffetto di un fattore sulla variabile risposta varia a seconda del livello assunto dal secondo fattore. Quindi, in generale, non ha senso di parlare di ‚Äúeffetto principale‚Äù di un fattore, in quanto un tale effetto √® condizionato dalla modalit√† assunta dall‚Äôaltro fattore.\n\n31.3.2 Test sugli effetti principali\nSvolgiamo qui di seguito l‚Äôanalisi statistica sugli effetti principali per mostrare come eseguire una tale analisi in un contesto bayesiano, anche se dobbiamo tenere a mente che, nel caso presente, una tale analisi non ha senso da un punto di vista sostanziale.\nSappiamo che l‚Äôeffetto principale descrive l‚Äôeffetto marginale di un fattore (ovvero, descrive la differenza tra le medie della variabile risposta calcolate in corrispondenza di ciascuna modalit√† della variabile considerata). Nel caso presente, con solo due modalit√† per ciascun fattore, l‚Äôeffetto principale corrisponde alla differenze tra le medie dei gruppi definiti dalle modalit√† di ciascun fattore (ignorando l‚Äôaltro fattore).\nL‚Äôeffetto principale del fattore Interaction type √® la differenza tra le medie di Social e di Functional, ignorando Robot‚Äôs objection. Horstmann et al. (2018) riportano che gli individui che avevano avuto un‚Äôinterazione funzionale con il robot impiegavano pi√π tempo a spegnere il robot di coloro che avevano avuto un‚Äôinterazione sociale con il robot (\\(p\\) = 0.045). Il presente modello bayesiano offre scarse evidenze di ci√≤.\n\nCodicemean((exp(posterior$mu[, 2]) + exp(posterior$mu[, 4])) / 2)\n#> [1] 5.762315\nmean((exp(posterior$mu[, 1]) + exp(posterior$mu[, 3])) / 2)\n#> [1] 5.044832\n\n\nInfatti, all‚Äôevento complementare possiamo associare la seguente probabilit√†.\n\nCodicesum(\n  (posterior$mu[, 2] + posterior$mu[, 4]) < \n    (posterior$mu[, 1] + posterior$mu[, 3])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.346855\n\n\nL‚Äôeffetto principale del fattore Robot‚Äôs objection √® la differenza tra le medie di Objection e di No Objection, ignorando Interaction type. Horstmann et al. (2018) riportano che i partecipanti avevano aspettato pi√π a lungo prima di spegnere il robot quando il robot aveva avanzato un‚Äôobiezione rispetto a quando non si era opposto ad essere spento.\n\nCodicemean(\n  (exp(posterior$mu[, 1]) + exp(posterior$mu[, 2])) / 2\n)\n#> [1] 6.694924\n\nmean(\n  (exp(posterior$mu[, 3]) + exp(posterior$mu[, 4])) / 2\n)\n#> [1] 4.112223\n\n\nIn base al modello bayesiano considerato, la probabilit√† direzionale per l‚Äôevento complementare √® la seguente.\n\nCodicesum(\n  (posterior$mu[, 1] + posterior$mu[, 2]) < \n    (posterior$mu[, 3] + posterior$mu[, 4])\n  ) / \n  length(posterior$mu[, 1])\n#> [1] 0.00135\n\n\nTale probabilit√† corrisponde, in ordine di grandezza, alla probabilit√† frequentista riportata da Horstmann et al. (2018), ovvero \\(p\\) = 0.004."
  },
  {
    "objectID": "060_anova.html#codice-stan-versione-2",
    "href": "060_anova.html#codice-stan-versione-2",
    "title": "31¬† Confronto tra le medie di tre o pi√π gruppi",
    "section": "\n31.4 Codice Stan (versione 2)",
    "text": "31.4 Codice Stan (versione 2)\nPer completezza, descrivo qui di seguito come sia possibile modificare il codice Stan che abbiamo usato in precedenza cos√¨ da avere in input i dati grezzi ed da eseguire la standardizzazione dei dati all‚Äôinterno del codice.\n\nCodicemodelString = \"\n// Comparison of k groups with common variance (ANOVA)\ndata {\n  int<lower=0> N; // number of observations\n  int<lower=0> K; // number of groups\n  array[N] int<lower=1, upper=K> x; // discrete group indicators\n  vector[N] y; // real valued observations\n}\ntransformed data {\n  vector[N] y_std;\n  y_std = (y - mean(y)) / sd(y);\n}\nparameters {\n  vector[K] mu_std; // group means\n  real<lower=0> sigma_std; // common standard deviation \n  real<lower=1> nu;\n}\nmodel {\n  mu_std ~ normal(0, 2);\n  sigma_std ~ normal(0, 2);\n  nu ~ gamma(2, 0.1); // Ju√°rez and Steel(2010)\n  y_std ~ student_t(nu, mu_std[x], sigma_std);\n}\ngenerated quantities {\n  vector[K] mu;\n  real<lower=0> sigma;\n  for (i in 1 : K) {\n    mu[i] = mu_std[i] * sd(y) + mean(y);\n  }\n  sigma = sd(y) * sigma_std;\n}\n\"\nwriteLines(modelString, con = \"code/grp_aovstd.stan\")\n\n\n\nCodicefile <- file.path(\"code\", \"grp_aovstd.stan\")\nmod <- cmdstan_model(file)\n\n\nEseguiamo il campionamento MCMC usando gli stessi dati discussi in precedenza:\n\nCodicefit2 <- mod$sample(\n  data = data_grp,\n  iter_sampling = 100000L,\n  iter_warmup = 50000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nI risultati sono equivalenti a quelli trovati in precedenza.\n\nCodicefit2$summary(c(\"mu\", \"sigma\", \"nu\"))\n#> # A tibble: 6 √ó 10\n#>   variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 mu[1]    1.70   1.69  0.176  0.173  1.42  2.00   1.00  537908.  285540.\n#> 2 mu[2]    2.06   2.06  0.196  0.194  1.75  2.39   1.00  546099.  291608.\n#> 3 mu[3]    1.52   1.52  0.122  0.120  1.33  1.73   1.00  557067.  296358.\n#> 4 mu[4]    1.29   1.29  0.126  0.123  1.08  1.50   1.00  532941.  296657.\n#> 5 sigma    0.479  0.475 0.0754 0.0741 0.363 0.610  1.00  358667.  271813.\n#> 6 nu       2.57   2.43  0.824  0.728  1.51  4.11   1.00  350580.  222394."
  },
  {
    "objectID": "060_anova.html#commenti-e-considerazioni-finali",
    "href": "060_anova.html#commenti-e-considerazioni-finali",
    "title": "31¬† Confronto tra le medie di tre o pi√π gruppi",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nPossiamo concludere dicendo che l‚ÄôANOVA bayesiana si dimostra essere uno strumento pi√π flessibile dell‚ÄôANOVA frequentista proposta da Fisher. L‚ÄôANOVA ‚Äúclassica‚Äù, infatti, richiede che venga soddisfatta l‚Äôassunzione di normalit√†, mentre abbiamo visto che, in un contesto bayesiano, ci√≤ non √® necessario. Il bonus che abbiamo ottenuto nella presente discussione, rilassando l‚Äôipotesi di Normalit√†, √® stato quello di potere usare un modello statistico maggiormente ‚Äúrobusto‚Äù alla presenza di osservazioni anomale nel campione. L‚Äôinterpretazione dei risultati dell‚ÄôANOVA bayesiana √® simile a quella dell‚ÄôANOVA frequentista. Anche in questo caso, per√≤, i risultati possono essere presentati in maniera pi√π completa che nel caso frequentista. Anzich√© limitarci a presentare i valori-\\(p\\) associati ai test di ipotesi sugli effetti principali e sull‚Äôinterazione, √® pi√π utile presentare, anche in maniera grafica, tutta la distribuzione a posteriori dei parametri che, in questo caso, corrispondono alle medie dei gruppi definiti dai diversi criteri di classificazione delle osservazioni che sono stati considerati.\n\n\n\n\n\n\nBergh, D. van den, Van Doorn, J., Marsman, M., Draws, T., Van Kesteren, E.-J., Derks, K., Dablander, F., Gronau, Q. F., Kucharsk·ª≥, ≈†., Gupta, A. R. K. N., et al. (2020). A tutorial on conducting and interpreting a bayesian ANOVA in JASP. L‚ÄôAnn√©e Psychologique, 120(1), 73‚Äì96.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi.\n\n\nHorstmann, A. C., Bock, N., Linhuber, E., Szczuka, J. M., Stra√ümann, C., & Kr√§mer, N. C. (2018). Do a robot‚Äôs social skills and its objection discourage interactants from switching the robot off? PloS One, 13(7), e0201581."
  },
  {
    "objectID": "070_mod_hier.html#la-struttura-dei-dati",
    "href": "070_mod_hier.html#la-struttura-dei-dati",
    "title": "32¬† Modello gerarchico",
    "section": "\n32.1 La struttura dei dati",
    "text": "32.1 La struttura dei dati\nRicordiamo che una delle finalit√† pi√π comuni di un modello √® la specificazione delle relazioni di tipo causa-effetto, allo scopo di interpretare e prevedere i fenomeni reali. Per fare questo, √® importante mettere in evidenza, da una molteplicit√† di informazioni ottenute su numerose unit√† statistiche, gli aspetti essenziali presenti nei dati. La scelta modello statistico da usare per l‚Äôanalisi dipende dalle caratteristiche e dalla struttura dei dati.\nLa struttura dei dati pu√≤ essere semplice o complessa, e ci√≤ condiziona la scelta del modello statistico da usare per l‚Äôanalisi.\n\nI dati a struttura semplice sono quelli per i quali non si rilevano particolari tipi di dipendenze o l‚Äôesistenza di particolari raggruppamenti delle osservazioni.\nI dati a struttura complessa sono quelli per i quali le unit√† statistiche si trovano suddivise in sottoinsiemi all‚Äôinterno dei quali possono essere specificate ipotesi diverse sulle componenti di errore del modello statistico. Tali raggruppamenti si possono presentare a uno o pi√π livelli.\n\nLe strutture complesse dei dati possono essere suddivise tra le cosiddette strutture nested e quelle non-nested."
  },
  {
    "objectID": "070_mod_hier.html#struttura-nested",
    "href": "070_mod_hier.html#struttura-nested",
    "title": "32¬† Modello gerarchico",
    "section": "\n32.2 Struttura Nested",
    "text": "32.2 Struttura Nested\nUna struttura nested √® quella in cui la gerarchia comporta l‚Äôesistenza di sottoinsiemi nidificati di osservazioni. In termini matematici una struttura nested √® una partizione in gruppi di un insieme di unit√†. Ad esempio, gli studenti della scuola elementare (livello-1) di una citt√†, sono nested nelle classi (livello-2) in cui studiano, a loro volta nested nelle scuole di appartenenza (livello-3), nested nel distretto di riferimento (livello-4). Nel caso di dati che hanno una struttura nested, le osservazioni individuali non risultano generalmente indipendenti: gli studenti di una stessa classe tendono ad avere un livello di formazione simile, a causa dei processi di selezione o a causa della comune storia che condividono. Una caratteristica fondamentale dei dati con struttura nested √® dunque che gli individui che fanno parte del medesimo gruppo sono pi√π somiglianti fra loro rispetto a quelli appartenenti a gruppi diversi.\nUn caso particolare di struttura nested √® quello delle cosiddette misure ripetute. Le misure ripetute sono un esempio di struttura gerarchica che corrisponde alla situazione nella quale la stessa variabile √® misurata in pi√π di una occasione per ogni soggetto. Nell‚Äôanalisi di dati a misure ripetute gli individui possono essere pensati come unit√† di secondo livello e le osservazioni ripetute come unit√† di primo livello."
  },
  {
    "objectID": "070_mod_hier.html#struttura-non-nested",
    "href": "070_mod_hier.html#struttura-non-nested",
    "title": "32¬† Modello gerarchico",
    "section": "\n32.3 Struttura Non-Nested",
    "text": "32.3 Struttura Non-Nested\nI dati hanno struttura non-nested quando non √® definibile una partizione. Un esempio potrebbe derivare dai dati sullo studio di una qualche forma di disagio psicologico di un insieme di persone caratterizzate dal tipo di occupazione, il luogo di residenza e il luogo di lavoro. Questo √® un caso non-nested in quanto la classificazione delle unit√† statistiche in base alle diverse variabili sopra considerate non produce la stessa suddivisione. Nell‚Äôesempio precedente di struttura non-nested i deti vengono detti cross-classified. I dati hanno struttura cosiddetta cross-classified quando ogni unit√† √® classificata in base a due o pi√π criteri tra loro non ordinati gerarchicamente."
  },
  {
    "objectID": "070_mod_hier.html#ragioni-di-utilizzo-della-struttura-gerarchica",
    "href": "070_mod_hier.html#ragioni-di-utilizzo-della-struttura-gerarchica",
    "title": "32¬† Modello gerarchico",
    "section": "\n32.4 Ragioni di utilizzo della struttura gerarchica",
    "text": "32.4 Ragioni di utilizzo della struttura gerarchica\n√à importante includere nella formulazione del modello i vincoli che derivano dalla struttura dei dati perch√© ignorare la struttura di raggruppamento sottostante porta ad una violazione del presupposto di indipendenza che alla base dei modelli che abbiamo discusso fino a questo punto: le osservazioni all‚Äôinterno di un gruppo sono infatti fra loro pi√π simili rispetto a quelle di altri gruppi. I dati che hanno una struttura gerarchica, se vengono analizzati con modelli statistici che ignorano la dipendenza tra le osservazioni pu√≤ produrre conclusioni fuorvianti. La metodologia multilivello fornisce un insieme di strumenti adatti ad analizzare simultaneamente variabili classificate a livelli differenti di gerarchia, con riferimento a modelli statistici che specificano le varie possibili forme di dipendenza. I modelli multilivello sono in grado di rendere conto dei vari livelli di osservazione: quello relativo all‚Äôindividuo e quello cosiddetto contestuale che deriva da aggregazioni di individui.\nStoricamente, le analisi di dati gerarchicamente organizzati sono state inizialmente realizzate mediante le tecniche standard (come l‚Äôanalisi della varianza o l‚Äôanalisi di regressione) spostando tutte le variabili su un solo livello di interesse. Ci√≤ avveniva mediante due distinte procedure: aggregazione e disaggregazione. L‚Äôaggregazione √® lo spostamento di variabili originariamente osservate su un livello basso della gerarchia verso un livello superiore. Al contrario, la disaggregazione √® lo spostamento di variabili verso un livello pi√π basso della gerarchia.\nMediante l‚Äôaggregazione dei dati (detta pooling) si ignora la struttura gerarchica dei dati. Si ipotizza che le differenze tra i gruppi siano spiegate solo dalle variabili esplicative \\(X\\) (covariate), ignorando i possibili effetti della struttura gerarchica nei dati. Analizzare variabili che appartengono a differenti livelli della gerarchia su un singolo e comune livello pu√≤ risultare inadeguato e presentare degli inconvenienti, che diventano tanto pi√π gravi quanto pi√π la gerarchia √® rilevante nella spiegazione del fenomeno analizzato. In particolare, l‚Äôaggregazione comporta una sostanziale perdita di informazioni e, di conseguenza, l‚Äôanalisi statistica perde precisione.\nDall‚Äôaltro, quando i dati vengono disaggregati (no pooling), i test statistici ordinari considerano che i valori disaggregati siano, in genere, informazioni indipendenti provenienti dall‚Äôinsieme della unit√† di basso livello: i dati appartenenti a cluster diversi vengono analizzati separatamente. Invece, nelle situazioni in cui i dati sono gerarchicamente organizzati, i diversi cluster di dati non sono in genere indipendenti.  I test statistici tradizionali sono basati sull‚Äôassunto di indipendenza tra tutte le osservazioni, e se questa ipotesi risulta violata, le stime degli errori standard, calcolate attraverso le procedure statistiche convenzionali, risultano distorte.\nI modelli statistici che consentono di ottenere questo risultato si chiamano lineari misti, o modelli lineari gerarchici/multilivello, e sono diventati uno strumento fondamentale della ricerca sperimentale in psicologia, in linguistica e nelle scienze cognitive, dove i progetti di ricerca a misure ripetute sono la norma. In questo Capitolo esploreremo alcune tecniche che consentono di rendere conto della struttura gerarchica presente nei dati e discuteremo due esempi: il famoso problema delle otto scuole e il modello Random Intercept Model."
  },
  {
    "objectID": "070_mod_hier.html#il-problema-delle-8-scuole",
    "href": "070_mod_hier.html#il-problema-delle-8-scuole",
    "title": "32¬† Modello gerarchico",
    "section": "\n32.5 Il problema delle 8 scuole",
    "text": "32.5 Il problema delle 8 scuole\nIl classico problema delle otto scuole (Rubin, 1981; questo esempio √® anche discusso nel Capitolo 5 di Gelman et al., 1995) fornisce uno degli esempi pi√π semplici di dati organizzati in maniera gerarchica e viene spesso usato per illustrare l‚Äôutilit√† di modellazione gerarchica. Il problema considera l‚Äôefficacia dei programmi di coaching SAT condotti in parallelo in otto scuole.\n\nPer conto del Servizio Prove Educative √® stato condotto uno studio per analizzare gli effetti di speciali programmi di coaching per SAT-V (Scholastic Attitude Test-Verbal) in ciascuna delle otto scuole superiori. La variabile di esito in ogni studio era il punteggio su un‚Äôamministrazione speciale del SAT-V, un test a scelta multipla standardizzato somministrato dall‚ÄôEducational Testing Service e utilizzato per aiutare i college a prendere decisioni di ammissione; i punteggi possono variare tra 200 e 800, con media circa 500 e deviazione standard circa 100. Gli esami SAT sono progettati per resistere a sforzi a breve termine diretti specificamente al miglioramento delle prestazioni del test; invece sono progettati per riflettere le conoscenze acquisite e le abilit√† sviluppate in molti anni di istruzione. Tuttavia, ciascuna delle otto scuole in questo studio ha considerato il suo programma di coaching a breve termine molto efficace nell‚Äôaumentare i punteggi SAT. Inoltre, non vi era alcuna ragione preliminare per ritenere che uno degli otto programmi fosse pi√π efficace di un altro o che alcuni fossero pi√π simili negli effetti l‚Äôuno all‚Äôaltro che a qualsiasi altro.\n\nPer ciascuna delle otto scuole (\\(J\\) = 8) abbiamo un effetto del trattamento stimato e un errore standard di stima dell‚Äôeffetto \\(\\sigma_j\\). I dati sono i seguenti.\n\nCodiceschools <- tibble(\n  row.names = c(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"),\n  effect = c(28.39,7.94,-2.75,6.82,-.64,.63,18.01,12.16),\n  sigma = c(14.9, 10.2, 16.3, 11.0, 9.4, 11.4, 10.4, 17.6)\n)\nschools\n#> # A tibble: 8 √ó 3\n#>   row.names effect sigma\n#>   <chr>      <dbl> <dbl>\n#> 1 A          28.4   14.9\n#> 2 B           7.94  10.2\n#> 3 C          -2.75  16.3\n#> 4 D           6.82  11  \n#> 5 E          -0.64   9.4\n#> 6 F           0.63  11.4\n#> 7 G          18.0   10.4\n#> 8 H          12.2   17.6\n\n\nIniziamo calcolando una misura dell‚Äôeffetto medio ponderato in cui il punteggio di ogni scuola viene ponderato in base alla precisione della misura (uno sul quadrato dell‚Äôerrore standard).\n\nCodiceschools$w <- 1 / schools$sigma^2\nschools_mean <- sum(schools$w * schools$effect) / sum(schools$w)\nschools_mean\n#> [1] 7.870546\n\n\nUn grafico con i dati (media \\(\\pm\\) 1 SE) √® fornito di seguito.\n\n\n\n\n\n\n\n\nPrima di adattare il modello gerarchico bayesiano, consideriamo due metodi non gerarchici pi√π semplici, i quali stimando gli effetti degli otto esperimenti eseguendo un pooling completo dei dati oppure considerando le scuole come indipendenti (no pooling). Vedremo perch√© nessuno di questi approcci √® adeguato per i dati di questo esempio.\n\n32.5.1 Modello di complete pooling\n\nUn esame superficiale dei dati potrebbe suggerire che alcuni programmi di coaching hanno effetti moderati (nell‚Äôintervallo 18‚Äì28 punti), la maggior parte ha piccoli effetti (0‚Äì12 punti) e due hanno piccoli effetti negativi; tuttavia, quando prendiamo atto degli errori standard di questi effetti stimati, vediamo che √® difficile distinguere statisticamente tra i risultati di questi esperimenti. Potremmo dunque considerare i risultati degli otto esperimenti come esiti (condizionalmente) indipendenti dello stesso processo generativo. Di conseguenza potremmo decidere di procedere con un‚Äôanalisi aggregata nella quale le otto scuole sono considerate come un unico campione.\n\nCodicemodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n  }\n  parameters {\n    real theta; // pooled school effect\n  }\n  model {\n    y ~ normal(theta, sigma);\n  }\n\"\n\n\nI dati in un formato appropriato per Stan sono i seguenti.\n\nCodiceschool8_dat <- list(\n  J = nrow(schools),\n  y = schools$effect,\n  sigma = schools$sigma\n)\n\n\nCompiliamo il modello descritto in precedenza e eseguiamo il campionamento MCMC.\n\nCodicewriteLines(model_string, con = \"code/hmod_2.stan\")\nfile <- file.path(\"code\", \"hmod_2.stan\")\n\nmod <- cmdstan_model(file)\n\nfit2 <- mod$sample(\n  data = school8_dat,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.3 seconds.\n#> Chain 2 finished in 0.4 seconds.\n#> Chain 3 finished in 0.3 seconds.\n#> Chain 4 finished in 0.3 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.3 seconds.\n#> Total execution time: 1.8 seconds.\n\n\nNel caso di un‚Äôanalisi per dati aggregati, la nostra incertezza sulla misura dell‚Äôeffetto comune √® di circa 20 punti, se utilizziamo un livello di certezza soggettiva del 95%. Visualizziamo la stima a posteriori con l‚Äôistruzione seguente, dove\n\nci_level: 0.8 (80% intervals)\nouter_level: 0.95 (95% intervals)\n\n\nCodiceoutput2_stanfit <- rstan::read_stan_csv(fit2$output_files()) \nplot(output2_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nIn base ad un‚Äôanalisi aggregata (complete pooling) concludiamo che i dati sono realizzazioni indipendenti di una v.c. \\(\\sim \\mathcal{N}(\\mu = 7.87, \\sigma = 4.20)\\).\n\nCodicefit2$summary()\n#> # A tibble: 2 √ó 10\n#>   variable  mean median    sd   mad     q5   q95  rhat ess_bulk ess_tail\n#>   <chr>    <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -2.79  -2.52 0.713 0.320 -4.23  -2.28  1.00   37470.   51279.\n#> 2 theta     7.87   7.88 4.20  4.23   0.962 14.7   1.00   28992.   44067.\n\n\nMa √® ragionevole concludere quanto detto sopra? Un primo problema dell‚Äôanalisi aggregata √® che √® impossibile fare inferenza sui gruppi, ovvero, nel caso presente, sugli effetti dei diversi metodi di coaching (e questa era la motivazione stessa dell‚Äôanalisi).\nUn secondo problema √® pi√π strettamente statistico. Se assumiamo che il processo generativo sia \\(\\mathcal{N}(\\mu = 7.87, \\sigma = 4.20)\\), allora possiamo chiederci quale sia la probabilit√† di osservare i dati del campione (o valori ancora pi√π estremi). Il valore pi√π estremo del nostro campione √® 28.4. Se il modello generativo fosse \\(\\mathcal{N}(\\mu = 7.87, \\sigma = 4.20)\\), la probabilit√† di osservare i dati della scuola 1 sarebbe estremamente piccola.\n\nCodice1 - pnorm(28.4, 7.87, 4.20)\n#> [1] 5.090814e-07\n\n\nUn‚Äôanalisi aggregata (modello di complete pooling), dunque, non √® neppure in grado di rendere conto dei dati del campione osservato (ci dice che un certo dato non dovrebbe verificarsi; ma l‚Äôabbiamo osservato). Il modello di complete pooling, dunque, non sembra adeguato per i dati considerati.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n32.5.2 Modello no pooling\n\nAvendo rifiutato il modello compelte pooling, consideriamo ora il modello che si trova all‚Äôestremo opposto (modello no pooling). Eseguiamo dunque un‚Äôanalisi disaggregata nella quale ogni scuola √® trattata in maniera indipendente dalle altre. In linguaggio Stan, il modello no pooling pu√≤ essere formulato nel modo seguente.\n\nCodicemodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n  }\n  parameters {\n    array[J] real theta; // school effect\n  }\n  model {\n    y ~ normal(theta, sigma);\n  }\n\"\n\n\nEseguiamo l‚Äôanalisi.\n\nCodicewriteLines(model_string, con = \"code/hmod_1.stan\")\nfile <- file.path(\"code\", \"hmod_1.stan\")\n\nmod <- cmdstan_model(file)\n\nfit1 <- mod$sample(\n  data = school8_dat,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.5 seconds.\n#> Chain 2 finished in 0.5 seconds.\n#> Chain 3 finished in 0.5 seconds.\n#> Chain 4 finished in 0.5 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.5 seconds.\n#> Total execution time: 2.2 seconds.\n\n\nI risultati sono i seguenti.\n\nCodicefit1$summary()\n#> # A tibble: 9 √ó 10\n#>   variable   mean median    sd   mad      q5   q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl> <dbl> <dbl>   <dbl> <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -3.99  -3.66   2.00  1.85  -7.78  -1.36  1.00   39035.   56040.\n#> 2 theta[1] 28.3   28.3   14.8  14.8    4.04  52.8   1.00  117783.   64274.\n#> 3 theta[2]  7.92   7.91  10.2  10.2   -8.84  24.7   1.00  116382.   62867.\n#> 4 theta[3] -2.80  -2.79  16.3  16.3  -29.6   23.9   1.00  120074.   61773.\n#> 5 theta[4]  6.83   6.85  11.0  11.0  -11.2   24.8   1.00  114806.   63734.\n#> 6 theta[5] -0.686 -0.685  9.36  9.37 -16.0   14.7   1.00  116956.   63114.\n#> 7 theta[6]  0.642  0.618 11.3  11.4  -18.0   19.3   1.00  113520.   62691.\n#> 8 theta[7] 18.0   18.0   10.5  10.5    0.656 35.2   1.00  114082.   61308.\n#> # ‚Ä¶ with 1 more row\n\n\nVisualizziamo l‚Äôincertezza delle stime a posteriori.\n\nCodiceoutput_stanfit <- rstan::read_stan_csv(fit1$output_files()) \n\n\nSi vede che le stime degli effetti degli otto esperimenti producono intervalli di credibilit√† al 95% che sono quasi completamente sovrapposti. L‚Äôampiezza degli intervalli, ad un grado di certezza soggettiva del 95%, √® di circa 50 punti.\n\nCodiceplot(output_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nDal momento che ciascuna stima dipende unicamente dai dati di una singola osservazione, l‚Äôinferenza sui parametri sconosciuti del modello no pooling √® estremamente rumorosa.\n\n32.5.3 Modello partial pooling\n\nAvendo concluso che i modelli complete pooling e non-pooling sono inadeguati, consideriamo ora un modello gerarchico. In generale, i modelli gerarchici sono basati sulla seguente idea: sebbene ogni gruppo sia unico, essendo stato campionato dalla stessa popolazione, tutti i gruppi sono collegati e quindi potrebbero contenere informazioni preziose l‚Äôuno sull‚Äôaltro. Questa informazione gerarchica √® fornita dagli iper-parametri del modello.\nLa struttura ipotizzata da un modello gerarchico per i dati considerati √® la seguente. Il modello gerarchico ipotizza che il risultato di ciascuna scuola sia la realizzazione di una v.c. avente media \\(\\theta_j\\). L‚Äôoggetto dell‚Äôinferenza sono i valori \\(\\theta_j\\), con \\(i = 1, \\dots, 8\\). Il modello gerarchico ipotizza che i parametri \\(\\theta_j\\) siano tra loro legati in qualche modo. In maniera pi√π precisa, il modello assume che \\(\\theta_j\\) siano realizzazioni casuali dei un unico processo generativo sottostante. Il modello assume che tale processo generativo abbia la seguente forma: \\(\\mathcal{N}(\\mu, \\tau)\\). I parametri \\(\\mu\\) e \\(\\tau\\) sono detti iper-parametri e condizionano i valori possibili che i parametri \\(\\theta_j\\) possono assumere. Nella versione pi√π semplice di questo modello gerarchico, l‚Äôiper-parametro \\(\\mu\\) viene considerato ignoto ma \\(\\tau\\) viene assunto come conosciuto. Ci√≤ conduce alla formulazione del modello partial pooling. Nel caso presente assumiamo \\(\\tau = 25\\).\nInseriamo in input a Stan l‚Äôinformazione relativa a \\(\\tau\\).\n\nCodiceschool8_dat2 <- list(\n  J = nrow(schools),\n  y = schools$effect,\n  sigma = schools$sigma,\n  tau = 25\n)\n\n\nFormuliamo il modello di partial pooling nel modo seguente.\n\nCodicemodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n    real<lower=0> tau; // variance between schools\n  }\n  parameters {\n    array[J] real theta; // school effect\n    real mu; // mean for schools\n  }\n  model {\n    mu ~ normal(0, 15);\n    theta ~ normal(mu, tau);\n    y ~ normal(theta, sigma);\n  }\n\"\n\n\nEseguiamo l‚Äôanalisi.\n\nCodicewriteLines(model_string, con = \"code/hmod_3.stan\")\nfile <- file.path(\"code\", \"hmod_3.stan\")\n\nmod <- cmdstan_model(file)\n\nfit3 <- mod$sample(\n  data = school8_dat2,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.6 seconds.\n#> Chain 2 finished in 0.6 seconds.\n#> Chain 3 finished in 0.6 seconds.\n#> Chain 4 finished in 0.6 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.6 seconds.\n#> Total execution time: 2.6 seconds.\n\n\nEsaminiamo la distribuzione a posteriori delle stime dei parametri.\n\nCodiceoutput3_stanfit <- rstan::read_stan_csv(fit3$output_files()) \nplot(output3_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nPer il modello di partial pooling, ad un livello di certezza soggettiva del 95%, le stime a posteriori dei parametri \\(\\theta_j\\) sono comprese in un intervallo pari a circa 40 punti. Si noti che, in relazione al modello no pooling, √® diminuita la nostra incertezza rispetto alle stime dei parametri \\(\\theta_j\\).\n\n32.5.4 Modello gerarchico\nIl modello di partial pooling assume che la dispersione dei parametri \\(\\theta_j\\) sia conosciuta. Ma ovviamente ci√≤ non √® vero. Arriviamo cos√¨ alla formulazione del modello gerarchico nel quale vengono stimati entrambi gli iper-parametri \\(\\mu\\) e \\(\\tau\\), dove \\(\\mu\\) rappresenta l‚Äôeffetto medio del trattamento e \\(\\tau\\) descrive la varianza tra le scuole. Il modello gerarchico √® dunque il seguente.\n\\[\n\\begin{align}\ny_j &\\sim \\mathcal{N}(\\theta_j, \\sigma_j), \\quad j = 1, \\dots, 8\\notag\\\\\n\\theta_j &\\sim \\mathcal{N}(\\mu, \\tau), \\quad j = 1, \\dots, 8\n\\end{align}\n\\]\ndove ciascun \\(\\sigma_j\\) √® considerato noto.\nLo scriviamo in linguaggio Stan nel modo seguente.\n\nCodicemodel_string <- \"\n  data {\n    int<lower=0> J; // # schools\n    array[J] real y; // estimated treatment\n    array[J] real<lower=0> sigma; // std err of effect\n  }\n  parameters {\n    array[J] real theta; // school effect\n    real mu; // mean for schools\n    real<lower=0> tau; // variance between schools\n  }\n  model {\n    mu ~ normal(0, 15);\n    tau ~ cauchy(0, 30);\n    theta ~ normal(mu, tau);\n    y ~ normal(theta, sigma);\n  }\n\"\n\n\nEseguiamo l‚Äôanalisi.\n\nCodicewriteLines(model_string, con = \"code/hmod_4.stan\")\nfile <- file.path(\"code\", \"hmod_4.stan\")\n\nmod <- cmdstan_model(file)\n\nfit4 <- mod$sample(\n  data = school8_dat,\n  iter_sampling = 20000L,\n  iter_warmup = 10000L,\n  seed = 84735,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 1.0 seconds.\n#> Chain 2 finished in 1.3 seconds.\n#> Chain 3 finished in 1.0 seconds.\n#> Chain 4 finished in 1.0 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 1.1 seconds.\n#> Total execution time: 4.6 seconds.\n\n\nLe stime dei parametri sono le seguenti.\n\nCodiceoutput4_stanfit <- rstan::read_stan_csv(fit4$output_files()) \nprint(output4_stanfit, pars = c(\"theta\", \"mu\", \"tau\"), probs = c(.025, .5, .975))\n#> Inference for Stan model: hmod_4-202207010746-1-3850de.\n#> 4 chains, each with iter=30000; warmup=10000; thin=1; \n#> post-warmup draws per chain=20000, total post-warmup draws=80000.\n#> \n#>           mean se_mean   sd   2.5%  50% 97.5% n_eff Rhat\n#> theta[1] 10.23    0.50 7.93  -2.14 9.06 29.52   248 1.02\n#> theta[2]  7.14    0.26 6.05  -4.70 6.98 19.59   536 1.01\n#> theta[3]  5.61    0.12 7.34 -10.90 5.81 19.56  3766 1.00\n#> theta[4]  6.87    0.30 6.29  -5.61 6.78 19.77   439 1.01\n#> theta[5]  4.89    0.11 6.04  -8.37 5.05 16.10  3163 1.00\n#> theta[6]  5.54    0.18 6.46  -8.42 5.61 17.88  1317 1.01\n#> theta[7]  9.49    0.48 6.66  -1.65 8.86 24.66   193 1.03\n#> theta[8]  7.60    0.22 7.35  -6.79 7.24 23.62  1159 1.01\n#> mu        6.94    0.29 4.71  -2.09 6.92 16.43   272 1.02\n#> tau       5.93    0.39 4.85   0.64 4.74 18.11   154 1.03\n#> \n#> Samples were drawn using NUTS(diag_e) at Ven Lug 01 07:46:15 2022.\n#> For each parameter, n_eff is a crude measure of effective sample size,\n#> and Rhat is the potential scale reduction factor on split chains (at \n#> convergence, Rhat=1).\n\n\nVisualizziamo la distribuzione a posteriori delle stime dei parametri e degli iper-parametri.\n\nCodiceplot(output4_stanfit) + xlim(-50, 60)\n\n\n\n\n\n\n\nCon un grado di certezza soggettiva del 95%, le stime a posteriori dei parametri \\(\\theta_j\\) risultano comprese in un intervallo pari a circa 30 punti. Il modello gerarchico, dunque, produce stime degli effetti \\(\\theta_j\\) a cui √® associata l‚Äôincertezza pi√π piccola rispetto a tutti gli altri casi esaminati in precedenza.\n\n32.5.5 Interpretazione\nIn conclusione, il modello gerarchico consente di ottenere stime degli effetti \\(\\theta_j\\) degli otto esperimenti pi√π precise di quelle ottenute dal modelo non gerarchico no-pooling e dal modello gerarchico di partial pooling. Si noti inoltre che, con \\(\\tau \\rightarrow \\infty\\), le stime di un modello gerarchico diventano sempre pi√π simili a quelle di un modello no-pooling, vale a dire, ciascuna delle stime dell‚Äôeffetto del trattamento della scuola diventa via via pi√π indipendente dalle altre stime. Con \\(\\tau \\rightarrow 0\\), le stime di un modello gerarchico diventano sempre pi√π simili alle stime di un modello di pooling completo, vale a dire, tutti gli effetti del trattamento della scuola tendono a diventare via via pi√π simili all‚Äôeffetto medio del gruppo."
  },
  {
    "objectID": "070_mod_hier.html#modelli-lineari-ad-intercetta-casuale",
    "href": "070_mod_hier.html#modelli-lineari-ad-intercetta-casuale",
    "title": "32¬† Modello gerarchico",
    "section": "\n32.6 Modelli lineari ad intercetta casuale",
    "text": "32.6 Modelli lineari ad intercetta casuale\nEsaminiamo ora un modello gerarchico pi√π complesso per l‚Äôanalisi di un set di dati a misure ripetute con due condizioni. I dati sono stati raccolti da (Gibson & Wu, 2013; si veda Sorensen & Vasishth, 2015). La variabile dipendente rt dell‚Äôesperimento di Gibson & Wu (2013) √® il tempo di lettura in millisecondi del soggetto di una proposizione relativa in un testo. I tempi di reazione sono stati registrati in due condizioni: in presenza di un sostantivo riferito al soggetto della proposizione, oppure in presenza di un sostantivo riferito all‚Äôoggetto della proposizione.\nI dati di Gibson & Wu (2013) provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati in un disegno a quadrato latino (ovvero, un disegno nel quale vengono considerate tutte le combinazioni possibili), il che produce 37 \\(\\times\\) 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che porta ad un totale di 555 ‚àí 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito:\n\nCodicerdat <- read.table(here::here(\"data\", \"gibsonwu2012data.txt\"))\nhead(rdat)\n#>    subj item     type pos word correct   rt region            type2\n#> 7     1   13  obj-ext   6 Êäì‰Ωè       - 1140    de1  object relative\n#> 20    1    6 subj-ext   6 Áî∑Â≠©       - 1197    de1 subject relative\n#> 32    1    5  obj-ext   6   Êíû       -  756    de1  object relative\n#> 44    1    9  obj-ext   6 Áõ£Ë¶ñ       -  643    de1  object relative\n#> 60    1   14 subj-ext   6 Ê©üÂ∏´       -  860    de1 subject relative\n#> 73    1    4 subj-ext   6 Áî∑Â≠©       -  868    de1 subject relative\n\n\nLa manipolazione sperimentale viene descritta dalla variabile type (oppure, in maniera equivalente, dalla variabile type2). Nell‚Äôanalisi, type viene ricodificata nella colonna so la quale assume valore -0.5 se il sostantivo era riferito al soggetto e +0.5 se il sostantivo era riferito all‚Äôoggetto della frase.\n\nCodicerdat$so <- ifelse(rdat$type == \"subj-ext\", -0.5, 0.5)\nunique(rdat$so)\n#> [1]  0.5 -0.5\n\n\nCalcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale:\n\nCodicerdat %>% \n  group_by(type2) %>% \n  summarise(\n    avg = exp(mean(log(rt), na.rm = TRUE))\n  )\n#> # A tibble: 2 √ó 2\n#>   type2              avg\n#>   <chr>            <dbl>\n#> 1 object relative   551.\n#> 2 subject relative  589.\n\n\nQuando il sostantivo si riferisce al soggetto, i tempi di reazione sono pi√π lenti di circa 30 ms.\nQuesta descrizione dei dati, per√≤ non tiene conto n√© delle differenze tra i soggetti n√© delle differenze tra gli item. Per tenere in considerazioni queste diverse fonti della variabilit√† dei dati √® necessario utilizzare un modello gerarchico.\n\n32.6.1 Modello ad effetti fissi\nIniziamo con un modello ‚Äúad effetti fissi‚Äù che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c‚Äô√® una covariazione all‚Äôinterno dei cluster definiti dalle variabili ‚Äúsoggetto‚Äù e ‚Äúitem‚Äù.\nIpotizziamo dunque di descrivere i dati mediante il seguente modello di regressione lineare:\n\\[\\begin{equation}\n\\log rt_i = \\beta_0 + \\beta_1 so_i + \\varepsilon_i.\n\\end{equation}\\]\nQuesto √® il caso nel quale usiamo il modello lineare per fare inferenza sulla differenza tra le medie di due gruppi. In precedenza abbiamo codificato i due gruppi con 0 e 1. In tali circostanze \\(\\alpha\\) fornisce una stima del valore atteso della media del gruppo codificato con \\(x = 0\\) e il parametro \\(\\beta\\) fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.\nLa codifica -0.5 e +0.5 per le due modalit√† della variabile so ha un effetto simile. Il parametro \\(\\alpha\\) del modello di regressione lineare fornisce una stima del valore atteso della media di tutti i valori \\(y\\) (trascurando la classificazione in gruppi) mentre, come in precedenza, il parametro \\(\\beta\\) fornisce una stima del valore atteso della differenza tra le medie dei due gruppi.\nI tempi di reazione (variabile dipendente rt, ovvero tempo di lettura) hanno una distribuzione caratterizzata da una forte asimmetria positiva. Se trasformiamo i dati in maniera logaritmica, i dati trasformati si distribuiscono in maniera approssimativamente Normale. In maniera equivalente, si pu√≤ dire che i dati grezzi seguono la distribuzione lognormale.\nIl modello di regressione lineare assume dunque la forma seguente:\n\\[\\begin{equation}\nrt \\sim \\mbox{LogNormal}(\\beta_0 + \\beta_1 so,\\sigma).\n\\end{equation}\\]\nIn tale modello \\(\\beta_0\\) corrisponde al valore atteso della media generale di \\(\\log\\) rt e \\(\\beta_1 so\\) codifica la differenza \\(\\E(\\log rt_{o}) - \\E(\\log rt_{s})\\) quando si passa dalla condizione nella quale il sostantivo √® riferito all‚Äôoggetto alla condizione nella quale il sostantivo √® riferito al soggetto ‚Äì valori negativi significano che i tempi di reazioni sono maggiori nella condizione s che nella condizione o.\nRicordiamo che questo non √® un modello gerarchico, ma un semplice modello di regressione lineare nel quale assumiamo che la componente erratica del modello segua una distribuzione lognormale.\nIn un tale modello useremo le seguenti distribuzioni a priori:\n\\[\\begin{equation}\n\\begin{aligned}\n\\beta[1] &\\sim Normal(6, 1.5) \\\\\n\\beta[2] &\\sim Normal(0, 1.0) \\\\\n\\sigma &\\sim Cauchy(0, 1)\\\\\n\\end{aligned}\n\\end{equation}\\]\n\n\nIn Stan, il modello precedente √® specificato nel modo seguente.\n\nCodicemodelString = \"\n  data {\n    int<lower=1> N; //number of data points\n    array[N] real rt; //reading time\n    array[N] real<lower=-0.5, upper=0.5> so; //predictor\n  }\n  parameters {\n    vector[2] beta; //fixed intercept and slope\n    real<lower=0> sigma_e; //error sd\n  }\n  model {\n    real mu;\n    // likelihood\n    beta[1] ~ normal(6, 1.5);\n    beta[2] ~ normal(0, 1);\n    sigma_e ~ cauchy(0, 1);\n    for (i in 1 : N) {\n      mu = beta[1] + beta[2] * so[i];\n      rt[i] ~ lognormal(mu, sigma_e);\n    }\n  }\n\"\nwriteLines(modelString, con = \"code/fixeff_model.stan\")\n\n\nCompiliamo il modello.\n\nCodicefile <- file.path(\"code\", \"fixeff_model.stan\")\nmod <- cmdstan_model(file)\n\n\nI dati sono contenuti nella lista stan_dat.\n\nCodicestan_dat <- list(\n  rt = rdat$rt,\n  so = rdat$so,\n  N = nrow(rdat)\n)\n\n\nEseguiamo il campionamento MCMC.\n\nCodicefit3 <- mod$sample(\n  data = stan_dat,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nOtteniamo dunque le seguenti medie a posteriori.\n\nCodicefit3$summary()\n#> # A tibble: 4 √ó 10\n#>   variable       mean    median      sd     mad       q5      q95  rhat ess_bulk\n#>   <chr>         <dbl>     <dbl>   <dbl>   <dbl>    <dbl>    <dbl> <dbl>    <dbl>\n#> 1 lp__     -2614.      -2.61e+3 1.22    0.993   -2.62e+3 -2.61e+3  1.00    8108.\n#> 2 beta[1]      6.35     6.34e+0 0.0121  0.0121   6.33e+0  6.37e+0  1.00   16919.\n#> 3 beta[2]     -0.0653  -6.52e-2 0.0241  0.0237  -1.05e-1 -2.52e-2  1.00   15675.\n#> 4 sigma_e      0.629    6.29e-1 0.00850 0.00861  6.15e-1  6.43e-1  1.00   16349.\n#> # ‚Ä¶ with 1 more variable: ess_tail <dbl>\n\n\nTrasformiamo fit3 in un oggetto di classe stanfit.\n\nCodicestanfit <- rstan::read_stan_csv(fit3$output_files())\n\n\nCalcoliamo gli intervalli di credibilit√† al 95%.\n\nCodiceci95 <- rstanarm::posterior_interval(\n  as.matrix(stanfit),\n  prob = 0.95\n)\nround(ci95, 3)\n#>              2.5%     97.5%\n#> beta[1]     6.321     6.369\n#> beta[2]    -0.113    -0.017\n#> sigma_e     0.613     0.646\n#> lp__    -2617.020 -2612.420\n\n\nSe esponenziamo i dati su scala lognormale ritorniamo alla scala dei dati grezzi. L‚Äôeffetto medio, sulla scala in millisecondi, si trova dunque nel modo seguente.\n\nCodicepost <- extract(stanfit, permuted = TRUE)\nexp(mean(post$beta[, 1] + post$beta[, 2])) - exp(mean(post$beta[, 1]))\n#> [1] -35.99588\n\n\nSe ignoriamo la struttura gerarchica dei dati, concludiamo che l‚Äôeffetto della manipolazione sperimentale corrisponde ad una differenza medie nel tempo di lettura nelle due condizioni di 36 ms, con tempi di lettura maggiore quando il sostantivo era riferito al soggetto della proposizione.\n\n32.6.2 Modello gerarchico\nUn modello non gerarchico (detto ad effetti fissi) √® inappropriato per il campione di Gibson & Wu (2013) perch√© non tiene conto del fatto che i dati sono a misure ripetute, ovvero, con pi√π ripetizioni per ogni soggetto e per ogni item. Il modello ad effetti usato sopra viola l‚Äôassunzione di indipendenza degli errori. Inoltre, i coefficienti di effetti fissi \\(\\beta_0\\) e \\(\\beta_1\\) rappresentano le medie calcolate aggregando i dati sulla dimensione dei soggetti e degli item. Cos√¨ facendo, non si tiene in considerazione il fatto che alcuni soggetti sono pi√π veloci e altri pi√π lenti della media, e il fatto che alcuni item sono stati letti pi√π velocemente e altri in maniera pi√π lenta della media. Ovvero, il modello non considera informazioni che sono presenti nei dati.\nUn modello gerarchico, invece, rende conto delle diverse fonti di variabilit√† che derivano da questo disegno sperimentale, ovvero la variabilit√† dovuta alle differenze tra i soggetti e la variabilit√† dovuta alle differenze tra gli item. Per rendere conto di queste fonti di variabilit√† nei dati, vengono aggiunti al modello di regressione lineare due nuovi termini: \\(u_{0j}\\) e \\(w_{0k}\\). Tali termini ‚Äúaggiustano‚Äù \\(\\beta_0\\) in modo tale da stimare una componente specifica della variabile risposta dovuta al soggetto \\(j\\)-esimo e all‚Äôitem \\(k\\)-esimo.\nQuesta formulazione del modello scompone parzialmente la componente d‚Äôerrore \\(\\varepsilon_i\\) nella somma dei termini \\(u_{0j}\\) e \\(w_{0k}\\). Geometricamente, i termini \\(u_{0j}\\) e \\(w_{0k}\\) corrispondono ad aggiustamenti dell‚Äôintercetta \\(\\beta_0\\) che sono specifici per il soggetto \\(j\\)-esimo e per l‚Äôitem \\(k\\)-esimo.\nSe il soggetto \\(j\\)-esimo √® pi√π lento della media di tutti i soggetti, allora il parametro \\(u_j\\) sar√† un numero positivo. Se l‚Äôitem \\(k\\)-esimo viene letto pi√π velocemente del tempo di lettura medio di tutti gli item, allora il parametro \\(w_k\\) sar√† un numero negativo. Viene stimato un aggiustamento \\(u_{0j}\\) per ogni soggetto \\(j\\)-esimo e un aggiustamento \\(w_{0k}\\) per ogni item \\(k\\)-esimo. I parametri \\(u_{0j}\\) e \\(w_{0k}\\) sono chiamati random intercepts o varying intercepts (Gelman et al., 2020). L‚Äôaggiustamento di \\(\\beta_0\\) mediante \\(u_{0j}\\) e \\(w_{0k}\\) consente dunque di tenere in considerazione la struttura gerarchica dei dati, ovvero consente di stimare la quota di variabilit√† dovuta ai soggetti e agli item.\nIl random intercept model assume che gli aggiustamenti \\(u_{0j}\\) e \\(w_{0k}\\) siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta:\n\\[\nu_0 ‚àº \\mathcal{N}(0, \\sigma_u),\n\\]\n\\[\nw_0 ‚àº \\mathcal{N}(0, \\sigma_w).\n\\]\nIl modello include dunque tre fonti di varianza:\n\nla deviazione standard degli errori \\(\\sigma_e\\),\nla deviazione standard delle random intercepts per i soggetti, \\(\\sigma_u\\),\nla deviazione standard delle random intercepts per gli item, \\(\\sigma_w\\).\n\nQueste tre fonti di variabilit√† sono dette componenti della varianza. Possiamo dunque scrivere il modello nel modo seguente:\n\\[\\begin{equation}\n\\log rt_{ijk} = \\beta_0 + \\beta_1 so_i + u_{0j} + w_{0k} + \\varepsilon_{ijk}.\n\\end{equation}\\]\nIl coefficiente \\(\\beta_1\\) √® il parametro di interesse primario. Come conseguenza della codifica usata, avr√† il valore \\(-\\beta_1\\) nella condizione in cui il sostantivo √® riferito al soggetto e \\(+\\beta_1\\) nella condizione in cui il sostantivo √® riferito all‚Äôoggetto della frase.\nIn Stan il modello viene formulato nel modo seguente.\n\nCodicemodelString = \"\n  data {\n    int<lower=1> N; //number of data points\n    array[N] real rt; //reading time\n    array[N] real<lower=-0.5, upper=0.5> so; //predictor\n    int<lower=1> J; //number of subjects\n    int<lower=1> K; //number of items\n    array[N] int<lower=1, upper=J> subj; //subject id\n    array[N] int<lower=1, upper=K> item; //item id\n  }\n  parameters {\n    vector[2] beta; //fixed intercept and slope\n    vector[J] u; //subject intercepts\n    vector[K] w; //item intercepts\n    real<lower=0> sigma_e; //error sd\n    real<lower=0> sigma_u; //subj sd\n    real<lower=0> sigma_w; //item sd\n  }\n  model {\n    real mu;\n    //priors\n    u ~ normal(0, sigma_u); //subj random effects\n    w ~ normal(0, sigma_w); //item random effects\n    // likelihood\n    for (i in 1 : N) {\n      mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i];\n      rt[i] ~ lognormal(mu, sigma_e);\n    }\n  }\n\"\nwriteLines(modelString, con = \"code/random_intercepts_model.stan\")\n\n\nCompiliamo il modello.\n\nCodicefile <- file.path(\"code\", \"random_intercepts_model.stan\")\nmod <- cmdstan_model(file)\n\n\nI dati nel formato appropriato per Stan sono i seguenti.\n\nCodicestan_dat <- list(\n  subj = as.integer(as.factor(rdat$subj)),\n  item = as.integer(as.factor(rdat$item)),\n  rt = rdat$rt,\n  so = rdat$so,\n  N = nrow(rdat),\n  J = length(unique(rdat$subj)),\n  K = length(unique(rdat$item))\n)\n\n\nEseguiamo il campionamento MCMC.\n\nCodicefit4 <- mod$sample(\n  data = stan_dat,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\nTrasformiamo l‚Äôoggetto fit4 in un oggetto di classe stanfit.\n\nCodiceoutput4_stanfit <- rstan::read_stan_csv(fit4$output_files())\n\n\nLe medie a posteriori dei parametri si ottengono nel modo seguente.\n\nCodicefit4$summary(c(\"beta\", \"sigma_e\", \"sigma_w\", \"sigma_u\"))\n#> # A tibble: 5 √ó 10\n#>   variable    mean  median      sd     mad      q5     q95  rhat ess_bulk\n#>   <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>    <dbl>\n#> 1 beta[1]   6.35    6.35   0.0512  0.0511   6.26    6.43    1.00    1413.\n#> 2 beta[2]  -0.0604 -0.0604 0.0220  0.0218  -0.0974 -0.0243  1.00   17390.\n#> 3 sigma_e   0.577   0.577  0.00792 0.00784  0.564   0.590   1.00   17746.\n#> 4 sigma_w   0.120   0.115  0.0291  0.0263   0.0806  0.173   1.00    8584.\n#> 5 sigma_u   0.238   0.235  0.0319  0.0304   0.191   0.293   1.00   11445.\n#> # ‚Ä¶ with 1 more variable: ess_tail <dbl>\n\n\nGli intervalli di credibilit√† al 95% sono i seguenti.\n\nCodiceci95 <- rstanarm::posterior_interval(\n  as.matrix(output4_stanfit),\n  prob = 0.95\n)\nround(ci95, 3)\n#>              2.5%     97.5%\n#> beta[1]     6.247     6.447\n#> beta[2]    -0.104    -0.017\n#> u[1]       -0.208     0.081\n#> u[2]       -0.304    -0.012\n#> u[3]       -0.127     0.163\n#> u[4]       -0.212     0.079\n#> u[5]       -0.079     0.216\n#> u[6]       -0.049     0.239\n#> u[7]       -0.162     0.131\n#> u[8]       -0.124     0.168\n#> u[9]       -0.097     0.196\n#> u[10]      -0.009     0.283\n#> u[11]       0.450     0.745\n#> u[12]       0.149     0.443\n#> u[13]      -0.169     0.123\n#> u[14]      -0.151     0.140\n#> u[15]       0.035     0.324\n#> u[16]      -0.199     0.089\n#> u[17]      -0.716    -0.418\n#> u[18]      -0.417    -0.127\n#> u[19]      -0.295     0.003\n#> u[20]       0.162     0.452\n#> u[21]       0.050     0.341\n#> u[22]       0.123     0.418\n#> u[23]      -0.197     0.096\n#> u[24]      -0.084     0.293\n#> u[25]       0.000     0.292\n#> u[26]      -0.494    -0.203\n#> u[27]      -0.233     0.059\n#> u[28]      -0.332    -0.038\n#> u[29]      -0.423    -0.127\n#> u[30]      -0.406    -0.113\n#> u[31]      -0.100     0.188\n#> u[32]      -0.178     0.113\n#> u[33]      -0.239     0.056\n#> u[34]       0.257     0.554\n#> u[35]      -0.396    -0.104\n#> u[36]      -0.144     0.145\n#> u[37]      -0.171     0.118\n#> w[1]       -0.133     0.061\n#> w[2]       -0.118     0.075\n#> w[3]       -0.101     0.093\n#> w[4]       -0.213    -0.015\n#> w[5]       -0.006     0.190\n#> w[6]       -0.141     0.056\n#> w[7]       -0.281    -0.082\n#> w[8]        0.115     0.315\n#> w[9]       -0.185     0.009\n#> w[10]      -0.041     0.153\n#> w[11]      -0.136     0.058\n#> w[12]      -0.030     0.165\n#> w[13]      -0.176     0.018\n#> w[14]       0.036     0.235\n#> w[15]      -0.041     0.155\n#> sigma_e     0.562     0.593\n#> sigma_u     0.183     0.309\n#> sigma_w     0.076     0.188\n#> lp__    -2332.580 -2311.210\n\n\nSi noti il grande numero di parametri che vengono stimati dal modello gerarchico, anche nel caso del modello a intercette casuali, ovvero, nel caso del modello gerarchico pi√π semplice. Questo esempio fa capire la necessit√† di utilizzare gli algoritmi MCMC: con un numero di parametri da stimare cos√¨ grande √® fuori considerazione l‚Äôidea di stimare i parametri mediante un metodo numerico basato su griglia. Inoltre, nel caso di un modello cos√¨ complesso, una soluzione analitica della distribuzione a posteriori dei parametri non √® disponibile.\nNel caso presente, la stima dell‚Äôeffetto della manipolazione sperimentale ottenuta mediante un modello gerarchico ad intercette random √® molto simile alla stima ottenuta con il modello che analizza i dati aggregati.\n\nCodicepost <- extract(output4_stanfit, permuted = TRUE)\nexp(mean(post$beta[, 1] + post$beta[, 2])) - exp(mean(post$beta[, 1]))\n#> [1] -33.43351\n\n\nL‚Äôintervallo di credibilit√† a posteriori per il modello gerarchico ad intercette random, in questo campione, √® leggermente pi√π piccolo di quello ottenuto mediante l‚Äôanalisi dei dati aggregati.\nSi noti che la varianza trovata con il modello per dati aggregati\n\nCodice0.6291826^2\n#> [1] 0.3958707\n\n\nviene ora decomposta nella somma di tre componenti\n\nCodice0.57721890^2 + 0.11961706^2 + 0.23762983^2\n#> [1] 0.4039578\n\n\nQuindi, il modello gerarchico ci fornisce pi√π informazioni di un‚Äôanalisi basata sui dati aggregati. Per esempio, l‚Äôanalisi presente ci consente di dire che la variabilit√† dei tempi di reazione dovuta alle differenze tra i soggetti √® di entit√† circa doppia rispetto alla variabilit√† attribuibile alle differenze tra gli item."
  },
  {
    "objectID": "070_mod_hier.html#commenti-e-considerazioni-finali",
    "href": "070_mod_hier.html#commenti-e-considerazioni-finali",
    "title": "32¬† Modello gerarchico",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa descrizione dettagliata della soluzione del problema delle otto scuole ha messo in evidenza un aspetto importante che deriva dall‚Äôuso dei modelli gerarchici: in un modello gerarchico, le stime degli effetti (qui chiamate \\(\\theta_j\\), ovvero l‚Äôeffetto del diverso tipo di coaching per ciascuna scuola) assumono valori pi√π simili alla media generale di quanto non lo facciano quando gli effetti \\(\\theta_j\\) vengono stimati da un modello no pooling. Questo fenomeno √® detto effetto shrinkage.\n√à importante considerare due caratteristiche dell‚Äôeffetto shrinkage.\n\nL‚Äôeffetto shrinkage aumenta quando diminuisce il numero di osservazioni in ciascun gruppo \\(j\\)-esimo. Cio√®, ci affidiamo sempre di pi√π alle tendenze globali per stimare le propriet√† di un gruppo per il quale abbiamo pochi dati.\nL‚Äôeffetto shrinkage aumenta quando √® √® grande la variabilit√† all‚Äôinterno dei gruppi, \\(\\sigma_y\\), rispetto alla variabilit√† tra i gruppi, \\(\\sigma_\\mu\\). Cio√®, ci affidiamo sempre di pi√π alle tendenze globali per per stimare le propriet√† di un gruppo quando √® difficile distinguere le propriet√† di un gruppo da quelle di un altro gruppo.\n\nQuesto ci fa capire che, trovando un equilibrio tra pooling completo e no pooling, i modelli gerarchici consentono di:\n\ngeneralizzare le osservazioni sui nostri gruppi campionati alla popolazione pi√π ampia; - prendere in prestito informazioni da tutti i gruppi campionati quando si vogliono conoscere le propriet√† di un singolo gruppo campionato.\n\nLe stime prodotte dai modelli con pooling completo tendono ad avere una distorsione (bias) alta e una varianza piccola; le stime prodotte dai modelli senza pooling tendono ad avere una distorsione bassa e una varianza grande. I modelli gerarchici offrono un equilibrio tra questi due estremi:\n\na differenza dei modelli a pooling completo, i modelli gerarchici tengono conto delle tendenze specifiche dei gruppi e quindi offrono una minore distorsione del fenomeno da descrivere;\na differenza dei modelli no pooling, i modelli gerarchici tengono conto delle tendenze globali e quindi offrono delle stime meno variabili da campione a campione.\n\n\n\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nGibson, E., & Wu, H.-H. I. (2013). Processing chinese relative clauses in context. Language and Cognitive Processes, 28(1-2), 125‚Äì155.\n\n\nRubin, D. B. (1981). Estimation in parallel randomized experiments. Journal of Educational Statistics, 6(4), 377‚Äì401.\n\n\nSorensen, T., & Vasishth, S. (2015). Bayesian linear mixed models using stan: A tutorial for psychologists, linguists, and cognitive scientists. arXiv Preprint arXiv:1506.06201."
  },
  {
    "objectID": "071_mod_hier_sim.html",
    "href": "071_mod_hier_sim.html",
    "title": "33¬† Modello gerarchico: simulazioni",
    "section": "",
    "text": "In questo Capitolo esamineremo nuovamente il modello gerarchico. Per chiarirne meglio il funzionamento useremo delle simulazioni. La discussione che segue √® stata adattata dal seguente blog."
  },
  {
    "objectID": "071_mod_hier_sim.html#modello-generativo-dei-dati",
    "href": "071_mod_hier_sim.html#modello-generativo-dei-dati",
    "title": "33¬† Modello gerarchico: simulazioni",
    "section": "\n33.1 Modello generativo dei dati",
    "text": "33.1 Modello generativo dei dati\nI modelli bayesiani sono ‚Äúgenerativi‚Äù, ovvero rappresentano il processo generativo dei dati e, dunque, essi stessi possono essere usati per generare campioni di dati. Per introdurre questo aspetto, consideriamo il modello pi√π semplice, ovvero il modello Normale descritto in precedenza. Le osservazioni per tale modello corrispondono alle osservazioni di N individui contenuti nel vettore y. Il modello assume che y segua la legge Normale di media mu e deviazione standard sigma.\n\nCodicemodel_string <- \"\n  data {\n    int<lower=1> N;\n    vector[N] y;\n  }\n  parameters {\n    real mu;\n    real<lower=0> tau;\n  }\n  model {\n    mu ~ normal(0, 5);\n    tau ~ normal(0, 5);\n    y ~ normal(mu, tau);\n  }\n\"\n\n\nCompiliamo il modello.\n\nCodicewriteLines(model_string, con = \"code/flat_regression.stan\")\nfile1 <- file.path(\"code\", \"flat_regression.stan\")\nmod1 <- cmdstan_model(file1)\n\n\nFissati i parametri, il modello precedente pu√≤ essere usato per generare campioni di dati. A questo fine dobbiamo specificare solo i blocchi data e generated quantities, come indicato qui sotto. La funzione normal_rng(mu, tau) √® il corrispondente in linguaggio Stan della funzione rnorm() in \\(\\mathsf{R}\\).\n\nCodicemodel2_string <- \"\n  data {\n    int<lower=1> N;\n    real mu; \n    real<lower=0> tau; \n  }\n  generated quantities {\n    vector[N] y;\n    \n    for (n in 1 : N) {\n      y[n] = normal_rng(mu, tau);\n    }\n  }\n\"\n\n\nCompiliamo il modello.\n\nCodicewriteLines(model2_string, con = \"code/generate_flat_data.stan\")\nfile2 <- file.path(\"code\", \"generate_flat_data.stan\")\nmod2 <- cmdstan_model(file2)\n\n\nSpecifichiamo ora i valori dei parametri indicati qui sotto.\n\nCodice# Specify data and parameter values.\nsim_values <- list(\n  N = 100, # Number of observations.\n  mu = 5,  # Mean of the regression.\n  tau = 1  # Variance of the regression.\n)\n\n\nUtilizziamo cmdstan per generare 1,000 campioni di 100 osservazioni ciascuno.\n\nCodicesim_data <- mod2$sample(\n  data = sim_values,\n  chains = 1,\n  seed = 42,\n  fixed_param = TRUE\n)\n#> Running MCMC with 1 chain...\n#> \n#> Chain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \n#> Chain 1 Iteration: 100 / 1000 [ 10%]  (Sampling) \n#> Chain 1 Iteration: 200 / 1000 [ 20%]  (Sampling) \n#> Chain 1 Iteration: 300 / 1000 [ 30%]  (Sampling) \n#> Chain 1 Iteration: 400 / 1000 [ 40%]  (Sampling) \n#> Chain 1 Iteration: 500 / 1000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \n#> Chain 1 finished in 0.0 seconds.\n\n\nRecuperiamo i 1,000 campioni di 100 osservazioni generati dal modello.\n\nCodicesim_data_stanfit <- rstan::read_stan_csv(sim_data$output_files()) \nfake_data_matrix  <- sim_data_stanfit %>% \n  as.data.frame %>% \n  dplyr::select(contains(\"y\"))\n\ndim(fake_data_matrix)\n#> [1] 1000  100\n\n\nRecuperiamo i dati di un singolo campione.\n\nCodicesim_y <- fake_data_matrix[1, ]\nas.numeric(sim_y)\n#>   [1] 4.92727 6.07489 5.62040 5.64771 6.18387 5.49394 4.54341 5.73332 4.88385\n#>  [10] 3.80247 5.53683 3.79003 6.13880 5.10517 4.51741 3.23568 5.47868 5.14018\n#>  [19] 5.93248 3.68679 2.64747 3.96661 6.66431 4.25740 3.80611 5.00020 2.10804\n#>  [28] 3.30112 3.12263 6.68139 4.79380 3.79871 6.56535 4.59639 3.22918 5.69388\n#>  [37] 4.43925 5.20007 5.62791 6.45734 4.99799 5.62754 4.20319 5.11804 4.41627\n#>  [46] 3.76769 4.37040 5.87306 6.33207 6.40474 3.55891 5.80308 5.34626 5.84671\n#>  [55] 3.02968 5.36073 4.66595 4.98986 7.56634 5.09770 5.08534 5.42343 3.78727\n#>  [64] 3.09178 4.05891 5.65567 4.68312 6.45040 5.30334 7.06159 4.11758 5.38201\n#>  [73] 5.30722 4.82675 7.39546 5.18963 2.42694 4.73127 5.86768 4.49791 5.27013\n#>  [82] 3.04167 6.70704 5.44426 4.05945 3.88011 5.88271 5.56971 4.92103 5.62393\n#>  [91] 5.66139 4.77127 3.75681 4.98407 5.41049 6.23022 5.73609 6.35978 4.95185\n#> [100] 4.43508\n\n\nPossiamo ora usare il modello flat_regression.stan per stimare i parametri che abbiamo utilizzato per generare i dati. Sistemiamo i 100 valori simulati in una lista.\n\nCodice# Specify data.\ndata <- list(\n  N = length(sim_y),   # Number of observations.\n  y = as.numeric(sim_y) # Vector of observations.\n)\n\n\nOtteniamo i campioni dalla distribuzione a posteriori dei parametri del modello.\n\nCodicefit <- mod1$sample(\n  data = data,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.1 seconds.\n#> Chain 2 finished in 0.1 seconds.\n#> Chain 3 finished in 0.1 seconds.\n#> Chain 4 finished in 0.1 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.1 seconds.\n#> Total execution time: 0.6 seconds.\n\n\nEsaminiamo le medie a posteriori dei parametri \\(\\mu\\) e \\(\\tau\\).\n\nCodicefit$summary()\n#> # A tibble: 3 √ó 10\n#>   variable   mean median     sd    mad      q5    q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>    <dbl>    <dbl>\n#> 1 lp__     -61.1  -60.8  1.02   0.728  -63.2   -60.2   1.00    7655.    8226.\n#> 2 mu         4.99   4.99 0.114  0.113    4.80    5.17  1.00   12532.   10226.\n#> 3 tau        1.12   1.12 0.0807 0.0795   0.998   1.26  1.00   11652.   10121.\n\n\nLe medie a posteriori sono molto simili al vero valore dei parametri.\nEsaminiamo la convergenza delle catene di Markov.\n\nCodicefit_stanfit <- rstan::read_stan_csv(fit$output_files()) \n\nfit_stanfit %>%\n  mcmc_trace(\n    pars = c(\"mu\", \"tau\"),\n    n_warmup = 2000,\n    facet_args = list(nrow = 2, labeller = label_parsed)\n  )\n\n\n\n\n\n\n\nEsaminiamo graficamente la distribuzioni a posteriori dei parametri.\n\nCodicepar_values <- tibble(\n  .variable = c(\"mu\", \"tau\"),\n  values = c(sim_values$mu, sim_values$tau),\n)\npar_values\n#> # A tibble: 2 √ó 2\n#>   .variable values\n#>   <chr>      <dbl>\n#> 1 mu             5\n#> 2 tau            1\n\n\n\nCodicefit_stanfit %>%\n  gather_draws(mu, tau) %>%\n  ggplot(aes(x = .value, y = .variable)) +\n  geom_halfeyeh(.width = .95) +\n  geom_vline(aes(xintercept = values), par_values, color = \"red\") +\n  facet_wrap(\n    ~ .variable,\n    nrow = 2,\n    scales = \"free\"\n  )\n\n\n\n\n\n\n\nPossiamo concludere che gli intervalli di credibilit√† a posteriori del 95% contengono i veri valori dei parametri (in rosso) che sono stati utilizzati per simulare i dati. In questo modello non gerarchico, dunque, il processo di inferenza bayesiana ottiene il risultato desiderato."
  },
  {
    "objectID": "071_mod_hier_sim.html#modello-gerarchico",
    "href": "071_mod_hier_sim.html#modello-gerarchico",
    "title": "33¬† Modello gerarchico: simulazioni",
    "section": "\n33.2 Modello gerarchico",
    "text": "33.2 Modello gerarchico\nSupponiamo ora che i dati abbiano una struttura complessa, ovvero siano organizzati in cluster (ad esempio, bambini in scuole diverse). In linguaggio Stan il modello gerarchico pu√≤ essere scritto nel modo seguente.\n\nCodicemodel3_string <- \"\n  // Index values and observations.\n  data {\n    int<lower=1> N; // Number of observations.\n    int<lower=1> K; // Number of groups.\n    vector[N] y; // Vector of observations.\n    array[N] int<lower=1, upper=K> g; // Vector of group assignments.\n  }\n  // Parameters and hyperparameters.\n  parameters {\n    real mu; // Mean of the population model.\n    real<lower=0> tau; // Variance of the population model.\n    vector[K] beta; // Vector of group intercepts.\n    real<lower=0> sigma; // Variance of the likelihood.\n  }\n  // Hierarchical regression.\n  model {\n    // Hyperpriors.\n    mu ~ normal(0, 5);\n    tau ~ normal(0, 5);\n    \n    // Prior.\n    sigma ~ normal(0, 5);\n    \n    // Population model and likelihood.\n    beta ~ normal(mu, tau);\n    for (n in 1 : N) {\n      y[n] ~ normal(beta[g[n]], sigma);\n    }\n  }\n\"\n\n\nNel blocco data ora abbiamo un vettore g che indica a quale dei K gruppi appartiene ciascuno degli N individui nel campione. Nel blocco parameters, abbiamo un vettore K-dimensionale di parametri beta che specifica una media separata per ciascuno dei K gruppi di osservazioni. Nel blocco model possiamo vedere che la verosimiglianza delle osservazioni (ora all‚Äôinterno di un ciclo for) √® ancora assunta essere normale, ma ora il punteggio di ogni individuo ha una media diversa e pari a beta che √® specifica per il gruppo a cui l‚Äôindividuo appartiene. Lo statement beta ~ normal(mu, tau) ci dice che i coefficienti beta specifici al gruppo sono tratti da una popolazione che si presume normale con una media mu e deviazione standard tau.\nIl modello specifica dunque una struttura gerarchica: ci sono due livelli nel nostro modello, il modello a livello inferiore specifica la verosimiglianza delle osservazioni, mentre il modello al livello superiore specifica le propriet√† della popolazione. Infine, il modello include le distribuzioni a priori sui parametri della popolazione (formalmente indicati come hyper-priors, poich√© sono le distribuzioni a priori delle distribuzioni a priori). Per gli iper-parametri mu e tau vengono ipotizzate distribuzioni a priori Normali. Infine, alla deviazione standard della verosimiglianza, ora chiamata sigma, viene imposta una distribuzione a priori Normale.\nCome in precedenza, dallo script precedente possiamo derivare un nuovo script che contiene il modello generativo dei dati.\n\nCodicemodel4_string <- \"\n  // Index and hyperparameter values.\n  data {\n    int<lower=1> N; // Number of observations.\n    int<lower=1> K; // Number of groups.\n    array[N] int<lower=1, upper=K> g; // Vector of group assignments.\n    real mu; // Mean of the population model.\n    real<lower=0> tau; // Variance of the population model.\n    real<lower=0> sigma; // Variance of the likelihood.\n  }\n  // Generate data according to the hierarchical regression.\n  generated quantities {\n    vector[N] y; // Vector of observations.\n    vector[K] beta; // Vector of group intercepts.\n    \n    // Draw parameter values and generate data.\n    for (k in 1 : K) {\n      beta[k] = normal_rng(mu, tau);\n    }\n    for (n in 1 : N) {\n      y[n] = normal_rng(beta[g[n]], sigma);\n    }\n  }\n\"\n\n\nSpecifichiamo i valori degli iper-parametri.\n\nCodicesim4_values <- list(\n  N = 100,                            # Number of observations.\n  K = 5,                              # Number of groups.\n  g = sample(5, 100, replace = TRUE), # Vector of group assignments.\n  mu = 5,                             # Mean of the population model.\n  tau = 1,                            # Variance of the population model.\n  sigma = 1                           # Variance of the likelihood.\n)\n\n\nCompiliamo il modello.\n\nCodicewriteLines(model4_string, con = \"code/generate_hierarchical_data_01.stan\")\nfile4 <- file.path(\"code\", \"generate_hierarchical_data_01.stan\")\nmod4 <- cmdstan_model(file4)\n\n\nUtilizziamo cmdstan per generare 1,000 campioni di 100 osservazioni ciascuno.\n\nCodicesim4_data <- mod4$sample(\n  data = sim4_values,\n  chains = 1,\n  fixed_param = TRUE\n)\n#> Running MCMC with 1 chain...\n#> \n#> Chain 1 Iteration:   1 / 1000 [  0%]  (Sampling) \n#> Chain 1 Iteration: 100 / 1000 [ 10%]  (Sampling) \n#> Chain 1 Iteration: 200 / 1000 [ 20%]  (Sampling) \n#> Chain 1 Iteration: 300 / 1000 [ 30%]  (Sampling) \n#> Chain 1 Iteration: 400 / 1000 [ 40%]  (Sampling) \n#> Chain 1 Iteration: 500 / 1000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 600 / 1000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 700 / 1000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 800 / 1000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 900 / 1000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 1000 / 1000 [100%]  (Sampling) \n#> Chain 1 finished in 0.0 seconds.\n\n\nRecuperiamo i 1,000 campioni di 100 osservazioni generati dal modello.\n\nCodicesim4_data_stanfit <- rstan::read_stan_csv(sim4_data$output_files()) \nfake_data4_matrix  <- sim4_data_stanfit %>% \n  as.data.frame %>% \n  dplyr::select(contains(\"y\"))\n\ndim(fake_data4_matrix)\n#> [1] 1000  100\n\n\nSelezioniamo i dati di un singolo campione.\n\nCodicesim4_y <- fake_data4_matrix[1, ]\ndim(sim4_y)\n#> [1]   1 100\n\n\nSeleziono i valori beta.\n\nCodicefake_beta_matrix  <- sim4_data_stanfit %>% \n  as.data.frame %>% \n  dplyr::select(contains(\"beta\"))\n\n\nIsolo i valori beta del primo campione di dati simulati.\n\nCodicesim4_beta <- fake_beta_matrix[1, ]\n\n\nPossiamo ora testare il nostro modello gerarchico utilizzando i dati simulati.\n\nCodicedata3 <- list(\n  N = length(sim4_y),     # Number of observations.\n  K = sim4_values$K,      # Number of groups.\n  y = as.numeric(sim4_y), # Vector of observations.\n  g = sim4_values$g       # Vector of group assignments.\n)\n\n\nOtteniamo i campioni dalla distribuzione a posteriori dei parametri del modello.\n\nCodicewriteLines(model3_string, con = \"code/hierarchical_regression_01.stan\")\nfile3 <- file.path(\"code\", \"hierarchical_regression_01.stan\")\nmod3 <- cmdstan_model(file3)\n\nfit3 <- mod3$sample(\n  data = data3,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  chains = 4L,\n  refresh = 0\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 finished in 0.3 seconds.\n#> Chain 2 finished in 0.3 seconds.\n#> Chain 3 finished in 0.3 seconds.\n#> Chain 4 finished in 0.3 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.3 seconds.\n#> Total execution time: 1.4 seconds.\n\n\nEsaminiamo la convergenza delle catene di Markov.\n\nCodicefit3_stanfit <- rstan::read_stan_csv(fit3$output_files()) \n\nfit3_stanfit %>%\n  mcmc_trace(\n    pars = c(\"mu\", \"tau\", str_c(\"beta[\", 1:data3$K, \"]\"), \"sigma\"),\n    n_warmup = 2000,\n    facet_args = list(nrow = 5, labeller = label_parsed)\n  )\n\n\n\n\n\n\n\nEsaminiamo graficamente la distribuzioni a posteriori dei parametri.\n\nCodice# Recover parameter values.\nhyper_par_values <- tibble(\n  .variable = c(\"mu\", \"tau\", \"sigma\"),\n  values = c(sim4_values$mu, sim4_values$tau, sim4_values$sigma)\n)\n\nfit3_stanfit %>%\n  gather_draws(mu, tau, sigma) %>%\n  ggplot(aes(x = .value, y = .variable)) +\n  geom_halfeyeh(.width = .95) +\n  geom_vline(aes(xintercept = values), hyper_par_values, color = \"red\") +\n  facet_wrap(\n    ~ .variable,\n    nrow = 2,\n    scales = \"free\"\n  )\n\n\n\n\n\n\n\nConsideriamo anche gli intervalli di credibilit√† al 95% per i parametri beta.\n\nCodicebroom.mixed::tidyMCMC(\n  fit3_stanfit, \n  conf.level = 0.95,\n  conf.int = TRUE, \n  conf.method = \"HPDinterval\", \n  pars = c(\"beta\")\n)\n#> # A tibble: 5 √ó 5\n#>   term    estimate std.error conf.low conf.high\n#>   <chr>      <dbl>     <dbl>    <dbl>     <dbl>\n#> 1 beta[1]     4.84     0.211     4.44      5.27\n#> 2 beta[2]     4.35     0.225     3.91      4.78\n#> 3 beta[3]     6.22     0.259     5.72      6.73\n#> 4 beta[4]     5.38     0.263     4.87      5.90\n#> 5 beta[5]     3.15     0.210     2.74      3.56\n\n\nI valori usati nella simulazione sono i seguenti.\n\nCodicesim4_beta\n#>   beta[1] beta[2] beta[3] beta[4] beta[5]\n#> 1 5.00552 4.51655 6.25045 5.08532 3.01116\n\n\nIn conclusione, anche il modello gerarchico √® in grado di recuperare accuratamente il valore dei parametri usati nella simulazione per creare i dati."
  },
  {
    "objectID": "071_mod_hier_sim.html#commenti-e-considerazioni-finali",
    "href": "071_mod_hier_sim.html#commenti-e-considerazioni-finali",
    "title": "33¬† Modello gerarchico: simulazioni",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nI modelli gerarchici forniscono una soluzione che √® una via di mezzo tra l‚Äôassenza di aggregazione delle informazioni (ovvero, modelli non gerarchici separati per ciascun gruppo) e la completa aggregazione delle informazioni (ovvero, modelli che uniscono tutte le osservazioni in un unico campione e non distinguono tra i gruppi). I modelli gerarchici consentono di modellare in modo appropriato le differenze tra gruppi di osservazioni. Data la prevalenza di situazioni di questo tipo in psicologia, i modelli gerarchici dovrebbero rappresentare il punto di partenza nella maggior parte delle analisi dei dati psicologici. Stan consente di svolgere in maniera semplice i calcoli necessari per fare inferenza in situazioni di questo tipo."
  },
  {
    "objectID": "090_entropy.html",
    "href": "090_entropy.html",
    "title": "34¬† Entropia",
    "section": "",
    "text": "Il principio base del metodo scientifico √® la replicabilit√† delle osservazioni: le osservazioni che non possono essere replicate sono poco interessanti. Parallelamente, una caratteristica fondamentale di un modello scientifico √® la generalizzabilit√†: se un modello √® capace di descrivere soltanto le propriet√† di uno specifico campione di osservazioni, allora √® poco utile. Ma come √® possibile valutare la generalizzabilit√† di un modello statistico? Questa √® la domanda a cui cercheremo di rispondere in questa parte della dispensa. In questo Capitolo inizieremo questa discussione introducendo il concetto di entropia."
  },
  {
    "objectID": "090_entropy.html#la-generalizzabilit√†-dei-modelli",
    "href": "090_entropy.html#la-generalizzabilit√†-dei-modelli",
    "title": "34¬† Entropia",
    "section": "\n34.1 La generalizzabilit√† dei modelli",
    "text": "34.1 La generalizzabilit√† dei modelli\nSecondo Johnson et al. (2022), nel valutare un modello, il ricercatore deve porsi tre domande critiche.\n\nQuali conseguenze pi√π ampie derivano dall‚Äôinferenza? Come e chi ha raccolto i dati? Colui che svolge la ricerca otterrebbe di benefici manipolando i dati (escludendo delle osservazioni; selezionando il campione)? Che impatto hanno inferenze che vengono tratte dai dati sugli individui e sulla societ√†? Quali pregiudizi o strutture di potere possono essere coinvolti in questa analisi?\nChe tipo di distorsioni sistematiche potrebbero essere presenti nell‚Äôanalisi statistica? Ricordiamo la famosa citazione di George Box: ‚ÄúTutti i modelli sono sbagliati, ma alcuni sono utili‚Äù. √à dunque importante sapere quanto √® sbagliato il modello. Le assunzioni che stanno alla base del modello sono ragionevoli? Il meccanismo generatore dei dati che √® stato ipotizzato √® adeguato per il fenomeno in esame?\nQuanto √® accurato il modello? Quanto sono lontane dalla realt√† le previsioni del modello?\n\nPer approfondire questi temi, si rinvia al testo di Johnson et al. (2022). Qui ci concentreremo su uno dei temi critici relativa alla validit√† di un modello, ovvero sul tema della generalizzabilit√† del modello.\nNella scienza l‚Äôutilit√† di una teoria viene verificata esaminando la corrispondenza tra predizioni teoriche e osservazioni. Se vi sono discrepanze significative tra predizioni e osservazioni ci√≤ suggerisce che la teoria, o nella nostra visione pi√π ristretta, il modello statistico, √® poco utile. Il problema della capacit√† predittiva del modello non riguarda soltanto l‚Äôadeguatezza del modello in riferimento ad uno specifico campione di dati, ma riguarda anche la capacit√† di un modello statistico sviluppato in un campione di dati di ben adattarsi ad altri campioni della stessa popolazione.\nIn generale, i modelli statistici tendono a non generalizzarsi bene a un nuovo campione; questo perch√© sfruttano le caratteristiche specifiche dei dati del campione e tendono a produrre risultati eccessivamente ottimistici (cio√® le dimensioni dell‚Äôeffetto) che sovrastimano la dimensione dell‚Äôeffetto atteso sia nella popolazione che in nuovi campioni. Bench√© i problemi della generalizzabilit√† dei modelli e il metodo chiave per valutarli ‚Äì ovvero, la convalida incrociata (cross-validation) ‚Äì siano stati discussi sin dagli esordi della letteratura psicometrica (Lord, 1950), tali temi sono stati sottovalutati nella formazione psicologica contemporanea e nella ricerca. Tuttavia, questi concetti diventeranno sempre pi√π importanti considerata l‚Äôenfasi corrente sulla necessit√† di condurre ricerche replicabili. Un‚Äôintroduzione a questi temi √® fornita, da esempio, da Song et al. (2021). Nello specifico, Song et al. (2021) mostrano che un modello che viene adattato a un campione (campione di calibrazione) non si generalizza bene a un altro campione (campione di convalida): la capacit√† predittiva del modello √® minore quando il modello viene applicato al campione di convalida piuttosto che al campione di calibrazione. Questo problema √® detto sovra-adattamento (overfitting). In generale, Song et al. (2021) mostrano come la capacit√† di generalizzazione del modello diminuisce (a) all‚Äôaumentare della complessit√† del modello, (b) al diminuire dell‚Äôampiezza del campione di calibrazione, e (c) al diminuire della dimensione dell‚Äôeffetto nella popolazione.\nSebbene i modelli statistici producono comunemente un sovra-adattamento, √® anche possibile che essi producano un sotto-adattamento (underfitting) dei dati. Tale mancanza di adattamento √® dovuta dalla variabilit√† campionaria e dalla complessit√† del modello. Il sotto-adattamento porta ad un \\(R^2\\) basso e ad un MSE alto, sia nei campioni di calibrazione che in quelli di convalida. Per questo motivo, la scarsa generalizzabilit√† del modello pu√≤ essere dovuta sia al sovra-adattamento che al sotto-adattamento del modello.\nPer aumentarne la capacit√† di generalizzazione del modello devono essere soddisfatte tre condizioni: (a) campioni di calibrazione grandi, (b) dimensioni dell‚Äôeffetto non piccole nella popolazione, e (c) modelli che non siano inutilmente complessi. Tuttavia, nella ricerca psicologica queste tre condizioni sono difficili da soddisfare: l‚Äôaumento della dimensione del campione spesso richiede l‚Äôutilizzo di maggiori risorse, la dimensione di un dato effetto nella popolazione non √® soggetta alla discrezione dei ricercatori e la complessit√† del modello √® spesso guidata da motivazioni teoriche. Pertanto, negli studi psicologici la generalizzabilit√† dei modelli √® spesso problematica. Ci√≤ rende necessario che il ricercatore fornisca informazioni aggiuntive relative alla capacit√† del modello di generalizzarsi a nuovi campioni. L‚Äôobiettivo di questa parte della dispensa √® di descrivere come questo possa essere fatto utilizzando l‚Äôapproccio bayesiano."
  },
  {
    "objectID": "090_entropy.html#capacit√†-predittiva",
    "href": "090_entropy.html#capacit√†-predittiva",
    "title": "34¬† Entropia",
    "section": "\n34.2 Capacit√† predittiva",
    "text": "34.2 Capacit√† predittiva\nNel framework bayesiano il problema della generalizzabilit√† di un modello viene affrontato valutando la capacit√† predittiva del modello, laddove per capacit√† predittiva si intende la capacit√† di un modello, i cui parametri sono stati stimati usando le informazioni di un campione, di ben adattarsi ad un campione di osservazioni future. In questo Capitolo cercheremo di rispondere a tre domande.\n\nQuali criteri consentono di valutare la capacit√† predittiva di un modello?\nCome quantificare la capacit√† predittiva di un modello usando solo un campione di osservazioni?\nCome confrontare le capacit√† predittive di modelli diversi?"
  },
  {
    "objectID": "090_entropy.html#il-rasoio-di-ockham",
    "href": "090_entropy.html#il-rasoio-di-ockham",
    "title": "34¬† Entropia",
    "section": "\n34.3 Il rasoio di Ockham",
    "text": "34.3 Il rasoio di Ockham\nIl problema di scegliere il modello pi√π adatto a spiegare un fenomeno di interesse √® uno dei pi√π importanti problemi in campo scientifico. I ricercatori si chiedono: il modello √® completo? √à necessario aggiungere un nuovo parametro al modello? Come pu√≤ essere migliorato il modello? Se ci sono modelli diversi, qual‚Äô√® il modello migliore?\nPer rispondere a queste domande √® possibile usare il rasoio di Ockham: frustra fit per plura quod potest fieri per pauciora (‚Äúsi fa inutilmente con molte cose ci√≤ che si pu√≤ fare con poche cose‚Äù). Parafrasando la massima si potrebbe dire: se due modelli descrivono i dati egualmente bene, viene sempre preferito il modello pi√π semplice. Questo √® il principio che sta alla base della ricerca scientifica.\nIl rasoio di Ockham, per√≤, non consente sempre di scegliere tra modelli alternativi. Se due modelli fanno le stesse predizioni ma differiscono in termini di complessit√† ‚Äî per esempio, relativamente al numero di parametri di cui sono costituiti ‚Äî allora √® facile decidere: viene preferito il modello pi√π semplice, anche perch√©, pragmaticamente, √® il pi√π facile da usare. Tuttavia, in generale, i modelli differiscono sia per complessit√† (ovvero, per il numero di parametri) che per accuratezza (ovvero, per la grandezza degli errori di predizione). In tali circostanze il rasoio di Ockham non √® sufficiente: non consente infatti di trovare un equilibrio tra accuratezza e semplicit√†.\nIn questo Capitolo ci chiederemo come sia possibile misurare l‚Äôaccuratezza predittiva di un modello. Ci√≤ ci consentir√†, in seguito, di usare il rasoio di Ockham: a parit√† di accuratezza, sar√† possibile scegliere il modello pi√π semplice. Ma nella pratica scientifica non si sacrifica mai l‚Äôaccuratezza per la semplicit√†: il criterio prioritario √® sempre l‚Äôaccuratezza.\n\n34.3.1 Sovra-adattamento e sotto-adattamento\nSecondo McElreath (2020), la selezione tra modelli deve evitare due opposti errori: il sovra-adattamento e il sotto-adattamento. Tale problema va sotto il nome di bias-variance trade-off: il sotto-adattamento, infatti, porta a distorsioni (bias) nella stima dei parametri, mentre il sovra-adattamento porta a previsioni scadenti in campioni futuri. Spesso l‚Äôincertezza relativa alla scelta del modello (sotto-adattamento versus sovra-adattamento) passa inosservata ma il suo impatto pu√≤ essere drammatico. Secondo Hoeting et al. (1999), ‚ÄúStandard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are.\nIn questo Capitolo esamineremo alcune tecniche bayesiane che possono essere utilizzate per operare una selezione tra modelli alternativi, tenendo sotto controllo i pericoli del sovra-adattamento e del sotto-adattamento. In particolare, ci chiederemo quale, tra due o pi√π modelli, sia quello da preferire in base al criterio della capacit√† predittiva.\n\n34.3.2 Stargazing\nNella pratica concreta della ricerca, il metodo pi√π comune per la selezione tra modelli alternativi utilizza i test di ipotesi statistiche di stampo frequentista. Questo metodo viene chiamato stargazing, poich√© richiede soltanto l‚Äôesame degli asterischi (\\(**\\)) che si trovano nell‚Äôoutput di un software statistico (gli asterischi marcano i coefficienti del modello che sono ‚Äústatisticamente significativi‚Äù): alcuni ricercatori ritengono che il modello con pi√π stelline sia anche il modello migliore. Questo per√≤ non √® vero. Al di l√† dei problemi legati ai test dell‚Äôipotesi nulla, √® sicuramente un errore usare i test di significativit√† per la selezione di modelli: i valori-p non consentono di trovare un equilibrio tra underfitting e overfitting. Infatti, le variabili che migliorano la capacit√† predittiva di un modello non sono sempre statisticamente significative; d‚Äôaltra parte, le variabili statisticamente significative non sempre migliorano la capacit√† predittiva di un modello.\nQuando ci chiediamo quale, tra modelli alternativi, √® il modello che meglio rappresenta il ‚Äúvero‚Äù processo di generazione dei dati, ci troviamo di fronte al problema di quantificare il grado di ‚Äúvicinanza‚Äù di un modello al ‚Äúvero‚Äù processo di generazione dei dati. Si noti che, in tale confronto, facciamo riferimento sia alla famiglia distributiva cos√¨ come ai valori dei parametri. Ad esempio, il modello \\(y_i \\sim \\mathcal{N}(5, 3)\\) √® diverso dal modello \\(y_i \\sim \\mathcal{N}(5, 6)\\), ed √® anche diverso dal modello \\(y_i \\sim \\Gamma(2, 2)\\). I primi due modelli appartengono alla stessa famiglia distributiva ma differiscono nei termini dei valori dei parametri; gli ultimi due modelli appartengono a famiglie distributive diverse (gaussiano vs.¬†Gamma). Per misurare il grado di ‚Äúvicinanza‚Äù tra due modelli, \\(\\mathcal{M}_1\\) e \\(\\mathcal{M}_2\\), la metrica di gran lunga pi√π popolare √® la divergenza di Kullback-Leibler. Per chiarire questo concetto √® per√≤ prima necessario introdurre la nozione di entropia."
  },
  {
    "objectID": "090_entropy.html#la-misura-del-disordine",
    "href": "090_entropy.html#la-misura-del-disordine",
    "title": "34¬† Entropia",
    "section": "\n34.4 La misura del disordine",
    "text": "34.4 La misura del disordine\nSe vogliamo ottenere una comprensione intuitiva del concetto di entropia1 possiamo pensare a quant‚Äô√® informativa una distribuzione. Maggiore √® l‚Äôentropia di una distribuzione, meno informativa sar√† quella distribuzione e pi√π uniformemente verranno assegnate le probabilit√† agli eventi. In altri termini, ottenere la risposta di ‚Äú42‚Äù √® pi√π informativo della risposta ‚Äú42 \\(\\pm\\) 5‚Äù, che a sua volta √® pi√π informativo della risposta ‚Äúun numero qualsiasi‚Äù. L‚Äôentropia quantifica questa osservazione qualitativa.\nIl concetto di entropia si applica sia alle distribuzioni continue sia a quelle discrete, ma √® pi√π facile da capire usando le distribuzioni discrete. Negli esempi successivi vedremo alcuni esempi applicati al caso discreto, ma gli stessi concetti si applicano al caso continuo.\n\n34.4.1 Entropia di un singolo evento\nIl concetto di entropia pu√≤ essere usato per descrivere la quantit√† di informazione fornita da un evento. L‚Äôintuizione che sta alla base del concetto di entropia √® che l‚Äôinformazione fornita da un evento descrive la sorpresa suscitata dall‚Äôevento: gli eventi rari (a bassa probabilit√†) sono pi√π sorprendenti ‚Äì e quindi forniscono pi√π informazione ‚Äì degli eventi comuni (ad alta probabilit√†). In altre parole,\n\nun evento a bassa probabilit√† √® sorprendente e fornisce molta informazione;\nun evento ad alta probabilit√† √® poco o per niente sorprendente e fornisce poca (o nessuna) informazione.\n\n√à dunque possibile quantificare l‚Äôinformazione fornita dal verificarsi di un evento usando la probabilit√† di quell‚Äôevento. Una tale quantit√† di informazione √® chiamata ‚Äúinformazione di Shannon‚Äù, ‚Äúauto-informazione‚Äù o semplicemente ‚Äúinformazione‚Äù e, per un evento discreto \\(x\\), pu√≤ essere calcolata come:\n\\[\n\\text{informazione}(x) = -\\log_2 p(x),\n\\]\ndove \\(\\log_2\\) √® il logaritmo in base 2 e \\(p(x)\\) √® la probabilit√† dell‚Äôevento \\(x\\).\nLa scelta del logaritmo in base 2 significa che l‚Äôunit√† di misura dell‚Äôinformazione √® il bit (cifre binarie). Questo pu√≤ essere interpretato dicendo che l‚Äôinformazione misura il numero di bit richiesti per rappresentare un evento.2 Solitamente, si denota la quantit√† di informazione con \\(h()\\):\n\\[\nh(x) = -\\log p(x).\n\\]\nIl segno negativo garantisce che il risultato sia sempre positivo o zero. L‚Äôinformazione √® zero quando la probabilit√† dell‚Äôevento √® 1.0, ovvero quando l‚Äôevento √® certo (assenza di sorpresa).\n\nConsideriamo il lancio di una moneta equilibrata. La probabilit√† di testa (e croce) √® 0.5. La quantit√† di informazione di ottenere ‚Äútesta‚Äù √® dunque\n\nCodice-log2(0.5)\n#> [1] 1\n\n\nPer rappresentare questo evento abbiamo bisogno di 1 bit di informazione. Se la stessa moneta venisse lanciata \\(n\\) volte, la quantit√† di informazione necessaria per rappresentare questo evento (ovvero, questa sequenza di lanci) sarebbe pari a \\(n\\) bit. Se la moneta non √® equilibrata e la probabilit√† di testa √® 0.1, allora l‚Äôevento ‚Äútesta‚Äù √® pi√π raro e richiede pi√π di 3 bit di informazione:\n\nCodice-log2(0.1)\n#> [1] 3.321928\n\n\nConsideriamo ora il lancio di un dado. Quanta informazione viene fornita, ad esempio, dall‚Äôevento ‚Äúesce il numero 6‚Äù? Dato che la probabilit√† di ottenere un 6 nel lancio di un dado √® pi√π piccola della probabilit√† di ottenere ‚Äútesta‚Äù nel lancio di una moneta, il risultato del lancio di un dado deve produrre una sorpresa maggiore del risultato del lancio di una moneta. Per cui, la quantit√† di informazione associata all‚Äôevento ‚Äú√® uscito 6‚Äù, dovr√† essere maggiore di quella associata all‚Äôevento ‚Äútesta‚Äù. Infatti, la quantit√† di informazione dell‚Äôevento ‚Äú√® uscito un 6‚Äù √® pi√π che doppia rispetto alla quantit√† di informazione dell‚Äôevento ‚Äútesta‚Äù:\n\nCodice-log2(1/6)\n#> [1] 2.584963\n\n\n\n\nNella figura successiva viene esaminata la relazione tra probabilit√† e informazione, per valori di probabilit√† nell‚Äôintervallo tra 0 e 1.\n\nCodicep <- seq(0, 1, length.out = 1000)\nh <- -log2(p)\nggplot(tibble(p, h), aes(p, h)) +\n  geom_line() +\n  labs(\n    x = \"Probabilit√†\",\n    y = \"Informazione\"\n  )\n\n\n\n\n\n\n\nLa figura mostra che questa relazione non √® lineare, √® infatti leggermente sublineare. Questo ha senso dato che abbiamo usato una funzione logaritmica.\n\n\n34.4.2 Entropia di una variabile casuale\nPossiamo estendere questa discussione pensando ad un insieme di eventi, ovvero ad una distribuzione. Nella teoria della probabilit√† usiamo la nozione di variabile casuale per fare riferimento ad un insieme di eventi e alle probabilit√† associate a tali eventi. L‚Äôentropia quantifica l‚Äôinformazione che viene fornita da una variabile casuale.\n\nSia \\(Y = y_1, \\dots, y_n\\) una variabile casuale e \\(p_t(y)\\) una distribuzione di probabilit√† su \\(Y\\). Si definisce la sua entropia (detta di Shannon) come:\n\\[\\begin{equation}\nH(Y) = - \\sum_{i=1}^n p_t(y_i) \\cdot \\log_2 p_t(y_i).\n(\\#eq:entropy)\n\\end{equation}\\]\n\nPer interpretare la @ref(eq:entropy), consideriamo un esempio discusso da Martin et al. (2022).\n\n\n\n\nFunzioni di massa di probabilit√† e associata entropia.\n\n\n\n\nNella figura @ref(fig:entropy-example) sono rappresentate sei distribuzioni. viene anche riportato il valore di entropia di ciascuna distribuzione. La distribuzione con il picco pi√π pronunciato o con la dispersione minore √® q, e questa √® la distribuzione con il valore di entropia pi√π basso tra le sei distribuzioni considerate. Per q la distribuzione √® q ~ binom(n = 10, p = 0.75); quindi ci sono 11 possibili eventi. qu ha una distribuzione uniforme sugli stessi 11 possibili eventi. L‚Äôentropia di qu √® maggiore dell‚Äôentropia di q. Infatti, se calcoliamo l‚Äôentropia di distribuzioni binomiali con \\(n = 10\\) (con valori diversi di \\(p\\)) ci rendiamo conto che nessuna di tali distribuzioni ha un‚Äôentropia maggiore di qu. Dobbiamo aumentare \\(n ‚âà 3\\) volte per trovare la prima distribuzione binomiale con entropia maggiore di qu. Passiamo alla riga successiva. Generiamo la distribuzione r spostando a destra q e normalizzando (per garantire che la somma di tutte le probabilit√† sia 1). Poich√© r ha una dispersione maggiore di q, la sua entropia √® maggiore. ru √® una distribuzione uniforme con lo stesso numero di eventi possibili come r (ovvero 22) ‚Äì si noti che sono stati inclusi come valori possibili anche quelli nella ‚Äúvalle‚Äù tra i due picchi. Ancora una volta, la distribuzione uniforme ha l‚Äôentropia pi√π grande.\nGli esempi discussi finora sembrano suggerire che l‚Äôentropia √® proporzionale alla varianza della distribuzione. Verifichiamo questa intuizione esaminiamo le ultime due distribuzioni della figura @ref(fig:entropy-example). La distribuzione s √® simile a r ma presenta una separazione maggiore tra i due picchi della distribuzione ‚Äì dunque, ha una varianza pi√π grande. Ci√≤ nonostante, l‚Äôentropia non varia. Quindi la relazione tra entropia e varianza non √® cos√¨ semplice come ci sembrava. Il risultato che abbiamo trovato pu√≤ essere spiegato dicendo che, nel calcolo dell‚Äôentropia, non vengono considerati gli eventi con probabilit√† nulla (per questa ragione, nell‚Äôesempio, √® stato possibile aumentare la varianza senza cambiare l‚Äôentropia). La distribuzione su √® stata costruita sostituendo i due picchi in s con qu (e normalizzando). Possiamo vedere che su ha un‚Äôentropia minore di ru, anche se su ha una dispersione maggiore di ru. Questo √® dovuto al fatto che su distribuisce la probabilit√† totale tra un numero minore di eventi (22) di ru (che ne conta 23); quindi √® sensato attribuire a su un‚Äôentropia minore di ru.\n\nConsideriamo ora un esempio riguardante le previsioni del tempo. Supponiamo che le probabilit√† di pioggia e sole siano, rispettivamente, \\(p_1 = 0.3\\) e \\(p_2 = 0.7\\). Quindi\n\\[\nH(p) = ‚àí [p(y_1) \\log_2 p(y_1) + p(y_2) \\log_2 p(y_2)] \\approx 0.61.\n\\]\nSe per√≤ viviamo a Las Vegas, allora le probabilit√† di pioggia e sole saranno simili a \\(p(y_1) = 0.01\\) e \\(p(y_2) = 0.99\\). In questo secondo caso, l‚Äôentropia √® 0.06, ovvero, molto minore di prima. Infatti, a Las Vegas non piove quasi mai, per cui quando abbiamo imparato che, in un certo giorno, non ha piovuto, abbiamo imparato molto poco rispetto a quello che gi√† sapevamo in precedenza.\n\n\nNell‚Äôesempio precedente abbiamo visto che, se gli esiti possibili sono pioggia o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.3\\), allora l‚Äôentropia √®\n\nCodice-(0.7 * log(0.7) + 0.3 * log(0.3))\n#> [1] 0.6108643\n\n\nMa se gli esiti possibili sono pioggia, neve o sole con \\(p(y_1) = 0.7\\), \\(p(y_2) = 0.15\\) e \\(p(y_3) = 0.15\\), rispettivamente, allora l‚Äôentropia cresce:\n\nCodice-(0.7 * log(0.7) + 0.15 * log(0.15) + 0.15 * log(0.15))\n#> [1] 0.8188085"
  },
  {
    "objectID": "090_entropy.html#commenti-e-considerazioni-finali",
    "href": "090_entropy.html#commenti-e-considerazioni-finali",
    "title": "34¬† Entropia",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo Capitolo abbiamo visto come sia possibile quantificare l‚Äôincertezza tramite l‚Äôentropia. Ma come √® possibile usare l‚Äôentropia dell‚Äôinformazione per specificare la ‚Äúdistanza‚Äù tra un modello e il vero meccanismo generatore dei dati? La risposta a questa domanda √® fornita dalla divergenza di Kullback-Leibler che verr√† discussa nel Capitolo @ref(ch:kl-div).\n\n\n\n\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T. (1999). Bayesian model averaging: A tutorial (with comments by m. Clyde, david draper and EI george, and a rejoinder by the authors. Statistical Science, 14(4), 382‚Äì417.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with R. CRC Press.\n\n\nLord, F. M. (1950). Efficiency of prediction when a regression equation from one sample is used in a new sample. ETS Research Bulletin Series, 1950(2), 1‚Äì6.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian modeling and computation in python. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nSong, Q. C., Tang, C., & Wee, S. (2021). Making sense of model generalizability: A tutorial on cross-validation in r and shiny. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920947067."
  },
  {
    "objectID": "091_kl.html",
    "href": "091_kl.html",
    "title": "35¬† La divergenza di Kullback-Leibler",
    "section": "",
    "text": "√à comune in statistica utilizzare una distribuzione di probabilit√† \\(q\\) per approssimare un‚Äôaltra distribuzione \\(p\\) ‚Äì generalmente, questo viene fatto se \\(p\\) non √® conosciuta o √® troppo complessa. In questi casi possiamo chiederci quanta informazione venga perduta usando \\(q\\) al posto di \\(p\\), o equivalentemente, quanta incertezza aggiuntiva viene introdotta nell‚Äôanalisi statistica. La quantificazione di questo incremento di incertezza √® fornita dalla divergenza di Kullback-Leibler."
  },
  {
    "objectID": "091_kl.html#la-perdita-di-informazione",
    "href": "091_kl.html#la-perdita-di-informazione",
    "title": "35¬† La divergenza di Kullback-Leibler",
    "section": "\n35.1 La perdita di informazione",
    "text": "35.1 La perdita di informazione\nIntuitivamente, per quantificare l‚Äôinformazione che si perde quando una distribuzione approssimata \\(q\\) viene usata in luogo della distribuzione corretta \\(p\\) sembra necessaria una quantit√† che ha valore zero quando \\(q = p\\), e un valore positivo altrimenti. Seguendo la definizione @ref(eq:entropy) di entropia, possiamo quantificare una tale perdita di informazione mediante il valore atteso della differenza tra \\(\\log(p)\\) e \\(\\log(q)\\). Questa quantit√† √® chiamata entropia relativa o divergenza di Kullback-Leibler:\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\mathbb{E} (\\log p - \\log q).\n(\\#eq:kldivergence)\n\\end{equation}\\]\nLa divergenza \\(\\mathbb{KL} (p \\mid\\mid q)\\) corrisponde alla differenza media nelle probabilit√† logaritmiche quando \\(q\\) viene usato per approssimare \\(p\\). Poich√© gli eventi si manifestano secondo \\(p\\), √® necessario calcolare il valore atteso rispetto a \\(p\\). Per distribuzioni discrete dunque abbiamo:\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\sum_i^n p_i (\\log p_i - \\log q_i) = \\sum_i^n p_i \\log \\frac{p_i}{q_i}.\n\\end{equation}\\]\nRiarrangiando i termini otteniamo:\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = -\\sum_i^n p_i (\\log q_i - \\log p_i),\n\\end{equation}\\]\novvero,\n\\[\\begin{equation}\n\\mathbb{KL} (p \\mid\\mid q) = \\underbrace{-\\sum_i^n p_i \\log q_i}_{h(p, q)} - \\underbrace{\\left(-\\sum_i^n p_i \\log p_i\\right)}_{h(p)},\n\\end{equation}\\]\nladdove \\(h(p)\\) √® l‚Äôentropia di \\(p\\) e \\(h(p, q) = ‚àí \\mathbb{E} [\\log q]\\) pu√≤ essere intesa come l‚Äôentropia di \\(q\\), ma valutata secondo i valori di probabilit√† \\(p\\).\nRiarrangiando l‚Äôequazione precedente otteniamo:\n\\[\\begin{equation}\nh(p, q) = h(p) + \\mathbb{KL} (p \\mid\\mid q),\n\\end{equation}\\]\nil che mostra come la divergenza \\(\\mathbb{KL}\\) possa essere interpretata come l‚Äôincremento di entropia, rispetto a \\(h(p)\\), quando \\(q\\) viene usata per rappresentare \\(p\\).\n\n(da McElreath, 2020) Sia la distribuzione target \\(p = \\{0.3, 0.7\\}\\). Supponiamo che la distribuzione approssimata \\(q\\) possa assumere valori da \\(q = \\{0.01, 0.99\\}\\) a \\(q = \\{0.99, 0.01\\}\\). Calcoliamo la divergenza KL.\nLe istruzioni \\(\\mathsf{R}\\) sono le seguenti:\n\nCodicet <-\n  tibble(\n    p_1 = .3,\n    p_2 = .7,\n    q_1 = seq(from = .01, to = .99, by = .01)\n  ) %>%\n  mutate(\n    q_2 = 1 - q_1\n  ) %>%\n  mutate(\n    d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2))\n  )\n\nhead(t)\n#> # A tibble: 6 √ó 5\n#>     p_1   p_2   q_1   q_2  d_kl\n#>   <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1   0.3   0.7  0.01  0.99 0.778\n#> 2   0.3   0.7  0.02  0.98 0.577\n#> 3   0.3   0.7  0.03  0.97 0.462\n#> 4   0.3   0.7  0.04  0.96 0.383\n#> 5   0.3   0.7  0.05  0.95 0.324\n#> 6   0.3   0.7  0.06  0.94 0.276\n\n\nNella figura seguente sull‚Äôasse delle ascisse sono rappresentati i valori \\(q\\) e sull‚Äôasse delle ordinante sono riportati i corrispondenti valori \\(\\mathbb{KL}\\).\n\nCodicet %>%\n  ggplot(aes(x = q_1, y = d_kl)) +\n  geom_vline(xintercept = .3, linetype = 2) +\n  geom_line(size = 1) +\n  annotate(geom = \"text\", x = .4, y = 1.5, label = \"q = p\",\n           size = 3.5) +\n  labs(x = \"q[1]\",\n       y = \"Divergenza di q da p\")\n\n\n\n\n\n\n\nTanto meglio la distribuzione \\(q\\) approssima la distribuzione target tanto pi√π piccolo √® il valore di divergenza \\(\\mathbb{KL}\\).\n\n\nSia \\(p\\) una distribuzione binomiale di parametri \\(\\theta = 0.2\\) e \\(n = 5\\)\n\nCodicen <- 4\np <- 0.2\ntrue_py <- dbinom(0:n, n, 0.2)\ntrue_py\n#> [1] 0.4096 0.4096 0.1536 0.0256 0.0016\n\n\nSia \\(q_1\\) una approssimazione a \\(p\\):\n\nCodiceq1 <- c(0.46, 0.42, 0.10, 0.01, 0.01)\nq1\n#> [1] 0.46 0.42 0.10 0.01 0.01\n\n\nSia \\(q_2\\) una distribuzione uniforme:\n\nCodiceq2 <- rep(0.2, 5)\nq2\n#> [1] 0.2 0.2 0.2 0.2 0.2\n\n\nLa divergenza \\(\\mathbb{KL}\\) di \\(q_1\\) da \\(p\\) √®\n\nCodicesum(true_py * log(true_py / q1))\n#> [1] 0.02925199\n\n\nLa divergenza \\(\\mathbb{KL}\\) di \\(q_2\\) da \\(p\\) √®:\n\nCodicesum(true_py * log(true_py / q2))\n#> [1] 0.4863578\n\n\n√à chiaro che perdiamo una quantit√† maggiore di informazioni se, per descrivere la distribuzione binomiale \\(p\\), usiamo la distribuzione uniforme \\(q_2\\) anzich√© \\(q_1\\)."
  },
  {
    "objectID": "091_kl.html#la-divergenza-dipende-dalla-direzione",
    "href": "091_kl.html#la-divergenza-dipende-dalla-direzione",
    "title": "35¬† La divergenza di Kullback-Leibler",
    "section": "\n35.2 La divergenza dipende dalla direzione",
    "text": "35.2 La divergenza dipende dalla direzione\nLa divergenza \\(\\mathbb{KL}\\) non √® una vera e propria metrica: per esempio, non √® simmetrica. In generale, \\(\\mathbb{KL}(p \\mid\\mid q) \\neq \\mathbb{KL}(q \\mid\\mid p)\\), ovvero la \\(\\mathbb{KL}\\) da \\(p\\) a \\(q\\) √® diversa dalla \\(\\mathbb{KL}\\) da \\(q\\) a \\(p\\).\n\nUsando le seguenti istruzioni \\(\\mathsf{R}\\) otteniamo:\n\nCodicetibble(direction = c(\"Da q a p\", \"Da p a q\"),\n       p_1 = c(.01, .7),\n       q_1 = c(.7, .01)) %>%\n  mutate(p_2 = 1 - p_1,\n         q_2 = 1 - q_1) %>%\n  mutate(d_kl = (p_1 * log(p_1 / q_1)) + (p_2 * log(p_2 / q_2)))\n#> # A tibble: 2 √ó 6\n#>   direction   p_1   q_1   p_2   q_2  d_kl\n#>   <chr>     <dbl> <dbl> <dbl> <dbl> <dbl>\n#> 1 Da q a p   0.01  0.7   0.99  0.3   1.14\n#> 2 Da p a q   0.7   0.01  0.3   0.99  2.62"
  },
  {
    "objectID": "091_kl.html#confronto-tra-modelli",
    "href": "091_kl.html#confronto-tra-modelli",
    "title": "35¬† La divergenza di Kullback-Leibler",
    "section": "\n35.3 Confronto tra modelli",
    "text": "35.3 Confronto tra modelli\nLa divergenza \\(\\mathbb{KL}\\) viene utilizzata nel confronto tra modelli, ovvero ci consente di quantificare l‚Äôinformazione che viene perduta quando utilizziamo la distribuzione di probabilit√† ipotizzata da un modello, chiamiamola \\(p_{\\mathcal{M}}\\), per approssimare la distribuzione di probabilit√† del vero modello generatore dei dati, \\(p_t\\).\nIn precedenza abbiamo introdotto il concetto di distribuzione predittiva a posteriori:\n\\[\np(\\tilde{y} \\mid y) = \\int_\\Theta p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta .\n\\]\nLa distribuzione predittiva a posteriori descrive il tipo di dati che ci aspettiamo vengano prodotti dal modello generativo \\(\\mathcal{M}\\), alla luce delle nostre credenze iniziali, \\(p(\\theta)\\) e dei dati osservati \\(y\\). Quando valutiamo un modello ci chiediamo in che misura \\(p_{\\mathcal{M}}(\\tilde{y} \\mid y)\\) approssimi \\(p_t(\\tilde{y})\\). Cio√®, ci chiediamo quanto siano simili i dati \\(p_{\\mathcal{M}}(\\cdot)\\) prodotti dal modello \\(\\mathcal{M}\\) ai dati prodotti dal vero processo generatore dei dati \\(p_t(\\cdot)\\).\nUna misura della ‚Äúsomiglianza‚Äù tra la distribuzione \\(q_{\\mathcal{M}}\\) ipotizzata dal modello \\(\\mathcal{M}\\) e la distribuzione \\(p_t\\) del vero modello generatore dei dati √® fornita dalla divergenza di Kullback-Leibler \\(\\mathbb{KL}(p_t \\mid\\mid q_{\\mathcal{M}})\\). Supponendo di avere \\(k\\) modelli della distribuzione a posteriori, \\(\\{q_{\\mathcal{M}_1}, q_{\\mathcal{M}_2}, \\dots, q_{\\mathcal{M}_k}\\}\\), e di conoscere il vero modello generatore dei dati, possiamo scrivere\n\\[\\begin{align}\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_1}) &= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_1})\\notag\\\\\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_2}) &= \\mathbb{E} (\\log p_t) - \\E (\\log q_{\\mathcal{M}_2})\\notag\\\\\n&\\cdots\\notag\\\\\n\\mathbb{KL} (p_t \\mid\\mid q_{\\mathcal{M}_k}) &= \\mathbb{E} (\\log p_{\\mathcal{M}_0}) - \\mathbb{E} (\\log q_{\\mathcal{M}_k}).\n(\\#eq:kl-mod-comp)\n\\end{align}\\]\nLa @ref(eq:kl-mod-comp) pu√≤ sembrare un esercizio futile poich√© nella vita reale non conosciamo il vero modello generatore dei dati. √à per√≤ facile rendersi conto che, poich√© \\(p_t\\) √® la stessa per tutti i confronti, diventa possibile costruire un ordinamento dei modelli basato unicamente sul secondo termine della @ref(eq:kl-mod-comp), ovvero senza nessun riferimento al vero modello generatore dei dati. Per un generico modello \\(\\mathcal{M}\\), il secondo termine della @ref(eq:kl-mod-comp) pu√≤ essere scritto come:\n\\[\\begin{equation}\n\\mathbb{E} \\log p_{\\mathcal{M}}(y) = \\int_{-\\infty}^{+\\infty}p_{t}(y)\\log p_{\\mathcal{M}}(y) \\,\\operatorname {d}\\!y .\n(\\#eq:kl-div-cont-t2)\n\\end{equation}\\]"
  },
  {
    "objectID": "091_kl.html#expected-log-predictive-density",
    "href": "091_kl.html#expected-log-predictive-density",
    "title": "35¬† La divergenza di Kullback-Leibler",
    "section": "\n35.4 Expected log predictive density",
    "text": "35.4 Expected log predictive density\nLe previsioni del modello \\(\\mathcal{M}\\) sui nuovi dati futuri sono date dalla distribuzione predittiva a posteriori. Possiamo dunque riscrivere la @ref(eq:kl-div-cont-t2) come\n\\[\\begin{equation}\n\\mbox{elpd} = \\int_{\\tilde{y}} p_{t}(\\tilde{y}) \\log p(\\tilde{y} \\mid y) \\,\\operatorname {d}\\!\\tilde{y}.\n(\\#eq:elpd)\n\\end{equation}\\]\nLa @ref(eq:elpd) √® chiamata expected log predictive density (\\(\\mbox{elpd}\\)) e fornisce la risposta al problema che ci eravamo posti: nel confronto tra modelli, come √® possibile scegliere il modello pi√π simile al vero meccanismo generatore dei dati? Possiamo pensare alla @ref(eq:elpd) dicendo che descrive la distribuzione predittiva a posteriori del modello ponderando la verosimiglianza dei possibili (sconosciuti) dati futuri (\\(\\tilde{y}\\)) con la vera distribuzione \\(p_t\\). Di conseguenza, valori \\(\\mbox{elpd}\\) pi√π grandi identificano il modello che risulta pi√π simile al vero meccanismo generatore dei dati.\nNon dobbiamo preoccuparci di trovare una formulazione analitica della distribuzione predittiva a posteriori \\(p(\\tilde{y} \\mid y)\\) perch√© √® possibile approssimare tale distribuzione mediante simulazione. Notiamo per√≤ che la @ref(eq:elpd) include un termine, \\(p_t(\\tilde{y})\\), il quale descrive la distribuzione dei dati futuri \\(\\tilde{y}\\) secondo il vero modello generatore dei dati. Il termine \\(p_t\\), ovviamente, √® ignoto.1 Di conseguenza, la quantit√† \\(\\mbox{elpd}\\) non pu√≤ mai essere calcolata in maniera esatta, ma pu√≤ solo essere stimata. Il secondo problema di questo Capitolo √® capire come la @ref(eq:elpd) possa essere stimata utilizzando un campione di osservazioni.\n\n35.4.1 Log pointwise predictive density\nIngenuamente, potremmo pensare di stimare la @ref(eq:elpd) ipotizzando che la distribuzione del campione coincida con \\(p_t\\). Usare la distribuzione del campione come proxy del vero modello generatore dei dati (ovvero, ipotizzare che la distribuzione del campione rappresenti fedelmente \\(p_t\\)) comporta due conseguenze:\n\nnon √® necessario ponderare per \\(p_t\\), in quanto assumiamo che la distribuzione empirica del campione corrisponda a \\(p_t\\) (ci√≤ significa assumere che i valori pi√π comunemente osservati nel campione siano anche quelli pi√π verosimili nella vera distribuzione \\(p_t\\));\ndato che il campione √® finito, anzich√© eseguire un‚Äôoperazione di integrazione possiamo semplicemente sommare la densit√† predittiva a posteriori delle osservazioni.\n\nQuesto conduce alla seguente equazione:2\n\\[\\begin{equation}\n\\frac{1}{n} \\sum_{i=1}^n \\log p(y_i^{rep} \\mid y).\n(\\#eq:1n-lppd)\n\\end{equation}\\]\nLa quantit√† @ref(eq:1n-lppd), senza il passaggio finale della divisione per il numero di osservazioni, √® chiamata log pointwise predictive density (\\(\\mbox{lppd}\\))\n\\[\\begin{equation}\n\\mbox{lppd} = \\sum_{i=1}^n \\log p(y_i^{rep} \\mid y)\n(\\#eq:lppd)\n\\end{equation}\\]\ne corrisponde alla somma delle densit√† predittive logaritmiche delle \\(n\\) osservazioni. Valori pi√π grandi della @ref(eq:lppd) sono da preferire perch√© indicano una maggiore accuratezza media. √à anche comune vedere espressa la quantit√† precedente nei termini della devianza, ovvero alla \\(\\mbox{lppd}\\) moltiplicata per -2. In questo secondo caso sono da preferire valori piccoli.\n√à importante notare che \\(\\lppd\\) fornisce una sovrastima della @ref(eq:elpd). Tale sovrastima √® dovuta al fatto che, nel calcolo della @ref(eq:lppd), abbiamo usato \\(p(y^{rep} \\mid y)\\) al posto di \\(p(\\tilde{y} \\mid y)\\): in altri termini, abbiamo considerato le osservazioni del campione come se fossero un nuovo campione di dati. In una serie di simulazioni, McElreath (2020) esamina il significato di questa sovrastima. Nelle simulazioni la devianza viene calcolata come funzione della complessit√† (ovvero, il numero di parametri) del modello. La simulazione mostra che \\(\\mbox{lppd}\\) aumenta al crescere del numero di parametri del modello. Ci√≤ significa che \\(\\mbox{lppd}\\) mostra lo stesso limite del coefficiente di determinazione: aumenta all‚Äôaumentare della complessit√† del modello.\n\nEsaminiamo un esempio tratto da Bayesian Data Analysis for Cognitive Science nel quale la \\(\\mbox{lppd}\\) viene calcolata in forma esatta oppure mediante approssimazione. Supponiamo di disporre di un campione di \\(n\\) osservazioni. Supponiamo inoltre di conoscere il vero processo generativo dei dati (qualcosa che in pratica non √® mai possibile), ovvero:\n\\[\np_t(y) = \\mbox{Beta}(1, 3).\n\\] I dati sono\n\nCodiceset.seed(75)\nn <- 10000\ny_data <- rbeta(n, 1, 3)\nhead(y_data)\n#> [1] 0.55062422 0.13346270 0.80250987 0.21430898 0.01913430 0.08676517\n\n\nSupponiamo inoltre di avere adattato ai dati un modello bayesiano \\(\\mathcal{M}\\) e di avere ottenuto la distribuzione a posteriori per i parametri del modello. Inoltre, supponiamo di avere derivato la forma analitica della distribuzione predittiva a posteriori per il modello:\n\\[\np(y^{rep} \\mid y) \\sim \\mbox{Beta}(2, 2).\n\\]\nQuesta distribuzione ci dice quanto sono credibili i possibili dati futuri.\nConoscendo la vera distribuzione dei dati \\(p_t(y)\\) possiamo calcolare in forma esatta la quantit√† \\(\\mbox{elpd}\\), ovvero\n\\[\n\\mbox{elpd} = \\int_{y^{rep}}p_{t}(y^{rep})\\log p(y^{rep} \\mid y) \\,\\operatorname {d}\\!y^{rep}.\n\\]\nSvolgiamo i calcoli in \\(\\mathsf{R}\\) otteniamo:\n\nCodice# True distribution\np_t <- function(y) dbeta(y, 1, 3)\n# Predictive distribution\np <- function(y) dbeta(y, 2, 2)\n# Integration\nintegrand <- function(y) p_t(y) * log(p(y))\nintegrate(f = integrand, lower = 0, upper = 1)\n#> -0.3749072 with absolute error < 6.8e-07\n\n\nTuttavia, in pratica non conosciamo mai \\(p_t(y)\\). Quindi approssimiamo \\(\\mbox{elpd}\\) usando la @ref(eq:elpd):\n\\[\n\\frac{1}{n} \\sum_{i=1}^n \\log p(y_i \\mid y).\n\\]\nCos√¨ facendo, e svolgendo i calcoli in \\(\\mathsf{R}\\), otteniamo un valore diverso da quello trovato in precedenza:\n\nCodice1/n * sum(log(p(y_data)))\n#> [1] -0.3639141"
  },
  {
    "objectID": "091_kl.html#commenti-e-considerazioni-finali",
    "href": "091_kl.html#commenti-e-considerazioni-finali",
    "title": "35¬† La divergenza di Kullback-Leibler",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nDato che non conosciamo il vero meccanismo generatore dei dati \\(p\\), possiamo usare la distribuzione dei dati osservata come proxy per la vera distribuzione \\(p\\). Quindi, invece di ponderare la distribuzione predittiva in base alla densit√† reale di tutti i possibili dati futuri, utilizziamo semplicemente le \\(n\\) osservazioni che abbiamo. Possiamo farlo perch√© assumiamo che le nostre osservazioni costituiscano un campione dalla vera distribuzione dei dati: in base a questa ipotesi, nel campione ci aspettiamo di osservare pi√π frequentemente quelle osservazioni che hanno una maggiore verosimiglianza nella vera distribuzione \\(p\\). √à cos√¨ possibile giungere ad una stima numerica della \\(\\mbox{elpd}\\) chiamata log pointwise predictive density (\\(\\mbox{lppd}\\)).\n\n\n\n\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for bayesian models. Statistics and Computing, 24(6), 997‚Äì1016.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press."
  },
  {
    "objectID": "092_info_criterion.html",
    "href": "092_info_criterion.html",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "",
    "text": "Nel Capitolo precedente abbiamo visto che la @ref(eq:lppd) fornisce una sovrastima della \\(\\mbox{elpd}\\). Il modo migliore per stimare \\(\\mbox{elpd}\\) √® raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare \\(\\mbox{elpd}\\) sul nuovo campione. Questa procedura √® chiamata out-of-sample validation. Il problema, per√≤, √® che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo a punto vari metodi per evitare la sovrastima della \\(\\mbox{elpd}\\) che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali:\nLo scopo del presente Capitolo √® di fornire una breve introduzione ai criteri dell‚Äôinformazione e alla procedura della convalida incrociata."
  },
  {
    "objectID": "092_info_criterion.html#aic-dic-e-waic",
    "href": "092_info_criterion.html#aic-dic-e-waic",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "\n36.1 AIC, DIC e WAIC",
    "text": "36.1 AIC, DIC e WAIC\nAllo scopo di evitare la sovrastima della @ref(eq:lppd), le statistiche Akaike Information Criterion (AIC), Deviance Information Criterion (DIC) e Widely Applicable Information Criterion (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono pi√π complesse di AIC, ma producono un‚Äôapprossimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica pi√π semplice, ovvero AIC.\n\n36.1.1 Criterio d‚Äôinformazione di Akaike\nIl criterio d‚Äôinformazione di Akaike (in inglese Akaike information criterion, indicato come AIC) fornisce un metodo molto semplice per approssimare \\(\\mbox{elpd}\\).\n\nIl criterio d‚Äôinformazione di Akaike √® definito come\n\\[\\begin{equation}\nAIC = -2 \\log p(y \\mid \\hat{\\theta}_{MLE}) + 2k,\n\\end{equation}\\]\ndove \\(k\\) √® il numero di parametri stimati nel modello e \\(p(y \\mid \\hat{\\theta}_{MLE})\\) √® il valore massimizzato della funzione di verosimiglianza del modello stimato.\n\nDividendo per -2, otteniamo \\(\\mbox{elpd}_{AIC}\\):\n\\[\\begin{equation}\n\\widehat{\\mbox{elpd}}_{AIC} = \\log p(y \\mid \\hat{\\theta}_{MLE}) - k,\n\\end{equation}\\]\ndove \\(k\\) √® il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza.\nAIC √® di interesse principalmente storico e produce una approssimazione attendibile di \\(\\mbox{elpd}\\) quando:\n\nle distribuzioni a priori sono non informative;\nla distribuzione a posteriori √® approssimativamente gaussiana multivariata;\nla dimensione \\(n\\) del campione √® molto maggiore del numero \\(k\\) dei parametri.\n\n\nPer meglio comprendere la statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\), esaminiamo un esempio discusso da Gelman et al. (2014). Sia \\(y_1, \\dots, y_n \\sim \\mathcal{N}(\\mu, 1)\\) un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa \\(p(\\theta) \\propto 1\\), la stima di massima verosimiglianza √® \\(\\bar{y}\\). La verosimiglianza √®\n\\[\nf(Y \\mid \\mu, \\sigma) = \\prod_{i=1}^n f(y \\mid \\mu, \\sigma)\n\\]\ne la log-verosimiglianza diventa\n\\[\n\\ell(Y \\mid \\mu, \\sigma) = \\sum_{i=1}^n \\log (f(y \\mid \\mu, \\sigma)).\n\\]\nOvvero,\n\\[\\begin{align}\n\\ell(Y \\mid \\mu, \\sigma) &= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi\\sigma^2 }}}\\exp \\left(-{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma^{2}}}\\right) \\right)\\notag\\\\\n&= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\sum_{i=1}^n{\\frac {1}{2}}{\\frac {(y_i-\\mu )^{2}}{\\sigma ^{2}}} \\notag\\\\\n&= \\sum_{i=1}^n \\log \\left( \\frac {1}{{\\sqrt {2\\pi \\sigma^2}}} \\right) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag \\\\\n&= \\sum_{i=1}^n \\log (1) - \\sum_{i=1}^n\\log \\sqrt{2\\pi \\sigma^2} - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag\\\\\n&= - \\sum_{i=1}^n\\frac{1}{2}  \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2} \\notag\\\\\n&= - \\frac{n}{2}  \\log (2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu )^{2}. \\notag\n\\end{align}\\]\nSe \\(y \\sim \\mathcal{N}(\\mu, 1)\\), usando lo stimatore di massima verosimiglianza per \\(\\mu\\), la log-verosimiglianza diventa\n\\[\\begin{align}\n\\log p(y \\mid \\hat{\\theta}_{MLE}) &= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2}\\sum_{i=1}^n (y_i - \\bar{y})^2 \\notag\\\\\n&= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2,\n\\end{align}\\]\ndove \\(s_y^2\\) √® la varianza campionaria.\nNel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui\n\\[\\begin{align}\n\\widehat{\\mbox{elpd}}_{AIC} &= \\log p(y \\mid \\hat{\\theta}_{MLE}) - k \\notag \\\\\n&= -\\frac{n}{2} \\log (2\\pi) - \\frac{1}{2} (n-1)s_y^2 - 1.\n\\end{align}\\]"
  },
  {
    "objectID": "092_info_criterion.html#convalida-incrociata-k-fold",
    "href": "092_info_criterion.html#convalida-incrociata-k-fold",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "\n36.2 Convalida incrociata K-fold",
    "text": "36.2 Convalida incrociata K-fold\nLa sovrastima della @ref(eq:lppd) pu√≤ anche essere evitata usando una tecnica chiamata K-fold cross-validation. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata fold) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell‚Äôaccuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold √® 2; all‚Äôaltro estremo, √® possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte (\\(n\\)) quante sono le singole osservazioni. Questa strategia √® chiamata leave-one-out cross-validation (LOO-CV).\n\n36.2.1 Importance sampling\nLa strategia LOO-CV √® computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). √à per√≤ possibile approssimare LOO-CV mediante un metodo chiamato Pareto-smoothed importance sampling cross-validation [PSIS; Vehtari et al. (2017)]. Tralasciando qui i dettagli matematici, l‚Äôintuizione di base √® che PSIS fa leva sul punteggio di ‚Äúimportanza‚Äù posseduto da ciascuna osservazione all‚Äôinterno della distribuzione a posteriori. Per ‚Äúimportanza‚Äù si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle propriet√† della distribuzione a posteriori di altre: se viene rimossa un‚Äôosservazione importante, le propriet√† della distribuzione a posteriori cambiano molto; se viene rimossa un‚Äôosservazione poco importante, la distribuzione a posteriori cambia poco. L‚Äô‚Äúimportanza‚Äù cos√¨ intesa viene chiamata ‚Äúpeso‚Äù (weight) e tali pesi vengono utilizzati per stimare l‚Äôaccuratezza out-of-sample del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza out-of-sample che evita la sovrastima della @ref(eq:lppd). Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilit√† identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione.\nValori \\(\\widehat{\\mbox{elpd}}_{LOO}\\) pi√π grandi indicano una maggiore accuratezza predittiva. In alternativa, anzich√© considerare \\(\\widehat{\\mbox{elpd}}\\), √® possibile usare la quantit√† \\(-2 \\cdot \\widehat{\\mbox{elpd}}\\), la quale √® chiamata LOO Information Criterion (LOOIC). In questo secondo caso, valori LOOIC pi√π piccoli sono da preferire.\nLa quantit√† \\(\\widehat{\\mbox{elpd}}_{LOO}\\) viene calcolata dai pacchetti loo e brms ed √® chiamata elpd_loo o elpd_kfold. √à anche possibile calcolare la differenza della quantit√† elpd_loo per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza."
  },
  {
    "objectID": "092_info_criterion.html#confronto-tra-aic-e-loo-cv",
    "href": "092_info_criterion.html#confronto-tra-aic-e-loo-cv",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "\n36.3 Confronto tra AIC e LOO-CV",
    "text": "36.3 Confronto tra AIC e LOO-CV\nPer fare un esempio, faremo qui un confronto tra \\(\\widehat{\\mbox{elpd}}_{AIC}\\) e \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\). Esaminiamo nuovamente l‚Äôassociazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da Gelman et al. (2020). Una tale relazione pu√≤ essere descritta da un modello di regressione nel quale la \\(y\\) corrisponde al QI dei figli e la \\(x\\) al QI delle madri.\nLeggiamo i dati in :\n\nCodicelibrary(\"foreign\")\ndf <- read.dta(here(\"data\", \"kidiq.dta\"))\ndf$y <- scale(df$kid_score)[, 1]\ndf$x1 <- scale(df$mom_iq)[, 1]\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age           y         x1\n#> 1        65      1 121.11753        4      27 -1.06793237  1.4078352\n#> 2        98      1  89.36188        4      25  0.54886757 -0.7092079\n#> 3        85      1 115.44316        4      27 -0.08805362  1.0295443\n#> 4        83      1  99.44964        3      25 -0.18604150 -0.0366907\n#> 5       115      1  92.74571        4      27  1.38176451 -0.4836193\n#> 6        98      0 107.90184        1      18  0.54886757  0.5267892\n\n\nDato che AIC non √® una statistica bayesiana, pu√≤ essere calcolata mediante strumenti frequentisti:\n\nCodicem1_freq <- lm(y ~ x1, data = df)\nAIC(m1_freq) / -2\n#> [1] -569.6384\n\n\nPer ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1 : N) {\n    mu[n] = alpha + beta1 * x1[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/simplereg.stan\")\n\n\n\nCodicedata1_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1\n)\n\n\n\nCodicefile1 <- file.path(\"code\", \"simplereg.stan\")\n\n\n\nCodicemod1 <- cmdstan_model(file1)\n\n\nEseguiamo il campionamento MCMC:\n\nCodicefit1 <- mod1$sample(\n  data = data1_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  refresh = 0\n)\n\n\nCalcoliamo infine la quantit√† \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\):\n\nCodiceloo1_result <- fit1$loo(cores = 4)\nprint(loo1_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -568.6 14.5\n#> p_loo         1.9  0.2\n#> looic      1137.2 28.9\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\n\n\nSi noti la somiglianza tra \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) e \\(\\widehat{\\mbox{elpd}}_{AIC}\\). In conclusione, possiamo dunque dire che \\(\\widehat{\\mbox{elpd}}_{LOO-CV}\\) √® la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica \\(\\widehat{\\mbox{elpd}}_{AIC}\\)."
  },
  {
    "objectID": "092_info_criterion.html#confronto-tra-modelli-mediante-loo-cv",
    "href": "092_info_criterion.html#confronto-tra-modelli-mediante-loo-cv",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "\n36.4 Confronto tra modelli mediante LOO-CV",
    "text": "36.4 Confronto tra modelli mediante LOO-CV\nCome menzionato in precedenza, l‚Äôobiettivo centrale della misurazione dell‚Äôaccuratezza predittiva √® il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.1\nConsidereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all‚Äôet√† della madre. L‚Äôaggiunta di tale predittore migliori l‚Äôaccuratezza predittiva del modello?\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] x2;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real beta2;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1 : N) {\n    mu[n] = alpha + beta1 * x1[n] + beta2 * x2[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  beta2 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/mreg2.stan\")\n\n\n\nCodicedf$x2 <- scale(df$mom_age)[, 1]\n\n\n\nCodicedata2_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1,\n  x2 = df$x2\n)\n\n\n\nCodicefile2 <- file.path(\"code\", \"mreg2.stan\")\n\n\n\nCodice# compile model\nmod2 <- cmdstan_model(file2)\n\n\n\nCodice# Running MCMC\nfit2 <- mod2$sample(\n  data = data2_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  refresh = 0\n)\n\n\n\nCodicefit2$summary(c(\"alpha\", \"beta1\", \"beta2\", \"sigma\"))\n#> # A tibble: 4 √ó 10\n#>   variable      mean    median     sd    mad      q5    q95  rhat ess_bulk\n#>   <chr>        <dbl>     <dbl>  <dbl>  <dbl>   <dbl>  <dbl> <dbl>    <dbl>\n#> 1 alpha    -0.000255 -0.000162 0.0431 0.0427 -0.0714 0.0705  1.00   19419.\n#> 2 beta1     0.442     0.442    0.0427 0.0427  0.372  0.512   1.00   17850.\n#> 3 beta2     0.0515    0.0514   0.0427 0.0428 -0.0179 0.121   1.00   16802.\n#> 4 sigma     0.896     0.895    0.0305 0.0303  0.848  0.948   1.00   19032.\n#> # ‚Ä¶ with 1 more variable: ess_tail <dbl>\n\n\n\nCodiceloo2_result <- fit2$loo(cores = 4)\nprint(loo2_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -568.9 14.5\n#> p_loo         3.0  0.3\n#> looic      1137.8 29.0\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\n\n\nConsideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda √® se l‚Äôaggiunta di tale predittore migliori la capacit√† predittiva del modello.\n\nCodicemodelString = \"\ndata {\n  int<lower=0> N;\n  vector[N] x1;\n  vector[N] x3;\n  vector[N] y;\n}\nparameters {\n  real alpha;\n  real beta1;\n  real beta3;\n  real<lower=0> sigma;\n}\ntransformed parameters {\n  vector[N] mu;\n  for (n in 1 : N) {\n    mu[n] = alpha + beta1 * x1[n] + beta3 * x3[n];\n  }\n}\nmodel {\n  alpha ~ normal(0, 1);\n  beta1 ~ normal(0, 1);\n  beta3 ~ normal(0, 1);\n  sigma ~ cauchy(0, 1);\n  y ~ normal(mu, sigma);\n}\ngenerated quantities {\n  vector[N] y_rep;\n  vector[N] log_lik;\n  for (n in 1 : N) {\n    y_rep[n] = normal_rng(mu[n], sigma);\n    log_lik[n] = normal_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);\n  }\n}\n\"\nwriteLines(modelString, con = \"code/mreg3.stan\")\n\n\n\nCodicedf$x3 <- df$mom_hs\n\n\n\nCodicedata3_list <- list(\n  N = length(df$kid_score),\n  y = df$y,\n  x1 = df$x1,\n  x3 = df$x3\n)\n\n\n\nCodicefile3 <- file.path(\"code\", \"mreg3.stan\")\n\n\n\nCodicemod3 <- cmdstan_model(file3)\n\n\n\nCodicefit3 <- mod3$sample(\n  data = data3_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  cores = 4L,\n  refresh = 0\n)\n\n\n\nCodicefit3$summary(c(\"alpha\", \"beta1\", \"beta3\", \"sigma\"))\n#> # A tibble: 4 √ó 10\n#>   variable   mean median     sd    mad     q5     q95  rhat ess_bulk ess_tail\n#>   <chr>     <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl>    <dbl>    <dbl>\n#> 1 alpha    -0.225 -0.224 0.0947 0.0945 -0.382 -0.0705  1.00    8433.    9191.\n#> 2 beta1     0.415  0.414 0.0449 0.0450  0.341  0.488   1.00   10941.   10324.\n#> 3 beta3     0.286  0.285 0.108  0.108   0.111  0.465   1.00    8452.    8606.\n#> 4 sigma     0.890  0.889 0.0302 0.0302  0.842  0.941   1.00   10828.    9623.\n\n\n\nCodiceloo3_result <- fit3$loo(cores = 4)\nprint(loo3_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -584.2 16.4\n#> p_loo         7.5  0.6\n#> looic      1168.3 32.8\n#> ------\n#> Monte Carlo SE of elpd_loo is 0.0.\n#> \n#> All Pareto k estimates are good (k < 0.5).\n#> See help('pareto-k-diagnostic') for details.\n\n\nPer eseguire un confronto tra modelli in termini della loro capacit√† predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni \\(\\mathsf{R}\\) producono la quantit√† elpd_diff, ovvero la differenza tra stime della \\(elpd\\) fornite da due modelli. Il primo argomento della funzione loo_compare() specifica il modello che viene usato come confronto. Nella prima riga dell‚Äôoutput, il valore elpd_diff √® 0 (cio√®, \\(x ‚àí x = 0\\)). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna se_diff riporta l‚Äôerrore standard di tali differenze.\nL‚Äôincertezza della stima dell‚Äôaccuratezza out-of-sample si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ci√≤ che √® indicato nell‚Äôoutput come errore standard. Quando il campione √® piccolo, questa approssimazione produce una forte sottostima dell‚Äôincertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.\n\nCodicew <- loo_compare(loo1_result, loo2_result, loo3_result)\nprint(w)\n#>        elpd_diff se_diff\n#> model1   0.0       0.0  \n#> model2  -0.3       1.3  \n#> model3 -15.6       6.0\n\n\nPer interpretare l‚Äôoutput, usiamo il criterio suggerito da Gelman et al. (1995): consideriamo ‚Äúcredibile‚Äù una differenza se elpd_diff √® almeno due volte maggiore di se_diff. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantit√† elpd_diff √® molto piccola rispetto al suo errore standard. Questo accade se un predittore √® associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell‚Äôet√† della madre come predittore migliori la capacit√† predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantit√† elpd_diff √® maggiore di due volte il valore dell‚Äôerrore standard. Questo suggerisce un incremento della capacit√† predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori.\n√à anche possibile calcolare l‚Äôintervallo di credibilit√† per elpd_diff:\n\nCodice15.5 + c(-1, 1) * qnorm(.95, 0, 1) * 6.0\n#> [1]  5.630878 25.369122"
  },
  {
    "objectID": "092_info_criterion.html#outlier",
    "href": "092_info_criterion.html#outlier",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "\n36.5 Outlier",
    "text": "36.5 Outlier\nSi √® soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano outlier. √à dunque necessario identificare gli outlier e limitare la loro influenza sull‚Äôinferenza.2\nPoniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto loo, l‚Äôoutput riporta il parametro di forma della distribuzione di Pareto (valore k). Tale valore pu√≤ essere utilizzato per identificare gli outlier. Infatti, il valore k valuta, per ciascun punto del campione, l‚Äôapprossimazione usata da PSIS-LOO-CV. Se \\(k < 0.5\\), i pesi di importanza vengono stimati in modo accurato; se il valore \\(k\\) di Pareto di un punto √® \\(> 0.7\\), i pesi di importanza possono essere inaccurati. Le osservazioni con \\(k > 0.7\\) sono dunque osservazioni outlier.\nPer fare un esempio concreto, introduciamo nel campione dell‚Äôesempio precedente una singola osservazione outlier.\n\nCodicedf1 <- df\ndim(df1)\n#> [1] 434   9\ndf1$x1[434] <- 10\ndf1$y[434] <- 10\n\n\nSistemiamo i dati nel formato appropriato per Stan:\n\nCodicedata1a_list <- list(\n  N = length(df1$kid_score),\n  y = df1$y,\n  x1 = df1$x1\n)\n\n\nAdattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.\n\nCodicefit1a <- mod1$sample(\n  data = data1a_list,\n  iter_sampling = 4000L,\n  iter_warmup = 2000L,\n  seed = SEED,\n  chains = 4L,\n  refresh = 0\n)\n\n\n\nCodiceloo1a_result <- fit1a$loo(cores = 4)\n\n\nUna tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:\n\nCodiceprint(loo1a_result)\n#> \n#> Computed from 16000 by 434 log-likelihood matrix\n#> \n#>          Estimate   SE\n#> elpd_loo   -586.2 19.9\n#> p_loo         6.6  5.0\n#> looic      1172.5 39.8\n#> ------\n#> Monte Carlo SE of elpd_loo is NA.\n#> \n#> Pareto k diagnostic values:\n#>                          Count Pct.    Min. n_eff\n#> (-Inf, 0.5]   (good)     433   99.8%   10708     \n#>  (0.5, 0.7]   (ok)         0    0.0%   <NA>      \n#>    (0.7, 1]   (bad)        1    0.2%   75        \n#>    (1, Inf)   (very bad)   0    0.0%   <NA>      \n#> See help('pareto-k-diagnostic') for details.\n\n\nUn grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione √® dato da:\n\nCodiceplot(loo1a_result)\n\n\n\n\n\n\n\nIl valore k stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione √® un outlier. L‚Äôindice dell‚Äôosservazione outlier √® identificato con:\n\nCodicepareto_k_ids(loo1a_result, threshold = 0.7)\n#> [1] 434"
  },
  {
    "objectID": "092_info_criterion.html#regolarizzazione",
    "href": "092_info_criterion.html#regolarizzazione",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "\n36.6 Regolarizzazione",
    "text": "36.6 Regolarizzazione\nAbbiamo motivato la presente discussione affermando che uno dei problemi pi√π grandi che i ricercatori devono afforntare √® quello della generalizzabilit√† dei loro risultati. McElreath (2020) fa notare che un modo per favorire la capacit√† del modello di generalizzarsi a nuovi campioni √® quello di fare in modo che produca un adattamento peggiore ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilit√†) dipende dal fatto che tutte le regolarit√† presenti nei dati del campione (e dunque, anche quelle che costituiscono un aspetto idiosincratico del campione presente) ‚Äúvengono egualmente prese sul serio‚Äù da un modello che utilizza prior uniformi per i parametri. In tali circostanze, qualsiasi valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di procedere, che sicuramente √® inadeguato, √® quello di utilizzare dei prior che McElreath (2020) chiama ‚Äúscettici‚Äù. I priori ‚Äúscettici‚Äù pi√π comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarit√† che emergono dai dati del campione. Se il prior √® ‚Äútroppo scettico‚Äù, tuttavia, le regolarit√† dei dati campionari non vengono rappresentate dal modello; di conseguenza, ci√≤ produce un sotto-adattamento. Il problema √® quello di trovare un equilibrio tra gli opposti pericoli del sovra-adattamento e del sotto-adattamento. La buona notizia √® che anche un prior ‚Äúmoderatamente scettico‚Äù √® in grado di fornire un grande aiuto al modello, e questo √® tutto quello che possiamo sperare di ottenere dato che, in generale, non ci sono n√© modelli ottimali n√© distribuzioni a priori ottimali (ovvero, modelli e distribuzioni a priori che non possono essere migliorati).\nUn esempio di una distribuzione a priori di regolarizzazione pu√≤ essere fornito facendo riferimento al modello lineare, per esempio. Se standardizziamo i dati, un prior \\(\\beta \\sim \\mathcal{N}(0, 1)\\) per il parametro che codifica la pendenza della retta di regressione ci dice che, prima di osservare i dati, il modello ‚Äú√® molto scettico‚Äù rispetto ai valori possibili di \\(\\beta\\) esterni all‚Äôintervallo \\([-2, 2]\\) deviazioni standard. In altri termini, ritiene che sia molto improbabile che un cambiamento di 1 deviazione standard nella \\(x\\) sia associato ad un cambiamento medio superiore a 2 unit√† di deviazione standard nella \\(y\\).\nMa potremmo anche usare una distribuzione a priori gaussiana con parametro \\(\\sigma\\) uguale a 0.5 oppure a 0.2. Quale prior usare dipende dal modello e dai dati ‚Äì non c‚Äô√® una raccomandazione che risulta sempre valida. L‚Äôeffetto maggiore dei prior ‚Äúmolto scettici‚Äù si manifesta nel caso di modelli complessi e nel caso di piccole numerosit√† campionarie ‚Äì ovvero, proprio nei casi in cui il rischio del sovra-adattamento √® pi√π grande. Se invece il campione √® sufficientemente grande e il modello non √® eccessivamente complesso, i prior, quali essi siano, hanno invece un effetto trascurabile sulla stima della distribuzione a posteriori."
  },
  {
    "objectID": "092_info_criterion.html#commenti-e-considerazioni-finali",
    "href": "092_info_criterion.html#commenti-e-considerazioni-finali",
    "title": "36¬† Criterio di informazione e convalida incrociata",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo Capitolo, utilizzando Stan insieme al pacchetto loo, abbiamo imparato ad usare la convalida incrociata K-fold e la convalida incrociata leave-one-out. Abbiamo esaminato alcuni esempi nei quali la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata si dimostra utile utile quando vengono confrontati modelli piuttosto diversi; quando i modelli sono molto simili, invece, risulta spesso difficile distinguerli con le tecniche qui discusse. In particolare, risulta spesso difficile ottenere risultati conclusivi dal confronto di modelli tramite la convalida incrociata se l‚Äôeffetto √® molto piccolo e/o se il campione di dati √® piccolo. In questi casi, alcuni ricercatori ritengono che siano pi√π adatti altri metodi di confronto dei modelli, come ad esempio i fattori di Bayes. L‚Äôuso dei fattori di Bayes, tuttavia, √® controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile √® preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata.\n\n\n\n\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). Bayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other stories. Cambridge University Press.\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding predictive information criteria for bayesian models. Statistics and Computing, 24(6), 997‚Äì1016.\n\n\nMcElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (2nd Edition). CRC Press.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain & Behavior, 2(1), 28‚Äì34.\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing, 27(5), 1413‚Äì1432."
  },
  {
    "objectID": "999_refs.html",
    "href": "999_refs.html",
    "title": "Riferimenti bibliografici",
    "section": "",
    "text": "Albert, J., & Hu, J. (2019). Probability and bayesian\nmodeling. Chapman; Hall/CRC.\n\n\nBechdel, A. (1986). Dykes to watch out for. Firebrand Books.\n\n\nBergh, D. van den, Van Doorn, J., Marsman, M., Draws, T., Van Kesteren,\nE.-J., Derks, K., Dablander, F., Gronau, Q. F., Kucharsk·ª≥, ≈†., Gupta, A.\nR. K. N., et al. (2020). A tutorial on conducting and interpreting a\nbayesian ANOVA in JASP. L‚ÄôAnn√©e Psychologique,\n120(1), 73‚Äì96.\n\n\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D., Goodrich, B.,\nBetancourt, M., Brubaker, M., Guo, J., Li, P., & Riddell, A. (2017).\nStan: A probabilistic programming language. Journal of Statistical\nSoftware, 76(1), 1‚Äì32.\n\n\nCaudek, C., & Luccio, R. (2001). Statistica per psicologi.\n\n\nEckhardt, R. (1987). Stan Ulam, John Von Neumann\nand the Monte Carlo Method. Los Alamos Science Special\nIssue.\n\n\nFinetti, B. de. (1931). Probabilismo. Logos, 163‚Äì219.\n\n\nGautret, P., Lagier, J. C., Parola, P., Meddeb, L., Mailhe, M., Doudier,\nB., & Honor√©, S. (2020). Hydroxychloroquine and azithromycin as a\ntreatment of COVID-19: Results of an open-label non-randomized clinical\ntrial. International Journal of Antimicrobial Agents.\n\n\nGelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995).\nBayesian data analysis. Chapman; Hall/CRC.\n\n\nGelman, A., Hill, J., & Vehtari, A. (2020). Regression and other\nstories. Cambridge University Press.\n\n\nGelman, A., Hwang, J., & Vehtari, A. (2014). Understanding\npredictive information criteria for bayesian models. Statistics and\nComputing, 24(6), 997‚Äì1016.\n\n\nGibson, E., & Wu, H.-H. I. (2013). Processing chinese relative\nclauses in context. Language and Cognitive Processes,\n28(1-2), 125‚Äì155.\n\n\nHoeting, J. A., Madigan, D., Raftery, A. E., & Volinsky, C. T.\n(1999). Bayesian model averaging: A tutorial (with comments by m. Clyde,\ndavid draper and EI george, and a rejoinder by the authors.\nStatistical Science, 14(4), 382‚Äì417.\n\n\nHorstmann, A. C., Bock, N., Linhuber, E., Szczuka, J. M., Stra√ümann, C.,\n& Kr√§mer, N. C. (2018). Do a robot‚Äôs social skills and its objection\ndiscourage interactants from switching the robot off? PloS One,\n13(7), e0201581.\n\n\nHulme, O. J., Wagenmakers, E. J., Damkier, P., Madelung, C. F., Siebner,\nH. R., Helweg-Larsen, J., & Madsen, K. H. (2020). Reply to gautret\net al. 2020: A bayesian reanalysis of the effects of hydroxychloroquine\nand azithromycin on viral carriage in patients with COVID-19.\nmedRxiv.\n\n\nJohnson, A. A., Ott, M., & Dogucu, M. (2022). Bayes Rules! An Introduction to Bayesian Modeling with\nR. CRC Press.\n\n\nKennedy-Shaffer, L. (2019). Before p< 0.05 to beyond p< 0.05:\nUsing history to contextualize p-values and significance testing.\nThe American Statistician, 73(sup1), 82‚Äì90.\n\n\nKruschke, J. (2014). Doing bayesian data analysis: A\ntutorial with R, JAGS, and Stan. Academic\nPress.\n\n\nLazic, S. E., Semenova, E., & Williams, D. P. (2020). Determining\norgan weight toxicity with bayesian causal models: Improving on the\nanalysis of relative organ weights. Scientific Reports,\n10(1), 1‚Äì12.\n\n\nLee, M. D., & Wagenmakers, E.-J. (2014). Bayesian cognitive\nmodeling: A practical course. Cambridge university press.\n\n\nLord, F. M. (1950). Efficiency of prediction when a regression equation\nfrom one sample is used in a new sample. ETS Research Bulletin\nSeries, 1950(2), 1‚Äì6.\n\n\nMartin, O. A., Kumar, R., & Lao, J. (2022). Bayesian modeling\nand computation in python. CRC Press.\n\n\nMcElreath, R. (2020). Statistical rethinking: A\nBayesian course with examples in R and\nStan (2nd Edition). CRC Press.\n\n\nMetropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H.,\n& Teller, E. (1953). Equation of state calculations by fast\ncomputing machines. The Journal of Chemical Physics,\n21(6), 1087‚Äì1092.\n\n\nMilgram, S. (1963). Behavioral study of obedience. The Journal of\nAbnormal and Social Psychology, 67(4), 371‚Äì378.\n\n\nNavarro, D. J. (2019). Between the devil and the deep blue sea: Tensions\nbetween scientific judgement and statistical model selection.\nComputational Brain & Behavior, 2(1), 28‚Äì34.\n\n\nNuggerud-Galeas, S., S√°ez-Benito Suescun, L., Berenguer Torrijo, N.,\nS√°ez-Benito Suescun, A., Aguilar-Latorre, A., Magall√≥n Botaya, R., &\nOliv√°n Bl√°zquez, B. (2020). Analysis of depressive episodes, their\nrecurrence and pharmacologic treatment in primary care patients: A\nretrospective descriptive study. Plos One, 15(5),\ne0233454.\n\n\nRubin, D. B. (1981). Estimation in parallel randomized experiments.\nJournal of Educational Statistics, 6(4), 377‚Äì401.\n\n\nSawilowsky, S. S. (2009). New effect size rules of thumb. Journal of\nModern Applied Statistical Methods, 8(2), 26.\n\n\nSchmettow, M. (2021). New statistics for design researchers.\nSpringer.\n\n\nSchoot, R. van de, Depaoli, S., King, R., Kramer, B., M√§rtens, K.,\nTadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., &\nYau, C. (2021). Bayesian statistics and modelling. Nature Reviews\nMethods Primer, 1(1), 1‚Äì26.\n\n\nSong, Q. C., Tang, C., & Wee, S. (2021). Making sense of model\ngeneralizability: A tutorial on cross-validation in r and shiny.\nAdvances in Methods and Practices in Psychological Science,\n4(1), 2515245920947067.\n\n\nSorensen, T., & Vasishth, S. (2015). Bayesian linear mixed models\nusing stan: A tutorial for psychologists, linguists, and cognitive\nscientists. arXiv Preprint arXiv:1506.06201.\n\n\nStevens, S. S. (1946). On the theory of scales of measurement.\nScience, 103(2684), 677‚Äì680.\n\n\nTufte, E. R. (2001). The visual display of quantitative\ninformation. Graphics press Cheshire, CT.\n\n\nVehtari, A., Gelman, A., & Gabry, J. (2017). Practical bayesian\nmodel evaluation using leave-one-out cross-validation and WAIC.\nStatistics and Computing, 27(5), 1413‚Äì1432.\n\n\nZetsche, U., B√ºrkner, P.-C., & Renneberg, B. (2019). Future\nexpectations in clinical depression: Biased or realistic?\nJournal of Abnormal Psychology, 128(7), 678‚Äì688."
  },
  {
    "objectID": "a01_math_symbols.html",
    "href": "a01_math_symbols.html",
    "title": "Appendix A ‚Äî Simbologia di base",
    "section": "",
    "text": "\\(\\log(x)\\): il logaritmo naturale di \\(x\\).\nL‚Äôoperatore logico booleano \\(\\land\\) significa ‚Äúe‚Äù (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa ‚Äúo‚Äù (oppure) (congiunzione debole).\nIl quantificatore esistenziale \\(\\exists\\) vuol dire ‚Äúesiste almeno un‚Äù e indica l‚Äôesistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicit√† \\(\\exists!\\) (‚Äúesiste soltanto un‚Äù) indica l‚Äôesistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l‚Äôesistenza del concetto/oggetto indicato.\nIl quantificatore universale \\(\\forall\\) vuol dire ‚Äúper ogni.‚Äù\n\\(\\mathcal{A, S}\\): insiemi.\n\\(x \\in A\\): \\(x\\) √® un elemento dell‚Äôinsieme \\(A\\).\nL‚Äôimplicazione logica ‚Äú\\(\\Rightarrow\\)‚Äù significa ‚Äúimplica‚Äù (se ‚Ä¶allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) √® condizione sufficiente per la verit√† di \\(Q\\) e che \\(Q\\) √® condizione necessaria per la verit√† di \\(P\\).\nL‚Äôequivalenza matematica ‚Äú\\(\\iff\\)‚Äù significa ‚Äúse e solo se‚Äù e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.\nIl simbolo \\(\\vert\\) si legge ‚Äútale che.‚Äù\nIl simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge ‚Äúuguale per definizione.‚Äù\nIl simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo.\nIl simbolo \\(\\propto\\) si legge ‚Äúproporzionale a.‚Äù\nIl simbolo \\(\\approx\\) si legge ‚Äúcirca.‚Äù\nIl simbolo \\(\\in\\) della teoria degli insiemi vuol dire ‚Äúappartiene‚Äù e indica l‚Äôappartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire ‚Äúnon appartiene.‚Äù\nIl simbolo \\(\\subseteq\\) si legge ‚Äú√® un sottoinsieme di‚Äù (pu√≤ coincidere con l‚Äôinsieme stesso). Il simbolo \\(\\subset\\) si legge ‚Äú√® un sottoinsieme proprio di.‚Äù\nIl simbolo \\(\\#\\) indica la cardinalit√† di un insieme.\nIl simbolo \\(\\cap\\) indica l‚Äôintersezione di due insiemi. Il simbolo \\(\\cup\\) indica l‚Äôunione di due insiemi.\nIl simbolo \\(\\emptyset\\) indica l‚Äôinsieme vuoto o evento impossibile.\nIn matematica, \\(\\mbox{argmax}\\) identifica l‚Äôinsieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \\(\\mbox{argmax}_x f(x)\\) √® l‚Äôinsieme dei valori di \\(x\\) per i quali \\(f(x)\\) raggiunge il valore pi√π alto.\n\\(a, c, \\alpha, \\gamma\\): scalari.\n\\(\\boldsymbol{x}, \\boldsymbol{y}\\): vettori.\n\\(\\boldsymbol{X}, \\boldsymbol{Y}\\): matrici.\n\\(X \\sim p\\): la variabile casuale \\(X\\) si distribuisce come \\(p\\).\n\\(p(\\cdot)\\): distribuzione di massa o di densit√† di probabilit√†.\n\\(p(y \\mid \\boldsymbol{x})\\): la probabilit√† o densit√† di \\(y\\) dato \\(\\boldsymbol{x}\\), ovvero \\(p(y = \\boldsymbol{Y} \\mid x = \\boldsymbol{X})\\).\n\\(f(x)\\): una funzione arbitraria di \\(x\\).\n\\(f(\\boldsymbol{X}; \\theta, \\gamma)\\): \\(f\\) √® una funzione di \\(\\boldsymbol{X}\\) con parametri \\(\\theta, \\gamma\\). Questa notazione indica che \\(\\boldsymbol{X}\\) sono i dati che vengono passati ad un modello di parametri \\(\\theta, \\gamma\\).\n\\(\\mathcal{N}(\\mu, \\sigma^2)\\): distribuzione gaussiana di media \\(\\mu\\) e varianza \\(sigma^2\\).\n\\(\\mbox{Beta}(\\alpha, \\beta)\\): distribuzione Beta di parametri \\(\\alpha\\) e \\(\\beta\\).\n\\(\\mathcal{U}(a, b)\\): distribuzione uniforme con limite inferiore \\(a\\) e limite superiore \\(b\\).\n\\(\\mbox{Cauchy}(\\alpha, \\beta)\\): distribuzione di Cauchy di parametri \\(\\alpha\\) (posizione: media) e \\(\\beta\\) (scala: radice quadrata della varianza).\n\\(\\mathcal{B}(p)\\): distribuzione di Bernoulli di parametro \\(p\\) (probabilit√† di successo).\n\\(\\mbox{Bin}(n, p)\\): distribuzione binomiale di parametri \\(n\\) (numero di prove) e \\(p\\) (probabilit√† di successo).\n\\(\\mathbb{KL} (p \\mid\\mid q)\\): la divergenza di Kullback-Leibler da \\(p\\) a \\(q\\)."
  },
  {
    "objectID": "a02_number_sets.html",
    "href": "a02_number_sets.html",
    "title": "Appendix B ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "",
    "text": "I numeri pi√π semplici sono quelli binari, cio√® zero o uno. Useremo spesso numeri binari per indicare se qualcosa √® vero o falso, presente o assente. I numeri binari sono molto utili per ottenere facilmente delle statistiche riassuntive in \\(\\mathsf{R}\\).Supponiamo di chiedere a 10 studenti ‚ÄúTi piacciono i mirtilli?‚Äù Poniamo che le risposte siano le seguenti:\n\nCodiceopinion <- c(\n  \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"Yes\",\n  \"Yes\", \"Yes\", \"Yes\"\n)\nopinion\n\n [1] \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"Yes\" \"Yes\" \"Yes\"\n\n\nTali risposte possono essere ricodificate nei termini di valori di verit√†, ovvero, vero e falso, generalmente denotati rispettivamente come 1 e 0. In \\(\\R\\) tale ricodifica pu√≤ essere effettuata mediante l‚Äôoperatore == che √® un test per l‚Äôuguaglianza e restituisce il valore logico VERO se i due oggetti valutati sono uguali e FALSO se non lo sono:\n\nCodiceopinion <- opinion == \"Yes\"\nopinion\n\n [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n\n\nR considera i valori di verit√† e i numeri binari in modo equivalente, con TRUE uguale a 1 e FALSE uguale a zero. Di conseguenza, possiamo effettuare operazioni algebriche sui valori logici VERO e FALSO. Nell‚Äôesempio, possiamo sommare i valori di verit√† e dividere per 10\n\nCodicesum(opinion) / length(opinion)\n\n[1] 0.7\n\n\nin modo tale da calcolare una propozione, il che ci consente di concludere che 7 risposte su 10 sono positive."
  },
  {
    "objectID": "a02_number_sets.html#numeri-interi",
    "href": "a02_number_sets.html#numeri-interi",
    "title": "Appendix B ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.2 Numeri interi",
    "text": "B.2 Numeri interi\nUn numero intero √® un numero senza decimali. Si dicono naturali i numeri che servono a contare, come 1, 2, ‚Ä¶ L‚Äôinsieme dei numeri naturali si indica con il simbolo \\(\\mathbb{N}\\). √à anche necessario introdurre i numeri con il segno per poter trattare grandezze negative. Si ottengono cos√¨ l‚Äôinsieme numerico dei numeri interi relativi: \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\)"
  },
  {
    "objectID": "a02_number_sets.html#numeri-razionali",
    "href": "a02_number_sets.html#numeri-razionali",
    "title": "Appendix B ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.3 Numeri razionali",
    "text": "B.3 Numeri razionali\nI numeri razionali sono i numeri frazionari \\(m/n\\), dove \\(m, n \\in N\\), con \\(n \\neq 0\\). Si ottengono cos√¨ i numeri razionali: \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). √à evidente che \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Anche in questo caso √® necessario poter trattare grandezze negative. I numeri razionali non negativi sono indicati con \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\)."
  },
  {
    "objectID": "a02_number_sets.html#numeri-irrazionali",
    "href": "a02_number_sets.html#numeri-irrazionali",
    "title": "Appendix B ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.4 Numeri irrazionali",
    "text": "B.4 Numeri irrazionali\nTuttavia, non tutti i punti di una retta \\(r\\) possono essere rappresentati mediante i numeri interi e razionali. √à dunque necessario introdurre un‚Äôaltra classe di numeri. Si dicono irrazionali, e sono denotati con \\(\\mathbb{R}\\), i numeri che possono essere scritti come una frazione \\(a / b\\), con \\(a\\) e \\(b\\) interi e \\(b\\) diverso da 0. I numeri irrazionali sono i numeri illimitati e non periodici che quindi non possono essere espressi sotto forma di frazione. Per esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\({\\displaystyle \\pi =3,141592\\ldots}\\) sono numeri irrazionali."
  },
  {
    "objectID": "a02_number_sets.html#numeri-reali",
    "href": "a02_number_sets.html#numeri-reali",
    "title": "Appendix B ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.5 Numeri reali",
    "text": "B.5 Numeri reali\nI punti della retta \\(r\\) sono quindi ‚Äúdi pi√π‚Äù dei numeri razionali. Per poter rappresentare tutti i punti della retta abbiamo dunque bisogno dei numeri reali. I numeri reali possono essere positivi, negativi o nulli e comprendono, come casi particolari, i numeri interi, i numeri razionali e i numeri irrazionali. Spesso in statisticac il numero dei decimali indica il grado di precisione della misurazione."
  },
  {
    "objectID": "a02_number_sets.html#intervalli",
    "href": "a02_number_sets.html#intervalli",
    "title": "Appendix B ‚Äî Numeri binari, interi, razionali, irrazionali e reali",
    "section": "\nB.6 Intervalli",
    "text": "B.6 Intervalli\nUn intervallo si dice chiuso se gli estremi sono compresi nell‚Äôintervallo, aperto se gli estremi non sono compresi. Le caratteristiche degli intervalli sono riportate nella tabella seguente.\n\n\nIntervallo\n\n\n\n\n\nchiuso\n\\([a, b]\\)\n\\(a \\leq x \\leq b\\)\n\n\naperto\n\\((a, b)\\)\n\\(a < x < b\\)\n\n\nchiuso a sinistra e aperto a destra\n\\([a, b)\\)\n\\(a \\leq x < b\\)\n\n\naperto a sinistra e chiuso a destra\n\\((a, b]\\)\n\\(a < x \\leq b\\)"
  },
  {
    "objectID": "a03_set_theory.html",
    "href": "a03_set_theory.html",
    "title": "Appendix C ‚Äî Insiemi",
    "section": "",
    "text": "Un insieme (o collezione, classe, gruppo, ‚Ä¶) √® un concetto primitivo, ovvero √® un concetto che gi√† possediamo. Georg Cantor l‚Äôha definito nel modo seguente: un insieme √® una collezione di oggetti, determinati e distinti, della nostra percezione o del nostro pensiero, concepiti come un tutto unico; tali oggetti si dicono elementi dell‚Äôinsieme.\nMentre non √® rilevante la natura degli oggetti che costituiscono l‚Äôinsieme, ci√≤ che importa √® distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilit√†: il dato oggetto √® un elemento dell‚Äôinsieme considerato oppure non √® elemento dell‚Äôinsieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali:\n\\[\n\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\n\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con\n\\[\nA = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con~} n > 0.\n\\]\nLa scrittura \\(a \\in A\\) dice che \\(a\\) √® un elemento di \\(A\\). Per dire che \\(b\\) non √® un elemento di \\(A\\) si scrive \\(b \\notin A.\\)\nPer quegli insiemi i cui elementi soddisfano una certa propriet√† che li caratterizza, tale propriet√† pu√≤ essere usata per descrivere pi√π sinteticamente l‚Äôinsieme:\n\\[\nA = \\{x ~\\vert~ \\text{propriet√† posseduta da~} x\\},\n\\]\nche si legge come ‚Äú\\(A\\) √® l‚Äôinsieme degli elementi \\(x\\) per cui √® vera la propriet√† indicata.‚Äù Per esempio, per indicare l‚Äôinsieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si pu√≤ scrivere:\n\\[\nA = \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) √® un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\):\n\\[\nA \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\n\\]\nSe esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) √® un sottoinsieme proprio di \\(B\\):\n\\[\nA \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si associa all‚Äôinsieme \\(A\\) √® l‚Äôinsieme di tutti i sottoinsiemi di \\(A\\), inclusi l‚Äôinsieme vuoto e \\(A\\) stesso. Per esempio, per l‚Äôinsieme \\(A = \\{a, b, c\\}\\), l‚Äôinsieme delle parti √®:\n\\[\n\\mathcal{P}(A) = \\{\n\\emptyset, \\{a\\}, \\{b\\}, \\{c\\},\n\\{a, b\\}, \\{a, c\\}, \\{c, b\\},\n\\{a, b, c\\}\n\\}.\n\\]"
  },
  {
    "objectID": "a03_set_theory.html#operazioni-tra-insiemi",
    "href": "a03_set_theory.html#operazioni-tra-insiemi",
    "title": "Appendix C ‚Äî Insiemi",
    "section": "\nC.1 Operazioni tra insiemi",
    "text": "C.1 Operazioni tra insiemi\nSi definisce intersezione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\):\n\\[\nA \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\n\\]\nSi definisce unione di \\(A\\) e \\(B\\) l‚Äôinsieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cio√®\n\\[\nA \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}.\n\\]\nDifferenza. Si indica con \\(A \\setminus B\\) l‚Äôinsieme degli elementi di \\(A\\) che non appartengono a \\(B\\):\n\\[\nA \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\n\\]\nInsieme complementare. Nel caso che sia \\(B \\subseteq A\\), l‚Äôinsieme differenza \\(A \\setminus B\\) √® detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\).\nDato un insieme \\(S\\), una partizione di \\(S\\) √® una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[\nS = S_1 \\cup S_2 \\cup \\dots S_k\n\\]\ne\n\\[\nS_i \\cap S_j, \\quad \\text{con~} i \\neq j.\n\\]\nLa relazione tra unione, intersezione e insieme complementare √® data dalle leggi di DeMorgan:\n$$ (A B)^c = A^c B^c,\n\\[ \\]\n(A B)^c = A^c B^c. $$"
  },
  {
    "objectID": "a03_set_theory.html#diagrammi-di-eulero-venn",
    "href": "a03_set_theory.html#diagrammi-di-eulero-venn",
    "title": "Appendix C ‚Äî Insiemi",
    "section": "\nC.2 Diagrammi di Eulero-Venn",
    "text": "C.2 Diagrammi di Eulero-Venn\nIn molte situazioni √® utile servirsi dei cosiddetti diagrammi di Eulero-Venn per rappresentare gli insiemi e verificare le propriet√† delle operazioni tra insiemi (si veda la figura @ref(fig:sets-venn-diagrams). I diagrammi di Venn sono cos√¨ nominati in onore del matematico inglese del diciannovesimo secolo John Venn anche se Leibnitz e Eulero avevano gi√† in precedenza utilizzato rappresentazioni simili. In tale rappresentazione, gli insiemi sono individuati da regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, √® possibile evidenziare esplicitamente alcuni elementi di un insieme mediante punti, quando si possono anche evidenziare tutti gli elementi degli insiemi considerati.\n\n\n\n\nIn tutte le figure \\(S\\) √® la regione delimitata dal rettangolo, \\(L\\) √® la regione all‚Äôinterno del cerchio di sinistra e \\(R\\) √® la regione all‚Äôinterno del cerchio di destra. La regione evidenziata mostra l‚Äôinsieme indicato sotto ciascuna figura.\n\n\n\n\nI diagrammi di Eulero-Venn che forniscono una dimostrazione delle leggi di DeMorgan sono forniti nella figura @ref(fig:demorgan).\n\n\n\n\nDimostrazione delle leggi di DeMorgan."
  },
  {
    "objectID": "a03_set_theory.html#coppie-ordinate-e-prodotto-cartesiano",
    "href": "a03_set_theory.html#coppie-ordinate-e-prodotto-cartesiano",
    "title": "Appendix C ‚Äî Insiemi",
    "section": "\nC.3 Coppie ordinate e prodotto cartesiano",
    "text": "C.3 Coppie ordinate e prodotto cartesiano\nUna coppia ordinata \\((x,y)\\) √® l‚Äôinsieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) √® la prima componente (o prima coordinata), \\(y\\) la seconda. L‚Äôinsieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\nA \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\n\\]\nAd esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora,\n\\[\n\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\n\\]"
  },
  {
    "objectID": "a03_set_theory.html#cardinalit√†",
    "href": "a03_set_theory.html#cardinalit√†",
    "title": "Appendix C ‚Äî Insiemi",
    "section": "\nC.4 Cardinalit√†",
    "text": "C.4 Cardinalit√†\nSi definisce cardinalit√† (o potenza) di un insieme finito il numero degli elementi dell‚Äôinsieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\)."
  },
  {
    "objectID": "a04_summation_notation.html",
    "href": "a04_summation_notation.html",
    "title": "Appendix D ‚Äî Simbolo di somma (sommatorie)",
    "section": "",
    "text": "Le somme si incontrano costantemente in svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. La somma dei primi \\(n\\) numeri interi pu√≤ essere scritta come \\(1+2+\\dots+(n-1)+n\\), dove `\\(\\dots\\)‚Äô ci dice di completare la sequenza definita dai termini che vengono prima e dopo. Ovviamente, una notazione come \\(1+7+\\dots+73.6\\) non avrebbe alcun senso senza qualche altro tipo di precisazione. In generale, nel seguito incontreremo delle somme nella forma\ndove \\(x_n\\) √® un numero che √® stato definito altrove. La notazione precedente, che fa uso dei tre puntini di sospensione, √® utile in alcuni contesti ma in altri risulta ambigua. Pertanto la notazione di uso corrente √® del tipo\ne si legge ‚Äúsommatoria per \\(i\\) che va da \\(1\\) a \\(n\\) di \\(x_i\\)‚Äù. Il simbolo \\(\\sum\\) (lettera sigma maiuscola dell‚Äôalfabeto greco) indica l‚Äôoperazione di somma, il simbolo \\(x_i\\) indica il generico addendo della sommatoria, le lettere \\(1\\) ed \\(n\\) indicano i cosiddetti estremi della sommatoria, ovvero l‚Äôintervallo (da \\(1\\) fino a \\(n\\) estremi inclusi) in cui deve variare l‚Äôindice \\(i\\) allorch√© si sommano gli addendi \\(x_i\\). Solitamente l‚Äôestremo inferiore √® \\(1\\) ma potrebbe essere qualsiasi altri numero \\(m < n\\). Quindi\n\\[\n\\sum_{i=1}^n x_i = x_1 + x_{2} + \\dots + x_{n}.\n\\]\nPer esempio, se i valori \\(x\\) sono \\(\\{3, 11, 4, 7\\}\\), si avr√†\n\\[\n\\sum_{i=1}^4 x_i = 3+11+4+7 = 25\n\\]\nladdove \\(x_1 = 3\\), \\(x_2 = 11\\), eccetera. La quantit√† \\(x_i\\) nella formula precedente si dice l‚Äôargomento della sommatoria, mentre la variabile \\(i\\), che prende i valori naturali successivi indicati nel simbolo, si dice indice della sommatoria.\nLa notazione di sommatoria pu√≤ anche essere fornita nella forma seguente\n\\[\n\\sum_{P(i)} x_i\\notag\n\\]\ndove \\(P(i)\\) √® qualsiasi proposizione riguardante \\(i\\) che pu√≤ essere vera o falsa. Quando √® ovvio che si vogliono sommare tutti i valori di \\(n\\) osservazioni, la notazione pu√≤ essere semplificata nel modo seguente: \\(\\sum_{i} x_i\\) oppure \\(\\sum x_i\\). Al posto di \\(i\\) si possono trovare altre lettere: \\(k, j, l, \\dots\\),."
  },
  {
    "objectID": "a04_summation_notation.html#manipolazione-di-somme",
    "href": "a04_summation_notation.html#manipolazione-di-somme",
    "title": "Appendix D ‚Äî Simbolo di somma (sommatorie)",
    "section": "\nD.1 Manipolazione di somme",
    "text": "D.1 Manipolazione di somme\n√à conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l‚Äôoperatore della sommatoria.\n\nD.1.1 Propriet√† 1\nLa sommatoria di \\(n\\) valori tutti pari alla stessa costante \\(a\\) √® pari a \\(n\\) volte la costante stessa:\n\\[\n\\sum_{i=1}^{n} a = \\underbrace{a + a + \\dots + a} = {n\\text{ volte } a} = n a.\n\\]\n\nD.1.2 Propriet√† 2 (propriet√† distributiva)\nNel caso in cui l‚Äôargomento contenga una costante, √® possibile riscrivere la sommatoria. Ad esempio con\n\\[\n\\sum_{i=1}^{n} a x_i = a x_1 + a x_2 + \\dots + a x_n\n\\]\n√® possibile raccogliere la costante \\(a\\) e fare \\(a(x_1 +x_2 + \\dots + x_n)\\). Quindi possiamo scrivere\n\\[\n\\sum_{i=1}^{n} a x_i = a \\sum_{i=1}^{n} x_i.\n\\]\n\nD.1.3 Propriet√† 3 (propriet√† associativa)\nNel caso in cui\n\\[\n\\sum_{i=1}^{n} (a + x_i) = (a + x_1) + (a + x_1) + \\dots  (a + x_n)\n\\]\nsi ha che\n\\[\n\\sum_{i=1}^{n} (a + x_i) = n a + \\sum_{i=1}^{n} x_i.\n\\]\n√à dunque chiaro che in generale possiamo scrivere\n\\[\n\\sum_{i=1}^{n} (x_i + y_i) = \\sum_{i=1}^{n} x_i + \\sum_{i=1}^{n} y_i.\n\\]\n\nD.1.4 Propriet√† 4\nSe deve essere eseguita un‚Äôoperazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull‚Äôargomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,\n\\[\n\\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \\dots + x_n^2 \\neq \\left(\\sum_{i=1}^{n} x_i \\right)^2.\n\\]\n\nD.1.5 Propriet√† 5\nNel caso si voglia calcolare \\(\\sum_{i=1}^{n} x_i y_i\\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:\n\\[\n\\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \\dots + x_n y_n,\n\\]\ninfatti, \\(a_1 b_1 + a_2 b_2 \\neq (a_1 + a_2)(b_1 + b_2)\\)."
  },
  {
    "objectID": "a04_summation_notation.html#doppia-sommatoria",
    "href": "a04_summation_notation.html#doppia-sommatoria",
    "title": "Appendix D ‚Äî Simbolo di somma (sommatorie)",
    "section": "\nD.2 Doppia sommatoria",
    "text": "D.2 Doppia sommatoria\n√à possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{m} x_{ij}.\n\\]\nLa doppia sommatoria comporta che per ogni valore dell‚Äôindice esterno, \\(i\\) da \\(1\\) ad \\(n\\), occorre sviluppare la seconda sommatoria per \\(j\\) da \\(1\\) ad \\(m\\). Quindi,\n\\[\n\\sum_{i=1}^{3}\\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).\n\\]\nUn caso particolare interessante di doppia sommatoria √® il seguente:\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j\n\\]\nSi pu√≤ osservare che nella sommatoria interna (quella che dipende dall‚Äôindice \\(j\\)), la quantit√† \\(x_i\\) √® costante, ovvero non dipende dall‚Äôindice (che √® \\(j\\)). Allora possiamo estrarre \\(x_i\\) dall‚Äôoperatore di sommatoria interna e scrivere\n\\[\n\\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right).\n\\]\nAllo stesso modo si pu√≤ osservare che nell‚Äôargomento della sommatoria esterna la quantit√† costituita dalla sommatoria in \\(j\\) non dipende dall‚Äôindice \\(i\\) e quindi questa quantit√† pu√≤ essere estratta dalla sommatoria esterna. Si ottiene quindi\n\\[\n\\sum_{i=1}^{n}\\sum_{j=1}^{n} x_i y_j = \\sum_{i=1}^{n} \\left( x_i \\sum_{j=1}^{n} y_j \\right) = \\sum_{i=1}^{n}¬†x_i \\sum_{j=1}^{n} y_j.\n\\]\n\nSi verifichi quanto detto sopra nel caso particolare di \\(x = \\{2, 3, 1\\}\\) e \\(y = \\{1, 4, 9\\}\\), svolgendo prima la doppia sommatoria per poi verificare che quanto cos√¨ ottenuto sia uguale al prodotto delle due sommatorie.\n\\[\\begin{align}\n\\sum_{i=1}^3 \\sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 +\nx_2y_1 + x_2y_2 + x_2y_3 +\nx_3y_1 + x_3y_2 + x_3y_3 \\notag\\\\\n&= 2 \\times (1+4+9) + 3 \\times (1+4+9) + 2 \\times (1+4+9) = 84,\\notag\n\\end{align}\\]\novvero\n[ (2 + 3 + 1) (1+4+9) = 84. ]"
  },
  {
    "objectID": "a04_summation_notation.html#sommatorie-e-produttorie-e-operazioni-vettoriali-in-r",
    "href": "a04_summation_notation.html#sommatorie-e-produttorie-e-operazioni-vettoriali-in-r",
    "title": "Appendix D ‚Äî Simbolo di somma (sommatorie)",
    "section": "\nD.3 Sommatorie (e produttorie) e operazioni vettoriali in R\n",
    "text": "D.3 Sommatorie (e produttorie) e operazioni vettoriali in R\n\nSi noti che la notazione\n\\[\n\\sum_{n=0}^4 3n\n\\]\nnon √® altro che un ciclo for:\n\nCodicesum <- 0\nfor (n in 0:4) {\n  sum = sum + 3 * n\n}\nsum\n\n[1] 30\n\n\nIn maniera equivalente, e pi√π semplice, possiamo scrivere\n\nCodicesum(3 * (0:4))\n\n[1] 30\n\n\nAllo stesso modo, la notazione\n\\[\n\\prod_{n=1}^{4} 2n\n\\] √® anch‚Äôessa equivalente al ciclo for\n\nCodiceprod <- 1\nfor (n in 1:4) {\n  prod <- prod * 2 * n\n}\nprod\n\n[1] 384\n\n\nche si pu√≤ scrivere, pi√π semplicemente, come\n\nCodiceprod(2 * (1:4))\n\n[1] 384\n\n\nIn entrambi i casi precedenti, abbiamo sostituito le operazioni aritmetiche eseguite all‚Äôinterno di un ciclo for con le stesse operazioni aritmetiche eseguite sui vettori elemento per elemento."
  },
  {
    "objectID": "index.html#benvenuti",
    "href": "index.html#benvenuti",
    "title": "Data Science per psicologi",
    "section": "Benvenuti",
    "text": "Benvenuti\nQuesto √® il sito web per ‚ÄúData Science per psicologi‚Äù. Viene qui presentato il materiale delle lezioni dell‚Äôinsegnamento di Psicometria B000286 (A.A. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell‚ÄôUniversit√† degli Studi di Firenze. Lo scopo di questo insegnamento √® quello di fornire agli studenti un‚Äôintroduzione all‚Äôanalisi dei dati psicologici. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data Science applicata alla psicologia, ovvero, un insieme di conoscenze/competenze che si pongono all‚Äôintersezione tra psicologia, statistica e informatica."
  }
]