[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science per psicologi",
    "section": "",
    "text": "Questo è il sito web per “Data Science per psicologi”. Viene qui presentato il materiale delle lezioni dell’insegnamento di Psicometria B000286 (A.A. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze. Lo scopo di questo insegnamento è quello di fornire agli studenti un’introduzione all’analisi dei dati psicologici. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data Science applicata alla psicologia, ovvero, un insieme di conoscenze/competenze che si pongono all’intersezione tra psicologia, statistica e informatica."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Data Science per psicologi",
    "section": "License",
    "text": "License\nThis book was created by Corrado Caudek and is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Prefazione",
    "section": "",
    "text": "Questo libro ti insegnerà i principi base della Data Science, con esempi pratici.\nSembra sensato spendere due parole su una domanda che è importante per gli studenti: perché dobbiamo perdere tanto tempo a studiare l’analisi dei dati psicologici quando in realtà quello che ci interessa è tutt’altro? Questa è una bella domanda. C’è una ragione molto semplice che dovrebbe farci capire perché la Data Science sia così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della Data Science in psicologia: perché la Data Science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici.\nSono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data Science? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data Science. Le tematiche della Data Science non possono essere ignorate né dai ricercatori in psicologia né da coloro che svolgono la professione di psicologo al di fuori dell’Università. Infatti, anche i professionisti al di fuori dall’università non possono fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po’ di Data Science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo.\nLe considerazioni precedenti cercano di chiarire il seguente punto: la Data Science non è qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data Science in tantissimi ambiti della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di Data Science è un tassello imprescindibile del bagaglio professionale dello psicologo. In questo insegnamento verrano trattati i temi base della Data Science e verrà adottato un punto di vista bayesiano, che corrisponde all’approccio più recente e sempre più diffuso in psicologia."
  },
  {
    "objectID": "preface.html#come-studiare",
    "href": "preface.html#come-studiare",
    "title": "Prefazione",
    "section": "Come studiare",
    "text": "Come studiare\nIl giusto metodo di studio per prepararsi all’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. Incoraggio gli studenti a farmi domande per chiarire ciò che non è stato capito appieno. Incoraggio gli studenti a utilizzare i forum attivi su Moodle e, soprattutto, a svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di comprendere se le competenze sviluppate fino a quel punto sono sufficienti rispetto alle richieste dell’esame.\nLa prima fase dello studio, che è sicuramente individuale, è quella in cui lo studente deve acquisire le conoscenze teoriche relative ai problemi che saranno presentati all’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta lo studente ad acquisire la capacità di applicare le conoscenze: è necessario capire come usare un software (\\(\\textsf{R}\\)) per applicare i concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono però separate: il saper fare molto spesso aiuta a capire meglio."
  },
  {
    "objectID": "prob.html",
    "href": "prob.html",
    "title": "Parte 2: Il calcolo delle probabilità",
    "section": "",
    "text": "Nel capitolo Capitolo 1 verrà presentata la legge dei grandi numeri, il concetto di variabile casuale e la funzione di massa di probabilità."
  },
  {
    "objectID": "015_prob_intro.html",
    "href": "015_prob_intro.html",
    "title": "1  La logica dell’incerto",
    "section": "",
    "text": "In questa parte della dispensa verrà introdotta la teoria delle probabilità. Prima di entrare nei dettagli, cerchiamo di capire perché la probabilità sia cruciale per la ricerca scientifica.\nLa teoria delle probabilità è cruciale per la scienza perché la ricerca procede mediante l’inferenza induttiva. Non siamo mai completamente sicuri della verità di una proposizione (ipotesi, teoria): al valore di verità di una proposizione possiamo solo assegnare un giudizio probabilistico. L’approccio bayesiano è una scuola di pensiero che usa la probabilità per quantificare il grado di fiducia che può essere attribuito ad una proposizione. L’inferenza statistica bayesiana è un tipo di inferenza induttiva che ha lo scopo di quantificare la fiducia che si ha nell’ipotesi \\(H\\) dopo il verificarsi del dato d’evidenza \\(E\\). Per quantificare un tale grado di fiducia l’inferenza statistica bayesiana utilizza la teoria delle probabilità. Una comprensione dell’inferenza statistica bayesiana richiede dunque, preliminarmente, la conoscenze della teoria delle probabilità."
  },
  {
    "objectID": "015_prob_intro.html#che-cosè-la-probabilità",
    "href": "015_prob_intro.html#che-cosè-la-probabilità",
    "title": "1  La logica dell’incerto",
    "section": "\n1.1 Che cos’è la probabilità?",
    "text": "1.1 Che cos’è la probabilità?\nLa definizione della probabilità è un problema estremamente dibattuto ed aperto. Sono state fornite due possibili soluzioni al problema di definire il concetto di probabilità.\n\nLa natura della probabilità è “ontologica” (ovvero, basata sulla metafisica): la probabilità è una proprietà della della realtà, del mondo, di come sono le cose, indipendentemente dalla nostra esperienza. È una visione che qualcuno chiama “oggettiva”.\nLa natura della probabilità è “epistemica” (ovvero, basata sulla conoscenza): la probabilità si riferisce alla conoscenza che abbiamo del mondo, non al mondo in sé. Di conseguenza è detta, in contrapposizione alla precedente definizione, “soggettiva”.\n\nIn termini epistemici, la probabilità fornisce una misura della nostra incertezza sul verificarsi di un fenomeno, alla luce delle informazioni disponibili. Potremmo dire che c’è una “scala” naturale che ha per estremi il vero (1: evento certo) da una parte ed il falso (0: evento impossibile) dall’altra. La probabilità è la quantificazione di questa scala: descrive lo stato della nostra incertezza rispetto al contenuto di verità di una proposizione.\nL’incertezza nelle nostre previsioni può sorgere per due ragioni fondamentalmente diverse. Il primo è dovuto alla nostra ignoranza delle cause nascoste sottostanti o dei meccanismi che generano i dati. Questa è appunto un’incertezza epistemica. Il secondo tipo di incertezza deriva dalla variabilità intrinseca dei fenomeni, che non può essere ridotta anche se raccogliamo più dati. Questa seconda forma di incertezza è talvolta chiamata aleatoria. Come esempio concreto, consideriamo il lancio di una moneta equilibrata. Sappiamo con certezza che la probabilità di testa è \\(P = 0.5\\), quindi non c’è incertezza epistemica, ma non questo non è sufficiente per prevedere con certezza il risultato – ovvero, l’incertezza aleatoria persiste anche in assenza di incertezza epistemica.\nNell’interpretazione frequentista, la probabilità \\(P(E)\\) rappresenta la frequenza relativa a lungo termine di un grande numero di ripetizioni di un esperimento casuale sotto le medesime condizioni. Viene stressata qui l’idea che ciò di cui parliamo è qualcosa che emerge nel momento in cui è possibile ripetere l’esperimento casuale tante volte sotto le medesime condizioni – sono invece esclusi gli eventi unici e irripetibili.\n\n\nL’interpretazione bayesiana della probabilità fa invece ricorso ad una concezione più ampia, non legata al solo evento in sé ma che include anche il soggetto assegnante la funzione di probabilità. In pratica l’assegnazione di probabilità bayesiana viene effettuata dal decisore, in base alle proprie conoscenze a priori integrate con tutto il generico bagaglio culturale personale. In questo modo, la probabilità non sarà obbligatoriamente la stessa per tutti i soggetti, ma variarierà a seconda delle informazioni a disposizione, dell’esperienza personale e soprattutto del punto di vista proprio di ogni decisore ed è dunque assimilabile al “grado di fiducia” – in inglese degree of belief – di un dato soggetto, in un dato istante e con un dato insieme d’informazioni, circa l’accadere dell’evento \\(E\\). “[N]essuna scienza ci permetterà di dire: il tale fatto accadrà, andrà così e così, perché ciò è conseguenza di tale legge, e tale legge è una verità assoluta, ma tanto meno ci condurrà a concludere scetticamente: la verità assoluta non esiste, e quindi tale fatto può accadere e può non accadere, può andare così e può andare in tutt’altro modo, nulla io ne so. Quel che si potrà dire è questo: io prevedo che il tale fatto avverrà, e avverrà nel tal modo, perché l’esperienza del passato e l’elaborazione scientifica cui il pensiero dell’uomo l’ha sottoposta mi fanno sembrare ragionevole questa previsione” (Finetti, 1931).\nL’impostazione bayesiana, sviluppata da Ramsey e de Finetti, riconduce l’assegnazione di probabilità allo scommettere sul verificarsi di un evento: la probabilità di un evento \\(E\\) è la quota \\(p(E)\\) che un individuo reputa di dover pagare ad un banco per ricevere “1” ovvero “0” verificandosi o non verificandosi \\(E\\).\nSecondo De Finetti, le valutazioni di probabilità degli eventi devono rispondere ai principi di equità e coerenza. Una scommessa risponde al principio di equità se il ruolo di banco e giocatore sono scambiabili in ogni momento del gioco e sempre alle stesse condizioni. Una scommessa risponde al principio di coerenza se non vi sono combinazioni di scommesse che consentano (sia al banco che al giocatore) di realizzare perdite o vincite certe.\nL’approccio definettiano dell’impostazione della scommessa si basa dunque sulle assunzioni di razionalità e coerenza del decisore, al quale è fatto esplicito divieto di effettuare scommesse a perdita o guadagno certo. Il decisore, proponendo la scommessa, deve essere disposto a scambiare il posto dello scommettitore con quello del banco.\nIl metodo della scommessa, oltre che una definizione, fornisce un mezzo operativo di assegnazione della probabilità. Sulla base di questa definizione operativa, che si può ritenere ragionevolmente soddisfatta dal comportamento di un qualunque individuo che agisca in modo razionale in condizioni di incertezza, possono essere agevolmente dimostrate tutte le proprietà classiche della probabilità: essa non può assumere valori negativi, né può essere superiore all’unità; se \\(E\\) è un evento certo, la sua probabilità è 1; se invece \\(E\\) è un evento impossibile, la sua probabilità è 0.\nI problemi posti dall’approccio definettiano riguardano l’arbitrarietà dell’assegnazione soggettività di probabilità la quale sembra negare la validità dell’intero costrutto teorico. In risposta a tale critica, i bayesiani sostengono che gli approcci oggettivisti alla probabilità nascondono scelte arbitrarie preliminari e sono basate su assunzioni implausibili. È molto più onesto esplicitare subito tutte le scelte arbitrarie effettuate nel corso dell’analisi in modo da controllarne coerenza e razionalità."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali-e-probabilità-di-un-evento",
    "href": "015_prob_intro.html#variabili-casuali-e-probabilità-di-un-evento",
    "title": "1  La logica dell’incerto",
    "section": "\n1.2 Variabili casuali e probabilità di un evento",
    "text": "1.2 Variabili casuali e probabilità di un evento\nEsaminiamo qui di seguito alcuni concetti di base della teoria delle probabilità, la quale può essere vista come un’estensione della logica.\n\n1.2.1 Eventi e probabilità\nNella teoria delle probabilità il risultato “testa” nel lancio di una moneta è chiamato evento.1 Un evento, denotato da una variabile binaria, corrisponde ad uno stato del mondo che si verifica oppure no. Ad esempio, \\(Y\\) = 1 può denotare l’evento per cui il lancio di una moneta produce il risultato testa. Il funzionale \\(P(Y)\\) denota la probabilità con cui si ritiene che l’evento \\(Y\\) sia vero (o la proporzione di volte che si verifica tale evento osservando a lungo termine delle ripetizioni indipendenti di un esperimento casuale). Ad esempio, per il lancio di una moneta equilibrata, la probabilità dell’evento “il risultato del lancio della moneta è testa” è scritta come \\(P(Y = 1) = 0.5.\\)\nSe la moneta è equilibrata dobbiamo anche avere \\(P(Y = 0) = 0.5\\). I due eventi Y = 1 e \\(Y\\) = 0 sono mutuamente esclusivi nel senso che non possono entrambi verificarsi contemporaneamente: \\(P(Y = 1\\; \\land \\; Y = 0) = 0.\\) Gli eventi \\(Y\\) = 1 e \\(Y\\) = 0 di dicono esaustivi, nel senso che almeno uno di essi deve verificarsi e nessun altro tipo di evento è possibile. Nella notazione probabilistica, \\(P(Y = 1\\; \\lor \\; Y = 0) = 1.\\) Il connettivo logico “o” (\\(\\lor\\)) specifica eventi disgiunti, ovvero eventi che non possono verificarsi contemporaneamente (eventi incompatibili) e per i quali, perciò, la probabilità della loro congiunzione è \\(P(A \\; \\land \\; B) = 0\\). Il connettivo logico “e” (\\(\\land\\)), invece, specifica eventi congiunti, ovvero eventi che possono verificarsi contemporaneamente (eventi compatibili) e per i quali, perciò, la probabilità della loro congiunzione è \\(P(A \\; \\land \\; B) > 0\\). La probabilità del verificarsi di due eventi congiunti \\(A\\) e \\(B\\) si può denotare, in maniera equivalente, con la notazione precedente, oppure con \\(P(A \\cap B)\\), oppure con \\(P(A, B)\\).\nSi richiede che \\(0 \\leq P(A) \\leq 1\\), dove \\(P(A) = 0\\) denota l’evento impossibile e \\(P(A) = 1\\) denota l’evento certo. Scriviamo \\(P(\\lnot A)\\) o \\(P(\\bar{A})\\) per denotare la probabilità che l’evento \\(A\\) non avvenga; questa probabilità è definita come \\(P(\\bar{A}) = 1 − P(A)\\).\n\n1.2.2 Spazio campione e risultati possibili\nAnche se il lancio di una moneta produce sempre uno specifico risultato nel mondo reale, possiamo anche immaginare i possibili risultati alternativi che si sarebbero potuti osservare. Quindi, anche se in uno specifico lancio la moneta dà testa (\\(Y\\) = 1), possiamo immaginare la possibilità che il lancio possa avere prodotto croce (\\(Y\\) = 0). Tale ragionamento controfattuale è la chiave per comprendere la teoria delle probabilità e l’inferenza statistica.\nI risultati possibili che si possono osservare come conseguenza del lancio di una moneta determinano i valori possibili che la variabile casuale può assumere. L’insieme \\(\\Omega\\) di tutti i risultati possibili è chiamato spazio campione (sample space). Lo spazio campione può essere concettualizzato come un’urna contenente una pallina per ogni possibile risultato del lancio della moneta. Su ogni pallina è scritto il valore della variabile casuale. Uno specifico lancio di una moneta – ovvero, l’osservazione di uno specifico valore di una variabile casuale – è chiamato esperimento casuale.\nIl lancio di un dado ci fornisce l’esempio di un altro esperimento casuale. Supponiamo di essere interessati all’evento “il lancio del dado produce un numero dispari”. Un evento seleziona un sottoinsieme dello spazio campione: in questo caso, l’insieme dei risultati \\(\\{1, 3, 5\\}\\). Se esce 3, per esempio, diciamo che si è verificato l’evento “dispari” (ma l’evento “dispari” si sarebbe anche verificato anche se fosse uscito 1 o 5)."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali",
    "href": "015_prob_intro.html#variabili-casuali",
    "title": "1  La logica dell’incerto",
    "section": "\n1.3 Variabili casuali",
    "text": "1.3 Variabili casuali\nSia \\(Y\\) il risultato del lancio di moneta equilibrata, non di un generico lancio di una moneta, ma un’istanza specifica del lancio di una specifica moneta in un dato momento. Definita in questo modo, \\(Y\\) è una variabile casuale, ovvero una variabile i cui valori non possono essere previsti con esattezza. Se la moneta è equilibrata, c’è una probabilità del 50% che il lancio della moneta dia come risultato “testa” e una probabilità del 50% che dia come risultato “croce”. Per facilitare la trattazione, le variabili casuali assumono solo valori numerici. Per lo specifico lancio della moneta in questione, diciamo, ad esempio, che la variabile casuale \\(Y\\) assume il valore 1 se esce testa e il valore 0 se esce croce.\nUna variabile casuale può essere discreta o continua. Una variabile casuale discreta può assumere un numero finito di valori \\(x_1, \\dots ,x_n\\), in corrispondenza degli eventi \\(E_i, \\dots, E_n\\) che si verificano con le rispettive probabilità \\(p_1, \\dots, p_n\\). Un esempio è il punteggio totale di un test psicometrico costituito da item su scala Likert. Invece un esempio di una variabile casuale continua è la distanza tra due punti, che può assumere infiniti valori all’interno di un certo intervallo. L’insieme \\(S\\) dei valori che la variabile casuale può assumere è detto spazio dei valori o spazio degli stati.\nLa caratteristica fondamentale di una variabile casuale è data dall’insieme delle probabilità dei suoi valori, detta distribuzione di probabilità. Nel seguito useremo la notazione \\(P(\\cdot)\\) per fare riferimento alle distribuzioni di probabilità delle variabili casuali discrete e \\(p(\\cdot)\\) per fare riferimento alla densità di probabilità delle variabili casuali continue. In questo contesto, l’insieme dei valori che la variabile casuale può assumere è detto supporto della sua distribuzione di probabilità. Il supporto di una variabile casuale può essere finito (come nel caso di una variabile casuale uniforme di supporto \\([a, b]\\)) o infinito (nel caso di una variabile causale gaussiana il cui supporto coincide con la retta reale)."
  },
  {
    "objectID": "015_prob_intro.html#usare-la-simulazione-per-stimare-le-probabilità",
    "href": "015_prob_intro.html#usare-la-simulazione-per-stimare-le-probabilità",
    "title": "1  La logica dell’incerto",
    "section": "\n1.4 Usare la simulazione per stimare le probabilità",
    "text": "1.4 Usare la simulazione per stimare le probabilità\n\nIn questa dispensa verrà adottata l’interpretazione bayesiana delle probabilità. Tuttavia, le regole di base della teoria delle probabilità sono le stesse, indipendentemente dall’interpretazione adottata. Pertanto, negli esempi seguenti, possiamo utilizzare la simulazione per stimare le probabilità degli eventi in un modo diretto, ovvero mediante la generazione di molteplici osservazioni delle variabili casuali derivate dagli eventi di interesse.\nAd esempio, per simulare in R il lancio di una moneta equilibrata iniziamo con il definire un vettore che contiene i risultati possibili del lancio della moneta (ovvero i valori possibili della variabile casuale \\(Y\\)):\n\ncoin <- c(0, 1)\n\nL’estrazione casuale di uno di questi due possibili valori (ovvero, la simulazione di uno specifico lancio di una moneta) si realizza con la funzione sample():\n\nsample(coin, size = 1)\n#> [1] 0\n\nIn maniera equivalente, la stessa operazione si può realizzare mediante l’istruzione\n\nrbinom(1, 1, 0.5)\n#> [1] 1\n\nSupponiamo di ripetere questo esperimento casuale 100 volte e di registrare i risultati così ottenuti. La stima della probabilità dell’evento \\(P(Y = 1)\\) è data dalla frequenza relativa del numero di volte in cui abbiamo osservato l’evento di interesse (\\(Y = 1\\)):\n\nM <- 100\ny <- rep(NA, M)\nfor (m in 1:M) {\n  y[m] = rbinom(1, 1, 0.5)\n}\nestimate = sum(y) / M\n\ncat(\"estimated P[Y = 1] =\", estimate)\n#> estimated P[Y = 1] = 0.53\n\nRipetiamo questa procedura 10 volte.\n\nflip_coin <- function(M) {\n  y <- rep(NA, M)\n  for (m in 1:M) {\n    y[m] = rbinom(1, 1, 0.5)\n  }\n  estimate <- sum(y) / M\n  cat(\"estimated P[Y = 1] =\", estimate, \"\\n\")\n}\n\n\nfor(i in 1:10) {\n  flip_coin(100)\n}\n#> estimated P[Y = 1] = 0.44 \n#> estimated P[Y = 1] = 0.52 \n#> estimated P[Y = 1] = 0.46 \n#> estimated P[Y = 1] = 0.57 \n#> estimated P[Y = 1] = 0.47 \n#> estimated P[Y = 1] = 0.46 \n#> estimated P[Y = 1] = 0.48 \n#> estimated P[Y = 1] = 0.49 \n#> estimated P[Y = 1] = 0.47 \n#> estimated P[Y = 1] = 0.62\n\nDato che la moneta è equilibrata, la stima delle probabilità dell’evento \\(P(Y = 1)\\) è simile a al valore che ci aspettiamo, ovvero \\(P(Y = 1) = 0.5\\), ma il risultato ottenuto nelle simulazioni non è esatto. Proviamo ad aumentare il numero di lanci in ciascuna simulazione:\n\nfor(i in 1:10) {\n  flip_coin(1000)\n}\n#> estimated P[Y = 1] = 0.497 \n#> estimated P[Y = 1] = 0.529 \n#> estimated P[Y = 1] = 0.493 \n#> estimated P[Y = 1] = 0.511 \n#> estimated P[Y = 1] = 0.506 \n#> estimated P[Y = 1] = 0.52 \n#> estimated P[Y = 1] = 0.49 \n#> estimated P[Y = 1] = 0.495 \n#> estimated P[Y = 1] = 0.489 \n#> estimated P[Y = 1] = 0.496\n\nIn questo secondo caso, gli errori tendono ad essere più piccoli che nel caso precedente. Cosa succede se in ciascuna simulazione esaminiamo i risultati di 10,000 lanci della moneta?\n\nfor(i in 1:10) {\n  flip_coin(1e4)\n}\n#> estimated P[Y = 1] = 0.4885 \n#> estimated P[Y = 1] = 0.4957 \n#> estimated P[Y = 1] = 0.4902 \n#> estimated P[Y = 1] = 0.5032 \n#> estimated P[Y = 1] = 0.5048 \n#> estimated P[Y = 1] = 0.4931 \n#> estimated P[Y = 1] = 0.4965 \n#> estimated P[Y = 1] = 0.499 \n#> estimated P[Y = 1] = 0.4979 \n#> estimated P[Y = 1] = 0.4973\n\nOra le stime ottenute sono molto vicine alla vera probabilità che vogliamo stimare (cioè 0.5, perché la moneta è equilibrata).\nI risultati delle simulazioni precedenti pongono dunque il problema di determinare quale sia il numero di lanci di cui abbiamo bisogno per assicurarci che le stime siano accurate (ovvero, vicine al valore corretto della probabilità)"
  },
  {
    "objectID": "015_prob_intro.html#la-legge-dei-grandi-numeri",
    "href": "015_prob_intro.html#la-legge-dei-grandi-numeri",
    "title": "1  La logica dell’incerto",
    "section": "\n1.5 La legge dei grandi numeri",
    "text": "1.5 La legge dei grandi numeri\nLa visualizzazione mediante grafici contribuisce alla comprensione dei concetti della statistica e della teoria delle probabilità. Un modo per descrivere ciò che accade all’aumentare del numero \\(M\\) di ripetizioni del lancio della moneta consiste nel registrare la stima della probabilità dell’evento \\(P(Y = 1)\\) in funzione del numero di ripetizioni dell’esperimento casuale per ogni \\(m \\in 1:M\\). Possiamo ottenere un grafico dell’andamento della stima di \\(P(Y = 1)\\) in funzione di \\(m\\) nel modo seguente:\n\nnrep <- 1e4\nestimate <- rep(NA, nrep)\nflip_coin <- function(m) {\n  y <- rbinom(m, 1, 0.5)\n  phat <- sum(y) / m\n  phat\n}\nfor(i in 1:nrep) {\n  estimate[i] <- flip_coin(i)\n}\nd <- tibble(\n  n = 1:nrep, \n  estimate\n)\nd %>% \n  ggplot(aes(x = n, y = estimate)) +\n  geom_line() +\n  labs(\n    x = \"Numero di lanci della moneta\", \n    y = \"Stima di P(Y = 1)\"\n)\n\n\n\nFigura 1.1: Stima della probabilità di successo in funzione del numero dei lanci di una moneta.\n\n\n\n\nLa Figura 1.1, quando è espressa su una scala lineare, non rivela chiaramente l’andamento della simulazione. Imponiamo dunque una scala logaritmica sull’asse delle ascisse (\\(x\\)). Su scala logaritmica, i valori tra 1 e 10 vengono tracciati all’incirca con la stessa ampiezza che si osserva tra i valori 50 e 700, eccetera.\n\nd %>%\n  ggplot(aes(x = n, y = estimate)) +\n  geom_line() +\n  geom_hline(\n    yintercept = 0.5, color = \"gray\", size = 1\n  ) +\n  scale_x_log10(\n    breaks = c(\n      1, 3, 10, 50, 200,\n      700, 2500, 10000\n    )\n  ) +\n  labs(\n    x = \"Numero dei lanci della moneta (scala logaritmica)\",\n    y = \"Stima di P(Y = 1)\"\n  )\n\n\n\nFigura 1.2: Stima della probabilità di successo in funzione del numero dei lanci di una moneta.\n\n\n\n\nLa legge dei grandi numeri ci dice che, all’aumentare del numero di ripetizioni dell’esperimento casuale, la media dei risultati ottenuti tende al valore atteso, man mano che vengono eseguite più prove. Nella figura Figura 1.2 vediamo infatti che, all’aumentare del numero M di lanci della moneta, la stima di \\(P(Y = 1)\\) converge al valore 0.5."
  },
  {
    "objectID": "015_prob_intro.html#variabili-casuali-multiple",
    "href": "015_prob_intro.html#variabili-casuali-multiple",
    "title": "1  La logica dell’incerto",
    "section": "\n1.6 Variabili casuali multiple",
    "text": "1.6 Variabili casuali multiple\nLe variabili casuali non esistono isolatamente. Abbiamo iniziato con una sola variabile casuale \\(Y\\) che rappresenta il risultato di un singolo, specifico lancio di una moneta equlibrata. Ma supponiamo ora di lanciare la moneta tre volte. I risultati di ciascuno dei tre lanci possono essere rappresentati da una diversa variabile casuale, ad esempio, \\(Y_1 , Y_2 , Y_3\\). Possiamo assumere che ogni lancio sia indipendente, ovvero che non dipenda dal risultato degli altri lanci. Per ciascuna di queste variabili \\(Y_n\\), con \\(n \\in 1:3\\), abbiamo che \\(P(Y_n =1)=0.5\\) e \\(P(Y_n =0)=0.5\\).\nÈ possibile combinare più variabili casuali usando le operazioni aritmetiche. Se \\(Y_1 , Y_2, Y_3\\) sono variabili casuali che rappresentano tre lanci di una moneta equilibrata (o un lancio di tre monete equilibrate), possiamo definire la somma di tali variabili casuali come\n\\[\nZ = Y_1 + Y_2 + Y_3.\n\\]\nPossiamo simulare i valori assunti dalla variabile casuale Z simulando i valori di \\(Y_1, Y_2, Y_3\\) per poi sommarli.\n\ny1 <- rbinom(1, 1, 0.5)\ny2 <- rbinom(1, 1, 0.5)\ny3 <- rbinom(1, 1, 0.5)\nc(y1, y2, y3)\n#> [1] 1 0 1\nz <- sum(c(y1, y2, y3))\ncat(\"z =\", z, \"\\n\")\n#> z = 2\n\novvero,\n\ny <- rep(NA, 3)\nfor (i in 1:3) {\n  y[i] <- rbinom(1, 1, 0.5)\n}\ny\n#> [1] 0 1 1\nz <- sum(y)\ncat(\"z =\", z, \"\\n\")\n#> z = 2\n\noppure, ancora più semplicemente:\n\ny <- rbinom(3, 1, 0.5)\ny\n#> [1] 1 0 1\nz <- sum(y)\ncat(\"z =\", z, \"\\n\")\n#> z = 2\n\nPossiamo ripetere questa simulazione \\(M = 1e5\\) volte:\n\nM <- 1e5\nz <- rep(NA, M)\nfor(i in 1:M) {\n  y <- rbinom(3, 1, 0.5)\n  z[i] <- sum(y)\n}\n\ne calcolare una stima della probabilità che la variabile casuale \\(Z\\) assuma ciascuno dei possibili valori 0, 1, 2, 3:\n\ntable(z) / M\n#> z\n#>       0       1       2       3 \n#> 0.12585 0.37495 0.37480 0.12440\n\nNel caso di 4 monete equilibrate, avremo:\n\nM <- 1e5\nz <- rep(NA, M)\nfor(i in 1:M) {\n  y <- rbinom(4, 1, 0.5)\n  z[i] <- sum(y)\n}\ntable(z) / M\n#> z\n#>       0       1       2       3       4 \n#> 0.06340 0.24917 0.37360 0.25022 0.06361\n\nUna variabile casuale le cui modalità possono essere costituite solo da numeri interi è detta variabile casuale discreta:\n\\[\n\\mathbb{Z} = \\dots, -2, -1, 0, 1, 2, \\dots\n\\]"
  },
  {
    "objectID": "015_prob_intro.html#sec:fun-mass-prob",
    "href": "015_prob_intro.html#sec:fun-mass-prob",
    "title": "1  La logica dell’incerto",
    "section": "\n1.7 Funzione di massa di probabilità",
    "text": "1.7 Funzione di massa di probabilità\nÈ conveniente avere una funzione che associa una probabilità a ciascun possibile valore di una variabile casuale. In generale, ciò è possibile se e solo se la variabile casuale è discreta, così com’è stata definita nel Paragrafo precedente. Ad esempio, se consideriamo \\(Z = Y_1 + \\dots + Y_4\\) come, ad esempio, il numero di risultati “testa” in 4 lanci della moneta, allora possiamo definire la seguente funzione:\n\\[\n\\begin{array}{rclll}\np_Z(0) & = & 1/16 & & \\mathrm{TTTT}\n\\\\\np_Z(1) & = & 4/16 & & \\mathrm{HTTT, THTT, TTHT, TTTH}\n\\\\\np_Z(2) & = & 6/16 & & \\mathrm{HHTT, HTHT, HTTH, THHT, THTH, TTTH}\n\\\\\np_Z(3) & = & 4/16 & & \\mathrm{HHHT, HHTH, HTHH, THHH}\n\\\\\np_Z(4) & = & 1/16 & & \\mathrm{HHHH}\n\\end{array}\n\\]\nIl lancio di quattro monete può produrre 16 risultati possibili. Dato che i lanci sono indipendenti, se le monete sono equilibrate ogni possibile risultato è ugualmente probabile. Nella tabella in alto, le sequenze dei risultati possibili del lancio delle 4 monete sono riportate nella colonna più a destra. Le probabilità si ottengono dividendo il numero di sequenze che producono lo stesso numero di eventi testa per il numero dei risultati possibili.\nLe sequenze come \\(\\mathrm{TTTT}\\), \\(\\mathrm{HTTT}\\), ecc. sono chiamate “eventi elementari” (corrispondono ad un possibile esito dell’esperimento casuale). L’evento \\(Z = u\\), con \\(u \\in 0 \\dots, 4\\) è un “evento composto”, il quale può essere costituito da più eventi elementari.\nLa funzione \\(p_Z\\) è stata costruita per associare a ciascun valore \\(u\\) della variabile casuale \\(Z\\) la probabilità dell’evento \\(Z = u\\). Convenzionalmente, queste probabilità sono scritte come\n\\[\nP_Z(z) = P(Z = z).\n\\]\nLa parte a destra dell’uguale si può leggere come: “la probabilità che la variabile casuale \\(Z\\) assuma il valore \\(z\\)”. Una funzione definita come sopra è detta funzione di massa di probabilità della variabile casuale \\(Z\\). Ad ogni variabile casuale discreta è associata un’unica funzione di massa di probabilità.\nUna rappresentazione grafica della stima della funzione di massa di probabilità per l’esperimento casuale del lancio di quattro monete equilibrate è fornita nella Figura 1.3.\n\nset.seed(1234)\nM <- 1e5\nnflips <- 4\nu <- rbinom(M, nflips, 0.5)\nx <- 0:nflips\ny <- rep(NA, nflips + 1)\nfor (n in 0:nflips) {\n  y[n + 1] <- sum(u == n) / M\n}\nbar_plot <-\n  data.frame(Z = x, count = y) %>%\n  ggplot(aes(x = Z, y = count)) +\n  geom_bar(stat = \"identity\") +\n  scale_x_continuous(\n    breaks = 0:4,\n    labels = c(0, 1, 2, 3, 4)\n  ) +\n  labs(\n    y = \"Probabilità stimata P(Z = z)\"\n  )\nbar_plot\n\n\n\nFigura 1.3: Grafico di \\(M = 100,000\\) simulazioni della funzione di massa di probabilità di una variabile casuale definita come il numero di teste in quattro lanci di una moneta equilibrata.\n\n\n\n\nSe \\(A\\) è un sottoinsieme della variabile casuale \\(Z\\), allora denotiamo con \\(P_{z}(A)\\) la probabilità assegnata ad \\(A\\) dalla distribuzione \\(P_{z}\\). Mediante una distribuzione di probabilità \\(P_{z}\\) è dunque possibile determinare la probabilità di ciascun sottoinsieme \\(A \\subset Z\\) come\n\\[\\begin{equation}\nP_{z}(A) = \\sum_{z \\in A} P_{z}(Z = z).\n\\end{equation}\\]\nUna funzione di massa di probabilità soddisfa le proprietà\n\n\n\\(0 \\leq P(X=x) \\leq 1\\),\n\n\\(\\sum_{x \\in X} P(x) = 1\\).\n\n\nNel caso dell’esempio discusso nel Paragrafo @ref(sec:fun-mass-prob), la probabilità che la variabile casuale \\(Z\\) sia un numero dispari è\n\\[\nP(\\text{Z è un numero dispari}) = P_{z}(Z = 1) + P_{z}(Z = 3) = \\frac{4}{16} + \\frac{4}{16} = \\frac{1}{2}.\n\\]\n\n\n1.7.1 Funzione di ripartizione\nData una variabile casuale discreta \\(X\\) possiamo calcolare la probabilità che \\(X\\) non superi un certo valore \\(x\\), ossia la sua funzione di ripartizione. Poichè \\(X\\) assume valori discreti possiamo cumulare le probabilità mediante una somma:\n\\[\nF(x_k) = P(X \\leq x_k) = \\sum_{x \\leq x_k} P(x).\n\\]"
  },
  {
    "objectID": "015_prob_intro.html#commenti-e-considerazioni-finali",
    "href": "015_prob_intro.html#commenti-e-considerazioni-finali",
    "title": "1  La logica dell’incerto",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn questo capitolo abbiamo visto come si costruisce lo spazio campione di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campione discreto. Abbiamo anche introdotto le nozioni di variabile casuale, ovvero di una variabile che assume i suoi valori in maniera casuale. Abbiamo descritto il modo di specificare la probabilità con cui sono una variabile casuale assume i suoi differenti valori, ovvero la funzione di ripartizione \\(F(X) = P(X < x)\\) e la funzione di massa di probabilità.\n\n\n\n\nFinetti, B. de. (1931). Probabilismo. Logos, 163–219."
  },
  {
    "objectID": "016_conditional_prob.html",
    "href": "016_conditional_prob.html",
    "title": "2  Probabilità condizionata",
    "section": "",
    "text": "Il fondamento della statistica bayesiana è il teorema di Bayes e il teorema di Bayes è una semplice ridescrizione della probabilità condizionata. Esaminiamo dunque la nozione di probabilità condizionata."
  },
  {
    "objectID": "016_conditional_prob.html#sec-bayes-cancer",
    "href": "016_conditional_prob.html#sec-bayes-cancer",
    "title": "2  Probabilità condizionata",
    "section": "\n2.1 Probabilità condizionata su altri eventi",
    "text": "2.1 Probabilità condizionata su altri eventi\nL’attribuzione di una probabilità ad un evento è sempre condizionata dalle conoscenze che abbiamo a disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilità di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà anche la probabilità che attribuiremo all’evento in questione. Infatti, si può pensare che tutte le probabilità siano probabilità condizionate, anche se l’evento condizionante non è sempre esplicitamente menzionato.\nPer introdurre la probabilità condizionata, Albert & Hu (2019) utilizzando il famoso paradosso delle tre carte. “Ci sono tre carte, delle quali la prima (\\(A\\)) è rossa su entrambi i lati, la seconda (\\(B\\)) su un lato è rossa e sull’altro è bianca e la terza (\\(C\\)) è bianca su entrambi i lati. Ponendo su un tavolo una delle tre carte, scelta a caso, ottengo che il lato visibile è di colore rosso. Qual è la probabilità che anche il lato non visibile sia di colore rosso? La risposta intuitiva porta solitamente a rispondere che la probabilità ricercata sia pari al 50%, in quanto solo due carte (la \\(A\\) e la \\(B\\)) possono mostrare il colore rosso e solo una di queste (la \\(A\\)) può mostrare anche sull’altro lato il colore rosso; tuttavia si dimostra che la risposta giusta è 2/3.” (da Wikipedia)\nAlbert & Hu (2019) propongono di risolvere il problema con una simulazione in \\(\\textsf{R}\\): prima di tutto si sceglie una carta a caso, e poi si sceglie un lato della carta. Ci sono tre carte possibili, che chiamiamo “c_rossa”, “c_bianca”, e “c_entrambi”. Per la carta rossa, ci sono due lati rossi; per la carta bianca ci sono due lati bianchi e la carta “entrambi” ha un lato rosso e un lato bianco.\n\ndf <- tibble(\n  Carta = c(\n    \"c_rossa\", \"c_rossa\", \"c_bianca\", \"c_bianca\", \"c_entrambi\", \n    \"c_entrambi\"\n  ),\n  Lato = c(\n    \"rosso\", \"rosso\", \"bianco\", \"bianco\", \"rosso\", \"bianco\"\n  )\n)\ndf\n#> # A tibble: 6 × 2\n#>   Carta      Lato  \n#>   <chr>      <chr> \n#> 1 c_rossa    rosso \n#> 2 c_rossa    rosso \n#> 3 c_bianca   bianco\n#> 4 c_bianca   bianco\n#> 5 c_entrambi rosso \n#> 6 c_entrambi bianco\n\nEstraiamo una carta a caso e classifichiamo il risultato ottenuto in base al tipo di carta e lato osservato. Ripetiamo l’esperimento 1,000 volte:\n\nset.seed(84735)\ncarte <- sample_n(df, 1e3, replace = TRUE)\ntable(carte$Carta, carte$Lato)\n#>             \n#>              bianco rosso\n#>   c_bianca      353     0\n#>   c_entrambi    143   160\n#>   c_rossa         0   344\n\nSe si osserva il colore rosso (seconda colonna nella tabella precedente), questo risultato è dovuto ad una carta \\(A\\) (“rossa”) in 344 casi e ad una carta \\(B\\) (“entrambi”) in 160 casi. Quindi, nella simulazione il risultato per cui è stato osservato un colore rosso (344 + 160) è associato ad una carta \\(A\\) (“rossa”) in circa 2/3 dei casi – se il lato visibile è di colore rosso, allora c’è una probabilità di 2/3 che anche il lato non visibile sia di colore rosso.\nQuesto esempio dimostra come le nostre intuizioni a proposito della probabilità condizionata non sono sempre corrette. Consideriamo un altro problema più articolato.\n\nEsempio 2.1 \nSupponiamo che lo screening per la diagnosi precoce del tumore mammario si avvalga di un test che è accurato al 90%, nel senso che classifica correttamente il 90% delle donne colpite dal cancro e il 90% delle donne che non hanno il cancro al seno. Supponiamo che l’1% delle donne sottoposte allo screening abbia effettivamente il cancro al seno (e d’altra parte, il 99% non lo ha). Ci chiediamo: (1) qual è la probabilità che una donna scelta a caso ottenga una mammografia positiva, e (2) se la mammografia è positiva, qual è la probabilità che vi sia effettivamente un tumore al seno?\n\n\nSoluzione. Per risolvere questo problema, supponiamo che il test in questione venga somministrato ad un grande campione di donne, diciamo a 1000 donne. Di queste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste 10 donne, il test darà un risultato positivo in 9 casi (ovvero, nel 90% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test darà un risultato positivo in 99 casi (se la probabilità di un vero positivo è del 90%, la probabilità di un falso positivo è del 10%). Questa situazione è rappresentata nella figura Figura 2.1.\nCombinando i due risultati precedenti, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 11%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilità di essere una donna che ha veramente il cancro al seno, dato un risultato positivo al test (che ha le proprietà descritte sopra), è pari a \\(\\frac{9}{108}\\) = 8%.\n\n\n\n\nFigura 2.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne.\n\n\n\n\n\nNell’esercizio precedente, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha prodotto un risultato positivo” è una probabilità condizionata.\nIn termini generali, la probabilità condizionata \\(P(A \\mid B)\\) rappresenta la probabilità che si verifichi l’evento \\(A\\) sapendo che si è verificato l’evento \\(B\\). Arriviamo dunque alla seguente definizione.\n\nDefinition 2.1 Dato un qualsiasi evento \\(A\\), si chiama probabilità condizionata di \\(A\\) dato \\(B\\) il numero\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) > 0,\n\\tag{2.1}\\]\ndove \\(P(A\\cap B)\\) è la probabilità congiunta dei due eventi, ovvero la probabilità che si verifichino entrambi.\n\nConcludiamo con un problema molto semplice per consolidare la nostra comprensione del concetto di probabilità condizionata.\n\nEsempio 2.2 \nDa un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta una in modo casuale. Qual è la probabilità che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la probabilità che il valore numerico della carta sia 7, 8 o 9?\n\n\nSoluzione. Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4. Questa è una probabilità non condizionata, dunque il suo calcolo non presenta alcuna difficoltà. La seconda probabilità cercata è una probabilità condizionata. Anche in questo secondo caso dobbiamo solo contare, ma, in questo caso, considerando solo un sottoinsieme di carte, ovvero le 13 carte di cuori. In questo modo è facile arrivare al risultato cercato, ovvero 3/13. Applicando la formula Equazione 2.1, con \\(A\\) = 7, 8, o 9 e \\(B\\) = cuori, arriviamo allo stesso risulato:\n\\[\nP(A \\mid B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{3/52}{13/52} = \\frac{3}{13}.\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#la-regola-moltiplicativa",
    "href": "016_conditional_prob.html#la-regola-moltiplicativa",
    "title": "2  Probabilità condizionata",
    "section": "\n2.2 La regola moltiplicativa",
    "text": "2.2 La regola moltiplicativa\nDalla definizione di probabilità condizionata (Equazione 2.1) è possibile esprimere la probabilità congiunta tramite le condizionate. La regola moltiplicativa (o legge delle probabilità composte, o regola della catena) afferma che la probabilità che si verifichino due eventi \\(A\\) e \\(B\\) è pari alla probabilità di uno dei due eventi moltiplicato con la probabilità dell’altro evento condizionato al verificarsi del primo:\n\\[\nP(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A).\n\\tag{2.2}\\]\nLa Equazione 2.2 si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\nP\\left( \\bigcap_{k=1}^n A_k \\right) = \\prod_{k=1}^n P\\left(  A_k  \\ \\Biggl\\lvert \\ \\bigcap_{j=1}^{k-1} A_j \\right)\n\\tag{2.3}\\]\nPer esempio, nel caso di quattro eventi abbiamo\n\\[\n\\begin{split}\nP(A_1 \\cap A_2 \\cap A_3 \\cap A_4) = {}& P(A_1) \\cdot P(A_2 \\mid A_1) \\cdot  P(A_3 \\mid A_1 \\cap A_2) \\cdot \\\\\n& P(A_4 \\mid A_1 \\cap A_2 \\cap A_{3}).\\notag\n\\end{split}\n\\]\n\nEsempio 2.3 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e, per l’Equazione 2.2, la sua probabilità vale\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:\n\\[\nP(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nIn modo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]\nSe l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche, per la Equazione 2.3, vale\n\\[\nP(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2),\n\\]\ndove la probabilità \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che si sia verificato l’evento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio campionario per questa probabilità condizionata è costituito da 4 palline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e quindi:\n\\[\nP (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8}  = \\frac{1}{6}.\n\\]\nLa probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\\n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#lindipendendenza-stocastica",
    "href": "016_conditional_prob.html#lindipendendenza-stocastica",
    "title": "2  Probabilità condizionata",
    "section": "\n2.3 L’indipendendenza stocastica",
    "text": "2.3 L’indipendendenza stocastica\nUn concetto molto importante per le applicazioni statistiche della probabilità è quello dell’indipendenza stocastica. L’Equazione 2.1 consente di esprimere il concetto di indipendenza di un evento da un altro in forma intuitiva: se \\(A\\) e \\(B\\) sono eventi indipendenti, allora il verificarsi di \\(A\\) non influisce sulla probabilità del verificarsi di \\(B\\), ovvero non la condiziona, e il verificarsi di \\(B\\) non influisce sulla probabilità del verificarsi di \\(A\\). Infatti, per l’Equazione 2.1, si ha che, se \\(A\\) e \\(B\\) sono due eventi indipendenti, risulta:\n\\[\nP(A \\mid B) = \\frac{P(A)P(B)}{P(B)} = P(A),\n\\]\n\\[\nP(B \\mid A) = \\frac{P(A)P(B)}{P(A)} = P(B).\n\\]\nPossiamo dunque dire che due eventi \\(A\\) e \\(B\\) sono indipendenti se\n\\[\n\\begin{split}\nP(A \\mid B) &= P(A), \\\\\nP(B \\mid A) &= P(B).\n\\end{split}\n\\]\n\nEsempio 2.4 Nel lancio di due dadi non truccati, si considerino gli eventi: \\(A\\) = {esce un 1 o un 2 nel primo lancio} e \\(B\\) = {il punteggio totale è 8}. Gli eventi \\(A\\) e \\(B\\) sono indipendenti?\nRappresentiamo qui sotto lo spazio campione dell’esperimento casuale.\n\n\n\n\nRappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento \\(B\\): ‘il punteggio totale è 8’.\n\n\n\n\nGli eventi \\(A\\) e \\(B\\) non sono statisticamente indipendenti. Infatti, le loro probabilità valgono \\(P(A) = 12/36\\) e \\(P(B) = 5/36\\) e la probabilità della loro intersezione è\n\\[\nP(A \\cap B) = 1/36 = 3/108 \\neq P(A)P(B) = 5/108.\n\\]\n\n\nNota. Il concetto di indipendenza è del tutto differente da quello di incompatibilità. Si noti infatti che due eventi A e B incompatibili (per i quali si ha \\(A \\cap B = \\emptyset\\)) sono statisticamente dipendenti, poiché il verificarsi dell’uno esclude il verificarsi dell’altro: \\(P(A \\cap B)=0 \\neq P(A)P(B)\\)."
  },
  {
    "objectID": "016_conditional_prob.html#il-teorema-della-probabilità-totale",
    "href": "016_conditional_prob.html#il-teorema-della-probabilità-totale",
    "title": "2  Probabilità condizionata",
    "section": "\n2.4 Il teorema della probabilità totale",
    "text": "2.4 Il teorema della probabilità totale\nDato un insieme finito \\(A_i\\) di eventi, nel calcolo della probabilità dell’unione di tutti gli eventi, se gli eventi considerati non sono a due a due incompatibili, si deve tenere conto delle loro intersezioni. In particolare, la probabilità dell’unione di due eventi \\(A\\) e \\(B\\) è pari alla somma delle singole probabilità \\(P(A)\\) e \\(P(B)\\) diminuita della probabilità della loro intersezione:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A \\cap B).\n\\tag{2.4}\\]\nNel caso di tre eventi, si ha\n\\[\n\\begin{split}\nP(A \\cup B \\cup C) &= P(A)+P(B)+P(C)-P(A\\cap B)-P(A\\cap C) - \\\\\n& \\qquad P(B\\cap C) + P(A\\cap B\\cap C).\n\\end{split}\n\\]\nLa formula per il caso di \\(n\\) eventi si ricava per induzione.\nPer il caso di due soli eventi, se \\(A\\) e \\(B\\) sono indipendenti, l’Equazione 2.4 si modifica nella relazione seguente:\n\\[\nP(A \\cup B) = P(A) + P(B) - P(A)P(B).\n\\]\nNel caso di due eventi \\(A\\) e \\(B\\) incompatibili, se cioè \\(P(A \\cap B) = \\varnothing\\), si ha che\n\\[\nA\\cap B=\\varnothing \\Rightarrow P(A\\cup B)=P(A)+P(B).\n\\]\nSi può dimostrare per induzione che ciò vale anche per un insieme finito di eventi \\(A_{n}\\) a due a due incompatibili, ovvero che:\n\\[\nA_i\\cap A_j=\\varnothing, i\\neq j \\Rightarrow P\\left(\\bigcup_{i=1}^n A_i\\right)=\\sum_{i=1}^nP(A_i).\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#il-teorema-della-probabilità-assoluta",
    "href": "016_conditional_prob.html#il-teorema-della-probabilità-assoluta",
    "title": "2  Probabilità condizionata",
    "section": "\n2.5 Il teorema della probabilità assoluta",
    "text": "2.5 Il teorema della probabilità assoluta\nIl teorema della probabilità assoluta consente di calcolare la probabilità di un evento \\(E\\) di cui sono note le probabilità condizionate rispetto ad altri eventi \\((H_i)_{i\\geq 1}\\), a condizione che essi costituiscano una partizione dell’evento certo \\(\\Omega\\), ovvero\n\n\n\\(\\bigcup_{i=1}^\\infty H_i = \\Omega\\);\n\n\\(H_j \\cap H_j = \\emptyset, i\\neq j\\);\n\n\\(P(H_i) > 0, i = 1, \\dots, \\infty\\).\n\nNel caso di una partizione dello spazio campione in \\(n\\) sottoinsiemi abbiamo\n\\[\nP(E) = \\sum_{i=1}^n P(H_i\\cap E) = \\sum_{i=1}^n P(E \\mid H_i) P(H_i).\n\\]\nConsideriamo, ad esempio, una partizione dell’evento certo in tre sottoinsiemi.\n\n\n\n\nPartizione dell’evento certo \\(\\Omega\\) in tre sottoinsiemi sui quali viene definito l’evento \\(E\\).\n\n\n\n\nIn tali circostanze si ha che\n\\[\nP(E) = P(E \\cap H_1) + P(E \\cap H_2) + P(E \\cap H_3),\n\\tag{2.5}\\]\novvero\n\\[\nP(E) = P(E \\mid H_1) P(H_1) + P(E \\mid H_2) P(H_2) + P(E \\mid H_3) P(H_3).\n\\tag{2.6}\\]\nIn base al teorema della probabilità assoluta, dunque, se l’evento \\(E\\) è costituito da tutti gli eventi elementari in \\(E \\cap H_1\\), \\(E \\cap H_2\\) e \\(E \\cap H_3\\), allora la sua probabilità è data dalla somma delle probabilità condizionate \\(P(E \\mid H_i)\\), ciascuna delle quali pesata per la probabilità dell’evento condizionante \\(H_i\\).\n\nEsempio 2.5 Si considerino tre urne, ciascuna delle quali contiene 100 palline:\n\nUrna 1: 75 palline rosse e 25 palline blu,\nUrna 2: 60 palline rosse e 40 palline blu,\nUrna 3: 45 palline rosse e 55 palline blu.\n\nUna pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?\n\n\nSoluzione. Sia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\quad P(R \\mid U_2) = 0.60, \\quad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campione in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, ovvero \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità assoluta, la probabilità di estrarre una pallina rossa è dunque\n\\[\n\\begin{split}\nP(R) &= P(R \\mid U_1)P(U_1) + P(R \\mid U_2)P(U_2) + P(R \\mid U_3)P(U_3) \\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} \\\\\n&=0.60.\n\\end{split}\n\\]"
  },
  {
    "objectID": "016_conditional_prob.html#indipendenza-condizionale",
    "href": "016_conditional_prob.html#indipendenza-condizionale",
    "title": "2  Probabilità condizionata",
    "section": "\n2.6 Indipendenza condizionale",
    "text": "2.6 Indipendenza condizionale\nAggiungo qui delle considerazioni sul concetto di indipendenza condizionale a cui si farà riferimento nell’ultima parte della dispensa. L’indipendenza condizionale descrive situazioni in cui un’osservazione è irrilevante o ridondante quando si valuta la certezza di un’ipotesi. L’indipendenza condizionale è solitamente formulata nei termini della probabilità condizionata, come un caso speciale in cui la probabilità dell’ipotesi data un’osservazione non informativa è uguale alla probabilità senza tale osservazione non informativa.\nSe \\(A\\) è l’ipotesi e \\(B\\) e \\(C\\) sono osservazioni, l’indipendenza condizionale può essere espressa come l’uguaglianza:\n\\[\nP(A \\mid B,C)=P(A \\mid C).\n\\]\nDato che \\(P(A \\mid B,C)\\) è uguale a \\(P(A \\mid C)\\), questa uguaglianza corrisponde all’affermazione che \\(B\\) non fornisce alcun contributo alla certezza di \\(A\\). In questo caso si dice che \\(A\\) e \\(B\\) condizionalmente indipendenti dato \\(C\\), scritto simbolicamente come: \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\).\nIn maniera equivalente, l’indipendenza condizionale \\((A \\perp\\!\\!\\!\\!\\perp B \\mid C)\\) si verifica se:\n\\[\nP(A, B \\mid C) = P(A \\mid C) P(B \\mid C).\n\\]\nUn esempio è il seguente (da Wikipedia). Siano due eventi le probabilità che le persone \\(A\\) e \\(B\\) tornino a casa in tempo per la cena, e il terzo evento è il fatto che una tempesta di neve ha colpito la città. Mentre sia \\(A\\) che \\(B\\) hanno una probabilità più piccola di tornare a casa in tempo per la cena di quando non c’è la neve, tali probabilità sono indipendenti l’una dall’altra. Cioè, sapere che \\(A\\) è in ritardo non ci dice nulla sul fatto che \\(B\\) sia in ritardo o meno – \\(A\\) e \\(B\\) potrebbero vivere in quartieri diversi, percorrere distanze diverse e utilizzare mezzi di trasporto diversi. Tuttavia, se sapessimo che \\(A\\) e \\(B\\) vivono nello stesso quartiere, usano lo stesso mezzo di trasporto e lavorano nello stesso luogo, allora i due eventi non sarebbero condizionatamente indipendenti."
  },
  {
    "objectID": "016_conditional_prob.html#commenti-e-considerazioni-finali",
    "href": "016_conditional_prob.html#commenti-e-considerazioni-finali",
    "title": "2  Probabilità condizionata",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nLa probabilità condizionata è importante perché ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle domande più importanti delle analisi statistiche è infatti quella che si chiede se due variabili siano associate tra loro oppure no. In questo Capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione). In seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili.\n\n\n\n\nAlbert, J., & Hu, J. (2019). Probability and bayesian modeling. Chapman; Hall/CRC."
  },
  {
    "objectID": "017_bayes_theorem.html",
    "href": "017_bayes_theorem.html",
    "title": "3  L’interpretazione soggettivista della probabilità",
    "section": "",
    "text": "Il teorema di Bayes assume un ruolo fondamentale nell’interpretazione soggettivista della probabilità perchè descrive l’aggiornamento della credenza che si aveva nel verificarsi dell’ipotesi \\(H\\) (quantificata con la probabilità assegnata all’ipotesi) in conseguenza del verificarsi dell’evidenza \\(E\\)."
  },
  {
    "objectID": "017_bayes_theorem.html#il-teorema-di-bayes",
    "href": "017_bayes_theorem.html#il-teorema-di-bayes",
    "title": "3  L’interpretazione soggettivista della probabilità",
    "section": "\n3.1 Il teorema di Bayes",
    "text": "3.1 Il teorema di Bayes\n\nTeorema 3.1 Sia \\((H_i)_{i\\geq 1}\\) una partizione dell’evento certo \\(\\Omega\\) e sia \\(E \\subseteq \\Omega\\) un evento tale che \\(P(E) > 0\\), allora, per \\(i = 1, \\dots, \\infty\\):\n\\[\n{\\mbox{P}}(H_i \\mid E) = \\frac{{\\mbox{P}}(E \\mid H_i){\\mbox{P}}(H_i)}{\\sum_{j=1}^{\\infty}{\\mbox{P}}(H_j)P(E \\mid H_j)}.\n\\tag{3.1}\\]\n\nL’Equazione 3.1 contiene tre concetti fondamentali. I primi due distinguono il grado di fiducia precedente al verificarsi dell’evidenza \\(E\\) da quello successivo al verificarsi dell’evidenza \\(E\\). Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega,\\) si definisce\n\n\nprobabilità a priori, \\(P(H)\\), la probabilità attribuita al verificarsi dell’ipotesi \\(H\\) prima di sapere che si è verificato l’evento \\(E\\);\n\nprobabilità a posteriori, \\(P(H \\mid E)\\), la probabilità assegnata ad \\(H\\) una volta che sia noto \\(E\\), ovvero l’aggiornamento della probabilità a priori alla luce della nuova evidenza \\(E\\).\n\nIl terzo concetto definisce la probabilità che ha l’evento \\(E\\) di verificarsi quando è vera l’ipotesi \\(H\\), ovvero la probabilità dell’evidenza in base all’ipotesi. Pertanto, dati gli eventi \\(H, E \\subseteq \\Omega\\) si definisce\n\n\nverosimiglianza di \\(H\\) dato \\(E\\), \\(P(E \\mid H)\\), la probabilità condizionata che si verifichi \\(E\\), se è vera \\(H\\).\n\nSi noti che, per il calcolo della quantità a denominatore della Equazione 3.1, si ricorre al teorema della probabilità assoluta.\n\nEsercizio 3.1 \nConsiderando una partizione dell’evento certo \\(\\Omega\\) in due soli eventi che chiamiamo ipotesi \\(H_1\\) e \\(H_2\\). Supponiamo conosciute le probabilità a priori \\(P(H_1)\\) e \\(P(H_2)\\). Consideriamo un terzo evento \\(E \\subseteq \\Omega\\) con probabilità non nulla di cui si conosce la verosimiglianza, ovvero si conoscono le probabilità condizionate \\({\\mbox{P}}(E \\mid H_1)\\) e \\(P(E \\mid H_2)\\). Supponendo che si sia verificato l’evento \\(E\\), vogliamo conoscere le probabilità a posteriori delle ipotesi, ovvero \\(P(H_1 \\mid E)\\) e \\(P(H_2 \\mid E)\\).\n\n\n\n\n\nFigura 3.1: Partizione dell’evento certo in due eventi chiamati ‘ipotesi’. L’evidenza \\(E\\) è un sottoinsieme dello spazio campione.\n\n\n\n\n\nSoluzione. Per trovare le probabilità cercate scriviamo:\n\\[\n\\begin{split}\nP(H_1 \\mid E) &= \\frac{P(E \\cap H_1)}{P(E)}\\notag\\\\\n              &= \\frac{P(E \\mid H_1) P(H_1)}{P(E)}.\n\\end{split}\n\\]\nSapendo che \\(E = (E \\cap H_1) \\cup (E \\cap H_2)\\) e che \\(H_1\\) e \\(H_2\\) sono eventi disgiunti, ovvero \\(H_1 \\cap H_2 = \\emptyset\\), ne segue che possiamo calcolare \\({\\mbox{P}}(E)\\) utilizzando il teorema della probabilità assoluta:\n\\[\n\\begin{split}\nP(E) &= P(E \\cap H_1) + P(E \\cap H_2)\\notag\\\\\n     &= P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2).\n\\end{split}\n\\]\nSostituendo tale risultato nella formula precedente otteniamo:\n\\[\nP(H_1 \\mid E) = \\frac{P(E \\mid H_1)P(H_1)}{P(E \\mid H_1)P(H_1) + P(E \\mid H_2)P(H_2)}.\n\\tag{3.2}\\]\nUn lettore attento si sarà reso conto che, in precedenza, abbiamo già applicato il teorema di Bayes quando abbiamo risolto l’Esempio 2.1. In quel caso, le due ipotesi erano “malattia presente”, che possiamo denotare con \\(M\\), e “malattia assente”, \\(M^\\complement\\). L’evidenza \\(E\\) era costituita dal risultato positivo al test, ovvero \\(+\\). Con questa notazione l’Equazione 3.2 diventa:\n\\[\nP(M \\mid +) = \\frac{P(+ \\mid M) P(M)}{P(+ \\mid M) P(M) + P(+ \\mid M^\\complement) P(M^\\complement)}\n\\]\nInserendo i dati nella formula, otteniamo\n\\[\n\\begin{align}\nP(M \\mid +) &= \\frac{0.9 \\cdot 0.01}{0.9 \\cdot 0.01 + 0.1 \\cdot 0.99} \\notag\\\\\n&= \\frac{9}{108} \\notag\\\\\n&\\approx 0.083.\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "017_bayes_theorem.html#commenti-e-considerazioni-finali",
    "href": "017_bayes_theorem.html#commenti-e-considerazioni-finali",
    "title": "3  L’interpretazione soggettivista della probabilità",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIl teorema di Bayes rende esplicito il motivo per cui la probabilità non possa essere pensata come uno stato oggettivo, quanto piuttosto come un’inferenza soggettiva e condizionata. Il denominatore del membro di destra della Equazione 3.1 è un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantità: \\({\\mbox{P}}(H_i\\)) e \\({\\mbox{P}}(E \\mid H_i)\\). La probabilità \\({\\mbox{P}}(H_i\\)) è la probabilità probabilità a priori (prior) dell’ipotesi \\(H_i\\) e rappresenta l’informazione che l’agente bayesiano possiede a proposito dell’ipotesi \\(H_i\\). Diremo che \\({\\mbox{P}}(H_i)\\) codifica il grado di fiducia che l’agente ripone in \\(H_i\\) precedentemente al verificarsi dell’evidenza \\(E\\). Nell’interpretazione bayesiana, \\({\\mbox{P}}(H_i)\\) rappresenta un giudizio personale dell’agente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. La probabilità condizionata \\({\\mbox{P}}(E \\mid H_i)\\) rappresenta invece la verosimiglianza di \\(H_i\\) dato \\(E\\) e descrive la plausibilità che si verifichi l’evento \\(E\\) se è vera l’ipotesi \\(H_i\\). Il teorema di Bayes descrive la regola che l’agente deve seguire per aggiornare il suo grado di fiducia nell’ipotesi \\(H_i\\) alla luce del verificarsi dell’evento \\(E\\). La \\({\\mbox{P}}(H_i \\mid E)\\) è chiamata probabilità a posteriori dato che rappresenta la nuova probabilità che l’agente assegna all’ipotesi \\(H_i\\) affinché rimanga consistente con le nuove informazioni fornitegli da \\(E\\).\nLa probabilità a posteriori dipende sia dall’evidenza \\(E\\), sia dalla conoscenza a priori dell’agente \\({\\mbox{P}}(H_i)\\). È dunque chiaro come non abbia senso parlare di una probabilità oggettiva: per il teorema di Bayes la probabilità è definita condizionatamente alla probabilità a priori, la quale a sua volta, per definizione, è un’assegnazione soggettiva. Ne segue pertanto che ogni probabilità deve essere considerata come una rappresentazione del grado di fiducia soggettiva dell’agente. Dato che ogni assegnazione probabilistica rappresenta uno stato di conoscenza e che ciascun particolare stato di conoscenza è arbitrario, un accordo tra agenti diversi non è richiesto.\nCiò nonostante, la teoria delle probabilità ci fornisce uno strumento che, alla luce di nuove evidenze, consente di aggiornare in un modo razionale il grado di fiducia che attribuiamo ad un’ipotesi, via via che nuove evidenze vengono raccolte, in modo tale da formulare un’ipotesi a posteriori la quale non è mai definitiva, ma può sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama aggiornamento bayesiano. Vedremo nel Capitolo @sec-intro-bayes-inference come estendere l’Equazione 3.1 al caso continuo."
  },
  {
    "objectID": "018_joint_prob.html",
    "href": "018_joint_prob.html",
    "title": "4  Probabilità congiunta",
    "section": "",
    "text": "La probabilità congiunta è la probabilità che due o più eventi si verifichino contemporaneamente. In questo Capitolo verrà esaminato il caso discreto."
  },
  {
    "objectID": "018_joint_prob.html#funzione-di-probabilità-congiunta",
    "href": "018_joint_prob.html#funzione-di-probabilità-congiunta",
    "title": "4  Probabilità congiunta",
    "section": "\n4.1 Funzione di probabilità congiunta",
    "text": "4.1 Funzione di probabilità congiunta\nDopo aver trattato della distribuzione di probabilità di una variabile casuale, la quale associa ad ogni evento elementare dello spazio campione uno ed un solo numero reale, è naturale estendere questo concetto al caso di due o più variabili casuali. Iniziamo a descrivere il caso discreto con un esempio. Consideriamo l’esperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campione è\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}.\n\\]\nDato che i tre lanci sono tra loro indipendenti, non c’è ragione di aspettarsi che uno degli otto risultati possibili dell’esperimento sia più probabile degli altri, dunque possiamo associare a ciascuno degli otto eventi elementari dello spazio campione la stessa probabilità, ovvero 1/8.\nDefiniamo sullo spazio campione \\(\\Omega\\) le seguenti variabili casuali:\n\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) = “numero di realizzazioni con il risultato testa nei tre lanci”,\n\n\\(Y \\in \\{0, 1\\}\\) = “numero di realizzazioni con il risultato testa nel primo lancio”.\n\nIndicando con T = ‘testa’ e C = ‘croce’, si ottiene la situazione riportata nella Tabella 4.1.\n\n\nTabella 4.1: Spazio campione dell’esperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \\(X\\) = ‘numero di realizzazioni con il risultato testa nei tre lanci’ e \\(Y\\) = ‘numero di realizzazioni con il risultato testa nel primo lancio’.\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\n\nCi poniamo il problema di associare un valore di probabilità ad ogni coppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si realizza in corrispondenza di un solo evento elementare, ovvero CCC; avrà dunque una probabilità pari a\n\\[\nP(X=0, Y=0) = P(CCC) = 1/8.\n\\]\nNel caso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC. La probabilità dell’evento composto \\(P(X=1, Y=0)\\) è dunque uguale alla somma delle probabilità dei due eventi elementari che lo costituiscono, cioé\n\\[\nP(X=1, Y=0) = P(\\mbox{CCT}) + P(\\mbox{CTC}) = 1/8 + 1/8 = 1/4.\n\\]\nDi seguito sono riportati i calcoli per tutte le possibili coppie \\(X, Y\\):\n\\[\\begin{align}\nP(X = 0, Y = 0) &= P(\\omega_8 = CCC) = 1/8; \\notag\\\\\nP(X = 1, Y = 0) &= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\\nP(X = 1, Y = 1) &= P(\\omega_7 = TCC) = 1/8; \\notag\\\\\nP(X = 2, Y = 0) &= P(\\omega_4 = CTT) = 1/8; \\notag\\\\\nP(X = 2, Y = 1) &= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\\nP(X = 3, Y = 1) &= P(\\omega_1 = TTT) = 1/8; \\notag\n\\end{align}\\]\nLe probabilità così trovate sono riportate nella Tabella 4.2 che descrive la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (“numero di realizzazioni con il risultato testa nei tre lanci”) e \\(Y\\) (“numero di realizzazioni con il risultato testa nel primo lancio”) per l’esperimento casuale che consiste nel lancio di tre monete equilibrate.\n\n\nTabella 4.2: Distribuzione di probabilità congiunta per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate.\n\n\\(x / y\\)\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n2/8\n\n\n3\n0\n1/8\n\n\n\n\nIn generale, possiamo dire che, dato uno spazio campione discreto \\(\\Omega\\), è possibile associare ad ogni evento elementare \\(\\omega_i\\) dello spazio campione una coppia di numeri reali \\((x, y)\\), essendo \\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente definizione.\n\nDefinizione 4.1 Siano \\(X\\) e \\(Y\\) due variabili casuali. La funzione che associa ad ogni coppia \\((x, y)\\) un valore di probabilità prende il nome di funzione di probabilità congiunta:\n\\[\nP(x, y) = P(X = x, Y = y).\n\\]\n\nIl termine “congiunta” deriva dal fatto che questa probabilità è legata al verificarsi di una coppia di valori, il primo associato alla variabile casuale \\(X\\) ed il secondo alla variabile casuale \\(Y\\). Nel caso di due sole variabili casuali si parla di distribuzione bivariata, mentre nel caso di più variabili casuali si parla di distribuzione multivariata.\n\n\n\n\n\n\n\n4.1.1 Proprietà\nUna distribuzione di massa di probabilità congiunta bivariata deve soddisfare due proprietà:\n\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\);\nla probabilità totale deve essere uguale a 1: \\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1.\\)\n\n\n4.1.2 Eventi\nSi noti che dalla probabilità congiunta possiamo calcolare la probabilità di qualsiasi evento definito in base alle variabili aleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto, consideriamo nuovamente l’esperimento casuale discusso in precedenza.\n\nEsercizio 4.1 \nPer la distribuzione di massa di probabilità congiunta riportata nella tabella Tabella 4.2 si trovi la probabilità dell’evento \\(X+Y \\leq 1\\).\n\n\nSoluzione. Per trovare la probabilità richiesta dobbiamo sommare le probabilità associate a tutte le coppie \\((x,y)\\) che soddisfano la condizione \\(X+Y \\leq 1\\), ovvero\n\\[\nP_{XY}(X+Y \\leq 1) = P_{XY}(0, 0)+ P_{XY}(0, 1) + P_{XY}(1, 0) = 3/8.\n\\]\n\n\n4.1.3 Funzioni di probabilità marginali\n\nNel caso di due variabili casuali discrete \\(X\\) e \\(Y\\) di cui conosciamo la distribuzione congiunta, la distribuzione marginale di \\(X\\) è calcolata sommando la distribuzione di probabilità congiunta sopra la variabile da “scartare”, in questo caso la \\(Y\\). La funzione di massa di probabilità marginale \\(P(X=x)\\) è\n\\[\\begin{equation}\nP(X = x) = \\sum_y P(X, Y = y) = \\sum_y P(X \\mid Y = y) P(Y = y),\n\\end{equation}\\]\ndove \\(P(X = x,Y = y)\\) è la distribuzione congiunta di \\(X, Y\\), mentre \\(P(X = x \\mid Y = y)\\) è la distribuzione condizionata di \\(X\\) dato \\(Y\\). Se esaminiamo \\(P(X=x)\\), diciamo che la variabile \\(Y\\) è stata marginalizzata.\nLe probabilità bivariate marginali e congiunte per variabili casuali discrete sono spesso mostrate come tabelle di contingenza. Si noti che \\(P(X = x)\\) e \\(P(Y = y)\\) sono normalizzate:\n\\[\n\\sum_x P(X=x) = 1.0, \\quad \\sum_y P(Y=y) = 1.0.\n\\]\nNel caso continuo si sostituisce l’integrazione alla somma – si veda la Sezione @ref(sec:margin-vc-cont).\n\nPer l’esperimento casuale consistente nel lancio di tre monete equilibrate, si calcolino le probabilità marginali di \\(X\\) e \\(Y\\).\nNell’ultima colonna a destra e nell’ultima riga in basso della tabella @ref(tab:ditr-cong-biv) sono riportate le distribuzioni di probabilità marginali di \\(X\\) e \\(Y\\). \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\). \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(i,\\) \\(P_Y (Y = i) = \\sum_x p_{xy}(x, y = i)\\).\n\n(#tab:ditr-cong-biv) Distribuzione di probabilità congiunta \\(p(x,y)\\) per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate e probabilità marginali \\(P(x)\\) e \\(P(y)\\).\n\n\\(x / y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0"
  },
  {
    "objectID": "018_joint_prob.html#sec:margin-vc-cont",
    "href": "018_joint_prob.html#sec:margin-vc-cont",
    "title": "4  Probabilità congiunta",
    "section": "\n4.2 Marginalizzazione di variabili casuali continue",
    "text": "4.2 Marginalizzazione di variabili casuali continue\nNella trattazione della statistca bayesiana useremo spesso il concetto di “marginalizzazione” e vedremo equazioni come la seguente:\n\\[\\begin{equation}\np(y) = \\int_{\\theta} p(y, \\theta) = \\int_{\\theta} p(y \\mid \\theta) p(\\theta),\n(\\#eq:ex-marg-cont)\n\\end{equation}\\]\nladdove \\(y\\) e \\(\\theta\\) sono due variabili casuali continue – nello specifico, con \\(y\\) denoteremo i dati e con \\(\\theta\\) i parametri di un modello statistico. Per ora, possiamo pensare a \\(y\\) e \\(\\theta\\) come a due variabili casuali qualsiasi. È possibiile pensare al caso continuo indicato nella @ref(eq:ex-marg-cont) come all’estensione dell’esempio precedente ad un numero infinito di valori \\(\\theta\\)."
  },
  {
    "objectID": "018_joint_prob.html#commenti-e-considerazioni-finali",
    "href": "018_joint_prob.html#commenti-e-considerazioni-finali",
    "title": "4  Probabilità congiunta",
    "section": "Commenti e considerazioni finali",
    "text": "Commenti e considerazioni finali\nIn alcuni casi, diverse variabili casuali possono essere associate a ciascuna unità statistica della popolazione. Ad esempio, immaginiamo di scegliere uno studente a caso dall’elenco di tutti gli studenti iscritti a un’università e di misurare l’altezza e il peso di quello studente. A ogni individuo nella popolazione degli studenti corrispondono dunque due variabili casuali, altezza e peso. Quando due o più variabili casuali sono associate a ciascun elemento di una popolazione, si dice che le variabili casuali sono distribuite congiuntamente. In questo capitolo abbiamo visto come si possa rappresentare la distribuzione di massa di probabilità congiunta di due variabili casuali discrete e come si possano ottenere le distribuzioni marginali delle due variabili."
  },
  {
    "objectID": "019_density_func.html",
    "href": "019_density_func.html",
    "title": "5  La densità di probabilità",
    "section": "",
    "text": "Finora abbiamo considerato solo variabili casuali discrete, cioè variabili che assumono solo valori interi. Ma cosa succede se vogliamo usare variabili casuali per rappresentare lunghezze, o volumi, o distanze, o una qualsiasi delle altre proprietà continue nel mondo fisico (o psicologico)? È necessario generalizzare l’approccio usato finora.\nLe variabili casuali continue assumono valori reali. L’insieme dei numeri reali è non numerabile perché è più grande dell’insieme degli interi.1 Le leggi della probabilità sono le stessa per le variabili casuali discrete e quelle continue. La nozione di funzione di massa di probabilità, invece, deve essere sostituita dal suo equivalente continuo, ovvero dalla funzione di densità di probabilità. Lo scopo di questo Capitolo è quello di chiarire il significato di questa nozione, usando un approccio basato sulle simulazioni."
  },
  {
    "objectID": "019_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "href": "019_density_func.html#spinner-e-variabili-casuali-continue-uniformi",
    "title": "5  La densità di probabilità",
    "section": "\n5.1 Spinner e variabili casuali continue uniformi",
    "text": "5.1 Spinner e variabili casuali continue uniformi\nConsideriamo il seguente esperimento casuale. Facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma (individuata dall’angolo acuto con segno tra il suo asse e l’asse orizzontale del goniometro). Chiamiamo \\(\\Theta\\) la variabile casuale “pendenza dello spinner”. Nella trattazione seguente useremo i gradi e, di conseguenza, \\(\\Theta \\in [0, 360]\\).\n\n\n\n\nUno spinner che riposa a 36 gradi, o il dieci percento del percorso intorno al cerchio. La pendenza dello spinner può assumere qualunque valore tra 0 e 360 gradi.\n\n\n\n\nCosa implica per \\(\\Theta\\) dire che lo spinner è simmetrico? Possiamo dire che, in ciascuna prova, la rotazione dello spinner produce un angolo qualunque da 0 a 360 gradi. In altri termini, un valore \\(\\Theta\\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \\(\\Theta\\) compreso tra 200 e 236 gradi. Inoltre, poiché 36 gradi è un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10%. Ovvero \\(\\mbox{P}(0 \\leq \\Theta \\leq 36) \\ = \\ \\frac{1}{10}\\) e \\(\\mbox{P}(200 \\leq \\Theta \\leq 236) \\ = \\ \\frac{1}{10}\\).\nÈ importante notare che le probabilità precedenti non si riferiscono al fatto che \\(\\Theta\\) assume uno specifico valore, ma piuttosto all’evento di osservare \\(\\Theta\\) in un intervallo di valori. In generale, la probabilità che la pendenza \\(\\Theta\\) dello spinner cada in intervallo è la frazione del cerchio rappresentata dall’intervallo, cioè,\n\\[\n\\mbox{P}(\\theta_1 \\leq \\Theta \\leq \\theta_2) = \\frac{\\theta_2 - \\theta_1}{360}, \\qquad 0 \\leq \\theta_1 \\leq \\theta_2 \\leq 360.\n\\]\nLa ragione di questo è che le variabili casuali continue non hanno una massa di probabilità. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale in un intervallo di valori.\n\n5.1.1 Il paradosso delle variabili casuali continue\nNel nostro esempio, la pendenza dello spinner è esattamente 36 gradi; ma avrebbe anche potuto essere 36.0376531 gradi, o qualunque altro valore in quell’intorno. Qual è la probabilità che la pendenza dello spinner sia esattamente 36? Paradossalmente, la risposta è zero:\n\\[\n\\mbox{P}(\\Theta = 36) = 0.\n\\]\nInfatti, se la probabilità di un qualunque valore fosse maggiore di zero, ogni altro possibile valore dovrebbe avere la stessa probabilità, dato che abbiamo assunto che tutti i valori \\(\\Theta\\) siano egualmente probabili. Ma se poi andiamo a sommare tutte queste probabilità il totale diventerà maggiore di uno, il che non è possibile.\nNel caso delle variabili casuali continue dobbiamo dunque rinunciare a qualcosa, e quel qualcosa è l’idea che, in una distribuzione continua, ciascun valore puntuale della variabile casuale possa avere una massa di probabilità maggiore di zero. Il paradosso sorge perché una realizzazione della variabile casuale continua produce sempre un qualche numero, ma ciscuno di tali numeri ha probabilità nulla."
  },
  {
    "objectID": "019_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "href": "019_density_func.html#la-funzione-di-ripartizione-per-una-variabile-casuale-continua",
    "title": "5  La densità di probabilità",
    "section": "\n5.2 La funzione di ripartizione per una variabile casuale continua",
    "text": "5.2 La funzione di ripartizione per una variabile casuale continua\nSupponiamo che \\(\\Theta \\sim \\mathcal{U}(0, 360)\\) sia la pendenza dello spinner. La funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:\n\\[\nF_{\\Theta}(\\theta) = \\mbox{P}(\\Theta \\leq \\theta).\n\\]\nCioè, è la probabilità che la variabile casuale \\(\\Theta\\) assuma un valore minore di o uguale a \\(\\theta\\). In questo caso, poiché si presume che lo spinner sia simmetrico, la funzione di distribuzione cumulativa è\n\\[\nF_{\\Theta}(\\theta) = \\frac{\\theta}{360}.\n\\]\nQuesta è una funzione lineare di \\(\\theta\\), cioè \\(\\frac{1}{360} \\cdot \\theta\\), come indicato dal grafico della figura @ref(fig:spinner-cdf).\n\n\n\n\nFunzione di distribuzione cumulativa per l’angolo \\(\\theta\\) (in gradi) risultante da una rotazione di uno spinner simmetrico. La linea tratteggiata mostra il valore a 180 gradi, che corrisponde ad una probabilità di 0.5, e la linea tratteggiata a 270 gradi, che corrisponde ad una probabilità di 0.75.\n\n\n\n\nPossiamo verificare questo risultato mediante simulazione. Per stimare la funzione di ripartizione, simuliamo \\(M\\) valori \\(\\theta^{(m)}\\) e poi li ordiniamo in ordine crescente.\n\nM <- 1000\ntheta <- runif(M, 0, 360)\ntheta_asc <- sort(theta)\nprob <- (1:M) / M\nunif_cdf_df <- data.frame(\n  theta = theta_asc,\n  prob = prob\n)\nunif_cdf_plot <-\n  unif_cdf_df %>%\n  ggplot(aes(x = theta, y = prob)) +\n  geom_line() +\n  scale_x_continuous(breaks = c(0, 90, 180, 270, 360)) +\n  scale_y_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1.0)) +\n  xlab(expression(theta)) +\n  ylab(expression(F(Theta)(theta)))\nunif_cdf_plot\n\n\n\nGrafico della funzione di ripartizione di una variabile casuale \\(\\Theta\\) che rappresenta il risultato di una rotazione di uno spinner simmetrico. Come previsto, tale funzione è una semplice funzione lineare perché la variabile sottostante \\(\\Theta\\) ha una distribuzione uniforme.\n\n\n\n\nAnche con M = 1000, tale grafico è praticamente indistinguibile da quello prodotto per via analitica.\nCome nel caso delle variabili casuali discrete, la funzione di ripartizione può essere utilizzata per calcolare la probabilità che la variabile casuale assuma valori in un certo intervallo. Ad esempio\n\\[\\begin{align}\n\\mbox{P}(180 < \\Theta \\leq 270) &= \\mbox{P}(\\Theta \\leq 270) \\ - \\ \\mbox{P}(\\Theta \\leq 180) \\notag\\\\\n&= F_{\\Theta}(270) - F_{\\Theta}(180)\\notag\\\\\n&= \\frac{3}{4} - \\frac{1}{2} \\notag\\\\\n&= \\frac{1}{4}.\\noindent\n\\end{align}\\]"
  },
  {
    "objectID": "019_density_func.html#la-distribuzione-uniforme",
    "href": "019_density_func.html#la-distribuzione-uniforme",
    "title": "5  La densità di probabilità",
    "section": "\n5.3 La distribuzione uniforme",
    "text": "5.3 La distribuzione uniforme\nDopo avere visto come generare numeri casuali uniformi da 0 a 360, consideriamo ora una variabile casuale che assume valori nell’intervallo da 0 a 1. Chiamiamo tale variabile casuale \\(\\Theta\\) e assumiamo che abbia una distribuzione continua uniforme sull’intervallo [0, 1]:\n\\[\n\\Theta \\sim \\mathcal{U}(0, 1).\n\\]\nPoiché le probabilità assumono valori nell’intervallo [0, 1], possiamo pensare a \\(\\Theta\\) come ad un valore di probabilità preso a caso in ciascuna realizzazione dell’esperimento casuale.\nLa distribuzione uniforme è la più semplice delle distribuzioni di densità di probabilità. Per chiarire le proprietà di tale distribuzione, iniziamo con una simulazione e generiamo 10,000 valori casuali di \\(\\Theta\\). I primi 10 di tali valori sono stampati qui di seguito:\n\nset.seed(1234)\nM <- 10000\ntheta <- runif(M)\ntheta[1:10]\n#>  [1] 0.113703411 0.622299405 0.609274733 0.623379442 0.860915384 0.640310605\n#>  [7] 0.009495756 0.232550506 0.666083758 0.514251141\n\nCreiamo ora un istogramma che descrive la distribuzione delle 10,000 realizzazioni \\(\\Theta\\) che abbiamo trovato:\n\ndf_prob_unif <- data.frame(theta = theta)\nunif_prob_plot <-\n  ggplot(df_prob_unif, aes(theta)) +\n  geom_histogram(\n    binwidth = 1 / 34, center = 1 / 68, color = \"black\",\n    size = 0.25\n  ) +\n  scale_x_continuous(breaks = c(0, 0.25, 0.5, 0.75, 1)) +\n  scale_y_continuous(lim = c(0, 1000), breaks = c(500, 1000)) +\n  xlab(expression(paste(Theta, \" ~ Uniform(0, 1)\")))\nunif_prob_plot\n\n\n\nIstogramma di \\(10\\,000\\) realizzazioni \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\).\n\n\n\n\nÈ chiaro che, all’aumentare del numero delle realizzazioni \\(\\Theta\\), il profilo dell’istogramma tenderà a diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante. Cioè, se \\(\\Theta \\sim \\mathcal{U} (a, b)\\), allora \\(p_{\\Theta}(\\theta) = c\\), dove \\(c\\) è una costante.\n\nuniform_pdf_df <- data.frame(y = c(0, 1), p_y = c(1, 1))\nuniform_pdf_plot <-\n  ggplot(uniform_pdf_df, aes(x = y, y = p_y)) +\n  geom_line(size = 0.5, color = \"#333333\") +\n  geom_point(size = 1.5, color = \"#333333\") +\n  scale_x_continuous(breaks = c(0, 1), labels = c(\"a\", \"b\")) +\n  scale_y_continuous(\n    lim = c(0, 1), breaks = c(0, 1),\n    labels = c(\"0\", \"c\")\n  ) +\n  xlab(expression(theta)) +\n  ylab(expression(paste(p[Theta], \"(\", theta, \" | a, b)\"))) +\n  geom_segment(aes(x = 0, y = 0, xend = 0, yend = 1),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = 1, y = 0, xend = 1, yend = 1),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 0),\n    linetype = \"dotted\"\n  ) +\n  geom_segment(aes(x = -0.25, y = 0, xend = 0, yend = 0)) +\n  geom_segment(aes(x = 1, y = 0, xend = 1.25, yend = 0)) +\n  geom_point(aes(x = 0, y = 0),\n    size = 1.5, shape = 21,\n    fill = \"#ffffe6\"\n  ) +\n  geom_point(aes(x = 1, y = 0),\n    size = 1.5, shape = 21,\n    fill = \"#ffffe6\"\n  )\nuniform_pdf_plot\n\n\n\n\n\n\n\nDal grafico vediamo che l’area sottesa alla funzione di densità è \\((b - a)\\cdot c\\). Dato che tale area deve essere unitaria, ovvero, \\((b - a) \\cdot c = 1\\), possiamo trovare \\(c\\) dividendo entrambi i termini per \\(b - a\\),\n\\[\nc  = \\frac{\\displaystyle{1}}{\\displaystyle b - a}.\n\\]\nOvvero, se \\(\\Theta \\sim \\mathcal{U}(a, b)\\), allora\n\\[\np_{\\Theta}(\\theta) = \\mathcal{U}(\\theta \\mid a, b),\n\\]\nladdove\n\\[\n\\mathcal{U}(\\theta \\mid a, b) = \\frac{1}{b - a}.\n\\]\nIn conclusione, la densità di una variabile casuale uniforme continua non dipende da \\(\\theta\\) — è costante e identica per ogni possibile valore \\(\\theta\\).2 Vedremo nel prossimo Paragrafo che, eseguendo una trasformazione su questa variabile casuale uniforme, possiamo creare altre variabili casuali di interesse.\n\nSi consideri una variabile casuale uniforme \\(X\\) definita sull’intervallo [0, 100]. Si trovi la probabilità \\(P(20 < X < 60)\\).\nPer trovare la soluzione è sufficiente calcolare l’area di un rettangolo di base \\(60 - 20 = 40\\) e di altezza 1/100. La probabilità cercata è dunque \\(P(20 < X < 60) = 40 \\cdot 0.01 = 0.4\\)."
  },
  {
    "objectID": "019_density_func.html#dagli-istogrammi-alle-densità",
    "href": "019_density_func.html#dagli-istogrammi-alle-densità",
    "title": "5  La densità di probabilità",
    "section": "\n5.4 Dagli istogrammi alle densità",
    "text": "5.4 Dagli istogrammi alle densità\nNon esiste l’equivalente di una funzione di massa di probabilità per le variabili casuali continue. Esiste invece una funzione di densità di probabilità la quale, nei termini di una simulazione, può essere concepita nel modo seguente: avendo a disposizione un numero enorme di casi, quando l’intervallo \\(\\Delta\\) di ciascuna classe \\(\\rightarrow\\) 0, il profilo dell’istogramma delle frequenze delle classi di ampiezza \\(\\Delta\\) tende a diventare una curva continua. Tale curva continua \\(f(x)\\) è detta funzione di densità di probabilità.\nCome si trasformano gli istogrammi all’aumentare del numero di osservazioni? Per fare un esempio, considereremo una funzione di una variabile casuale uniforme \\([0, 1]\\). Nello specifico, esamineremo la funzione logit:\n\\[\n\\alpha = \\log \\left(\\frac{\\theta}{1-\\theta}\\right)\n\\]\nAlcuni valori \\(\\alpha\\) presi a caso sono i seguenti:\n\nset.seed(1234)\nM <- 10000\nlogit <- function(x) log(x / (1 - x))\ntheta <- runif(M)\nalpha <- logit(theta)\nfor (m in 1:10)\n  print(alpha[m])\n#> [1] -2.053458\n#> [1] 0.4993195\n#> [1] 0.4442646\n#> [1] 0.5039172\n#> [1] 1.822914\n#> [1] 0.5767125\n#> [1] -4.647369\n#> [1] -1.193965\n#> [1] 0.6905252\n#> [1] 0.05702001\n\nNei grafici seguenti, la numerosità cresce da \\(10\\) a \\(1\\,000\\,000\\).\n\ndf_log_odds_growth <- data.frame()\nfor (log10M in 1:6) {\n  M <- 10^log10M\n  alpha <- logit(runif(M))\n  df_log_odds_growth <- rbind(\n    df_log_odds_growth,\n    data.frame(\n      alpha = alpha,\n      M = rep(sprintf(\"M = %d\", M), M)\n    )\n  )\n}\nlog_odds_growth_plot <-\n  df_log_odds_growth %>%\n  ggplot(aes(alpha)) +\n  geom_histogram(color = \"black\", bins = 75) +\n  facet_wrap(~M, scales = \"free\") +\n  scale_x_continuous(\n    lim = c(-8.5, 8.5), breaks = c(-5, 0, 5)\n  ) +\n  xlab(expression(paste(Phi, \" = \", logit(Theta)))) +\n  ylab(\"proportion of draws\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.spacing.x = unit(2, \"lines\"),\n    panel.spacing.y = unit(2, \"lines\")\n  )\nlog_odds_growth_plot\n\n\n\nIstogramma di \\(M\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0, 1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta).\\) Il profilo limite dell’istogramma è evidenziato nella figura in basso a destra che è stata costruita usando \\(1\\,000\\,000\\) di osservazioni.\n\n\n\n\nIn un istogramma, l’area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni in quel’intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l’altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni in quel’intervallo.\nNella simulazione, possiamo pensare all’area di ciascuna barra dell’istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell’intervallo considerato. All’aumentare del numero \\(M\\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. All’aumentare del numero degli intervalli (quando l’ampiezza \\(\\Delta\\) dell’intervallo \\(\\rightarrow\\) 0), il profilo dell’istogramma tende a diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale. Per l’esempio presente, con \\(M =1\\,000\\,000\\), otteniamo il grafico riportato nella figura @ref(fig:hist-dens-example).\n\nM <- 1e6\nalpha <- logit(runif(M))\ndensity_limit_df <- data.frame(alpha = alpha)\ndensity_limit_plot <-\n  density_limit_df %>%\n  ggplot(aes(alpha)) +\n  geom_histogram(\n    stat = \"density\", n = 75, color = \"black\", size = 0.15\n  ) +\n  stat_function(\n    fun = dlogis,\n    args = list(location = 0, scale = 1),\n    col = \"black\",\n    size = 0.3\n  ) +\n  scale_x_continuous(\n    lim = c(-9, 9),\n    breaks = c(-6, -4, -2, 0, 2, 4, 6)\n  ) +\n  xlab(\n    expression(paste(Phi, \" = \", logit(Theta)))\n  ) +\n  ylab(\"Frequenza relativa\") +\n  theme(\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank()\n  )\ndensity_limit_plot\n\n\n\nIstogramma di \\(M = 1\\,000\\,000\\) campioni casuali \\(\\Theta \\sim \\mbox{Uniform}(0,1)\\) trasformati in valori \\(\\Phi = \\mbox{logit}(\\Theta)\\). La spezzata nera congiunge i punti centrali superiori delle barre dell’istogramma. Nel limite, quando il numero di osservazioni e di barre tende all’infinito, tale spezzata approssima la funzione di densità di probabilità della variabile casuale.\n\n\n\n\nNella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un metodo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale."
  },
  {
    "objectID": "019_density_func.html#funzione-di-densità-di-probabilità",
    "href": "019_density_func.html#funzione-di-densità-di-probabilità",
    "title": "5  La densità di probabilità",
    "section": "\n5.5 Funzione di densità di probabilità",
    "text": "5.5 Funzione di densità di probabilità\nPer descrivere le probabilità che possono essere associate ad una variabile casuale continua \\(X\\) è necessario definire una funzione \\(p(X)\\) che deve soddisfare le seguenti due proprietà:\n\n\\(p(x) \\geq 0, \\forall x\\), ovvero, l’ordinata della funzione di densità è 0 o positiva;\n\\(\\int_{-\\infty}^{\\infty} p(x) \\,\\operatorname {d}\\!x = 1\\), ovvero, l’area sottesa dalla \\(p(x)\\) è unitaria3;\n\\(p(a < x < b) = \\int_a^b p(x) \\,\\operatorname {d}\\!x\\), se \\(a \\leq b\\), ovvero, l’area sottesa dalla \\(p(y)\\) tra due punti \\(a\\) e \\(b\\) corrisponde alla probabilità che la v.c. \\(x\\) assuma un valore compresto tra questi due estremi.\n\nInterpretazione. È possibile che \\(p(x) > 1\\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \\(p(x)\\) può essere utilizzata per confrontare la fiducia relativa che può essere assegnata a diversi valori \\(x\\). Considerata una variabile casuale \\(X\\) di cui è disponibile un insieme di realizzazioni, possiamo dire che, se consideriamo due valori \\(x_k\\) e \\(x_l\\) con \\(p(x_k) > p(x_l)\\), allora possiamo concludere che è più probabile, in termini relativi, osservare realizzazioni \\(X\\) nell’intorno di \\(x_k\\) piuttosto che nell’intorno di \\(x_l\\)."
  },
  {
    "objectID": "019_density_func.html#la-funzione-di-ripartizione",
    "href": "019_density_func.html#la-funzione-di-ripartizione",
    "title": "5  La densità di probabilità",
    "section": "\n5.6 La funzione di ripartizione",
    "text": "5.6 La funzione di ripartizione\nLa funzione di ripartizione \\(F(X)\\) è quella funzione che associa a ogni valore di una variabile casuale \\(X\\) la probabilità che la variabile assuma valore minore o uguale a un prefissato valore \\(x_k\\). Come nel caso discreto, anche nel caso continuo la funzione di ripartizione è sempre non negativa, monotona non decrescente tra \\(0\\) e \\(1\\), tale che:\n\\[\n\\lim_{x \\to -\\infty} F_x(X) = F_X(-\\infty) = 0, \\quad \\lim_{x \\to +\\infty} F_X(X) = F_X(+\\infty) = 1.\n\\]\n\n\n\n\n\nSe \\(X\\) è una variabile aleatoria continua, la funzione di ripartizione è:\n\\[\nF(x_k) = P(X \\leq x_k) = \\int_{-\\infty}^{x_k} f(x) \\,\\operatorname {d}\\!x .\n\\]"
  },
  {
    "objectID": "019_density_func.html#media-e-mediana",
    "href": "019_density_func.html#media-e-mediana",
    "title": "5  La densità di probabilità",
    "section": "\n5.7 Media e mediana",
    "text": "5.7 Media e mediana\nConcludiamo questo capitolo con alcune considerazioni relative al contronto tra la media (valore atteso) e la mediana, nel caso di variabili casuali continue.\nPer distribuzioni simmetriche, sappiamo che la media e la mediana sono uguali. Chiediamoci ora cosa succede, nel caso di variabili casuali continue, nel caso di distribuzioni asimmetriche.\nLa mediana indica il punto in cui la “massa totale” della distribuzione è suddivisa in due porzioni uguali. Nel caso della densità di probabilità, ciascuna di queste porzioni rappresenta un’area uguale, \\(A_1 = A_2 = 1/2\\) poiché l’area totale sottesa alla funzione di densità è 1 per definizione.\n\n\n\n\nQual è la differenza tra mediana e media?\n\n\n\n\nLa figura @ref(fig:median-mean) mostra come differiscono i due concetti di mediana (indicata dalla linea verticale) e media (indicata dal “punto di equilibrio” triangolare). A sinistra, per una densità di probabilità simmetrica, la media e la mediana coincidono. A destra, una piccola porzione della distribuzione è stata spostata all’estremo destro. Questa modifica non ha influito sulla posizione della mediana, poiché le aree a destra e a sinistra della linea verticale sono ancora uguali. In altri termini, la mediana, \\(x_m\\), divide l’area sottesa alla funzione di densità in due porzioni uguali:\n\\[\n\\int_{-\\infty}^{x_m} p(x) dx = \\int_{x_m}^{-\\infty} p(x) dx = \\frac{1}{2}.\n\\]\nSegue da tale definizione che la mediana è il valore \\(x\\) per il quale la distribuzione cumulativa soddisfa\n\\[\nF(x_m) = \\frac{1}{2}.\n\\]\nTuttavia, il fatto che una parte della massa sia stata allontanata verso destra porta a uno spostamento della media della distribuzione, per compensare tale cambiamento. In altre parole, la media contiene più informazioni sulla distribuzione “spaziale” delle osservazioni, rispetto alla mediana. Ciò deriva dal fatto che la media della distribuzione (il valore atteso) è una “somma” - cioè è un integrale - di termini cha hanno la forma \\(x p(x) \\Delta x\\). Quindi la posizione lungo l’asse \\(x\\), ovvero \\(x\\), e non solo la “massa”, \\(p(x) \\Delta x\\), influenza il contributo che le componenti della distribuzione hanno sulla media."
  },
  {
    "objectID": "999_refs.html",
    "href": "999_refs.html",
    "title": "Riferimenti bibliografici",
    "section": "",
    "text": "Albert, J., & Hu, J. (2019). Probability and bayesian\nmodeling. Chapman; Hall/CRC.\n\n\nFinetti, B. de. (1931). Probabilismo. Logos, 163–219."
  },
  {
    "objectID": "018_joint_prob.html#sec-fun-join-prob",
    "href": "018_joint_prob.html#sec-fun-join-prob",
    "title": "4  Probabilità congiunta",
    "section": "\n4.1 Funzione di probabilità congiunta",
    "text": "4.1 Funzione di probabilità congiunta\nDopo aver trattato della distribuzione di probabilità di una variabile casuale, la quale associa ad ogni evento elementare dello spazio campione uno ed un solo numero reale, è naturale estendere questo concetto al caso di due o più variabili casuali. Iniziamo a descrivere il caso discreto con un esempio. Consideriamo l’esperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campione è\n\\[\n\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}.\n\\]\nDato che i tre lanci sono tra loro indipendenti, non c’è ragione di aspettarsi che uno degli otto risultati possibili dell’esperimento sia più probabile degli altri, dunque possiamo associare a ciascuno degli otto eventi elementari dello spazio campione la stessa probabilità, ovvero 1/8.\nDefiniamo sullo spazio campione \\(\\Omega\\) le seguenti variabili casuali:\n\n\n\\(X \\in \\{0, 1, 2, 3\\}\\) = “numero di realizzazioni con il risultato testa nei tre lanci”,\n\n\\(Y \\in \\{0, 1\\}\\) = “numero di realizzazioni con il risultato testa nel primo lancio”.\n\nIndicando con T = ‘testa’ e C = ‘croce’, si ottiene la situazione riportata nella Tabella 4.1.\n\n\nTabella 4.1: Spazio campione dell’esperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \\(X\\) = ‘numero di realizzazioni con il risultato testa nei tre lanci’ e \\(Y\\) = ‘numero di realizzazioni con il risultato testa nel primo lancio’.\n\n\\(\\omega\\)\n\\(X\\)\n\\(Y\\)\n\\(P(\\omega)\\)\n\n\n\n\n\\(\\omega_1\\) = TTT\n3\n1\n1/8\n\n\n\n\\(\\omega_2\\) = TTC\n2\n1\n1/8\n\n\n\n\\(\\omega_3\\) = TCT\n2\n1\n1/8\n\n\n\n\\(\\omega_4\\) = CTT\n2\n0\n1/8\n\n\n\n\\(\\omega_5\\) = CCT\n1\n0\n1/8\n\n\n\n\\(\\omega_6\\) = CTC\n1\n0\n1/8\n\n\n\n\\(\\omega_7\\) = TCC\n1\n1\n1/8\n\n\n\n\\(\\omega_8\\) = CCC\n0\n0\n1/8\n\n\n\n\nCi poniamo il problema di associare un valore di probabilità ad ogni coppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si realizza in corrispondenza di un solo evento elementare, ovvero CCC; avrà dunque una probabilità pari a\n\\[\nP(X=0, Y=0) = P(CCC) = 1/8.\n\\]\nNel caso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC. La probabilità dell’evento composto \\(P(X=1, Y=0)\\) è dunque uguale alla somma delle probabilità dei due eventi elementari che lo costituiscono, cioé\n\\[\nP(X=1, Y=0) = P(\\mbox{CCT}) + P(\\mbox{CTC}) = 1/8 + 1/8 = 1/4.\n\\]\nDi seguito sono riportati i calcoli per tutte le possibili coppie \\(X, Y\\):\n\\[\\begin{align}\nP(X = 0, Y = 0) &= P(\\omega_8 = CCC) = 1/8; \\notag\\\\\nP(X = 1, Y = 0) &= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\\nP(X = 1, Y = 1) &= P(\\omega_7 = TCC) = 1/8; \\notag\\\\\nP(X = 2, Y = 0) &= P(\\omega_4 = CTT) = 1/8; \\notag\\\\\nP(X = 2, Y = 1) &= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\\nP(X = 3, Y = 1) &= P(\\omega_1 = TTT) = 1/8; \\notag\n\\end{align}\\]\nLe probabilità così trovate sono riportate nella Tabella 4.2 che descrive la distribuzione di probabilità congiunta delle variabili casuali \\(X\\) (“numero di realizzazioni con il risultato testa nei tre lanci”) e \\(Y\\) (“numero di realizzazioni con il risultato testa nel primo lancio”) per l’esperimento casuale che consiste nel lancio di tre monete equilibrate.\n\n\nTabella 4.2: Distribuzione di probabilità congiunta per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate.\n\n\\(x / y\\)\n0\n1\n\n\n\n0\n1/8\n0\n\n\n1\n2/8\n1/8\n\n\n2\n1/8\n2/8\n\n\n3\n0\n1/8\n\n\n\n\nIn generale, possiamo dire che, dato uno spazio campione discreto \\(\\Omega\\), è possibile associare ad ogni evento elementare \\(\\omega_i\\) dello spazio campione una coppia di numeri reali \\((x, y)\\), essendo \\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente definizione.\n\nDefinizione 4.1 Siano \\(X\\) e \\(Y\\) due variabili casuali. La funzione che associa ad ogni coppia \\((x, y)\\) un valore di probabilità prende il nome di funzione di probabilità congiunta:\n\\[\nP(x, y) = P(X = x, Y = y).\n\\]\n\nIl termine “congiunta” deriva dal fatto che questa probabilità è legata al verificarsi di una coppia di valori, il primo associato alla variabile casuale \\(X\\) ed il secondo alla variabile casuale \\(Y\\). Nel caso di due sole variabili casuali si parla di distribuzione bivariata, mentre nel caso di più variabili casuali si parla di distribuzione multivariata.\n\n\n\n\n\n\n\n4.1.1 Proprietà\nUna distribuzione di massa di probabilità congiunta bivariata deve soddisfare due proprietà:\n\n\n\\(0 \\leq P(x_i, y_j) \\leq 1\\);\nla probabilità totale deve essere uguale a 1: \\(\\sum_{i} \\sum_{j} P(x_i, y_j) = 1.\\)\n\n\n4.1.2 Eventi\nSi noti che dalla probabilità congiunta possiamo calcolare la probabilità di qualsiasi evento definito in base alle variabili aleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto, consideriamo nuovamente l’esperimento casuale discusso in precedenza.\n\nEsercizio 4.1 \nPer la distribuzione di massa di probabilità congiunta riportata nella tabella Tabella 4.2 si trovi la probabilità dell’evento \\(X+Y \\leq 1\\).\n\n\nSoluzione. Per trovare la probabilità richiesta dobbiamo sommare le probabilità associate a tutte le coppie \\((x,y)\\) che soddisfano la condizione \\(X+Y \\leq 1\\), ovvero\n\\[\nP_{XY}(X+Y \\leq 1) = P_{XY}(0, 0)+ P_{XY}(0, 1) + P_{XY}(1, 0) = 3/8.\n\\]\n\n\n4.1.3 Funzioni di probabilità marginali\n\nNel caso di due variabili casuali discrete \\(X\\) e \\(Y\\) di cui conosciamo la distribuzione congiunta, la distribuzione marginale di \\(X\\) è calcolata sommando la distribuzione di probabilità congiunta sopra la variabile da “scartare”, in questo caso la \\(Y\\). La funzione di massa di probabilità marginale \\(P(X=x)\\) è dunque\n\\[\\begin{equation}\nP(X = x) = \\sum_y P(X, Y = y) = \\sum_y P(X \\mid Y = y) P(Y = y),\n\\end{equation}\\]\ndove \\(P(X = x,Y = y)\\) è la distribuzione congiunta di \\(X, Y\\), mentre \\(P(X = x \\mid Y = y)\\) è la distribuzione condizionata di \\(X\\) dato \\(Y\\). Nel caso di \\(P(X=x)\\), diciamo che la variabile \\(Y\\) è stata marginalizzata.\nLe probabilità bivariate marginali e congiunte di variabili casuali discrete sono spesso rappresentate mediante tabelle di contingenza. Si noti che \\(P(X = x)\\) e \\(P(Y = y)\\) sono normalizzate:\n\\[\n\\sum_x P(X=x) = 1.0, \\quad \\sum_y P(Y=y) = 1.0.\n\\]\nNel caso continuo si sostituisce l’integrazione alla somma – si veda la Sezione 4.1.4.\n\nEsercizio 4.2 \nPer l’esperimento casuale descritto nella Sezione 4.1, si calcolino le probabilità marginali di \\(X\\) e \\(Y\\).\n\n\nSoluzione. Come indicato nella Tabella 4.3, \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\) e \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(i,\\) \\(P_Y (Y = i) = \\sum_x p_{xy}(x, y = i)\\).\n\n\nTabella 4.3: Distribuzione di probabilità congiunta \\(P(X,Y)\\) per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate e probabilità marginali \\(P(X)\\) e \\(P(Y)\\).\n\n\\(x / y\\)\n0\n1\n\\(P(x)\\)\n\n\n\n0\n1/8\n0\n1/8\n\n\n1\n2/8\n1/8\n3/8\n\n\n2\n1/8\n2/8\n3/8\n\n\n3\n0\n1/8\n1/8\n\n\n\\(P(y)\\)\n4/8\n4/8\n1.0\n\n\n\n\n\n\n4.1.4 Marginalizzazione di variabili casuali continue\nNella trattazione della statistca bayesiana useremo spesso il concetto di “marginalizzazione” e vedremo equazioni come la seguente:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) = \\int_{\\theta} p(y \\mid \\theta) p(\\theta),\n\\tag{4.1}\\]\nladdove \\(y\\) e \\(\\theta\\) sono due variabili casuali continue – nello specifico, con \\(y\\) denoteremo i dati e con \\(\\theta\\) i parametri di un modello statistico. Alla luce di quanto detto sopra, è possibiile pensare al caso continuo indicato nella Equazione 4.1 come all’estensione dell’esempio discusso in questo capitolo ad un numero infinito di valori delle due variabili continue (qui \\(y\\) e \\(\\theta\\))."
  },
  {
    "objectID": "018_joint_prob.html#sec-margin-vc-cont",
    "href": "018_joint_prob.html#sec-margin-vc-cont",
    "title": "4  Probabilità congiunta",
    "section": "\n4.3 Marginalizzazione di variabili casuali continue",
    "text": "4.3 Marginalizzazione di variabili casuali continue\nNella trattazione della statistca bayesiana useremo spesso il concetto di “marginalizzazione” e vedremo equazioni come la seguente:\n\\[\np(y) = \\int_{\\theta} p(y, \\theta) = \\int_{\\theta} p(y \\mid \\theta) p(\\theta),\n\\tag{4.1}\\]\nladdove \\(y\\) e \\(\\theta\\) sono due variabili casuali continue – nello specifico, con \\(y\\) denoteremo i dati e con \\(\\theta\\) i parametri di un modello statistico. Alla luce di quanto detto sopra, è possibiile pensare al caso continuo indicato nella Equazione 4.1 come all’estensione dell’esempio discusso in questo capitolo ad un numero infinito di valori delle due variabili continue (qui \\(y\\) e \\(\\theta\\))."
  },
  {
    "objectID": "018_joint_prob.html#indipendenza",
    "href": "018_joint_prob.html#indipendenza",
    "title": "4  Probabilità congiunta",
    "section": "\n4.2 Indipendenza",
    "text": "4.2 Indipendenza\nLa nozione di indipendenza per le variabili casuali è molto simile alla nozione di indipendenza per gli eventi. Due variabili casuali sono indipendenti se la conoscenza relativa a una di esse non influisce sulle probabilità dell’altra. Nel caso di due variabili casuali discrete, presentiamo qui una definizione di indipendenza formulatanei termini della loro distribuzione di massa di probabilità congiunta.\n\nDefinizione 4.2 Due variabili casuali \\(X\\) e \\(Y\\) distribuite congiuntamente si dicono indipendenti se e solo se\n\\[\nP_{X, Y}(x, y) = P_X(x) P_Y(y).\n\\]\n\nA parole, se due variabili discrete \\(X\\) e \\(Y\\) non si influenzano, ovvero se sono statisticamente indipendenti, allora la distribuzione di massa di probabilità congiunta si ottiene come prodotto delle funzioni di probabilità marginali di \\(X\\) e \\(Y\\). Se \\(P_{X, Y}(x, y) \\neq P_X(x) P_Y(y)\\), allora le due variabili si dicono associate.\nVedremo in seguito come una misura del grado di associazione lineare tra due variabili casuali è fornita dalla covarianza (o dalla correlazione)."
  },
  {
    "objectID": "018_joint_prob.html#valore-atteso-di-funzioni-di-variabili-casuali",
    "href": "018_joint_prob.html#valore-atteso-di-funzioni-di-variabili-casuali",
    "title": "4  Probabilità congiunta",
    "section": "\n4.3 Valore atteso di funzioni di variabili casuali",
    "text": "4.3 Valore atteso di funzioni di variabili casuali\nA volte ci viene data una variabile casuale $ X$e dobbiamo lavorare con una funzione di \\(X\\). Se \\(X\\) è una variabile casuale e \\(h(X)\\) è una funzione di \\(X\\), allora anche \\(h(X)\\) è una variabile casuale. Se si vuole calcolare il valore atteso di \\(h(X)\\), lo si può fare usando la funzione di massa di probabilità o la funzione di densità di probabilità di \\(X\\). Non è necessario conoscere la funzione di massa di probabilità (o la funzione di densità di probabilità) di \\(h(X)\\).\n\nEsercizio 4.3 \nSia \\(X\\) una variabile casuale discreta. Si trovi \\(\\mathbb{E}(aX + b)\\).\n\n\nSoluzione. \\(\\mathbb{E}(aX + b) = a\\mathbb{E}(X) + b = a \\sum_{x \\in \\Omega} xP(x) + b.\\)\n\n\nNota. Il risultato precedente è valido per variabili casuali continua dove la somma viene sostituita da un integrale."
  },
  {
    "objectID": "018_joint_prob.html#valore-atteso-di-una-funzione-di-una-variabile-casuale",
    "href": "018_joint_prob.html#valore-atteso-di-una-funzione-di-una-variabile-casuale",
    "title": "4  Probabilità congiunta",
    "section": "\n4.3 Valore atteso di una funzione di una variabile casuale",
    "text": "4.3 Valore atteso di una funzione di una variabile casuale\nA volte ci viene data una variabile casuale $ X$e dobbiamo lavorare con una funzione di \\(X\\). Se \\(X\\) è una variabile casuale e \\(h(X)\\) è una funzione di \\(X\\), allora anche \\(h(X)\\) è una variabile casuale. Se si vuole calcolare il valore atteso di \\(h(X)\\), lo si può fare usando la funzione di massa di probabilità o la funzione di densità di probabilità di \\(X\\); non è necessario conoscere la funzione di massa di probabilità (o la funzione di densità di probabilità) di \\(h(X)\\).\n\nEsercizio 4.3 \nSia \\(X\\) una variabile casuale discreta. Si trovi \\(\\mathbb{E}(aX + b)\\).\n\n\nSoluzione. \\(\\mathbb{E}(aX + b) = a\\mathbb{E}(X) + b = a \\sum_{x \\in \\Omega} xP(x) + b.\\) Si noti che la soluzione ha richiesto l’uso \\(P(x)\\), e non di \\(P(aX + b)\\).\n\n\nNota. Il risultato precedente è valido per variabili casuali continua dove la somma viene sostituita da un integrale."
  },
  {
    "objectID": "018_joint_prob.html#valore-atteso-di-una-funzione-di-molteplici-variabili-casuali",
    "href": "018_joint_prob.html#valore-atteso-di-una-funzione-di-molteplici-variabili-casuali",
    "title": "4  Probabilità congiunta",
    "section": "\n4.4 Valore atteso di una funzione di molteplici variabili casuali",
    "text": "4.4 Valore atteso di una funzione di molteplici variabili casuali\nA volte ci vengono fornite due variabili casuali \\(X\\) e \\(Y\\) e dobbiamo lavorare con una funzione di \\(X\\) e \\(Y\\). Se \\(X\\) e \\(Y\\) sono variabili casuali e \\(h(X, Y)\\) è una funzione di \\(X\\) e \\(Y\\), allora anche \\(h( X, Y)\\) è una variabile casuale. Se si desidera calcolare la media di \\(h(X, Y)\\), lo si può fare utilizzando la funzione di massa di probabilità congiunta (o la funzione di densità di probabilità congiunta di \\(X\\) e \\(Y\\)); non è necessario conoscere la funzione di massa di probabilità congiunta (o la funzione di massa congiunta funzione di densità di probabilità) di \\(h(X, Y)\\).\n\nEsercizio 4.4  \nSiano \\(X\\) e \\(Y\\) due variabili casuali discrete con distribuzione di massa di probabilità congiunta\n\\[\nP_{XY} (1,1) = 1/3; \\quad P_{XY}  (1,2) = 1/8; \\quad P_{XY} (2,1) = 1/2; \\quad P_{XY} (2,2) = 1/24.\n\\]\nSi trovi il valore atteso di \\(g(X, Y) = XY\\).\n\n\nSoluzione. \\[\n\\begin{align}\n\\mathbb{E}g(X, Y) &= \\mathbb{E}(XY) \\notag\\\\\n&= \\sum_{x=1}^2 \\sum_{y=1}^2 x y P_{XY}(x, y) \\notag\\\\\n&= 1 \\cdot 1 \\cdot \\frac{1}{3} +  \n   1 \\cdot 2 \\cdot \\frac{1}{8} +\n   2 \\cdot 1 \\cdot \\frac{1}{2} +\n   2 \\cdot 2 \\cdot \\frac{1}{24}\\notag\\\\\n&= \\frac{7}{4}.\\notag\n\\end{align}\n\\]\n\n\nEsercizio 4.5 \nSia \\(X_1, X_2, \\dots, X_n\\) una sequenza di variabili casuali i.i.d., ciascuna con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Si trovi il valore atteso di \\(X = X_1 + X_2 + \\dots + X_n\\).\n\n\nSoluzione. \\(\\mathbb{E}(X) = \\mathbb{E}(X_1) + \\mathbb{E}(X_2) + \\dots + \\mathbb{E}(X_n) = \\sum_{i=1}^n \\mathbb{E}(X_i) = n \\mu.\\)\n\n\nEsercizio 4.6 \nSia \\(X_1, X_2, \\dots, X_n\\) una sequenza di variabili casuali i.i.d., ciascuna con media \\(\\mu\\) e varianza \\(\\sigma^2\\). Si definisca una nuova variabile casuale\n\\[\n\\bar{X} = \\frac{X_1 + X_2 + \\dots + X_n}{n}\n\\]\ndetta media campionaria. Si trovi il valore atteso di \\(\\bar{X}\\).\n\n\nSoluzione. \\(\\mathbb{E}(\\bar{X}) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{E}(X_i) = \\mu.\\)"
  }
]