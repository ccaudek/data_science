<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.624">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 1&nbsp; Valore atteso e varianza</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./999_refs.html" rel="next">
<link href="./prob.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Valore atteso e varianza</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilità</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_expval_var.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Valore atteso e varianza</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li>
<a href="#valore-atteso" id="toc-valore-atteso" class="nav-link active" data-scroll-target="#valore-atteso"> <span class="header-section-number">1.1</span> Valore atteso</a>
  <ul class="collapse">
<li><a href="#interpretazione" id="toc-interpretazione" class="nav-link" data-scroll-target="#interpretazione"> <span class="header-section-number">1.1.1</span> Interpretazione</a></li>
  <li><a href="#propriet%C3%A0-del-valore-atteso" id="toc-proprietà-del-valore-atteso" class="nav-link" data-scroll-target="#propriet%C3%A0-del-valore-atteso"> <span class="header-section-number">1.1.2</span> Proprietà del valore atteso</a></li>
  <li><a href="#variabili-casuali-continue" id="toc-variabili-casuali-continue" class="nav-link" data-scroll-target="#variabili-casuali-continue"> <span class="header-section-number">1.1.3</span> Variabili casuali continue</a></li>
  </ul>
</li>
  <li>
<a href="#varianza" id="toc-varianza" class="nav-link" data-scroll-target="#varianza"> <span class="header-section-number">1.2</span> Varianza</a>
  <ul class="collapse">
<li><a href="#formula-alternativa-per-la-varianza" id="toc-formula-alternativa-per-la-varianza" class="nav-link" data-scroll-target="#formula-alternativa-per-la-varianza"> <span class="header-section-number">1.2.1</span> Formula alternativa per la varianza</a></li>
  <li><a href="#variabili-casuali-continue-1" id="toc-variabili-casuali-continue-1" class="nav-link" data-scroll-target="#variabili-casuali-continue-1"> <span class="header-section-number">1.2.2</span> Variabili casuali continue</a></li>
  </ul>
</li>
  <li><a href="#deviazione-standard" id="toc-deviazione-standard" class="nav-link" data-scroll-target="#deviazione-standard"> <span class="header-section-number">1.3</span> Deviazione standard</a></li>
  <li><a href="#standardizzazione" id="toc-standardizzazione" class="nav-link" data-scroll-target="#standardizzazione"> <span class="header-section-number">1.4</span> Standardizzazione</a></li>
  <li><a href="#momenti-di-variabili-casuali" id="toc-momenti-di-variabili-casuali" class="nav-link" data-scroll-target="#momenti-di-variabili-casuali"> <span class="header-section-number">1.5</span> Momenti di variabili casuali</a></li>
  <li><a href="#covarianza" id="toc-covarianza" class="nav-link" data-scroll-target="#covarianza"> <span class="header-section-number">1.6</span> Covarianza</a></li>
  <li><a href="#correlazione" id="toc-correlazione" class="nav-link" data-scroll-target="#correlazione"> <span class="header-section-number">1.7</span> Correlazione</a></li>
  <li>
<a href="#propriet%C3%A0" id="toc-proprietà" class="nav-link" data-scroll-target="#propriet%C3%A0"> <span class="header-section-number">1.8</span> Proprietà</a>
  <ul class="collapse">
<li><a href="#incorrelazione" id="toc-incorrelazione" class="nav-link" data-scroll-target="#incorrelazione"> <span class="header-section-number">1.8.1</span> Incorrelazione</a></li>
  </ul>
</li>
  <li><a href="#conclusioni" id="toc-conclusioni" class="nav-link" data-scroll-target="#conclusioni">Conclusioni</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="ch-expval-var-rv" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Valore atteso e varianza</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><p>Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità.</p>
<section id="valore-atteso" class="level2" data-number="1.1"><h2 data-number="1.1" class="anchored" data-anchor-id="valore-atteso">
<span class="header-section-number">1.1</span> Valore atteso</h2>
<p>Quando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo “valore tipico”. La nozione di “valore tipico”, tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi:</p>
<ul>
<li>la <em>media</em> (somma dei valori divisa per il numero dei valori),</li>
<li>la <em>mediana</em> (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente),</li>
<li>la <em>moda</em> (il valore che ricorre più spesso).</li>
</ul>
<p>Per esempio, la media di <span class="math inline">\(\{3, 1, 4, 1, 5\}\)</span> è <span class="math inline">\(\frac{3+1+4+1+5}{5} = 2.8\)</span>, la mediana è <span class="math inline">\(3\)</span> e la moda è <span class="math inline">\(1\)</span>. Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per “valore tipico” quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione. <!-- Supponiamo di ripetere un esperimento casuale molte volte in modo tale che ciascun valore $Y$ si presenti con una frequenza approssimativamente uguale alla sua probabilità. Per esempio, possiamo lanciare una coppia di dadi e osservare i valori di $S$ = "somma dei punti" e di $P$ = "prodotto dei punti". Ci poniamo il problema di definire il "risultato tipico" di questo esperimento in modo tale che esso corrisponda al valore medio dei valori della variabile casuale, quando l'esperimento casuale viene ripetuto tante volte.  --></p>
<div id="def-exp-val-discr" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 1.1 </strong></span>Sia <span class="math inline">\(Y\)</span> è una variabile casuale discreta che assume i valori <span class="math inline">\(y_1, \dots, y_n\)</span> con distribuzione <span class="math inline">\(P(Y = y_i) = p(y_i)\)</span>. Per definizione il <em>valore atteso</em> di <span class="math inline">\(Y\)</span>, <span class="math inline">\(\mathbb{E}(Y)\)</span>, è</p>
<p><span id="eq-expval-discr"><span class="math display">\[
\mathbb{E}(Y) = \sum_{i=1}^n y_i \cdot p(y_i).
\tag{1.1}\]</span></span></p>
</div>
<p>A parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.</p>
<div id="exr-exp-val-discr" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.1 </strong></span></p>
<p>Si calcoli il valore atteso della variabile casuale <span class="math inline">\(Y\)</span> corrispondente al lancio di una moneta equilibrata (testa: <em>Y</em> = 1; croce: <em>Y</em> = 0).</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Abbiamo</p>
<p><span class="math display">\[
\mathbb{E}(Y) = \sum_{i=1}^{2} y_i \cdot P(y_i) = 0 \cdot \frac{1}{5} + 1 \cdot \frac{1}{5} = 0.5.
\]</span></p>
</div>
<div id="exr-exp-val-discr-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.2 </strong></span></p>
<p>Si calcoli il valore atteso della variabile casuale <span class="math inline">\(Y\)</span> corrispondente ai punti ottenuti dal lancio di un dado equilibrato.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Il valore atteso di <span class="math inline">\(Y\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(Y) = \sum_{i=1}^{6} y_i \cdot P(y_i) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + \dots + 6 \cdot \frac{1}{6} = \frac{21}{6} = 3.5.
\]</span></p>
</div>
<section id="interpretazione" class="level3" data-number="1.1.1"><h3 data-number="1.1.1" class="anchored" data-anchor-id="interpretazione">
<span class="header-section-number">1.1.1</span> Interpretazione</h3>
<p>Che interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di <em>previsione</em> (e lo stesso simbolo) tanto per la probabilità che per la speranza matematica. Si può pertanto dire che, dal punto di vista bayesiano, la speranza matematica è l’estensione naturale della nozione di probabilità soggettiva.</p>
</section><section id="proprietà-del-valore-atteso" class="level3" data-number="1.1.2"><h3 data-number="1.1.2" class="anchored" data-anchor-id="proprietà-del-valore-atteso">
<span class="header-section-number">1.1.2</span> Proprietà del valore atteso</h3>
<p>La proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:</p>
<p><span id="eq-prop-expval-linearity"><span class="math display">\[
\mathbb{E}(X + Y) = \mathbb{E}(X) + \mathbb{E}(Y).
\tag{1.2}\]</span></span></p>
<p>L’<a href="#eq-prop-expval-linearity">Equazione&nbsp;<span>1.2</span></a> sembra ragionevole quando <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono indipendenti, ma è anche vera quando <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono associati. Abbiamo anche che</p>
<p><span id="eq-prop-expval-const"><span class="math display">\[
\mathbb{E}(cY) = c \mathbb{E}(Y).
\tag{1.3}\]</span></span></p>
<p>L’<a href="#eq-prop-expval-const">Equazione&nbsp;<span>1.3</span></a> ci dice che possiamo estrarre una costante dall’operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono indipendenti, abbiamo che</p>
<p><span id="eq-expval-prod-ind-rv"><span class="math display">\[
\mathbb{E}(X Y) = \mathbb{E}(X) \mathbb{E}(Y).
\tag{1.4}\]</span></span></p>
<div id="exr-exp-val-discr-3" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.3 </strong></span></p>
<p>Si considerino le seguenti variabili casuali: <span class="math inline">\(Y\)</span>, ovvero il numero che si ottiene dal lancio di un dado equilibrato, e <span class="math inline">\(Y\)</span>, il numero di teste prodotto dal lancio di una moneta equilibrata. Si trovi il valore atteso di <span class="math inline">\(X+Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Per risolvere il problema iniziamo a costruire lo spazio campionario dell’esperimento casuale consistente nel lancio di un dado e di una moneta.</p>
<table class="table">
<colgroup>
<col style="width: 31%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(x \textbackslash y\)</span></th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">(0, 1)</td>
<td style="text-align: center;">(0, 2)</td>
<td style="text-align: center;">(0, 3)</td>
<td style="text-align: center;">(0, 4)</td>
<td style="text-align: center;">(0, 5)</td>
<td style="text-align: center;">(0, 6)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">(1, 1)</td>
<td style="text-align: center;">(1, 2)</td>
<td style="text-align: center;">(1, 3)</td>
<td style="text-align: center;">(1, 4)</td>
<td style="text-align: center;">(1, 5)</td>
<td style="text-align: center;">(1, 6)</td>
</tr>
</tbody>
</table>
<p>ovvero</p>
<table class="table">
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(x \textbackslash y\)</span></th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">7</td>
</tr>
</tbody>
</table>
<p>Il risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero <span class="math inline">\(P(\omega) = \frac{1}{12}\)</span>. Il valore atteso di <span class="math inline">\(X+Y\)</span> è dunque uguale a:</p>
<p><span class="math display">\[
\mathbb{E}(X+Y) = 1 \cdot \frac{1}{12} + 2 \cdot \frac{1}{12} + \dots + 7 \cdot \frac{1}{12} = 4.0.
\]</span></p>
<p>Lo stesso risultato si ottiene nel modo seguente:</p>
<p><span class="math display">\[
\mathbb{E}(X+Y) = \mathbb{E}(X) + E(Y) = 3.5 + 0.5 = 4.0.
\]</span></p>
</div>
<div id="exr-exp-val-discr-4" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.4 </strong></span></p>
<p>Si considerino le variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> definite nel caso del lancio di tre monete equilibrate, dove <span class="math inline">\(X\)</span> conta il numero delle teste nei tre lanci e <span class="math inline">\(Y\)</span> conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>La distribuzione di probabilità congiunta <span class="math inline">\(P(X, Y)\)</span> è fornita nella tabella seguente.</p>
<table class="table">
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(x \textbackslash y\)</span></th>
<th style="text-align: center;">0</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;"><span class="math inline">\(p(Y)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1/8</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2/8</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">3/8</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">2/8</td>
<td style="text-align: center;">3/8</td>
</tr>
<tr class="even">
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1/8</td>
<td style="text-align: center;">1/8</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(p(y)\)</span></td>
<td style="text-align: center;">4/8</td>
<td style="text-align: center;">4/8</td>
<td style="text-align: center;">1.0</td>
</tr>
</tbody>
</table>
<p>Il calcolo del valore atteso di <span class="math inline">\(XY\)</span> si riduce a</p>
<p><span class="math display">\[
\mathbb{E}(XY) = 1 \cdot \frac{1}{8} + 2 \cdot \frac{2}{8} + 3 \cdot \frac{1}{8} = 1.0.
\]</span></p>
<p>Si noti che le variabili casuali <span class="math inline">\(Y\)</span> e <span class="math inline">\(Y\)</span> non sono indipendenti. Dunque non possiamo usare la proprietà del <span class="quarto-unresolved-ref">?thm-prodindrv</span>. Infatti, il valore atteso di <span class="math inline">\(X\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(X) = 1 \cdot \frac{3}{8} + 2 \cdot \frac{3}{8} + 3 \cdot \frac{1}{8} = 1.5
\]</span></p>
<p>e il valore atteso di <span class="math inline">\(Y\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(Y) = 0 \cdot \frac{4}{8} + 1 \cdot \frac{4}{8} = 0.5.
\]</span></p>
<p>Perciò</p>
<p><span class="math display">\[
1.5 \cdot 0.5 \neq 1.0.
\]</span></p>
</div>
</section><section id="variabili-casuali-continue" class="level3" data-number="1.1.3"><h3 data-number="1.1.3" class="anchored" data-anchor-id="variabili-casuali-continue">
<span class="header-section-number">1.1.3</span> Variabili casuali continue</h3>
<p>Nel caso di una variabile casuale continua <span class="math inline">\(Y\)</span> il valore atteso diventa:</p>
<p><span id="eq-def-ev-rv-cont"><span class="math display">\[
\mathbb{E}(Y) = \int_{-\infty}^{+\infty} y p(y) \,\operatorname {d}\!y.
\tag{1.5}\]</span></span></p>
<p>Anche in questo caso il valore atteso è una media ponderata della <span class="math inline">\(y\)</span>, nella quale ciascun possibile valore <span class="math inline">\(y\)</span> è ponderato per il corrispondente valore della densità <span class="math inline">\(p(y)\)</span>. Possiamo leggere l’integrale pensando che <span class="math inline">\(y\)</span> rappresenti l’ampiezza delle barre infinitamente strette di un istogramma, con la densità <span class="math inline">\(p(y)\)</span> che corrisponde all’altezza di tali barre e la notazione <span class="math inline">\(\int_{-\infty}^{+\infty}\)</span> che corrisponde ad una somma.</p>
<p>Un’altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda della <span class="math inline">\(Y\)</span> individua il valore <span class="math inline">\(y\)</span> più plausibile, ovvero il valore <span class="math inline">\(y\)</span> che massimizza la funzione di densità <span class="math inline">\(p(y)\)</span>:</p>
<p><span id="eq-def-mode"><span class="math display">\[
\mbox{Mo}(Y) = \mbox{argmax}_y p(y).
\tag{1.6}\]</span></span></p>
</section></section><section id="varianza" class="level2" data-number="1.2"><h2 data-number="1.2" class="anchored" data-anchor-id="varianza">
<span class="header-section-number">1.2</span> Varianza</h2>
<p>La seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la <em>varianza</em>.</p>
<div id="def-var-rv-definition" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 1.2 </strong></span>Se <span class="math inline">\(Y\)</span> è una variabile casuale discreta con distribuzione <span class="math inline">\(p(y)\)</span>, per definizione la varianza di <span class="math inline">\(Y\)</span>, <span class="math inline">\(\mathbb{V}(Y)\)</span>, è</p>
<p><span id="eq-def-var-rv"><span class="math display">\[
\mathbb{V}(Y) = \mathbb{E}\Big[\big(Y - \mathbb{E}(Y)\big)^2\Big].
\tag{1.7}\]</span></span></p>
</div>
<p>A parole: la varianza è la deviazione media quadratica della variabile dalla sua media.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Se denotiamo <span class="math inline">\(\mathbb{E}(Y) = \mu\)</span>, la varianza <span class="math inline">\(\mathbb{V}(Y)\)</span> diventa il valore atteso di <span class="math inline">\((Y - \mu)^2\)</span>.</p>
<div id="exr-var-discr-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.5 </strong></span></p>
<p>Posta <span class="math inline">\(S\)</span> uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, si calcoli la varianza di <span class="math inline">\(S\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>La variabile casuale <span class="math inline">\(S\)</span> ha la seguente distribuzione di probabilità:</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;"><span class="math inline">\(s\)</span></th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
<th style="text-align: center;">6</th>
<th style="text-align: center;">7</th>
<th style="text-align: center;">8</th>
<th style="text-align: center;">9</th>
<th style="text-align: center;">10</th>
<th style="text-align: center;">11</th>
<th style="text-align: center;">12</th>
</tr></thead>
<tbody><tr class="odd">
<td style="text-align: center;"><span class="math inline">\(P(S = s)\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{2}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{3}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{4}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{5}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{6}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{5}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{4}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{3}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{2}{36}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{36}\)</span></td>
</tr></tbody>
</table>
<p>Essendo <span class="math inline">\(\mathbb{E}(S) = 7\)</span>, la varianza diventa</p>
<p><span class="math display">\[
\begin{align}
\mathbb{V}(S) &amp;= \sum \left(S- \mathbb{E}(S)\right)^2 \cdot P(S) \notag\\
&amp;= (2 - 7)^2 \cdot 0.0278 + (3-7)^2 \cdot 0.0556 + \dots + (12 - 7)^2 \cdot 0.0278 \notag\\
&amp;= 5.8333.\notag
\end{align}
\]</span></p>
</div>
<section id="formula-alternativa-per-la-varianza" class="level3" data-number="1.2.1"><h3 data-number="1.2.1" class="anchored" data-anchor-id="formula-alternativa-per-la-varianza">
<span class="header-section-number">1.2.1</span> Formula alternativa per la varianza</h3>
<p>C’è un modo più semplice per calcolare la varianza:</p>
<p><span class="math display">\[
\begin{align}
\mathbb{E}\Big[\big(Y - \mathbb{E}(Y)\big)^2\Big] &amp;= \mathbb{E}\big(Y^2 - 2Y\mathbb{E}(Y) + \mathbb{E}(Y)^2\big)\notag\\
&amp;= \mathbb{E}(Y^2) - 2\mathbb{E}(Y)\mathbb{E}(Y) + \mathbb{E}(Y)^2,
\end{align}
\]</span></p>
<p>dato che <span class="math inline">\(\mathbb{E}(Y)\)</span> è una costante. Pertanto</p>
<p><span id="eq-def-alt-var-rv"><span class="math display">\[
\mathbb{V}(Y) = \mathbb{E}(Y^2) - \big(\mathbb{E}(Y) \big)^2.
\tag{1.8}\]</span></span></p>
<p>A parole: la varianza è la media dei quadrati meno il quadrato della media.</p>
<div id="exr-var-discr-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.6 </strong></span></p>
<p>Consideriamo la variabile casuale <span class="math inline">\(Y\)</span> che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Si trovi la varianza di <span class="math inline">\(Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Il valore atteso di <span class="math inline">\(Y\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(Y) = 0 \cdot 0.2 + 1 \cdot 0.8 = 0.8.
\]</span></p>
<p>Usando la formula tradizionale della varianza otteniamo:</p>
<p><span class="math display">\[
\mathbb{V}(Y) = (0 - 0.8)^2 \cdot 0.2 + (1 - 0.8)^2 \cdot 0.8 = 0.16.
\]</span></p>
<p>Lo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di <span class="math inline">\(Y^2\)</span> è</p>
<p><span class="math display">\[
\mathbb{E}(Y^2) = 0^2 \cdot 0.2 + 1^2 \cdot 0.8 = 0.8.
\]</span></p>
<p>e la varianza diventa</p>
<p><span class="math display">\[
\mathbb{V}(Y) = \mathbb{E}(Y^2) - \big(\mathbb{E}(Y) \big)^2 = 0.8 - 0.8^2 = 0.16.
\]</span></p>
</div>
</section><section id="variabili-casuali-continue-1" class="level3" data-number="1.2.2"><h3 data-number="1.2.2" class="anchored" data-anchor-id="variabili-casuali-continue-1">
<span class="header-section-number">1.2.2</span> Variabili casuali continue</h3>
<p>Nel caso di una variabile casuale continua <span class="math inline">\(Y\)</span>, la varianza diventa:</p>
<p><span id="eq-def-var-rv-cont"><span class="math display">\[
\mathbb{V}(Y) = \int_{-\infty}^{+\infty} \large[y - \mathbb{E}(Y)\large]^2 p(y) \,\operatorname {d}\!y.
\tag{1.9}\]</span></span></p>
<p>Come nel caso discreto, la varianza di una v.c. continua <span class="math inline">\(Y\)</span> misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori <span class="math inline">\(Y\)</span> dalla loro media.</p>
</section></section><section id="deviazione-standard" class="level2" data-number="1.3"><h2 data-number="1.3" class="anchored" data-anchor-id="deviazione-standard">
<span class="header-section-number">1.3</span> Deviazione standard</h2>
<p>Quando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell’unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato <em>deviazione standard</em> e solitamente è denotato dalla lettera greca <span class="math inline">\(\sigma\)</span>.</p>
<div id="def-sd-vc" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 1.3 </strong></span>Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:</p>
<p><span id="eq-def-sd"><span class="math display">\[
\sigma_Y = \sqrt{\mathbb{V}(Y)}.
\tag{1.10}\]</span></span></p>
</div>
<p>Interpretiamo la deviazione standard di una variabile casuale come nella statistica descrittiva: misura approssimativamente la distanza tipica o prevista dei possibili valori <span class="math inline">\(y\)</span> dalla loro media.</p>
<div id="exr-sd-discr-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.7 </strong></span></p>
<p>Per i dadi equilibrati dell’<a href="#exr-var-discr-1">Esercizio&nbsp;<span>1.5</span></a>, la deviazione standard della variabile casuale <span class="math inline">\(S\)</span> è uguale a <span class="math inline">\(\sqrt{5.833} = 2.415\)</span>.</p>
</div>
</section><section id="standardizzazione" class="level2" data-number="1.4"><h2 data-number="1.4" class="anchored" data-anchor-id="standardizzazione">
<span class="header-section-number">1.4</span> Standardizzazione</h2>
<div id="def-standardization" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 1.4 </strong></span>Data una variabile casuale <span class="math inline">\(Y\)</span>, si dice variabile standardizzata di <span class="math inline">\(Y\)</span> l’espressione</p>
<p><span id="eq-standardization"><span class="math display">\[
Z = \frac{Y - \mathbb{E}(Y)}{\sigma_Y}.
\tag{1.11}\]</span></span></p>
</div>
<p>Solitamente, una variabile standardizzata viene denotata con la lettera <span class="math inline">\(Z\)</span>.</p>
</section><section id="momenti-di-variabili-casuali" class="level2" data-number="1.5"><h2 data-number="1.5" class="anchored" data-anchor-id="momenti-di-variabili-casuali">
<span class="header-section-number">1.5</span> Momenti di variabili casuali</h2>
<div class="definition">
<p>Si chiama <em>momento</em> di ordine <span class="math inline">\(q\)</span> di una v.c. <span class="math inline">\(X\)</span>, dotata di densità <span class="math inline">\(p(x)\)</span>, la quantità</p>
<p><span id="eq-moments-cont"><span class="math display">\[
\mathbb{E}(X^q) = \int_{-\infty}^{+\infty} x^q p(x) \; dx.
\tag{1.12}\]</span></span></p>
<p>Se <span class="math inline">\(X\)</span> è una v.c. discreta, i suoi momenti valgono:</p>
<p><span id="eq-moments-discr"><span class="math display">\[
\mathbb{E}(X^q) = \sum_i x_i^q P(x_i).
\tag{1.13}\]</span></span></p>
</div>
<p>I momenti sono importanti parametri indicatori di certe proprietà di <span class="math inline">\(X\)</span>. I più noti sono senza dubbio quelli per <span class="math inline">\(q = 1\)</span> e <span class="math inline">\(q = 2\)</span>. Il momento del primo ordine corrisponde al valore atteso di <span class="math inline">\(X\)</span>. Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di <span class="math inline">\(X\)</span>, operando una traslazione <span class="math inline">\(x_0 = x − \mathbb{E}(X)\)</span> che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.</p>
</section><section id="covarianza" class="level2" data-number="1.6"><h2 data-number="1.6" class="anchored" data-anchor-id="covarianza">
<span class="header-section-number">1.6</span> Covarianza</h2>
<p>La covarianza quantifica la tendenza delle variabili aleatorie <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> a “variare assieme”. Per esempio, l’altezza e il peso delle giraffe producono una covarianza positiva perché all’aumentare di una di queste due quantità tende ad aumentare anche l’altra. La covarianza misura la forza e la direzione del legame lineare tra due variabili aleatorie <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span>. Si utilizza la notazione <span class="math inline">\(\mbox{Cov}(X,Y)=\sigma_{xy}\)</span>.</p>
<div id="def-covariance-rv" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 1.5 </strong></span>Date due variabili aleatorie <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, chiamiamo covarianza tra <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> il numero</p>
<p><span id="eq-cov-def-rv"><span class="math display">\[
\mbox{Cov}(X,Y) = \mathbb{E}\Bigl(\bigl(X - \mathbb{E}(X)\bigr) \bigl(Y - \mathbb{E}(Y)\bigr)\Bigr),
\tag{1.14}\]</span></span></p>
<p>dove <span class="math inline">\(\mathbb{E}(X)\)</span> e <span class="math inline">\(\mathbb{E}(Y)\)</span> sono i valori attesi di <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span>.</p>
</div>
<p>In maniera esplicita,</p>
<p><span id="eq-cov_def"><span class="math display">\[
\mbox{Cov}(X,Y) = \sum_{(x,y) \in \Omega} (x - \mu_X) (y - \mu_Y) f(x, y).
\tag{1.15}\]</span></span></p>
<p>La definizione è analoga, algebricamente, a quella di varianza e risulta infatti</p>
<p><span class="math display">\[
\mathbb{V}(x) = \mbox{Cov}(X, X)
\]</span></p>
<p>e</p>
<p><span id="eq-cov_vc_alt"><span class="math display">\[
\mbox{Cov}(X,Y) = \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X).
\tag{1.16}\]</span></span></p>
<div class="proof">
<p><span class="proof-title"><em>Dimostrazione</em>. </span>L’<a href="#eq-cov_vc_alt">Equazione&nbsp;<span>1.16</span></a> si ricava nel modo seguente:</p>
<p><span class="math display">\[
\begin{align}
\mbox{Cov}(X,Y) &amp;= \mathbb{E}\Bigl(\bigl(X-\mathbb{E}(X)\bigr) \bigl(Y-\mathbb{E}(Y)\bigr)\Bigr)\notag\\
          %&amp;= \mathbb{E}(XY) - \mathbb{E}(Y)X -\mathbb{E}(X)Y + \mathbb{E}(X)\mathbb{E}(Y) )\notag\\
          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X) - \mathbb{E}(X)\mathbb{E}(Y) + \mathbb{E}(X)\mathbb{E}(Y)\notag\\
          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X)\notag.
\end{align}
\]</span></p>
</div>
<div id="exr-cov-rv-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.8 </strong></span></p>
<p>Consideriamo le variabili casuali definite nell’Esercizio 2.4. Si calcoli la covarianza di <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>Abbiamo che <span class="math inline">\(\mu_X = 1.5\)</span> e <span class="math inline">\(\mu_Y = 0.5\)</span>. Ne segue che la covarianza di <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> è:</p>
<p><span class="math display">\[
\begin{align}
\mbox{Cov}(X,Y) &amp;= \sum_{(x,y) \in \Omega} (x - \mu_X) (y - \mu_Y) f(x, y)\notag\\
&amp;= (0-1.5)(0-0.5)\cdot \frac{1}{8} + (0-1.5)(1-0.5) \cdot 0 \\
   &amp;\qquad + (1-1.5)(0-0.5)\cdot \frac{2}{8} + (1-1.5)(1-0.5) \cdot \frac{1}{8} \notag\\
    &amp;\qquad+ (2-1.5)(0-0.5) \cdot \frac{1}{8} + (2-1.5)(1-0.5) \cdot \frac{2}{8} \\
   &amp;\qquad+ (3-1.5)(0-0.5) \cdot 0 +  (3-1.5)(1-0.5)\cdot\frac{1}{8} \notag\\
   &amp;= \frac{1}{4}. \notag
\end{align}
\]</span></p>
<p>Lo stesso risultato può essere trovato nel modo seguente. Iniziamo a calcolare il valore atteso del prodotto <span class="math inline">\(XY\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}(XY) = 0 \cdot\frac{4}{8} + 1 \cdot\frac{1}{8} + 2 \cdot\frac{2}{8} + 3 \cdot\frac{1}{8} = 1.0.
\]</span></p>
<p>Dunque, la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> diventa</p>
<p><span class="math display">\[
\begin{align}
\mbox{Cov}(X,Y) &amp;= \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y)\notag\\
&amp;= 1 -  1.5\cdot 0.5 \notag\\
&amp;= 0.25.\notag
\end{align}
\]</span></p>
</div>
</section><section id="correlazione" class="level2" data-number="1.7"><h2 data-number="1.7" class="anchored" data-anchor-id="correlazione">
<span class="header-section-number">1.7</span> Correlazione</h2>
<p>La covarianza dipende dall’unità di misura delle due variabili e quindi non consente di stabilire l’intensità della relazione. Una misura standardizzata della relazione che intercorre fra due variabili è invece rappresentata dalla correlazione. La correlazione si ottiene dividendo la covarianza per le deviazioni standard delle due variabili aleatorie.</p>
<div id="defn-cor-rv-def">
<p>Il coefficiente di correlazione tra <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> è il numero definito da</p>
<p><span id="eq-cor-rv-def"><span class="math display">\[
\rho(X,Y) =\frac{\mbox{Cov}(X,Y)}{\sqrt{\mathbb{V}(X)\mathbb{V}(Y)}}.
\tag{1.17}\]</span></span></p>
</div>
<p>Si può anche scrivere <span class="math inline">\(\rho_{X,Y}\)</span> al posto di <span class="math inline">\(\rho(X,Y)\)</span>.</p>
<p>Il coefficiente di correlazione <span class="math inline">\(\rho_{xy}\)</span> è un numero puro, cioè non dipende dall’unità di misura delle variabili, e assume valori compresi tra -1 e +1.</p>
</section><section id="proprietà" class="level2" data-number="1.8"><h2 data-number="1.8" class="anchored" data-anchor-id="proprietà">
<span class="header-section-number">1.8</span> Proprietà</h2>
<ul>
<li><p>La covarianza tra una variabile aleatoria <span class="math inline">\(X\)</span> e una costante <span class="math inline">\(c\)</span> è nulla: <span class="math inline">\(\mbox{Cov}(c,X) = 0;\)</span></p></li>
<li><p>la covarianza è simmetrica: <span class="math inline">\(\mbox{Cov}(X,Y) = \mbox{Cov}(Y,X);\)</span></p></li>
<li><p>vale <span class="math inline">\(-1 \leq \rho(X,Y) \leq 1;\)</span></p></li>
<li><p>la correlazione non dipende dall’unità di misura: <span class="math inline">\(\rho(aX, bY) = \rho(X,Y), \qquad \forall a, b &gt; 0;\)</span></p></li>
<li><p>se <span class="math inline">\(Y = a + bX\)</span> è una funzione lineare di <span class="math inline">\(X\)</span> con costanti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>, allora <span class="math inline">\(\rho(X,Y) = \pm 1\)</span>, a seconda del segno di <span class="math inline">\(b\)</span>;</p></li>
<li><p>la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, ciascuna moltiplicata per una costante, è uguale al prodotto delle costanti per la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>: <span class="math inline">\(\mbox{Cov}(aX,bY) = ab \;\mbox{Cov}(X,Y), \qquad \forall a,b \in\)</span>;</p></li>
<li><p>vale <span class="math inline">\(\mathbb{V}(X \pm Y) = \mathbb{V}(X) + \mathbb{V}(Y) \pm 2 \cdot \mbox{Cov}(X,Y)\)</span>;</p></li>
<li><p>vale <span class="math inline">\(\mbox{Cov}(X + Y, Z) = \mbox{Cov}(X,Z) + \mbox{Cov}(Y,Z);\)</span></p></li>
<li><p>per una sequenza di variabili aleatorie <span class="math inline">\(X_1, \dots, X_n\)</span>, si ha <span class="math inline">\(\mathbb{V}\left( \sum_{i=1}^n X_i\right) = \sum_{i=1}^n \mathbb{V}(X_i) + 2\sum_{i,j: i&lt;j}cov(X_i, X_j);\)</span></p></li>
<li><p>vale <span class="math inline">\(\mbox{Cov}\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^m b_jY_j\right) = \sum_{i=1}^n \sum_{j=1}^m a_j b_j\mbox{Cov}(X_j, Y_j);\)</span></p></li>
<li><p>se <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> sono indipendenti, allora <span class="math inline">\(\mbox{Cov}\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^n b_jX_j\right) = \sum_{i=1}^n a_i b_i \mathbb{V}(X_i).\)</span></p></li>
</ul>
<section id="incorrelazione" class="level3" data-number="1.8.1"><h3 data-number="1.8.1" class="anchored" data-anchor-id="incorrelazione">
<span class="header-section-number">1.8.1</span> Incorrelazione</h3>
<div id="def-incorrelation-def" class="theorem definition">
<p><span class="theorem-title"><strong>Definizione 1.6 </strong></span>Si dice che <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla,</p>
<p><span id="eq-incorrelation-def"><span class="math display">\[
\sigma_{XY} = \mathbb{E} \big[(X - \mu_X) (y-\mu_u) \big] = 0,
\tag{1.18}\]</span></span></p>
<p>che si può anche scrivere come</p>
<p><span class="math display">\[
\rho_{XY} = 0, \quad \mathbb{E}(XY) = \mathbb{E}(X) \mathbb{E}(Y).
\]</span></p>
</div>
<p>Si introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se <span class="math inline">\(\mbox{Cov}(X, Y) = 0\)</span>, non è detto che <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> siano indipendenti.</p>
<div id="exr-incorrelation-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Esercizio 1.9 </strong></span>Siano <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> due variabili aleatorie discrete avente una distribuzione di massa di probabilità congiunta pari a</p>
<p><span class="math display">\[
f_{XY}(x,y) = \frac{1}{4} \quad (x,y) \in \{(0,0), (1,1), (1, -1), (2,0) \}
\]</span></p>
<p>e zero altrimenti. Le due variabili aleatorie <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono mutuamente indipendenti?</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Soluzione</em>. </span>La distribuzione marginale della <span class="math inline">\(X\)</span> è</p>
<p><span class="math display">\[
\begin{cases}
X = 0, \quad  P_X = 1/4, \\
X = 1, \quad P_X = 2/4, \\
X = 2, \quad P_X = 1/4.
\end{cases}
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(X) = 0 \frac{1}{4} + 1 \frac{2}{4} + 2 \frac{1}{4} = 1.
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(X^2) = 0^2 \frac{1}{4} + 1^2 \frac{2}{4} + 2^2 \frac{1}{4} = \frac{3}{2}.
\]</span></p>
<p><span class="math display">\[
\mathbb{V}(X) = \frac{3}{2} - 1^2 = \frac{1}{2}.
\]</span></p>
<p>La distribuzione marginale della <span class="math inline">\(Y\)</span> è</p>
<p><span class="math display">\[
\begin{cases}
Y = -1, \quad  P_Y = 1/4, \\
Y = 0, \quad P_Y = 2/4, \\
Y = 1, \quad P_Y = 1/4.
\end{cases}
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(Y) = 0 \frac{2}{4} + 1 \frac{1}{4} + (-1) \frac{1}{4} = 0.
\]</span></p>
<p><span class="math display">\[
\mathbb{E}(Y^2) = 0^2 \frac{2}{4} + 1^2 \frac{1}{4} + (-1)^2 \frac{1}{4} = \frac{1}{2}.
\]</span></p>
<p><span class="math display">\[
\mathbb{V}(X) = \frac{1}{2} - 0^2 = \frac{1}{2}.
\]</span></p>
<p>Calcoliamo ora la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}(XY) = \sum_x\sum_y xy f_{XY} (x,y) =
(0\cdot 0)\frac{1}{4} +
(1\cdot 1)\frac{1}{4} +
(1\cdot -1)\frac{1}{4} +
(2\cdot 0)\frac{1}{4} = 0.
\]</span></p>
<p><span class="math display">\[
\mbox{Cov}(X,Y) = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y) = 0 - 1\cdot0 = 0.
\]</span></p>
<p>Quindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non sono indipendenti, in quanto non è vero che</p>
<p><span class="math display">\[
f_{XY} (x,y) = f_X(x) f_Y(y)
\]</span></p>
<p>per tutti gli <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
</div>
<p>In conclusione, anche se condizione di indipendenza implica una covarianza nulla, l’esempio precedente mostra come l’inverso non sia necessariamente vero: la covarianza può essere zero anche quando le due variabili aleatorie non sono indipendenti.</p>
</section></section><section id="conclusioni" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="conclusioni">Conclusioni</h2>
<p>La densità di probabilità congiunta bivariata tiene simultaneamente conto del comportamento di due variabili aleatorie <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> e di come esse si influenzino. Se <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono legate linearmente, allora il coefficiente di correlazione</p>
<span class="math display">\[\begin{equation}
\rho = \frac{\mbox{Cov}(X, Y)}{\sigma_X \sigma_Y}\notag
\end{equation}\]</span>
<p>fornisce l’indice maggiormente utilizzato per descrivere l’intensità e il segno dell’associazione lineare. Nel caso di un’associazione lineare perfetta, <span class="math inline">\(Y = a + bX\)</span>, avremo <span class="math inline">\(\rho = 1\)</span> con <span class="math inline">\(b\)</span> positivo ed <span class="math inline">\(\rho = -1\)</span> con <span class="math inline">\(b\)</span> negativo. Se il coefficiente di correlazione è pari a 0 le variabili si dicono incorrelate. Condizione sufficiente (ma non necessaria) affinché <span class="math inline">\(\rho = 0\)</span> è che le due variabili siano tra loro indipendenti.</p>


</section><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Data una variabile casuale <span class="math inline">\(Y\)</span> con valore atteso <span class="math inline">\(\mathbb{E}(Y)\)</span>, le “distanze” tra i valori di <span class="math inline">\(Y\)</span> e il valore atteso <span class="math inline">\(\mathbb{E}(Y)\)</span> definiscono la variabile casuale <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> chiamata <em>scarto</em>, oppure <em>deviazione</em> oppure <em>variabile casuale centrata</em>. La variabile <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell’origine degli assi. Si può dimostrare facilmente che il valore atteso della variabile scarto <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> vale zero, dunque la media di tale variabile non può essere usata per quantificare la “dispersione” dei valori di <span class="math inline">\(Y\)</span> relativamente al suo valore medio. Occorre rendere sempre positivi i valori di <span class="math inline">\(Y - \mathbb{E}(Y)\)</span> e tale risultato viene ottenuto considerando la variabile casuale <span class="math inline">\(\left(Y - \mathbb{E}(Y)\right)^2\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./prob.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Parte 2: Il calcolo delle probabilità</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./999_refs.html" class="pagination-link">
        <span class="nav-page-text">Riferimenti bibliografici</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>