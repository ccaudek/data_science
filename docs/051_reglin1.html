<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Data Science per psicologi - 25&nbsp; Introduzione</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./052_reglin2.html" rel="next">
<link href="./regression.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Introduzione</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Data Science per psicologi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/ccaudek/data_science/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Benvenuti</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">Prefazione</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./basics.html" class="sidebar-item-text sidebar-link">Parte 1: Nozioni di base</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./001_key_notions.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Concetti chiave</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./005_measurement.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">La misurazione in psicologia</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./007_freq_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Variabili e distribuzioni di frequenza</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./011_loc_scale.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Indici di posizione e di scala</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./012_correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Le relazioni tra variabili</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./prob.html" class="sidebar-item-text sidebar-link">Parte 2: Il calcolo delle probabilit√†</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./015_prob_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">La logica dell‚Äôincerto</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./016_conditional_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Probabilit√† condizionata</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./017_bayes_theorem.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">L‚Äôinterpretazione soggettivista della probabilit√†</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./018_joint_prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Probabilit√† congiunta</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./019_density_func.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">La densit√† di probabilit√†</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./020_expval_var.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Valore atteso e varianza</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./distr.html" class="sidebar-item-text sidebar-link">Parte 3: Distribuzioni di v.c. discrete e continue</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./022_discr_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. discrete</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./023_cont_rv_distr.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Distribuzioni di v.c. continue</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./024_likelihood.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">La funzione di verosimiglianza</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./bayes_inference.html" class="sidebar-item-text sidebar-link">Parte 4: Inferenza bayesiana</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./025_intro_bayes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Credibilit√†, modelli e parametri</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./026_subj_prop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Pensare ad una proporzione in termini soggettivi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./029_conjugate_families.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Distribuzioni coniugate</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./030_balance_prior_post.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">L‚Äôinfluenza della distribuzione a priori</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./036_posterior_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Approssimazione della distribuzione a posteriori</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./040_beta_binomial_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Il modello beta-binomiale in linguaggio Stan</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./041_mcmc_diagnostics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Diagnostica delle catene markoviane</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./045_summarize_posterior.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Sintesi a posteriori</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./046_bayesian_prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">La predizione bayesiana</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./050_normal_normal_mod.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Inferenza sul parametro <span class="math inline">\(\mu\)</span> (media di una v.c. Normale)</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./regression.html" class="sidebar-item-text sidebar-link">Parte 5: Regressione lineare</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./051_reglin1.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Introduzione</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./052_reglin2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regressione lineare con un singolo predittore</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./053_reglin3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Modello di regressione in linguaggio Stan</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./054_reglin4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Inferenza sul modello lineare</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./055_reglin5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Confronto tra due gruppi indipendenti</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./056_pred_check.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Predictive checks</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./060_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Confronto tra le medie di tre o pi√π gruppi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./070_mod_hier.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Modello gerarchico</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./071_mod_hier_sim.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Modello gerarchico: simulazioni</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./entropy.html" class="sidebar-item-text sidebar-link">Parte 6: Entropia</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./090_entropy.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Entropia</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./091_kl.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">La divergenza di Kullback-Leibler</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./092_info_criterion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Criterio di informazione e convalida incrociata</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./999_refs.html" class="sidebar-item-text sidebar-link">Riferimenti bibliografici</a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Appendici</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a01_math_symbols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Simbologia di base</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a02_number_sets.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Numeri binari, interi, razionali, irrazionali e reali</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a03_set_theory.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Insiemi</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a04_summation_notation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Simbolo di somma (sommatorie)</span></a>
  </div>
</li>
    </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc"><h2 id="toc-title">Sommario</h2>
   
  <ul>
<li><a href="#la-funzione-lineare" id="toc-la-funzione-lineare" class="nav-link active" data-scroll-target="#la-funzione-lineare"> <span class="header-section-number">25.1</span> La funzione lineare</a></li>
  <li><a href="#una-media-per-ciascuna-osservazione" id="toc-una-media-per-ciascuna-osservazione" class="nav-link" data-scroll-target="#una-media-per-ciascuna-osservazione"> <span class="header-section-number">25.2</span> Una media per ciascuna osservazione</a></li>
  <li><a href="#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore" id="toc-relazione-lineare-tra-la-media-y-mid-x-e-il-predittore" class="nav-link" data-scroll-target="#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore"> <span class="header-section-number">25.3</span> Relazione lineare tra la media <span class="math inline">\(y \mid x\)</span> e il predittore</a></li>
  <li><a href="#il-modello-lineare" id="toc-il-modello-lineare" class="nav-link" data-scroll-target="#il-modello-lineare"> <span class="header-section-number">25.4</span> Il modello lineare</a></li>
  <li><a href="#commenti-e-considerazioni-finali" id="toc-commenti-e-considerazioni-finali" class="nav-link" data-scroll-target="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-regr-intro" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Introduzione</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Codice</button></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><div class="cell">

</div>
<p>Lo scopo della ricerca √® trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra i costrutti psicologici e le relazioni che intercorrono tra i fenomeni psicologici e quelli non psicologici (sociali, economici, storici, ‚Ä¶). Abbiamo gi√† visto come la correlazione di Pearson sia uno strumento adatto a questo scopo. Infatti, essa ci informa sulla direzione e sull‚Äôintensit√† della relazione lineare tra due variabili. Tuttavia, la correlazione non √® sufficiente, in quanto il ricercatore ha a disposizione solo i dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. A causa della variabilit√† campionaria, le propriet√† dei campioni sono necessariamente diverse da quelle della popolazione: ci√≤ che si pu√≤ osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. √à dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le propriet√† del campione e le propriet√† della popolazione da cui esso √® stato estratto. Il modello lineare utilizza la funzione matematica pi√π semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. In questo Capitolo vedremo come si possa fare inferenza sulla relazione tra due variabili mediante il modello lineare bayesiano. Inizieremo a descrivere le propriet√† geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire un modello statistico secondo un approccio bayesiano.</p>
<section id="la-funzione-lineare" class="level2" data-number="25.1"><h2 data-number="25.1" class="anchored" data-anchor-id="la-funzione-lineare">
<span class="header-section-number">25.1</span> La funzione lineare</h2>
<p>Iniziamo con un ripasso sulla funzione di lineare. Si chiama <em>funzione lineare</em> una funzione del tipo</p>
<span class="math display">\[\begin{equation}
f(x) = a + b x,
\end{equation}\]</span>
<p>dove <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> sono delle costanti. Il grafico di tale funzione √® una retta di cui il parametro <span class="math inline">\(b\)</span> √® detto <em>coefficiente angolare</em> e il parametro <span class="math inline">\(a\)</span> √® detto <em>intercetta</em> con l‚Äôasse delle <span class="math inline">\(y\)</span> [infatti, la retta interseca l‚Äôasse <span class="math inline">\(y\)</span> nel punto <span class="math inline">\((0,a)\)</span>, se <span class="math inline">\(b \neq 0\)</span>].</p>
<p>Per assegnare un‚Äôinterpretazione geometrica alle costanti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> si consideri la funzione</p>
<span class="math display">\[\begin{equation}
y = b x.
\end{equation}\]</span>
<p>Tale funzione rappresenta un caso particolare, ovvero quello della <em>proporzionalit√† diretta</em> tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Il caso generale della linearit√†</p>
<span class="math display">\[\begin{equation}
y = a + b x
\end{equation}\]</span>
<p>non fa altro che sommare una costante <span class="math inline">\(a\)</span> a ciascuno dei valori <span class="math inline">\(y = b x\)</span>. Nella funzione lineare <span class="math inline">\(y = a + b x\)</span>, se <span class="math inline">\(b\)</span> √® positivo allora <span class="math inline">\(y\)</span> aumenta al crescere di <span class="math inline">\(x\)</span>; se <span class="math inline">\(b\)</span> √® negativo allora <span class="math inline">\(y\)</span> diminuisce al crescere di <span class="math inline">\(x\)</span>; se <span class="math inline">\(b=0\)</span> la retta √® orizzontale, ovvero <span class="math inline">\(y\)</span> non muta al variare di <span class="math inline">\(x\)</span>.</p>
<p>Consideriamo ora il coefficiente <span class="math inline">\(b\)</span>. Si consideri un punto <span class="math inline">\(x_0\)</span> e un incremento arbitrario <span class="math inline">\(\varepsilon\)</span> come indicato nella figura @ref(fig:linearfunction). Le differenze <span class="math inline">\(\Delta x = (x_0 + \varepsilon) - x_0\)</span> e <span class="math inline">\(\Delta y = f(x_0 + \varepsilon) - f(x_0)\)</span> sono detti <em>incrementi</em> di <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Il coefficiente angolare <span class="math inline">\(b\)</span> √® uguale al rapporto</p>
<span class="math display">\[\begin{equation}
    b = \frac{\Delta y}{\Delta x} = \frac{f(x_0 + \varepsilon) - f(x_0)}{(x_0 + \varepsilon) - x_0},
\end{equation}\]</span>
<p>indipendentemente dalla grandezza degli incrementi <span class="math inline">\(\Delta x\)</span> e <span class="math inline">\(\Delta y\)</span>. Il modo pi√π semplice per assegnare un‚Äôinterpretazione geometrica al coefficiente angolare (o pendenza) della retta √® dunque quello di porre <span class="math inline">\(\Delta x = 1\)</span>. In tali circostanze infatti <span class="math inline">\(b = \Delta y\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="images/linear_function.png" class="img-fluid figure-img" style="width:75.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">La funzione lineare <span class="math inline">\(y = a + bx\)</span>.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<!-- ## L'errore di misurazione -->
<!-- Per descrivere l'associazione tra due variabili, tuttavia, la funzione lineare non √® sufficiente. Nel mondo empirico, infatti, la relazione tra variabili non √® mai perfettamente lineare. √à dunque necessario includere nel modello lineare anche una componente d'errore, ovvero una componente della $Y$ che non pu√≤ essere spiegata dal modello lineare. Nel caso di due sole variabili, questo ci conduce alla seguente formulazione del modello lineare: -->
<!-- \begin{equation} -->
<!-- y = \beta_0 + \beta_1 x + \varepsilon, -->
<!-- (\#eq:regbivpop) -->
<!-- \end{equation} -->
<!-- laddove i parametri $\beta_0$ e $\beta_1$ descrivono l'associazione tra le variabili casuali $Y$ e $X$, e il termine d'errore $\varepsilon$ specifica quant'√® grande la porzione della variabile $y$ che non pu√≤ essere predetta nei termini di una relazione lineare con la $X$. -->
<!-- Si noti che la @ref(eq:regbivpop) consente di formulare una predizione, nei termini di un modello lineare, del valore atteso della $Y$ conoscendo $X$, ovvero -->
<!-- \begin{equation} -->
<!-- \hat{Y} = \mathbb{E}(Y \mid X = x) = \beta_0 + \beta_1 x. -->
<!-- (\#eq:regbivpop2) -->
<!-- \end{equation} -->
<!-- In altri termini, se i parametri del modello ($\beta_0$ e $\beta_1$) sono noti, allora √® possibile predire la $Y$ sulla base della nostra conoscenza della $X$.  -->
<!-- Per esempio, se conosciamo la relazione lineare tra quoziente di intelligenza ed aspettativa di vita, allora possiamo prevedere quanto a lungo vivr√† una persona sulla base del suo QI. S√¨, c'√® una relazione lineare tra intelligenza e aspettativa di vita [@hambrick2015research]! Ma quando √® accurata la previsione? Ci√≤ dipende dal termine d'errore della @ref(eq:regbivpop). Il modello lineare fornisce un metodo per rispondere a domande di questo tipo^[Per una discussione sugli aspetti di base del modello lineare, si veda il [capitolo 7](https://openintro-ims.netlify.app/model-slr.html) di _Introduction to Modern Statistics_.]. -->
</section><section id="una-media-per-ciascuna-osservazione" class="level2" data-number="25.2"><h2 data-number="25.2" class="anchored" data-anchor-id="una-media-per-ciascuna-osservazione">
<span class="header-section-number">25.2</span> Una media per ciascuna osservazione</h2>
<p>In precedenza abbiamo visto come sia possibile stimare i parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densit√† gaussiana,</p>
<span class="math display">\[\begin{equation}
Y_i \stackrel{i.i.d.}{\sim} \mathcal{N}(\mu, \sigma), \quad i = 1, \dots, n.
(\#eq:normalsamplingmodel)
\end{equation}\]</span>
<p>Il modello @ref(eq:normalsamplingmodel) assume che ogni <span class="math inline">\(Y_i\)</span> sia la realizzazione di una v.c. descritta da una <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span>. Da un punto di vista bayesiano,questo modello pu√≤ essere implementato assegnando le distribuzioni a priori ai parametri <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span> e generando la verosimiglianza in base ai dati osservati. Con queste informazioni, possono poi essere definite le distribuzioni a posteriori dei parametri <span class="citation" data-cites="gelman2020regression">(<a href="999_refs.html#ref-gelman2020regression" role="doc-biblioref">Gelman et al., 2020</a>)</span>:</p>
<span class="math display">\[\begin{align}
Y_i \mid \mu, \sigma &amp; \stackrel{iid}{\sim} \mathcal{N}(\mu, \sigma^2)\notag\\
\mu       &amp; \sim \mathcal{N}(\mu_0, \tau^2) \notag\\
\sigma    &amp; \sim \mbox{Cauchy}(x_0, \gamma) \notag
\end{align}\]</span>
</section><section id="relazione-lineare-tra-la-media-y-mid-x-e-il-predittore" class="level2" data-number="25.3"><h2 data-number="25.3" class="anchored" data-anchor-id="relazione-lineare-tra-la-media-y-mid-x-e-il-predittore">
<span class="header-section-number">25.3</span> Relazione lineare tra la media <span class="math inline">\(y \mid x\)</span> e il predittore</h2>
<p>√à per√≤ comune che vengano registrate altre variabili che possono essere associate alla risposta di interesse <span class="math inline">\(y_i\)</span>. Chiamiamo <span class="math inline">\(x\)</span> una di tali variabili. La variabile <span class="math inline">\(x\)</span> viene chiamata <em>predittore</em> (o variabile indipendente) in quanto il ricercatore √® tipicamente interessato a predire <span class="math inline">\(y_i\)</span> a partire dal valore assunto da <span class="math inline">\(x_i\)</span>. Come si pu√≤ estende il modello @ref(eq:normalsamplingmodel) descritto in precedenza per lo studio della relazione tra <span class="math inline">\(y_i\)</span> e <span class="math inline">\(x_i\)</span>?</p>
<p>Il modello @ref(eq:normalsamplingmodel) assume una media <span class="math inline">\(\mu\)</span> comune per ciascuna osservazione <span class="math inline">\(Y_i\)</span>. Dal momento che desideriamo introdurre una nuova variabile <span class="math inline">\(x_i\)</span> che assume un diverso valore per ciascuna osservazione <span class="math inline">\(y_i\)</span>, il modello @ref(eq:normalsamplingmodel) pu√≤ essere modificato in modo che la media comune <span class="math inline">\(\mu\)</span> venga sostituita da una media <span class="math inline">\(\mu_i\)</span> specifica a ciascuna osservazione <span class="math inline">\(i\)</span>-esima:</p>
<span class="math display">\[\begin{equation}
Y_i \mid \mu_i, \sigma \stackrel{ind}{\sim} \mathcal{N}(\mu_i, \sigma), \quad i = 1, \dots, n.
(\#eq:normalsamplinglinearmodel)
\end{equation}\]</span>
<p>Si noti che le osservazioni <span class="math inline">\(Y_1, \dots, Y_n\)</span> non sono pi√π identicamente distribuite poich√© hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione <code>ind</code> posta sopra il simbolo <span class="math inline">\(\sim\)</span> nella @ref(eq:normalsamplinglinearmodel).</p>
<p>L‚Äôapproccio che consente di mettere in relazione un predittore <span class="math inline">\(x_i\)</span> con la risposta <span class="math inline">\(Y_i\)</span> √® quello di assumere che la media di ciascuna <span class="math inline">\(Y_i\)</span>, ovvero <span class="math inline">\(\mu_i\)</span>, sia una funzione lineare del predittore <span class="math inline">\(x_i\)</span>. Una tale relazione lineare √® scritta come</p>
<span class="math display">\[\begin{equation}
\mu_i = \beta_0 + \beta_ 1 x_i, \quad i = 1, \dots, n.
(\#eq:regmodel)
\end{equation}\]</span>
<p>Nella @ref(eq:regmodel), ciascuna <span class="math inline">\(x_i\)</span> √® una costante nota (ecco perch√© viene usata una lettera minuscola per la <span class="math inline">\(x\)</span>) e <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_ 1\)</span> sono parametri incogniti. Questi parametri rappresentano l‚Äôintercetta e la pendenza della retta di regressione e sono delle variabili casuali.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> L‚Äôinferenza bayesiana procede assegnando una distribuzione a priori a <span class="math inline">\(\beta_0\)</span> e a <span class="math inline">\(\beta_ 1\)</span> e si esegue l‚Äôinferenza riassumendo la distribuzione a posteriori di questi parametri.</p>
<p>Nel modello @ref(eq:regmodel), la funzione lineare <span class="math inline">\(\beta_0 + \beta_ 1 x_i\)</span> √® interpretata come il valore atteso della <span class="math inline">\(Y_i\)</span> per ciascun valore <span class="math inline">\(x_i\)</span>, mentre l‚Äôintercetta <span class="math inline">\(\beta_0\)</span> rappresenta il valore atteso della <span class="math inline">\(Y_i\)</span> quando <span class="math inline">\(x_i = 0\)</span>. Il parametro <span class="math inline">\(\beta_ 1\)</span> (pendenza) rappresenta invece l‚Äôaumento medio della <span class="math inline">\(Y_i\)</span> quando <span class="math inline">\(x_i\)</span> aumenta di un‚Äôunit√†. √à importante notare che la relazione lineare @ref(eq:normalsamplinglinearmodel) di parametri <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_ 1\)</span> descrive l‚Äôassociazione tra <em>la media</em> <span class="math inline">\(\mu_i\)</span> e il predittore <span class="math inline">\(x_i\)</span>. In altri termini, tale relazione lineare ci fornisce una predizione sul valore medio <span class="math inline">\(\mu_i\)</span>, non sul valore <em>effettivo</em> <span class="math inline">\(Y_i\)</span>.</p>
</section><section id="il-modello-lineare" class="level2" data-number="25.4"><h2 data-number="25.4" class="anchored" data-anchor-id="il-modello-lineare">
<span class="header-section-number">25.4</span> Il modello lineare</h2>
<p>Sostituendo la @ref(eq:regmodel) nella @ref(eq:normalsamplinglinearmodel) otteniamo il modello lineare:</p>
<span class="math display">\[\begin{equation}
Y_i \mid \beta_0, \beta_ 1, \sigma \stackrel{ind}{\sim} \mathcal{N}(\beta_0 + \beta_ 1 x_i, \sigma), \quad i = 1, \dots, n.
(\#eq:samplinglinearmodel)
\end{equation}\]</span>
<p>Questo √® dunque un caso speciale del modello di campionamento Normale, dove le <span class="math inline">\(Y_i\)</span> seguono indipendentemente una densit√† Normale con una media (<span class="math inline">\(\beta_0 + \beta_ 1 x_i\)</span>) specifica per ciascuna osservazione e con una deviazione standard (<span class="math inline">\(\sigma\)</span>) comune a tutte le osservazioni. Poich√© include un solo predittore (<span class="math inline">\(x\)</span>), questo modello √® chiamato <em>modello di regressione lineare bivariata</em>.</p>
<p>Il modello statistico di regressione lineare bivariata pu√≤ essere rappresentato in forma geometrica come indicato di seguito. La figura illustra che, in tale modello statistico, la variabile <span class="math inline">\(X\)</span> √® fissa per disegno ‚Äì in altre parole, i valori <span class="math inline">\(x\)</span> restano immutati tra campioni diversi. Potendo ipotizzare infiniti campioni tutti con gli stessi valori <span class="math inline">\(x\)</span>, in corrispondenza di ciascun valore <span class="math inline">\(x_i\)</span> vi sar√† una distribuzione di valori <span class="math inline">\(y\)</span>. La figura illustra il caso di tre valori <span class="math inline">\(x\)</span>. A ciascun valore <span class="math inline">\(x_i\)</span>, con <span class="math inline">\(i = 1, 2, 3\)</span> per l‚Äôesempio della figura, corrisponde una distribuzione di valori <span class="math inline">\(y\)</span> condizionati a <span class="math inline">\(x_i\)</span>, <span class="math inline">\(p(y \mid x_i)\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="051_reglin1_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="576"></p>
</figure>
</div>
</div>
</div>
<p>Il modello statistico di regressione lineare assume che le distribuzioni condizionate <span class="math inline">\(p(y \mid x_i)\)</span> siano</p>
<p><span class="math display">\[
y_i \sim \mathcal{N}(\mu_i, \sigma),
\]</span></p>
<p>(assunzione di <em>normalit√†</em>), laddove</p>
<p><span class="math display">\[
\mu_i = \mathbb{E}(y \mid x_i) = \alpha + \beta x_i.
\]</span></p>
<p>L‚Äôequazione precedente descrive l‚Äôassunzione di <em>linearit√†</em>.</p>
<p>Si noti che il parametro <span class="math inline">\(\sigma\)</span> non ha un pedice: questo significa che il modello ipotizza una dispersione costante delle distribuzioni <span class="math inline">\(p(y \mid x_i), \forall i\)</span>. Tale assunzione va sotto il nome di <em>omoschedasticit√†</em>.</p>
<p>Se questa √® la struttura della popolazione, possiamo pensare ad un campione casuale di ampiezza <span class="math inline">\(n\)</span> come ad una serie di coppie <span class="math inline">\(x_i, y_i\)</span>, con <span class="math inline">\(i = 1, \dots, n\)</span>, nelle quali i valori <span class="math inline">\(x\)</span> sono fissi per disegno e ciascun valore <span class="math inline">\(y_i\)</span> √® una realizzazione della variabile casuale <span class="math inline">\(Y = y_i \mid X = x_i\)</span>. Questa √® l‚Äôultima assunzione del modello statistico lineare: l‚Äô<em>indipendenza</em>. In maniera equivalente possiamo dire che gli <em>errori</em> <span class="math inline">\(\varepsilon_i = y_i - \hat{y}_i = y_i - (\beta_0 + \beta_1 x_i)\)</span> sono variabili casuali distribuite secondo la legge Normale di parametri <span class="math inline">\(\mathcal{N}(0, \sigma)\)</span>.</p>
<!-- Nel modello lineare, l'osservazione $Y_i$ √® una variabile casuale, il predittore $x_i$ √® una costante fissa, e $\beta_0$, $\beta_1$ e $\sigma$ sono parametri incogniti. Utilizzando il paradigma bayesiano, viene assegnata una distribuzione a priori congiunta a $(\beta_0, \beta_1, \sigma)$. Dopo avere osservato le risposte $Y_i, i = 1, \dots, n$, l'inferenza procede stimando la distribuzione a posteriori dei parametri.  -->
<!-- ::: {.remark} -->
<!-- Nella costruzione di un modello di regressione bayesiano, √® importante iniziare dalle basi e procedere un passo alla volta. Sia $Y$ una variabile di risposta e -->
<!-- sia $x$ un predittore o un insieme di predittori. √à possibile costruire un modello di regressione di $Y$ su $x$ applicando i seguenti principi generali: -->
<!-- - Stabilire se $Y$  √® discreto o continuo. Di conseguenza, identificare l'appropriata struttura dei dati (per esempio, Normale, di Poisson, o Binomiale). -->
<!-- - Esprimere la media di $Y$ come funzione dei predittori $x$ (per esempio, $\mu = \beta_0 + \beta_1 x$). -->
<!-- - Identificare tutti i parametri incogniti del modello (per esempio, $\mu, \beta_1, \beta_2$). -->
<!-- - Valutare quali valori che ciascuno di questi parametri potrebbe assumere. Di conseguenza, identificare le distribuzioni a priori appropriate per questi parametri. -->
<!-- :::  -->
<!-- Nel caso di una variabile $Y$ continua che segue la legge gaussiana e un solo predittore, ad esempio, il modello diventa: -->
<!-- \begin{align}  -->
<!-- Y_i \mid \beta_0, \beta_1, \sigma  &\stackrel{ind}{\sim} \mathcal{N}\left(\mu_i, \sigma^2\right) \;\; \text{ con } \;\; \mu_i = \beta_0 + \beta_1 x_i \notag\\ -->
<!-- \beta_0  &\sim \mathcal{N}\left(\mu_0, \sigma_0^2 \right)  \notag\\ -->
<!-- \beta_1  & \sim \mathcal{N}\left(\mu_1, \sigma_1^2 \right) \notag\\ -->
<!-- \sigma & \sim \text{Cauchy}(x_0, \gamma) \; .\notag -->
<!-- \end{align} -->
<!-- Un algoritmo MCMC viene usato per simulare i campioni dalle distribuzioni a posteriori e, mediante tali campioni, si fanno inferenze sulla risposta attesa $\beta_0 + \beta_1 x$ per ciascuno specifico valore del predittore $x$. Inoltre, √® possibile valutare le dimensioni degli errori di previsione mediante un indice sintetico della densit√† a posteriori della deviazione standard $\sigma$. -->
<!-- In maniera equivalente, il modello @ref(eq:samplinglinearmodel) pu√≤ essere formulato come -->
<!-- \begin{equation} -->
<!-- Y_i = \mu_i + \varepsilon_i, \quad i = 1, \dots, n, -->
<!-- (\#eq:samplinglinearmodel2) -->
<!-- \end{equation} -->
<!-- dove la risposta media √® $\mu_i = \beta_0 + \beta_ 1 x_i$ e i residui $\varepsilon_1, \dots, \varepsilon_n$ sono i.i.d. da una Normale con media 0 e deviazione standard $\sigma$.  -->
</section><section id="commenti-e-considerazioni-finali" class="level2 unnumbered"><h2 class="unnumbered anchored" data-anchor-id="commenti-e-considerazioni-finali">Commenti e considerazioni finali</h2>
<p>Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l‚Äôintensit√† di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente.</p>
<!-- Il modello lineare semplice √® in realt√† molto limitato, in quanto descrive soltanto la relazione tra la variabile dipendente $y$ e una sola variabile esplicativa $x$. Esso diventa molto pi√π utile quando incorpora pi√π variabili indipendenti. In questo secondo caso, per√≤, i calcoli per la stima dei coefficienti del modello diventano pi√π complicati. Abbiamo deciso di iniziare considerando il modello lineare semplice perch√©, in questo caso, sia la logica dell'inferenza sia le procedure di calcolo sono facilmente maneggiabili. Nel caso pi√π generale, quello del modello lineare multiplo (ovvero, con pi√π di un predittore), la logica dell'inferenza rimane identica a quella discussa qui, ma le procedure di calcolo richiedono l'uso dell'algebra matriciale. Il modello lineare multiplo pu√≤ includere sia regressori quantitativi, sia regressori qualitativi, utilizzando un opportuno schema di codifica. √à interessante notare come un modello lineare multiplo che include una sola variabile esplicativa qualitativa corrisponde all'analisi della varianza ad una via; un modello lineare multiplo che include pi√π di una variabile esplicativa qualitativa corrisponde all'analisi della varianza pi√π vie. Possiamo qui concludere dicendo che il modello lineare, nelle sue varie forme e varianti, costituisce la tecnica di analisi dei dati maggiormente usata in psicologia. -->


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="doc-bibliography" style="display: none">
<div id="ref-gelman2020regression" class="csl-entry" role="doc-biblioentry">
Gelman, A., Hill, J., &amp; Vehtari, A. (2020). <em>Regression and other stories</em>. Cambridge University Press.
</div>
</div>
</section><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Una notazione alternativa per tali parametri √® <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, anzich√© <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_ 1\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./regression.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Parte 5: Regressione lineare</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./052_reglin2.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Regressione lineare con un singolo predittore</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduzione {#sec-regr-intro}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_common.R"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"_stan_options.R"</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"magick"</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>Lo scopo della ricerca √® trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra i costrutti psicologici e le relazioni che intercorrono tra i fenomeni psicologici e quelli non psicologici (sociali, economici, storici, ...). Abbiamo gi√† visto come la correlazione di Pearson sia uno strumento adatto a questo scopo. Infatti, essa ci informa sulla direzione e sull'intensit√† della relazione lineare tra due variabili. Tuttavia, la correlazione non √® sufficiente, in quanto il ricercatore ha a disposizione solo i dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. A causa della variabilit√† campionaria, le propriet√† dei campioni sono necessariamente diverse da quelle della popolazione: ci√≤ che si pu√≤ osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. √à dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le propriet√† del campione e le propriet√† della popolazione da cui esso √® stato estratto. Il modello lineare utilizza la funzione matematica pi√π semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. In questo Capitolo vedremo come si possa fare inferenza sulla relazione tra due variabili mediante il modello lineare bayesiano. Inizieremo a descrivere le propriet√† geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire un modello statistico secondo un approccio bayesiano.</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## La funzione lineare</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>Iniziamo con un ripasso sulla funzione di lineare. Si chiama *funzione lineare* una funzione del tipo</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="in">f(x) = a + b x,</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>dove $a$ e $b$ sono delle costanti. Il grafico di tale funzione √® una retta di cui il parametro $b$ √® detto *coefficiente angolare* e il parametro $a$ √® detto *intercetta* con l'asse delle $y$ <span class="sc">\[</span>infatti, la retta interseca l'asse $y$ nel punto $(0,a)$, se $b \neq 0$<span class="sc">\]</span>.</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>Per assegnare un'interpretazione geometrica alle costanti $a$ e $b$ si consideri la funzione</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="in">y = b x.</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>Tale funzione rappresenta un caso particolare, ovvero quello della *proporzionalit√† diretta* tra $x$ e $y$. Il caso generale della linearit√†</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="in">y = a + b x</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>non fa altro che sommare una costante $a$ a ciascuno dei valori $y = b x$. Nella funzione lineare $y = a + b x$, se $b$ √® positivo allora $y$ aumenta al crescere di $x$; se $b$ √® negativo allora $y$ diminuisce al crescere di $x$; se $b=0$ la retta √® orizzontale, ovvero $y$ non muta al variare di $x$.</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>Consideriamo ora il coefficiente $b$. Si consideri un punto $x_0$ e un incremento arbitrario $\varepsilon$ come indicato nella figura \@ref(fig:linearfunction). Le differenze $\Delta x = (x_0 + \varepsilon) - x_0$ e $\Delta y = f(x_0 + \varepsilon) - f(x_0)$ sono detti *incrementi* di $x$ e $y$. Il coefficiente angolare $b$ √® uguale al rapporto</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="in">    b = \frac{\Delta y}{\Delta x} = \frac{f(x_0 + \varepsilon) - f(x_0)}{(x_0 + \varepsilon) - x_0},</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>indipendentemente dalla grandezza degli incrementi $\Delta x$ e $\Delta y$. Il modo pi√π semplice per assegnare un'interpretazione geometrica al coefficiente angolare (o pendenza) della retta √® dunque quello di porre $\Delta x = 1$. In tali circostanze infatti $b = \Delta y$.</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="in">```{r linearfunction, echo=FALSE, out.width="75%", fig.cap="La funzione lineare $y = a + bx$."}</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">"images/linear_function.png"</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ## L'errore di misurazione --&gt;</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Per descrivere l'associazione tra due variabili, tuttavia, la funzione lineare non √® sufficiente. Nel mondo empirico, infatti, la relazione tra variabili non √® mai perfettamente lineare. √à dunque necessario includere nel modello lineare anche una componente d'errore, ovvero una componente della $Y$ che non pu√≤ essere spiegata dal modello lineare. Nel caso di due sole variabili, questo ci conduce alla seguente formulazione del modello lineare: --&gt;</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{equation} --&gt;</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- y = \beta_0 + \beta_1 x + \varepsilon, --&gt;</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- (\#eq:regbivpop) --&gt;</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{equation} --&gt;</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- laddove i parametri $\beta_0$ e $\beta_1$ descrivono l'associazione tra le variabili casuali $Y$ e $X$, e il termine d'errore $\varepsilon$ specifica quant'√® grande la porzione della variabile $y$ che non pu√≤ essere predetta nei termini di una relazione lineare con la $X$. --&gt;</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Si noti che la @ref(eq:regbivpop) consente di formulare una predizione, nei termini di un modello lineare, del valore atteso della $Y$ conoscendo $X$, ovvero --&gt;</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{equation} --&gt;</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \hat{Y} = \mathbb{E}(Y \mid X = x) = \beta_0 + \beta_1 x. --&gt;</span></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- (\#eq:regbivpop2) --&gt;</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{equation} --&gt;</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- In altri termini, se i parametri del modello ($\beta_0$ e $\beta_1$) sono noti, allora √® possibile predire la $Y$ sulla base della nostra conoscenza della $X$.  --&gt;</span></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Per esempio, se conosciamo la relazione lineare tra quoziente di intelligenza ed aspettativa di vita, allora possiamo prevedere quanto a lungo vivr√† una persona sulla base del suo QI. S√¨, c'√® una relazione lineare tra intelligenza e aspettativa di vita [@hambrick2015research]! Ma quando √® accurata la previsione? Ci√≤ dipende dal termine d'errore della @ref(eq:regbivpop). Il modello lineare fornisce un metodo per rispondere a domande di questo tipo^[Per una discussione sugli aspetti di base del modello lineare, si veda il [capitolo 7](https://openintro-ims.netlify.app/model-slr.html) di _Introduction to Modern Statistics_.]. --&gt;</span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="fu">## Una media per ciascuna osservazione</span></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>In precedenza abbiamo visto come sia possibile stimare i parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densit√† gaussiana,</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a><span class="in">Y_i \stackrel{i.i.d.}{\sim} \mathcal{N}(\mu, \sigma), \quad i = 1, \dots, n.</span></span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a><span class="in">(\#eq:normalsamplingmodel)</span></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>Il modello \@ref(eq:normalsamplingmodel) assume che ogni $Y_i$ sia la realizzazione di una v.c. descritta da una $\mathcal{N}(\mu, \sigma^2)$. Da un punto di vista bayesiano,questo modello pu√≤ essere implementato assegnando le distribuzioni a priori ai parametri $\mu$ e $\sigma$ e generando la verosimiglianza in base ai dati osservati. Con queste informazioni, possono poi essere definite le distribuzioni a posteriori dei parametri <span class="co">[</span><span class="ot">@gelman2020regression</span><span class="co">]</span>:</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{align}</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a><span class="in">Y_i \mid \mu, \sigma &amp; \stackrel{iid}{\sim} \mathcal{N}(\mu, \sigma^2)\notag\\</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a><span class="in">\mu       &amp; \sim \mathcal{N}(\mu_0, \tau^2) \notag\\</span></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="in">\sigma    &amp; \sim \mbox{Cauchy}(x_0, \gamma) \notag</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a><span class="in">\end{align}</span></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a><span class="fu">## Relazione lineare tra la media $y \mid x$ e il predittore</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>√à per√≤ comune che vengano registrate altre variabili che possono essere associate alla risposta di interesse $y_i$. Chiamiamo $x$ una di tali variabili. La variabile $x$ viene chiamata *predittore* (o variabile indipendente) in quanto il ricercatore √® tipicamente interessato a predire $y_i$ a partire dal valore assunto da $x_i$. Come si pu√≤ estende il modello \@ref(eq:normalsamplingmodel) descritto in precedenza per lo studio della relazione tra $y_i$ e $x_i$?</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>Il modello \@ref(eq:normalsamplingmodel) assume una media $\mu$ comune per ciascuna osservazione $Y_i$. Dal momento che desideriamo introdurre una nuova variabile $x_i$ che assume un diverso valore per ciascuna osservazione $y_i$, il modello \@ref(eq:normalsamplingmodel) pu√≤ essere modificato in modo che la media comune $\mu$ venga sostituita da una media $\mu_i$ specifica a ciascuna osservazione $i$-esima:</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="in">Y_i \mid \mu_i, \sigma \stackrel{ind}{\sim} \mathcal{N}(\mu_i, \sigma), \quad i = 1, \dots, n.</span></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="in">(\#eq:normalsamplinglinearmodel)</span></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>Si noti che le osservazioni $Y_1, \dots, Y_n$ non sono pi√π identicamente distribuite poich√© hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione <span class="in">`ind`</span> posta sopra il simbolo $\sim$ nella \@ref(eq:normalsamplinglinearmodel).</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a>L'approccio che consente di mettere in relazione un predittore $x_i$ con la risposta $Y_i$ √® quello di assumere che la media di ciascuna $Y_i$, ovvero $\mu_i$, sia una funzione lineare del predittore $x_i$. Una tale relazione lineare √® scritta come</span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a><span class="in">\mu_i = \beta_0 + \beta_ 1 x_i, \quad i = 1, \dots, n.</span></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a><span class="in">(\#eq:regmodel)</span></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>Nella \@ref(eq:regmodel), ciascuna $x_i$ √® una costante nota (ecco perch√© viene usata una lettera minuscola per la $x$) e $\beta_0$ e $\beta_ 1$ sono parametri incogniti. Questi parametri rappresentano l'intercetta e la pendenza della retta di regressione e sono delle variabili casuali.<span class="ot">[^reglin1-1]</span> L'inferenza bayesiana procede assegnando una distribuzione a priori a $\beta_0$ e a $\beta_ 1$ e si esegue l'inferenza riassumendo la distribuzione a posteriori di questi parametri.</span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a><span class="ot">[^reglin1-1]: </span>Una notazione alternativa per tali parametri √® $\alpha$, $\beta$, anzich√© $\beta_0$, $\beta_ 1$.</span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>Nel modello \@ref(eq:regmodel), la funzione lineare $\beta_0 + \beta_ 1 x_i$ √® interpretata come il valore atteso della $Y_i$ per ciascun valore $x_i$, mentre l'intercetta $\beta_0$ rappresenta il valore atteso della $Y_i$ quando $x_i = 0$. Il parametro $\beta_ 1$ (pendenza) rappresenta invece l'aumento medio della $Y_i$ quando $x_i$ aumenta di un'unit√†. √à importante notare che la relazione lineare \@ref(eq:normalsamplinglinearmodel) di parametri $\beta_0$ e $\beta_ 1$ descrive l'associazione tra *la media* $\mu_i$ e il predittore $x_i$. In altri termini, tale relazione lineare ci fornisce una predizione sul valore medio $\mu_i$, non sul valore *effettivo* $Y_i$.</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a><span class="fu">## Il modello lineare</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>Sostituendo la \@ref(eq:regmodel) nella \@ref(eq:normalsamplinglinearmodel) otteniamo il modello lineare:</span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a><span class="in">```{=tex}</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{equation}</span></span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a><span class="in">Y_i \mid \beta_0, \beta_ 1, \sigma \stackrel{ind}{\sim} \mathcal{N}(\beta_0 + \beta_ 1 x_i, \sigma), \quad i = 1, \dots, n.</span></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a><span class="in">(\#eq:samplinglinearmodel)</span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a><span class="in">\end{equation}</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>Questo √® dunque un caso speciale del modello di campionamento Normale, dove le $Y_i$ seguono indipendentemente una densit√† Normale con una media ($\beta_0 + \beta_ 1 x_i$) specifica per ciascuna osservazione e con una deviazione standard ($\sigma$) comune a tutte le osservazioni. Poich√© include un solo predittore ($x$), questo modello √® chiamato *modello di regressione lineare bivariata*.</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>Il modello statistico di regressione lineare bivariata pu√≤ essere rappresentato in forma geometrica come indicato di seguito. La figura illustra che, in tale modello statistico, la variabile $X$ √® fissa per disegno -- in altre parole, i valori $x$ restano immutati tra campioni diversi. Potendo ipotizzare infiniti campioni tutti con gli stessi valori $x$, in corrispondenza di ciascun valore $x_i$ vi sar√† una distribuzione di valori $y$. La figura illustra il caso di tre valori $x$. A ciascun valore $x_i$, con $i = 1, 2, 3$ per l'esempio della figura, corrisponde una distribuzione di valori $y$ condizionati a $x_i$, $p(y \mid x_i)$.</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo = FALSE, message=FALSE, warning=FALSE}</span></span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">15</span>)</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">1000</span> <span class="sc">+</span> <span class="dv">200</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">300</span>)</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y)</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>lm_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> df)</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fl">2.5</span></span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sigma</span>(lm_fit)</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>ab <span class="ot">&lt;-</span> <span class="fu">coef</span>(lm_fit); a <span class="ot">&lt;-</span> ab[<span class="dv">1</span>]; b <span class="ot">&lt;-</span> ab[<span class="dv">2</span>]</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span>k<span class="sc">*</span>sigma, k<span class="sc">*</span>sigma, <span class="at">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="dv">0</span>, sigma)<span class="sc">/</span><span class="fu">dnorm</span>(<span class="dv">0</span>, <span class="dv">0</span>, sigma) <span class="sc">*</span> <span class="dv">3</span></span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> a<span class="sc">+</span>b<span class="sc">*</span>x0</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>path1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> y <span class="sc">+</span> x0, <span class="at">y =</span> x <span class="sc">+</span> y0)</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>segment1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x0, <span class="at">y =</span> y0 <span class="sc">-</span> k<span class="sc">*</span>sigma, <span class="at">xend =</span> x0, <span class="at">yend =</span> y0 <span class="sc">+</span> k<span class="sc">*</span>sigma)</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> a<span class="sc">+</span>b<span class="sc">*</span>x0</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>path2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> y <span class="sc">+</span> x0, <span class="at">y =</span> x <span class="sc">+</span> y0)</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>segment2 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x0, <span class="at">y =</span> y0 <span class="sc">-</span> k<span class="sc">*</span>sigma, <span class="at">xend =</span> x0, <span class="at">yend =</span> y0 <span class="sc">+</span> k<span class="sc">*</span>sigma)</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>x0 <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> a<span class="sc">+</span>b<span class="sc">*</span>x0</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>path3 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> y <span class="sc">+</span> x0, <span class="at">y =</span> x <span class="sc">+</span> y0)</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>segment3 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x0, <span class="at">y =</span> y0 <span class="sc">-</span> k<span class="sc">*</span>sigma, <span class="at">xend =</span> x0, <span class="at">yend =</span> y0 <span class="sc">+</span> k<span class="sc">*</span>sigma)</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y)) <span class="sc">+</span> </span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>  <span class="co"># geom_point(color="blue") + </span></span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">'lm'</span>, <span class="at">se=</span><span class="cn">FALSE</span>, <span class="at">color=</span><span class="st">"black"</span>) <span class="sc">+</span> </span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="fu">aes</span>(x,y), <span class="at">data =</span> path1, <span class="at">color =</span> <span class="st">"darkgray"</span>) <span class="sc">+</span> </span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y,<span class="at">xend=</span>xend,<span class="at">yend=</span>yend), <span class="at">data =</span> segment1) <span class="sc">+</span></span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="fu">aes</span>(x,y), <span class="at">data =</span> path2, <span class="at">color =</span> <span class="st">"darkgray"</span>) <span class="sc">+</span> </span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y,<span class="at">xend=</span>xend,<span class="at">yend=</span>yend), <span class="at">data =</span> segment2) <span class="sc">+</span></span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="fu">aes</span>(x,y), <span class="at">data =</span> path3, <span class="at">color =</span> <span class="st">"darkgray"</span>) <span class="sc">+</span> </span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y,<span class="at">xend=</span>xend,<span class="at">yend=</span>yend), <span class="at">data =</span> segment3) <span class="sc">+</span></span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks =</span> <span class="fu">element_blank</span>()</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a>Il modello statistico di regressione lineare assume che le distribuzioni condizionate $p(y \mid x_i)$ siano</span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>y_i \sim \mathcal{N}(\mu_i, \sigma),</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>(assunzione di *normalit√†*), laddove</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>\mu_i = \mathbb{E}(y \mid x_i) = \alpha + \beta x_i.</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>L'equazione precedente descrive l'assunzione di *linearit√†*.</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>Si noti che il parametro $\sigma$ non ha un pedice: questo significa che il modello ipotizza una dispersione costante delle distribuzioni $p(y \mid x_i), \forall i$. Tale assunzione va sotto il nome di *omoschedasticit√†*.</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>Se questa √® la struttura della popolazione, possiamo pensare ad un campione casuale di ampiezza $n$ come ad una serie di coppie $x_i, y_i$, con $i = 1, \dots, n$, nelle quali i valori $x$ sono fissi per disegno e ciascun valore $y_i$ √® una realizzazione della variabile casuale $Y = y_i \mid X = x_i$. Questa √® l'ultima assunzione del modello statistico lineare: l'*indipendenza*. In maniera equivalente possiamo dire che gli *errori* $\varepsilon_i = y_i - \hat{y}_i = y_i - (\beta_0 + \beta_1 x_i)$ sono variabili casuali distribuite secondo la legge Normale di parametri $\mathcal{N}(0, \sigma)$.</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Nel modello lineare, l'osservazione $Y_i$ √® una variabile casuale, il predittore $x_i$ √® una costante fissa, e $\beta_0$, $\beta_1$ e $\sigma$ sono parametri incogniti. Utilizzando il paradigma bayesiano, viene assegnata una distribuzione a priori congiunta a $(\beta_0, \beta_1, \sigma)$. Dopo avere osservato le risposte $Y_i, i = 1, \dots, n$, l'inferenza procede stimando la distribuzione a posteriori dei parametri.  --&gt;</span></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ::: {.remark} --&gt;</span></span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Nella costruzione di un modello di regressione bayesiano, √® importante iniziare dalle basi e procedere un passo alla volta. Sia $Y$ una variabile di risposta e --&gt;</span></span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- sia $x$ un predittore o un insieme di predittori. √à possibile costruire un modello di regressione di $Y$ su $x$ applicando i seguenti principi generali: --&gt;</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - Stabilire se $Y$  √® discreto o continuo. Di conseguenza, identificare l'appropriata struttura dei dati (per esempio, Normale, di Poisson, o Binomiale). --&gt;</span></span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - Esprimere la media di $Y$ come funzione dei predittori $x$ (per esempio, $\mu = \beta_0 + \beta_1 x$). --&gt;</span></span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - Identificare tutti i parametri incogniti del modello (per esempio, $\mu, \beta_1, \beta_2$). --&gt;</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- - Valutare quali valori che ciascuno di questi parametri potrebbe assumere. Di conseguenza, identificare le distribuzioni a priori appropriate per questi parametri. --&gt;</span></span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- :::  --&gt;</span></span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Nel caso di una variabile $Y$ continua che segue la legge gaussiana e un solo predittore, ad esempio, il modello diventa: --&gt;</span></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{align}  --&gt;</span></span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Y_i \mid \beta_0, \beta_1, \sigma  &amp;\stackrel{ind}{\sim} \mathcal{N}\left(\mu_i, \sigma^2\right) \;\; \text{ con } \;\; \mu_i = \beta_0 + \beta_1 x_i \notag\\ --&gt;</span></span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \beta_0  &amp;\sim \mathcal{N}\left(\mu_0, \sigma_0^2 \right)  \notag\\ --&gt;</span></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \beta_1  &amp; \sim \mathcal{N}\left(\mu_1, \sigma_1^2 \right) \notag\\ --&gt;</span></span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \sigma &amp; \sim \text{Cauchy}(x_0, \gamma) \; .\notag --&gt;</span></span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{align} --&gt;</span></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Un algoritmo MCMC viene usato per simulare i campioni dalle distribuzioni a posteriori e, mediante tali campioni, si fanno inferenze sulla risposta attesa $\beta_0 + \beta_1 x$ per ciascuno specifico valore del predittore $x$. Inoltre, √® possibile valutare le dimensioni degli errori di previsione mediante un indice sintetico della densit√† a posteriori della deviazione standard $\sigma$. --&gt;</span></span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- In maniera equivalente, il modello @ref(eq:samplinglinearmodel) pu√≤ essere formulato come --&gt;</span></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \begin{equation} --&gt;</span></span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Y_i = \mu_i + \varepsilon_i, \quad i = 1, \dots, n, --&gt;</span></span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- (\#eq:samplinglinearmodel2) --&gt;</span></span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- \end{equation} --&gt;</span></span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- dove la risposta media √® $\mu_i = \beta_0 + \beta_ 1 x_i$ e i residui $\varepsilon_1, \dots, \varepsilon_n$ sono i.i.d. da una Normale con media 0 e deviazione standard $\sigma$.  --&gt;</span></span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a><span class="fu">## Commenti e considerazioni finali {.unnumbered}</span></span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l'intensit√† di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base al valore assunto dalla variabile indipendente.</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Il modello lineare semplice √® in realt√† molto limitato, in quanto descrive soltanto la relazione tra la variabile dipendente $y$ e una sola variabile esplicativa $x$. Esso diventa molto pi√π utile quando incorpora pi√π variabili indipendenti. In questo secondo caso, per√≤, i calcoli per la stima dei coefficienti del modello diventano pi√π complicati. Abbiamo deciso di iniziare considerando il modello lineare semplice perch√©, in questo caso, sia la logica dell'inferenza sia le procedure di calcolo sono facilmente maneggiabili. Nel caso pi√π generale, quello del modello lineare multiplo (ovvero, con pi√π di un predittore), la logica dell'inferenza rimane identica a quella discussa qui, ma le procedure di calcolo richiedono l'uso dell'algebra matriciale. Il modello lineare multiplo pu√≤ includere sia regressori quantitativi, sia regressori qualitativi, utilizzando un opportuno schema di codifica. √à interessante notare come un modello lineare multiplo che include una sola variabile esplicativa qualitativa corrisponde all'analisi della varianza ad una via; un modello lineare multiplo che include pi√π di una variabile esplicativa qualitativa corrisponde all'analisi della varianza pi√π vie. Possiamo qui concludere dicendo che il modello lineare, nelle sue varie forme e varianti, costituisce la tecnica di analisi dei dati maggiormente usata in psicologia. --&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>